{"pages":[{"title":"","text":"cuzz’s blog由Hexo强力驱动，托管在github，采用next主题","link":"/README.html"},{"title":"404","text":"","link":"/404/index.html"},{"title":"关于","text":"自我介绍联系我： 微信：cuzz_2020 邮箱：cuzz5030@gmail.com","link":"/about/index.html"},{"title":"","text":"","link":"/categories/index.html"},{"title":"喜欢的文章","text":"计算机基础计算机系统计算机网络数据库MySQLRedisJava 相关Golang 相关架构设计相关DDD 领域驱动设计 阿里技术专家详解DDD系列 第一讲：Domain Primitive 第二讲：应用架构 第三讲 - Repository模式 第四讲 - 领域层设计规范 第五讲：聊聊如何避免写流水账代码","link":"/likes/index.html"},{"title":"","text":"","link":"/tags/index.html"},{"title":"喜欢的图片","text":"冬奥二十四节气图(小糖糖专属) 24 雨水 Rain Water 23 惊蛰 Awakening of Insects 22 春分 Spring Equinox 21 清明 Pure Brighthess 20 谷雨 Grain Rain 19 立夏 Beginning of Summer 18 小满 Grain Buds 17 芒种 Grain in Ear 16 夏至 Summer Solestice 15 小暑 Minor Heat 14 大暑 Major Heat 13 立秋 Beginning of Autumn 12 处暑 End of Heat 11 白露 White Dew 10 秋分 Autumn Equinox 09 寒露 Cold Dew 08 霜降 Frost’s Descent 07 立冬 Beginning of Winter 06 小雪 Minor Snow 05 大雪 Major Snow 04 冬至 Winter Solstice 03 Minor Cold 02 大寒 Major Cold 01 立春 Beginning of Spring 冬奥 图 1 图 2 图 3 图 4","link":"/images/index.html"}],"posts":[{"title":"Cache Lab","text":"介绍本实验有两个部分，Part A 要求我们模拟一个 cache 行为，正确地模拟每次操作（如 load、store、modify） cache 的响应（hit、miss、eviction）。Part B 要求我们用尽可能少的 cache 的 miss 实现矩阵的转置，充分利用 cache。 实验说明：地址 Part A在本实验中，需要完成 csim.c 文件，使之编译后实现类似功能： Usage: ./csim-ref [-hv] -s &lt;s&gt; -E &lt;E&gt; -b &lt;b&gt; -t &lt;tracefile&gt;• -h: Optional help flag that prints usage info• -v: Optional verbose flag that displays trace info• -s &lt;s&gt;: Number of set index bits (S = 2sis the number of sets)• -E &lt;E&gt;: Associativity (number of lines per set)• -b &lt;b&gt;: Number of block bits (B = 2bis the block size)• -t &lt;tracefile&gt;: Name of the valgrind trace to replay 要求我们的程序可以手动设置 cache 的 set 数、line 数、block 大小，读取指定的文件内容进行操作，指令类似如下： I 0400d7d4,8M 0421c7f0,4L 04f6b868,8S 7ff0005c8,8 每行代表一个操作，格式: [space]operation address,size I 代表 instruction load, L 代表 data load, S 代表 data store, M 代表 data modify (i.e., a data load followed by a data store) 回顾一下 cahce 具体结构： 具体如下： #include &quot;cachelab.h&quot;#include &lt;getopt.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;math.h&gt;typedef unsigned long int uint64_t;typedef struct { int valid; int lru; uint64_t tag;}cacheLine;typedef cacheLine* cacheSet;typedef cacheSet* Cache;const char* usage = &quot;Usage: %s [-hv] -s &lt;s&gt; -E &lt;E&gt; -b &lt;b&gt; -t &lt;tracefile&gt;\\n&quot;;int verbose = 0; //verbose flag int s; //number of set index bits int E; //number of lines per setint b; //number of block bitsFILE* fp = NULL;Cache cache;int hits = 0;int misses = 0;int evictions = 0;void parseArgument(int argc, char* argv[]);int visitCache(uint64_t address);int simulate();int main(int argc, char* argv[]){ parseArgument(argc, argv); simulate(); printSummary(hits, misses, evictions); return 0;}void parseArgument(int argc, char* argv[]){ int opt; while ((opt = getopt(argc, argv, &quot;hvs:E:b:t:&quot;)) != -1) { switch(opt) { case 'h': fprintf(stdout, usage, argv[0]); exit(1); case 'v': verbose = 1; break; case 's': s = atoi(optarg); break; case 'E': E = atoi(optarg); break; case 'b': b = atoi(optarg); break; case 't': fp = fopen(optarg, &quot;r&quot;); break; default: fprintf(stdout, usage, argv[0]); exit(1); } }}int simulate(){ int S = pow(2, s); cache = (Cache)malloc(sizeof(cacheSet) * S); if (cache == NULL) return -1; for (int i = 0; i &lt; S; i++) { cache[i] = (cacheSet)calloc(E, sizeof(cacheLine)); if (cache[i] == NULL) return -1; } char buf[20]; char operation; uint64_t address; int size; while (fgets(buf, sizeof(buf), fp) != NULL) { int ret; if (buf[0] == 'I') //ignore instruction cache accesses { continue; } else { sscanf(buf, &quot; %c %lx,%d&quot;, &amp;operation, &amp;address, &amp;size); switch (operation) { case 'S': ret = visitCache(address); break; case 'L': ret = visitCache(address); break; case 'M': ret = visitCache(address); hits++; break; } if (verbose) { switch(ret) { case 0: printf(&quot;%c %lx,%d hit\\n&quot;, operation, address, size); break; case 1: printf(&quot;%c %lx,%d miss\\n&quot;, operation, address, size); break; case 2: printf(&quot;%c %lx,%d miss eviction\\n&quot;, operation, address, size); break; } } } } for (int i = 0; i &lt; S; i++) free(cache[i]); free(cache); fclose(fp); return 0;}/*return value 0 cache hit 1 cache miss 2 cache miss, eviction*/int visitCache(uint64_t address){ uint64_t tag = address &gt;&gt; (s + b); unsigned int setIndex = address &gt;&gt; b &amp; ((1 &lt;&lt; s) - 1); int evict = 0; int empty = -1; cacheSet cacheset = cache[setIndex]; for (int i = 0; i &lt; E; i++) { if (cacheset[i].valid) { if (cacheset[i].tag == tag) { hits++; cacheset[i].lru = 1; return 0; } cacheset[i].lru++; if (cacheset[evict].lru &lt;= cacheset[i].lru) // =是必须的,why? { evict = i; } } else { empty = i; } } //cache miss misses++; if (empty != -1) { cacheset[empty].valid = 1; cacheset[empty].tag = tag; cacheset[empty].lru = 1; return 1; } else { cacheset[evict].tag = tag; cacheset[evict].lru = 1; evictions++; return 2; }} Part B参考总结","link":"/2000/12/13/CSAPP_Cache_Lab/"},{"title":"Data Lab","text":"前言CSAPP 这本书买了好几年，最近抽出一些时间开始重头读这本书，发现这些基础知识比较重要，边看书边跟着视频课程过了一遍，有些东西还是比较模糊。本文开始做 CSAPP Lab 实验，加强巩固书的内容。 说明这个实验主要考察整数和单精度浮点数的表示以及位运算，加强深对对计算机数据表示的理解。 任务指引还是比较清晰的，主要有以下一些说明： 整型的范围是 0 到 255(0xFF)，不允许用更大 只能包含参数和局部变量 一元操作符 ! ~ 二元操作符 &amp; | + &lt;&lt; &gt;&gt; 浮点数可以使用控制语句 题目bitXor/* * bitXor - x^y using only ~ and &amp; * Example: bitXor(4, 5) = 1 * Legal ops: ~ &amp; * Max ops: 14 * Rating: 1 */int bitXor(int x, int y) { return ~(~(~x &amp; y) &amp; ~(x &amp; ~y));} 异或就是二级制不相等才为1，同时为 0 或者同时为 1，结果为 0 ，比如： 十进制 二进制 4 100 5 101 001 // 异或结果 其中(~x &amp; y) 表示 x 中的 0 和 y 中的 1，(x &amp; ~y)表示 x 中的 1和 y 中的 0，然后通过德·摩根定律~(a &amp; b) = ~a | ~b。 x ^ y = (~x &amp; y) | (x &amp; ~y) = ~(~(~x &amp; y) &amp; ~(x &amp; ~y)) tmin/* * tmin - return minimum two's complement integer * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 4 * Rating: 1 */int tmin(void) { return 1 &lt;&lt; 31;} 这个题目比较简单，int 有符号采用的是补码表示如图，最小为10000000 00000000 00000000 00000000 我们只需要把 1 往左移动 31 位就行。 isTmax/* * isTmax - returns 1 if x is the maximum, two's complement number, * and 0 otherwise * Legal ops: ! ~ &amp; ^ | + * Max ops: 10 * Rating: 1 */int isTmax(int x) { return !(x + 1 + x + 1) &amp; !!(~x);} 我们发现最大值两倍加二为0，但是要排除 -1（补码全为1）后面!!(~x) 就是这个逻辑。 x 01111111 11111111 11111111 11111111x + 1 10000000 00000000 00000000 00000000x + 1 + x 11111111 11111111 11111111 11111111x + 1 + x + 1 00000000 00000000 00000000 00000000 allOddBits/* * allOddBits - return 1 if all odd-numbered bits in word set to 1 * where bits are numbered from 0 (least significant) to 31 (most significant) * Examples allOddBits(0xFFFFFFFD) = 0, allOddBits(0xAAAAAAAA) = 1 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 12 * Rating: 2 */int allOddBits(int x) { int e = 0xAA | (0xAA &lt;&lt; 8); e = e | (e &lt;&lt; 16); return !((e &amp; x) ^ e);} 先获取全为奇数位的数，这里的奇数指的是位的阶级是 2 的几次幂。然后取并如果偶数为有值，那么异或之后就不会为0。 // 10101010 10101010 10101010 10101010int a = 0xAA; // 00000000 00000000 00000000 10101010int b = 0xAA &lt;&lt; 8; // 00000000 00000000 10101010 00000000int c = a | b; // 00000000 00000000 10101010 10101010int d = c &lt;&lt; 16; // 10101010 10101010 00000000 00000000int e = c | d; // 10101010 10101010 10101010 10101010 negate/* * negate - return -x * Example: negate(1) = -1. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 5 * Rating: 2 */int negate(int x) { return ~x + 1;} 可以发现取反之后两个之和为 -1，x + ~x = -1，那么-x = ~x + 1然后只需要取反加 1就行， -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 71000 1001 1010 1011 1100 1101 1110 1111 0000 0001 0010 0011 0100 0101 0110 0111 0111 1001 0101 0100 0011 0010 0001 0000 1111 1110 1101 1100 1011 1010 1001 1000 7 6 5 4 3 2 1 0 -1 -2 -3 -4 -5 -6 -7 -8 isAsciiDigit/* * isAsciiDigit - return 1 if 0x30 &lt;= x &lt;= 0x39 (ASCII codes for characters '0' to '9') * Example: isAsciiDigit(0x35) = 1. * isAsciiDigit(0x3a) = 0. * isAsciiDigit(0x05) = 0. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 15 * Rating: 3 */int isAsciiDigit(int x) { int min = 0x1 &lt;&lt; 31; int max = ~min; int start = ~0x39; int end = max - 0x30 + 1; int c = (x + start) &gt;&gt; 31; int d = (x + end) &gt;&gt; 31; // printf(&quot;x=%d, c=%d, d=%d\\n&quot;,x, c, d); return !!(c &amp; d);} 比如保证 a + start &lt; 0 并且 b + start &lt; 0，然后 a + end &lt; 0 并且 b + end &lt; 0，这个时候是溢出小于零。根据如果 x 为负数x &gt;&gt; 31 = -1，否者 x &gt;&gt; 31 = 0，再通过两次去反获得。 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 71000 1001 1010 1011 1100 1101 1110 1111 0000 0001 0010 0011 0100 0101 0110 0111 a &lt;= x &lt;= b 1 &lt;= x &lt;= 3 2&lt;= x &lt;= 5 start end -4 7 -6 6 -y = ~y + 1start + b = -1 =&gt; start = -1 - b = ~ba + end = max + 1 =&gt; end = max + 1 - a = max - a + 1 conditional/* * conditional - same as x ? y : z * Example: conditional(2,4,5) = 4 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 16 * Rating: 3 */int conditional(int x, int y, int z) { int mask = ~!x + 1; return (y &amp; ~mask) | (z &amp; mask);} 这是一个if-else 语句，我们可以转化为 (y op expr) | (z op expr)，其中 op 为操作符，expr 为表达式。 (y op expr) | (z op expr)x == 0 mask = 0xFFFFFFFx != 0 mask = 0xOOOOOOO isLessOrEqual/* * isLessOrEqual - if x &lt;= y then return 1, else return 0 * Example: isLessOrEqual(4,5) = 1. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 24 * Rating: 3 */int isLessOrEqual(int x, int y) { int x_sign = (x &gt;&gt; 31) &amp; 0x01; // x 的符号 int y_sign = (y &gt;&gt; 31) &amp; 0x01; // y 的符号 int a = !(x ^ y); int b = (x_sign &amp; (!y_sign)); // 判断是否 x &lt; 0 y &gt; 0 int c = (!((x_sign ^ y_sign) &amp; 0x01)); // 判断符号是否相等 // x - y = x + ~y + 1 int res_sign = ((x + ~y + 1) &gt;&gt; 31) &amp; 0x01;// 判断x-y的符号 return a | b | (c &amp; res_sign);} 用 x - y 通过符号来判断，但是可能会溢出，所以当符号不相同就可以直接判断大小。 x y x - y x &gt; 0 y &gt; 0 正常 x &gt; 0 y &lt; 0 可能向上溢出 x &lt; 0 y &gt; 0 可能向下溢出 x &lt; 0 y &lt; 0 正常 主要分为3部， 看看是否两个数相等 !(x ^ y) 如果相等为1 判断符号是否相反，主要看 x &lt; 0，y &gt; 0 判断符号相等的时候，x - y &lt; 0 logicalNeg/* * logicalNeg - implement the ! operator, using all of * the legal operators except ! * Examples: logicalNeg(3) = 0, logicalNeg(0) = 1 * Legal ops: ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 12 * Rating: 4 */int logicalNeg(int x) { int neg_x = ~x + 1; return ((neg_x | x) &gt;&gt; 31) + 1;} 求 x | -x ，如果 x 不为 0 的化，那么符号位一定为 1，如果 x 为 0 那么符号为0。 howManyBits/* howManyBits - return the minimum number of bits required to represent x in * two's complement * Examples: howManyBits(12) = 5 // 0_1100 * howManyBits(298) = 10 // 0_100101010 * howManyBits(-5) = 4 // 1_101 * howManyBits(0) = 1 // 0 * howManyBits(-1) = 1 // 1 * howManyBits(1) = 2 // 0_1 * howManyBits(0x80000000) = 32 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 90 * Rating: 4 */int howManyBits(int x) { int b16, b8, b4, b2, b1, b0; int mask = x &gt;&gt; 31; // 如果x为正数，保持不变；如果为负数，按位取反 x = (mask &amp; ~x) | (~mask &amp; x); // 如果高16位有1，b16 = 16，否者为0 b16 = !!(x &gt;&gt; 16) &lt;&lt; 4; // 如果高16位有1，x右移16位，在新的16为重继续找 x = x &gt;&gt; b16; // 高8 b8 = !!(x &gt;&gt; 8) &lt;&lt; 3; x = x &gt;&gt; b8; // 高4位 b4 = !!(x &gt;&gt; 4) &lt;&lt; 2; x = x &gt;&gt; b4; // 高2位 b2 = !!(x &gt;&gt; 2) &lt;&lt; 1; x = x &gt;&gt; b2; // 高1位 b1 = !!(x &gt;&gt; 1); x = x &gt;&gt; b1; // 底1位 b0 = x; return b16 + b8 + b4 + b2 + b1 + b0 + 1;} 对于正数，找到最左边的 1，对于负数，按位取反处理。 0 1 1 1 0 0 0 1 b4 = 40 1 1 1 b2 = 20 1 b1 = 0 1 b0 = 1 floatScale2/* * floatScale2 - Return bit-level equivalent of expression 2*f for * floating point argument f. * Both the argument and result are passed as unsigned int's, but * they are to be interpreted as the bit-level representation of * single-precision floating point values. * When argument is NaN, return argument * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. also if, while * Max ops: 30 * Rating: 4 */unsigned floatScale2(unsigned uf) { // sign exp frac // 1 8 23 unsigned sign = (uf &gt;&gt; 31) &amp; 0x01; unsigned exp = (uf &gt;&gt; 23) &amp; 0xFF; unsigned frac = uf &amp; 0x7FFFFF; // 特殊 if (exp == 0xFF) { return uf; } // 非规格化 else if (exp == 0) { frac = frac &lt;&lt; 1; return (sign &lt;&lt; 31) | (exp &lt;&lt; 23) | frac; } // 规格化 else { exp ++; return (sign &lt;&lt; 31) | (exp &lt;&lt; 23) | frac; }} 先分别求出 sign ，exp 和 frac，如果是特殊值直接返回，在判断是否是规格化，分别处理。 floatFloat2Int/* * floatFloat2Int - Return bit-level equivalent of expression (int) f * for floating point argument f. * Argument is passed as unsigned int, but * it is to be interpreted as the bit-level representation of a * single-precision floating point value. * Anything out of range (including NaN and infinity) should return * 0x80000000u. * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. also if, while * Max ops: 30 * Rating: 4 */int floatFloat2Int(unsigned uf) { // sign exp frac // 1 8 23 unsigned sign = (uf &gt;&gt; 31) &amp; 0x01; unsigned exp = (uf &gt;&gt; 23) &amp; 0xFF; unsigned frac_v = uf &amp; 0x7FFFFF; // E = exp - Bias = exp - 127 int E = exp - 127; // 超过范围 if (E &gt;= 31) { return 0x80000000u; } // 小数 if (E &lt; 0) { return 0; } // M = frac + 1; unsigned unsigned_res = (frac_v &gt;&gt; (23 - E)) | (1 &lt;&lt; E); if (sign) { return -unsigned_res; } return unsigned_res;} 把浮点数转化为有符号整数，M = 1 + frac，frac 一共 23 位，左移 23 - E 就获得我们想要的书，但是要加上隐藏的 1，最后根据符号位取相反数就行。 floatPower2/* * floatPower2 - Return bit-level equivalent of the expression 2.0^x * (2.0 raised to the power x) for any 32-bit integer x. * * The unsigned value that is returned should have the identical bit * representation as the single-precision floating-point number 2.0^x. * If the result is too small to be represented as a denorm, return * 0. If too large, return +INF. * * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. Also if, while * Max ops: 30 * Rating: 4 */unsigned floatPower2(int x) { // 非规格化最小值 // 0 00000000 00000000000000000000001 // E = 1 - Bias = 1 - 127 = 126 // frac = 1 * 2^-22 // M = frac // V = 2^E * M = 2^-148 if (x &lt; -148) { return 0; } // 非规格化最大值 // 0 000000 111111111111111111111111 // E = 1 - Bias = 1 - 127 = -126 // frac = 1 (近似,小于) // M = frac // V = 2^E * M = 2^-126 (近似，小于) if (x &lt; -126) { return 1 &lt;&lt; (x + 148); } // 规格化最大值 // 0 11111110 11111111111111111111111 // E = exp - Bias = 254 - 127 = 127 // M = 1 + frac = 1.111111111111111111111111 // V = 2^E * M = 2^128 (近似,小于) if (x &gt;= 128) { return 0xFF &lt;&lt; 23; } // 规格化最小值 // 0 00000001 00000000000000000000000 // E = exp - Bias = 1 - 127 = -126 // M = 1 + frac = 1 // V = 2^E * M = 2^-126 if (x &gt;= -126) { int exp = x + 127; return exp &lt;&lt; 23; } return 0;} 求 2.0^x 的浮点数表示，只要抓住几个边界条件就行。 测试一下最后我们运行一下测试程序，发现都通过了，开心。 总结主要考察整数和单精度浮点数的表示以及位运算，加强深对对计算机数据表示的理解。 参考 CSAPP:Lab1-Data Lab 【读厚 CSAPP】I Data Lab","link":"/2020/10/11/CSAPP_Data_Lab/"},{"title":"DDD领域驱动设计|基础篇","text":"前言DDD 全称为 Domain-Driven Design，中文叫领域驱动设计，是一套应对复杂软件系统分析和设计的面向对象建模方法论。 基本概念DDD 的核心知识体系概念特别多，具体包括：领域、子域、核心域、通用域、支撑域、限界上下文、实体、值对象、聚合和聚合根等概念。 软件架构模式的演进","link":"/2020/08/26/DDD%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"},{"title":"Go项目笔记","text":"前言最近在公司有开始接触 Go 的项目，想系统的学习一下。相对来说 Go 的语法还是比较简单，很容易上手。快速看完两本入门书，想找一些偏项目的书来看，发现目前国内还是比较少。然后翻了一下培训机构的教程，感觉也不是很好，偶然在油管上看到这个教程 Backend master class，感觉讲的不错，就把这个教程整理出来。 介绍这是一个从设计、开发到部署的完整的 Go 项目，使用 PostgreSQL、Golang 和 Docker，这个项目主要来构建一个简单的银行系统，主要提供一下功能： 创建和管理帐户：所有者、余额、货币 记录所有余额变化：为每次更改创建一个帐户条目 转账交易：在一笔交易中，在两个账户之间进行一致的转账 数据库设计设计数据库架构使用 dbdiagram.io 设计表结构，采用的 DSL 语言来定义： Table accounts as A { id bigint [pk, increment, note: '主键'] owner varchar [not null, note: '账户所有者'] balance bigint [not null, note: '账户余额'] currency varchar [not null, note: '货币类型，比如：人民币'] created_at timestamptz [not null, default:`now()`, note: '创建时间'] Indexes { owner } note: '账户'}Table entries { id bigint [pk, increment, note: '主键'] account_id bigint [not null, ref: &gt; A.id, note:'账户id，关联account的id'] amount bigint [not null, note:'变化金额，可正可负'] created_at timestamptz [not null, default:`now()`, note: '创建时间'] Indexes { account_id } note: '记录所有余额变化'}Table transfers { id bigint [pk, increment, note: '主键'] from_account_id bigint [not null, ref: &gt; A.id, note: '转账id'] to_account_id bigint [not null, ref: &gt; A.id, note: '被转账id'] amount bigint [not null, note: '必须为正'] created_at timestamptz [not null, default:`now()`, note: '创建时间'] Indexes { from_account_id to_account_id (from_account_id, to_account_id) } note: '转账交易记录'} 可以生成响应的关系图： 可以导出 PostgreSQL，MySQL等等 还可以创建分享链接，这个表的链接为： https://dbdiagram.io/d/5fcc5ee49a6c525a03b9f27d 使用 Docker 安装 Postgers先安装 docker，可参考网上 先登入 docker 官方，查找可用的镜像，找到一个为 12-alpine，使用 docker pull &lt;image&gt;:&lt;tag&gt; 方式拉去这个镜像 docker pull postgres:12-alpine 输入 docker images 就可看到我们拉去的镜像了 ~ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEpostgres 12-alpine b5a8143fc58d 3 weeks ago 158MB 通过以下格式来运行，我们知道一个镜像（image）可用运行多个容器（container） docker run --name&lt;container_name&gt; // 容器名称 -e &lt;environment_variable&gt; // 环境变量 -p &lt;host_port:containter_ports&gt; // 端口映射 -d &lt;image&gt;:&lt;tag&gt; // 后台运行 运行镜像： docker run --name postgres12 \\ -e POSTGRES_USER=root -e POSTGRES_PASSWORD=12356 \\ -p 5432:5432 \\ -d postgres:12-alpine \\ 使用 docker ps 查看运行的镜像 ~ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES5c337d6516a6 postgres:12-alpine &quot;docker-entrypoint.s…&quot; About a minute ago Up About a minute 0.0.0.0:5432-&gt;5432/tcp postgres12 在运行的容器中执行命令： docker exec -it &lt;container_name_or_id&gt; &lt;commend&gt; [args] 进入 postgres 命令终端 docker exec -it postgres12 psql -U rootpsql (12.5)Type &quot;help&quot; for help.root=# 使用 DataGrip 连接数据库，并且把生成的 SQL 导入 DataGrip 中，生成相应的表。 SQL/GORM/SQLX/SQLC生成CRUD的比较SQL 快、直接 手动映射 容易写错 GORM CRUD 已经实现了 需要学习一些 gorm 语法 比较慢 SQLX 快，容易使用 通过查询语句和结构体tag映射 SQLC 快，容易使用 自动代码生成 最终我们选择 SQLC，https://github.com/kyleconroy/sqlc 在 mac 上安装 brew install kyleconroy/sqlc/sqlc","link":"/2020/05/06/Go%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/"},{"title":"Java中是如何实现线程通信","text":"正常情况下，每个子线程完成各自的任务就可以结束了。不过有的时候，我们希望多个线程协同工作来完成某个任务，这时就涉及到了线程间通信了。 本文涉及到的知识点：thread.join(), object.wait(), object.notify(), CountdownLatch, CyclicBarrier, FutureTask, Callable 等。 下面我从几个例子作为切入点来讲解下 Java 里有哪些方法来实现线程间通信。 如何让两个线程依次执行？ 那如何让两个线程按照指定方式有序交叉运行呢？ 四个线程 A B C D，其中 D 要等到 A B C 全执行完毕后才执行，而且 A B C 是同步运行的 三个运动员各自准备，等到三个人都准备好后，再一起跑 子线程完成某件任务后，把得到的结果回传给主线程 如何让两个线程依次执行？假设有两个线程，一个是线程 A，另一个是线程 B，两个线程分别依次打印 1-3 三个数字即可。我们来看下代码： private static void demo1() { Thread A = new Thread(new Runnable() { @Override public void run() { printNumber(&quot;A&quot;); } }); Thread B = new Thread(new Runnable() { @Override public void run() { printNumber(&quot;B&quot;); } }); A.start(); B.start();} 其中的 printNumber(String) 实现如下，用来依次打印 1, 2, 3 三个数字： private static void printNumber(String threadName) { int i=0; while (i++ &lt; 3) { try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(threadName + &quot; print: &quot; + i); }} 这时我们得到的结果是： B print: 1A print: 1B print: 2A print: 2B print: 3A print: 3 可以看到 A 和 B 是同时打印的。 那么，如果我们希望 B 在 A 全部打印 完后再开始打印呢？我们可以利用 thread.join() 方法，代码如下: private static void demo2() { Thread A = new Thread(new Runnable() { @Override public void run() { printNumber(&quot;A&quot;); } }); Thread B = new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;B 开始等待 A&quot;); try { A.join(); } catch (InterruptedException e) { e.printStackTrace(); } printNumber(&quot;B&quot;); } }); B.start(); A.start();} 得到的结果如下： B 开始等待 AA print: 1A print: 2A print: 3 B print: 1B print: 2B print: 3 A.join 把指定的线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行的线程。比如在线程B中调用了线程A的 join() 方法，直到线程A执行完毕后，才会继续执行线程B。 t.join(); 调用 join 方法，等待线程 t 执行完毕 t.join(1000); 等待 t 线程，等待时间是1000毫秒。 所以我们能看到 A.join() 方法会让 B 一直等待直到 A 运行完毕。 那如何让两个线程按照指定方式有序交叉运行呢？还是上面那个例子，我现在希望 A 在打印完 1 后，再让 B 打印 1, 2, 3，最后再回到 A 继续打印 2, 3。这种需求下，显然 Thread.join() 已经不能满足了。我们需要更细粒度的锁来控制执行顺序。 这里，我们可以利用 object.wait() 和 object.notify() 两个方法来实现。代码如下： /** * A 1, B 1, B 2, B 3, A 2, A 3 */private static void demo3() { Object lock = new Object(); Thread A = new Thread(new Runnable() { @Override public void run() { synchronized (lock) { System.out.println(&quot;A 1&quot;); try { lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;A 2&quot;); System.out.println(&quot;A 3&quot;); } } }); Thread B = new Thread(new Runnable() { @Override public void run() { synchronized (lock) { System.out.println(&quot;B 1&quot;); System.out.println(&quot;B 2&quot;); System.out.println(&quot;B 3&quot;); lock.notify(); } } }); A.start(); B.start();} 打印结果如下： A 1A waiting… B 1B 2B 3A 2A 3 正是我们要的结果。 那么，这个过程发生了什么呢？ 首先创建一个 A 和 B 共享的对象锁 lock = new Object(); 当 A 得到锁后，先打印 1，然后调用 lock.wait() 方法，交出锁的控制权，进入 wait 状态； 对 B 而言，由于 A 最开始得到了锁，导致 B 无法执行；直到 A 调用 lock.wait() 释放控制权后， B 才得到了锁； B 在得到锁后打印 1， 2， 3；然后调用 lock.notify() 方法，唤醒正在 wait 的 A; A 被唤醒后，继续打印剩下的 2，3。 为了更好理解，我在上面的代码里加上 log 方便读者查看。 private static void demo3() { Object lock = new Object(); Thread A = new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;INFO: A 等待锁 &quot;); synchronized (lock) { System.out.println(&quot;INFO: A 得到了锁 lock&quot;); System.out.println(&quot;A 1&quot;); try { System.out.println(&quot;INFO: A 准备进入等待状态，放弃锁 lock 的控制权 &quot;); lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;INFO: 有人唤醒了 A, A 重新获得锁 lock&quot;); System.out.println(&quot;A 2&quot;); System.out.println(&quot;A 3&quot;); } } }); Thread B = new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;INFO: B 等待锁 &quot;); synchronized (lock) { System.out.println(&quot;INFO: B 得到了锁 lock&quot;); System.out.println(&quot;B 1&quot;); System.out.println(&quot;B 2&quot;); System.out.println(&quot;B 3&quot;); System.out.println(&quot;INFO: B 打印完毕，调用 notify 方法 &quot;); lock.notify(); } } }); A.start(); B.start();} 打印结果如下: INFO: A 等待锁INFO: A 得到了锁 lockA 1INFO: A 准备进入等待状态，调用 lock.wait() 放弃锁 lock 的控制权INFO: B 等待锁INFO: B 得到了锁 lockB 1B 2B 3INFO: B 打印完毕，调用 lock.notify() 方法INFO: 有人唤醒了 A, A 重新获得锁 lockA 2A 3 四个线程 A B C D，其中 D 要等到 A B C 全执行完毕后才执行，而且 A B C 是同步运行的最开始我们介绍了 thread.join()，可以让一个线程等另一个线程运行完毕后再继续执行，那我们可以在 D 线程里依次 join A B C，不过这也就使得 A B C 必须依次执行，而我们要的是这三者能同步运行。 或者说，我们希望达到的目的是：A B C 三个线程同时运行，各自独立运行完后通知 D；对 D 而言，只要 A B C 都运行完了，D 再开始运行。针对这种情况，我们可以利用 CountdownLatch 来实现这类通信方式。它的基本用法是： 创建一个计数器，设置初始值，CountdownLatch countDownLatch = new CountDownLatch(2); 在 等待线程 里调用 countDownLatch.await() 方法，进入等待状态，直到计数值变成 0； 在 其他线程 里，调用 countDownLatch.countDown() 方法，该方法会将计数值减小 1； 当 其他线程 的 countDown() 方法把计数值变成 0 时，等待线程 里的 countDownLatch.await() 立即退出，继续执行下面的代码。 实现代码如下： private static void runDAfterABC() { int worker = 3; CountDownLatch countDownLatch = new CountDownLatch(worker); new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;D is waiting for other three threads&quot;); try { countDownLatch.await(); System.out.println(&quot;All done, D starts working&quot;); } catch (InterruptedException e) { e.printStackTrace(); } } }).start(); for (char threadName='A'; threadName &lt;= 'C'; threadName++) { final String tN = String.valueOf(threadName); new Thread(new Runnable() { @Override public void run() { System.out.println(tN + &quot; is working&quot;); try { Thread.sleep(100); } catch (Exception e) { e.printStackTrace(); } System.out.println(tN + &quot; finished&quot;); countDownLatch.countDown(); } }).start(); }} 下面是运行结果： D is waiting for other three threadsA is workingB is workingC is working A finishedC finishedB finishedAll done, D starts working 其实简单点来说，CountDownLatch 就是一个倒计数器，我们把初始计数值设置为3，当 D 运行时，先调用 countDownLatch.await() 检查计数器值是否为 0，若不为 0 则保持等待状态；当A B C 各自运行完后都会利用countDownLatch.countDown()，将倒计数器减 1，当三个都运行完后，计数器被减至 0；此时立即触发 D的 await() 运行结束，继续向下执行。 因此，CountDownLatch 适用于一个线程去等待多个线程的情况。 三个运动员各自准备，等到三个人都准备好后，再一起跑上面是一个形象的比喻，针对 线程 A B C 各自开始准备，直到三者都准备完毕，然后再同时运行 。也就是要实现一种线程之间互相等待的效果，那应该怎么来实现呢？ 上面的 CountDownLatch 可以用来倒计数，但当计数完毕，只有一个线程的 await() 会得到响应，无法让多个线程同时触发。 为了实现线程间互相等待这种需求，我们可以利用 CyclicBarrier 数据结构，它的基本用法是： 先创建一个公共 CyclicBarrier 对象，设置 同时等待 的线程数，CyclicBarrier cyclicBarrier = new CyclicBarrier(3); 这些线程同时开始自己做准备，自身准备完毕后，需要等待别人准备完毕，这时调用 cyclicBarrier.await(); 即可开始等待别人； 当指定的 同时等待 的线程数都调用了 cyclicBarrier.await();时，意味着这些线程都准备完毕好，然后这些线程才 同时继续执行。 实现代码如下，设想有三个跑步运动员，各自准备好后等待其他人，全部准备好后才开始跑： private static void runABCWhenAllReady() { int runner = 3; CyclicBarrier cyclicBarrier = new CyclicBarrier(runner); final Random random = new Random(); for (char runnerName='A'; runnerName &lt;= 'C'; runnerName++) { final String rN = String.valueOf(runnerName); new Thread(new Runnable() { @Override public void run() { long prepareTime = random.nextInt(10000) + 100; System.out.println(rN + &quot; is preparing for time: &quot; + prepareTime); try { Thread.sleep(prepareTime); } catch (Exception e) { e.printStackTrace(); } try { System.out.println(rN + &quot; is prepared, waiting for others&quot;); cyclicBarrier.await(); // 当前运动员准备完毕，等待别人准备好 } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } System.out.println(rN + &quot; starts running&quot;); // 所有运动员都准备好了，一起开始跑 } }).start(); }} 打印的结果如下： A is preparing for time: 4131B is preparing for time: 6349C is preparing for time: 8206 A is prepared, waiting for others B is prepared, waiting for others C is prepared, waiting for others C starts runningA starts runningB starts running 子线程完成某件任务后，把得到的结果回传给主线程实际的开发中，我们经常要创建子线程来做一些耗时任务，然后把任务执行结果回传给主线程使用，这种情况在 Java 里要如何实现呢？ 回顾线程的创建，我们一般会把 Runnable 对象传给 Thread 去执行。Runnable定义如下： public interface Runnable { public abstract void run();} 可以看到 run() 在执行完后不会返回任何结果。那如果希望返回结果呢？这里可以利用另一个类似的接口类 Callable： @FunctionalInterfacepublic interface Callable&lt;V&gt; { /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;} 可以看出 Callable 最大区别就是返回范型 V 结果。 那么下一个问题就是，如何把子线程的结果回传回来呢？在 Java 里，有一个类是配合 Callable 使用的：FutureTask，不过注意，它获取结果的 get 方法会阻塞主线程。 举例，我们想让子线程去计算从 1 加到 100，并把算出的结果返回到主线程。 private static void doTaskWithResultInWorker() { Callable&lt;Integer&gt; callable = new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { System.out.println(&quot;Task starts&quot;); Thread.sleep(1000); int result = 0; for (int i=0; i&lt;=100; i++) { result += i; } System.out.println(&quot;Task finished and return result&quot;); return result; } }; FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(callable); new Thread(futureTask).start(); try { System.out.println(&quot;Before futureTask.get()&quot;); System.out.println(&quot;Result: &quot; + futureTask.get()); System.out.println(&quot;After futureTask.get()&quot;); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); }} 打印结果如下： Before futureTask.get() Task startsTask finished and return result Result: 5050After futureTask.get() 可以看到，主线程调用 futureTask.get() 方法时阻塞主线程；然后 Callable 内部开始执行，并返回运算结果；此时 futureTask.get() 得到结果，主线程恢复运行。 这里我们可以学到，通过 FutureTask 和 Callable 可以直接在主线程获得子线程的运算结果，只不过需要阻塞主线程。当然，如果不希望阻塞主线程，可以考虑利用 ExecutorService，把 FutureTask 放到线程池去管理执行。 小结多线程是现代语言的共同特性，而线程间通信、线程同步、线程安全是很重要的话题。本文针对 Java 的线程间通信进行了大致的讲解，后续还会对线程同步、线程安全进行讲解。 参考 Java 中是如何实现线程通信","link":"/2019/02/14/Java%E4%B8%AD%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%BA%BF%E7%A8%8B%E9%80%9A%E4%BF%A1/"},{"title":"Java 反射","text":"java 反射 Reflection is a feature in the Java programming language. It allows an executing Java program to examine or “introspect” upon itself, and manipulate internal properties of the program. For example, it’s possible for a Java class to obtain the names of all its members and display them. The ability to examine and manipulate a Java class from within itself may not sound like very much, but in other programming languages this feature simply doesn’t exist. For example, there is no way in a Pascal, C, or C++ program to obtain information about the functions defined within that program. One tangible use of reflection is in JavaBeans, where software components can be manipulated visually via a builder tool. The tool uses reflection to obtain the properties of Java components (classes) as they are dynamically loaded. 类加载器当程序有使用某个类时，如果该类还没有被加载到内存中，则系统会通过加载，连接，初始化三步来实现对这个类进行初始化 加载 就是指将class文件读入内存，并为之创建一个Class对象，任何类被使用时系统都会建立一个Class对象 连接 验证：是否有正确的内部结构，并和其他类协调一致 准备：负责为类的静态成员分配内存，并设置默认初始化值 解析：将类的二进制数据中的符号引用替换为直接引用 初始化 对类的静态变量，静态代码块执行初始化操作 类初始化时机 创建类的实例 类的静态变量，或者为静态变量赋值 类的静态方法 使用反射方式来强制创建某个类或接口对应的java.lang.Class对象 初始化某个类的子类 直接使用java.exe命令来运行某个主类 类加载器作用 负责将.class文件加载到内在中，并为之生成对应的Class对象 虽然我们不需要关心类加载机制，但是了解这个机制我们就能更好的理解程序的运行 类加载器的组成 Bootstrap ClassLoader 根类加载器也被称为引导类加载器，负责Java核心类的加载比如System，String等。在 JDK 中 JRE 的 lib 目录下 rt.jar 文件中 Extension ClassLoader 扩展类加载器负责 JRE 的扩展目录中 jar 包的加载。在 JDK 中 JRE 的 lib 目录下 ext 目录 System ClassLoader 系统类加载器负责在JVM启动时加载来自java命令的class文件，以及classpath环境变量所指定的jar包和类路径 通过这些描述就可以知道我们常用的类，都是由谁来加载完成的。 到目前为止我们已经知道把class文件加载到内存了，那么，如果我们仅仅站在这些class文件的角度，我们如何来使用这些class文件中的内容呢? 这就是我们反射要研究的内容 反射JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。 要想解剖一个类,必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法.所以先要获取到每一个字节码文件对应的Class类型的对象。 Class类阅读API的Class类得知，Class 没有公共构造方法。Class 对象是在加载类时由 Java 虚拟机以及通过调用类加载器中的 defineClass 方法自动构造的。 获取Class对象的三种方式方式一: 通过Object类中的getObject()方法 Person p = new Person();Class c = p.getClass(); 方式二: 通过 类名.class 获取到字节码文件对象（任意数据类型都具备一个class静态属性,看上去要比第一种方式简单） Class c2 = Person.class; 方式三: 通过Class类中的方法（将类名作为字符串传递给Class类中的静态方法forName即可） Class c3 = Class.forName(&quot;cn.cuzz.Person&quot;); 注意：第三种和前两种的区别 前两种你必须明确Person类型。 后面是指定这种类型的字符串就行(要包含包名)，这种扩展更强，我不需要知道你的类，我只提供字符串，按照配置文件加载就可以了。 Person类public class Person { // 成员变量 public String name; public int age; private String address; // 构造方法 public Person() { System.out.println(&quot;空参数构造方法&quot;); } public Person(String name) { this.name = name; System.out.println(&quot;带有String的构造方法&quot;); } // 私有的构造方法 private Person(String name, int age){ this.name = name; this.age = age; System.out.println(&quot;带有String，int的构造方法&quot;); } public Person(String name, int age, String address){ this.name = name; this.age = age; this.address = address; System.out.println(&quot;带有String, int, String的构造方法&quot;); } // 成员方法 // 没有返回值没有参数的方法 public void method1(){ System.out.println(&quot;没有返回值没有参数的方法&quot;); } // 没有返回值，有参数的方法 public void method2(String name){ System.out.println(&quot;没有返回值，有参数的方法 name= &quot;+ name); } // 有返回值，没有参数 public int method3(){ System.out.println(&quot;有返回值，没有参数的方法&quot;); return 123; } // 有返回值，有参数的方法 public String method4(String name){ System.out.println(&quot;有返回值，有参数的方法&quot;); return &quot;哈哈&quot; + name; } // 私有方法 private void method5(){ System.out.println(&quot;私有方法&quot;); } @Override public String toString() { return &quot;Person [name=&quot; + name + &quot;, age=&quot; + age + &quot;, address=&quot; + address+ &quot;]&quot;; }} 通过反射获取构造方法并使用在反射机制中，把类中的成员（构造方法、成员方法、成员变量）都封装成了对应的类进行表示。其中，构造方法使用类Constructor表示。可通过Class类中提供的方法获取构造方法： 返回一个构造方法 public Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 获取public修饰, 指定参数类型所对应的构造方法 public Constructor&lt;T&gt; getDeclaredConstructor(Class&lt;?&gt;... parameterTypes) 获取指定参数类型所对应的构造方法(包含私有的) 返回多个构造方法 public Constructor&lt;?&gt;[] getConstructors() 获取所有的public 修饰的构造方法 public Constructor&lt;?&gt;[] getDeclaredConstructors() 获取所有的构造方法(包含私有的) package cn.cuzz;import java.lang.reflect.Constructor;public class Test { public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException, SecurityException { // 获取Class对象 包名.类 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取所有构造方法 // 只包括public Constructor[] cons = c.getConstructors(); // 即包括public也包括private Constructor[] conss = c.getDeclaredConstructors(); // 获取一个构造方法 // public Person() Constructor con1 = c.getConstructor(null); System.out.println(con1); // public Person(String name) Constructor con2 = c.getConstructor(String.class); System.out.println(con2); // private Person(String name, int age) Constructor con3 = c.getDeclaredConstructor(String.class, int.class); System.out.println(con3); // public Person(String name, int age, String address) Constructor con4 = c.getDeclaredConstructor(String.class, int.class, String.class); System.out.println(con4); }} 通过反射方式，获取构造方法，创建对象获取构造方法，步骤如下： 获取到Class对象 获取指定的构造方法 通过构造方法类Constructor中的方法，创建对象public T newInstance(Object... initargs) package cn.cuzz;import java.lang.reflect.Constructor;public class Test2 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取指定构造器 Constructor con = c.getConstructor(String.class, int.class, String.class); // 通过构造方法中的Constructor的方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;, 18, &quot;武汉&quot;); System.out.println(obj); // Person [name=cuzz, age=18, address=武汉] }} 通过反射获取成员变量并使用在反射机制中，把类中的成员变量使用类Field表示。可通过Class类中提供的方法获取成员变量： 返回一个成员变量 public Field getField(String name) 获取指定的public修饰的变量 public Field getDeclaredField(String name) 获取指定的任意变量 返回多个成员变量 public Field[] getFields() 获取所有public 修饰的变量 public Field[] getDeclaredFields() 获取所有的 变量 (包含私有) package cn.cuzz;import java.lang.reflect.Field;public class Test3 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取多个成员变量 Field[] fields = c.getFields(); Field[] fieldss = c.getDeclaredFields(); // 一个变量 // public int age Field ageField = c.getField(&quot;age&quot;); System.out.println(ageField); // public int cn.cuzz.Person.age // private String address Field addressField = c.getDeclaredField(&quot;address&quot;); System.out.println(addressField); // private java.lang.String cn.cuzz.Person.address }} 通过反射，创建对象，获取指定的成员变量，进行赋值与获取值操作获取成员变量，步骤如下： 获取Class对象 获取构造方法 通过构造方法，创建对象 获取指定的成员变量（私有成员变量，通过setAccessible(boolean flag)方法暴力访问） 通过方法，给指定对象的指定成员变量赋值或者获取值public void set(Object obj, Object value)在指定对象obj中，将此 Field 对象表示的成员变量设置为指定的新值public Object get(Object obj)返回指定对象obj中，此 Field 对象表示的成员变量的值 package cn.cuzz;import java.lang.reflect.Constructor;import java.lang.reflect.Field;public class Test4 { public static void main(String[] args) throws IllegalAccessException, Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取构造方法 Constructor con = c.getConstructor(String.class); // 通过构造方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;); // 获取指定成员变量 // public String name Field nameField = c.getField(&quot;name&quot;); // public int age Field ageField = c.getField(&quot;age&quot;); // 赋值 nameField.set(obj, &quot;Cuzz&quot;); ageField.set(obj, 23); System.out.println(&quot;name = &quot;+ nameField.get(obj)); // name = Cuzz System.out.println(&quot;age = &quot;+ ageField.get(obj)); // age = 23 }} 通过反射获取成员方法并使用在反射机制中，把类中的成员方法使用类Method表示。可通过Class类中提供的方法获取成员方法： 返回获取一个方法： public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 获取 public 修饰的方法 public Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) 获取任意的方法，包含私有的 参数1: name 要查找的方法名称； 参数2： parameterTypes 该方法的参数类型 返回获取多个方法： public Method[] getMethods() 获取本类与父类中所有public 修饰的方法 public Method[] getDeclaredMethods() 获取本类中所有的方法(包含私有的) package cn.cuzz;import java.lang.reflect.Method;public class Test5 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取多个方法 Method[] methods = c.getMethods(); Method[] methodss = c.getDeclaredMethods(); // 获取一个方法： // public void method1() Method method = c.getMethod(&quot;method1&quot;, null); System.out.println(method); // public String method4(String name){ method = c.getMethod(&quot;method4&quot;, String.class); System.out.println(method); // 私有方法 // private void method5() method = c.getDeclaredMethod(&quot;method5&quot;, null); System.out.println(method); }} 通过反射，创建对象，调用指定的方法获取成员方法，步骤如下： 获取Class对象 获取构造方法 通过构造方法，创建对象 获取指定的方法 执行找到的方法(如果获取的是私有方法则要开启暴力访问m5.setAccessible(true)) public Object invoke(Object obj, Object... args) 执行指定对象obj中，当前Method对象所代表的方法，方法要传入的参数通过args指定 package cn.cuzz;import java.lang.reflect.Constructor;import java.lang.reflect.Method;public class Test6 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取指定构造器 Constructor con = c.getConstructor(String.class, int.class, String.class); // 通过构造方法中的Constructor的方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;, 18, &quot;武汉&quot;); // 获取指定的方法 Method m4 = c.getMethod(&quot;method4&quot;, String.class); // 执行找到的方法 Object result = m4.invoke(obj, &quot;2018/03/19&quot;); System.out.println(&quot;result = &quot; + result); // result = 哈哈2018/03/19 }} 反射练习下面展示一下反射的利用场景。 泛型擦除思考，将已存在的ArrayList&lt;Integer&gt;集合中添加一个字符串数据，如何实现呢？ 我来告诉大家，其实程序编译后产生的.class文件中是没有泛型约束的，这种现象我们称为泛型的擦除。那么，我们可以通过反射技术，来完成向有泛型约束的集合中，添加任意类型的元素。 package cn.cuzz;import java.lang.reflect.Method;import java.util.ArrayList;public class Test7 { public static void main(String[] args) throws Exception, SecurityException { ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); // 添加元素 list.add(&quot;cuzz&quot;); // list.add(23); 报错 // 通过反射技术，实现添加任意类型的元素 // 获取字节码文件对象 Class c = Class.forName(&quot;java.util.ArrayList&quot;); // 找到add()方法 Method addMethod = c.getMethod(&quot;add&quot;, Object.class); // 执行add()方法 addMethod.invoke(list, 23); System.out.println(list); //[cuzz, 23] }} 反射配置文件通过配置文件得到类名和要运行的方法名,用反射的操作类名得到对象和调用方法 实现步骤: 准备配置文件,键值对 IO流读取配置文件 Reader 文件中的键值对存储到集合中 Properties集合保存的键值对,就是类名和方法名 反射获取指定类的class文件对象 class文件对象,获取指定的方法 运行方法 public class Test8 { public static void main(String[] args) throws Exception{ // IO流读取配置文件 FileReader r = new FileReader(&quot;config.properties&quot;); // 创建集合对象 Properties pro = new Properties(); // 调用集合方法load,传递流对象 pro.load(r); r.close(); // 通过键获取值 String className = pro.getProperty(&quot;className&quot;); String methodName = pro.getProperty(&quot;methodName&quot;); // 反射获取指定类的class文件对象 Class c = Class.forName(className); Object obj = c.newInstance(); // 获取指定的方法名 Method method = c.getMethod(methodName); method.invoke(obj); }} 配置文件 # className=cn.cuzz.Student# methodName=studyclassName=cn.cuzz.TeachermethodName=teach# className=cn.cuzz.Worker# methodName=work","link":"/2019/02/11/Java%E5%8F%8D%E5%B0%84/"},{"title":"LRUCache","text":"LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高” 。 代码： /** * @Author: cuzz * @Date: 2019/3/16 15:35 * @Description: LRU cache */public class LRUCache { private Map&lt;Integer, DLinkedList&gt; cache = new HashMap&lt;&gt;(); private int count; private int capacity; private DLinkedList head, tail; public LRUCache(int capacity) { this.count = 0; this.capacity = capacity; this.head = new DLinkedList(); this.tail = new DLinkedList(); head.next = tail; tail.pre = head; } public int get(int key) { DLinkedList node = cache.get(key); if (node == null) { return -1; } removeNode(node); addHead(node); return node.value; } public void put(int key, int value) { DLinkedList node = cache.get(key); if (node == null) { node = new DLinkedList(key, value); addHead(node); cache.put(key, node); count++; if (count &gt; capacity) { DLinkedList preTail = tail.pre; removeNode(preTail); cache.remove(preTail.key); count--; } } else { node.value = value; removeNode(node); addHead(node); } } // 移除给定的结点 private void removeNode(DLinkedList node) { DLinkedList pre = node.pre; DLinkedList next = node.next; pre.next = next; next.pre = pre; } // 把结点添加头节点 private void addHead(DLinkedList node) { DLinkedList next = head.next; head.next = node; node.next = next; next.pre = node; node.pre = head; } public static void main(String[] args) { LRUCache cache = new LRUCache(2); cache.put(1, 1); cache.put(2, 2); System.out.println(cache.get(1)); // 返回 1 cache.put(3, 3); // 使 2 作废 System.out.println(cache.get(2)); // 返回 -1 cache.put(4, 4); // 使 1 作废 System.out.println(cache.get(1)); // 返回 -1 未找到 System.out.println(cache.get(3)); // 返回 3 System.out.println(cache.get(4)); // 返回 4 }}class DLinkedList { int key; int value; DLinkedList pre; DLinkedList next; public DLinkedList() {}; public DLinkedList(int key, int value) { this.key = key; this.value = value; }}","link":"/2019/03/16/LRUCache/"},{"title":"Let&#39;s build a Full-Text Search engine","text":"这是一篇转载文章原文地址，原文讲述如何构建一个全文搜索引擎，用的 Go 实现的，本来想翻译一下，顺便用 Java 实现一下，由于翻译出来比较生硬，还是把原文放出来，顺便把我用 Java 实现的版本放在链接中Java实现版本。 Full-Text Search is one of those tools people use every day without realizing it. If you ever googled “golang coverage report” or tried to find “indoor wireless camera” on an e-commerce website, you used some kind of full-text search. Full-Text Search (FTS) is a technique for searching text in a collection of documents. A document can refer to a web page, a newspaper article, an email message, or any structured text. Today we are going to build our own FTS engine. By the end of this post, we’ll be able to search across millions of documents in less than a millisecond. We’ll start with simple search queries like “give me all documents that contain the word cat“ and we’ll extend the engine to support more sophisticated boolean queries. Note Most well-known FTS engine is Lucene (as well as Elasticsearch and Solr built on top of it). Why FTSBefore we start writing code, you may ask “can’t we just use grep or have a loop that checks if every document contains the word I’m looking for?“. Yes, we can. However, it’s not always the best idea. CorpusWe are going to search a part of the abstract of English Wikipedia. The latest dump is available at dumps.wikimedia.org. As of today, the file size after decompression is 913 MB. The XML file contains over 600K documents. Document example: &lt;title&gt;Wikipedia: Kit-Cat Klock&lt;/title&gt;&lt;url&gt;https://en.wikipedia.org/wiki/Kit-Cat_Klock&lt;/url&gt;&lt;abstract&gt;The Kit-Cat Klock is an art deco novelty wall clock shaped like a grinning cat with cartoon eyes that swivel in time with its pendulum tail.&lt;/abstract&gt; Loading documentsFirst, we need to load all the documents from the dump. The built-in encoding/xml package comes very handy: import ( &quot;encoding/xml&quot; &quot;os&quot;)type document struct { Title string `xml:&quot;title&quot;` URL string `xml:&quot;url&quot;` Text string `xml:&quot;abstract&quot;` ID int}func loadDocuments(path string) ([]document, error) { f, err := os.Open(path) if err != nil { return nil, err } defer f.Close() dec := xml.NewDecoder(f) dump := struct { Documents []document `xml:&quot;doc&quot;` }{} if err := dec.Decode(&amp;dump); err != nil { return nil, err } docs := dump.Documents for i := range docs { docs[i].ID = i } return docs, nil} Every loaded document gets assigned a unique identifier. To keep things simple, the first loaded document gets assigned ID=0, the second ID=1 and so on. First attemptSearching the contentNow that we have all documents loaded into memory, we can try to find the ones about cats. At first, let’s loop through all documents and check if they contain the substring cat: func search(docs []document, term string) []document { var r []document for _, doc := range docs { if strings.Contains(doc.Text, term) { r = append(r, doc) } } return r} On my laptop, the search phase takes 103ms - not too bad. If you spot check a few documents from the output, you may notice that the function matches caterpillar and category, but doesn’t match Cat with the capital C. That’s not quite what I was looking for. We need to fix two things before moving forward: Make the search case-insensitive (so Cat matches as well). Match on a word boundary rather than on a substring (so caterpillar and communication don’t match). Searching with regular expressionsOne solution that quickly comes to mind and allows implementing both requirements is regular expressions. Here it is - (?i)\\bcat\\b: (?i) makes the regex case-insensitive \\b matches a word boundary (position where one side is a word character and another side is not a word character) func search(docs []document, term string) []document { re := regexp.MustCompile(`(?i)\\b` + term + `\\b`) // Don't do this in production, it's a security risk. term needs to be sanitized. var r []document for _, doc := range docs { if re.MatchString(doc.Text) { r = append(r, doc) } } return r} Ugh, the search took more than 2 seconds. As you can see, things started getting slow even with 600K documents. While the approach is easy to implement, it doesn’t scale well. As the dataset grows larger, we need to scan more and more documents. The time complexity of this algorithm is linear - the number of documents required to scan is equal to the total number of documents. If we had 6M documents instead of 600K, the search would take 20 seconds. We need to do better than that. Inverted IndexTo make search queries faster, we’ll preprocess the text and build an index in advance. The core of FTS is a data structure called Inverted Index. The Inverted Index associates every word in documents with documents that contain the word. Example: documents = { 1: &quot;a donut on a glass plate&quot;, 2: &quot;only the donut&quot;, 3: &quot;listen to the drum machine&quot;,}index = { &quot;a&quot;: [1], &quot;donut&quot;: [1, 2], &quot;on&quot;: [1], &quot;glass&quot;: [1], &quot;plate&quot;: [1], &quot;only&quot;: [2], &quot;the&quot;: [2, 3], &quot;listen&quot;: [3], &quot;to&quot;: [3], &quot;drum&quot;: [3], &quot;machine&quot;: [3],} Below is a real-world example of the Inverted Index. An index in a book where a term references a page number: Text analysisBefore we start building the index, we need to break the raw text down into a list of words (tokens) suitable for indexing and searching. The text analyzer consists of a tokenizer and multiple filters. TokenizerThe tokenizer is the first step of text analysis. Its job is to convert text into a list of tokens. Our implementation splits the text on a word boundary and removes punctuation marks: func tokenize(text string) []string { return strings.FieldsFunc(text, func(r rune) bool { // Split on any character that is not a letter or a number. return !unicode.IsLetter(r) &amp;&amp; !unicode.IsNumber(r) })} &gt; tokenize(&quot;A donut on a glass plate. Only the donuts.&quot;)[&quot;A&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;Only&quot;, &quot;the&quot;, &quot;donuts&quot;] FiltersIn most cases, just converting text into a list of tokens is not enough. To make the text easier to index and search, we’ll need to do additional normalization. LowercaseIn order to make the search case-insensitive, the lowercase filter converts tokens to lower case. cAt, Cat and caT are normalized to cat. Later, when we query the index, we’ll lower case the search terms as well. This will make the search term cAt match the text Cat. func lowercaseFilter(tokens []string) []string { r := make([]string, len(tokens)) for i, token := range tokens { r[i] = strings.ToLower(token) } return r} &gt; lowercaseFilter([]string{&quot;A&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;Only&quot;, &quot;the&quot;, &quot;donuts&quot;})[&quot;a&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;the&quot;, &quot;donuts&quot;] Dropping common wordsAlmost any English text contains commonly used words like a, I, the or be. Such words are called stop words. We are going to remove them since almost any document would match the stop words. There is no “official” list of stop words. Let’s exclude the top 10 by the OEC rank. Feel free to add more: var stopwords = map[string]struct{}{ // I wish Go had built-in sets. &quot;a&quot;: {}, &quot;and&quot;: {}, &quot;be&quot;: {}, &quot;have&quot;: {}, &quot;i&quot;: {}, &quot;in&quot;: {}, &quot;of&quot;: {}, &quot;that&quot;: {}, &quot;the&quot;: {}, &quot;to&quot;: {},}func stopwordFilter(tokens []string) []string { r := make([]string, 0, len(tokens)) for _, token := range tokens { if _, ok := stopwords[token]; !ok { r = append(r, token) } } return r} &gt; stopwordFilter([]string{&quot;a&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;the&quot;, &quot;donuts&quot;})[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donuts&quot;] StemmingBecause of the grammar rules, documents may include different forms of the same word. Stemming reduces words into their base form. For example, fishing, fished and fisher may be reduced to the base form (stem) fish. Implementing a stemmer is a non-trivial task, it’s not covered in this post. We’ll take one of the existing modules: import snowballeng &quot;github.com/kljensen/snowball/english&quot;func stemmerFilter(tokens []string) []string { r := make([]string, len(tokens)) for i, token := range tokens { r[i] = snowballeng.Stem(token, false) } return r} &gt; stemmerFilter([]string{&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donuts&quot;})[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donut&quot;] Note A stem is not always a valid word. For example, some stemmers may reduce airline to airlin. Putting the analyzer togetherfunc analyze(text string) []string { tokens := tokenize(text) tokens = lowercaseFilter(tokens) tokens = stopwordFilter(tokens) tokens = stemmerFilter(tokens) return tokens} The tokenizer and filters convert sentences into a list of tokens: &gt; analyze(&quot;A donut on a glass plate. Only the donuts.&quot;)[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donut&quot;] The tokens are ready for indexing. Building the indexBack to the inverted index. It maps every word in documents to document IDs. The built-in map is a good candidate for storing the mapping. The key in the map is a token (string) and the value is a list of document IDs: type index map[string][]int Building the index consists of analyzing the documents and adding their IDs to the map: func (idx index) add(docs []document) { for _, doc := range docs { for _, token := range analyze(doc.Text) { ids := idx[token] if ids != nil &amp;&amp; ids[len(ids)-1] == doc.ID { // Don't add same ID twice. continue } idx[token] = append(ids, doc.ID) } }}func main() { idx := make(index) idx.add([]document{{ID: 1, Text: &quot;A donut on a glass plate. Only the donuts.&quot;}}) idx.add([]document{{ID: 2, Text: &quot;donut is a donut&quot;}}) fmt.Println(idx)} It works! Each token in the map refers to IDs of the documents that contain the token: map[donut:[1 2] glass:[1] is:[2] on:[1] only:[1] plate:[1]] QueryingTo query the index, we are going to apply the same tokenizer and filters we used for indexing: func (idx index) search(text string) [][]int { var r [][]int for _, token := range analyze(text) { if ids, ok := idx[token]; ok { r = append(r, ids) } } return r} &gt; idx.search(&quot;Small wild cat&quot;)[[24, 173, 303, ...], [98, 173, 765, ...], [[24, 51, 173, ...]] And finally, we can find all documents that mention cats. Searching 600K documents took less than a millisecond (18µs)! With the inverted index, the time complexity of the search query is linear to the number of search tokens. In the example query above, other than analyzing the input text, search had to perform only three map lookups. Boolean queriesThe query from the previous section returned a disjoined list of documents for each token. What we normally expect to find when we type small wild cat in a search box is a list of results that contain small, wild and cat at the same time. The next step is to compute the set intersection between the lists. This way we’ll get a list of documents matching all tokens. Luckily, IDs in our inverted index are inserted in ascending order. Since the IDs are sorted, it’s possible to compute the intersection between two lists in linear time. The intersection function iterates two lists simultaneously and collect IDs that exist in both: func intersection(a []int, b []int) []int { maxLen := len(a) if len(b) &gt; maxLen { maxLen = len(b) } r := make([]int, 0, maxLen) var i, j int for i &lt; len(a) &amp;&amp; j &lt; len(b) { if a[i] &lt; b[j] { i++ } else if a[i] &gt; b[j] { j++ } else { r = append(r, a[i]) i++ j++ } } return r} Updated search analyzes the given query text, lookups tokens and computes the set intersection between lists of IDs: func (idx index) search(text string) []int { var r []int for _, token := range analyze(text) { if ids, ok := idx[token]; ok { if r == nil { r = ids } else { r = intersection(r, ids) } } else { // Token doesn't exist. return nil } } return r} The Wikipedia dump contains only two documents that match small, wild and cat at the same time: &gt; idx.search(&quot;Small wild cat&quot;)130764 The wildcat is a species complex comprising two small wild cat species, the European wildcat (Felis silvestris) and the African wildcat (F. lybica).131692 Catopuma is a genus containing two Asian small wild cat species, the Asian golden cat (C. temminckii) and the bay cat. The search is working as expected! By the way, this is the first time I hear about catopuma, here is one of them: ConclusionsWe just built a Full-Text Search engine. Despite its simplicity, it can be a solid foundation for more advanced projects. I didn’t touch on a lot of things that can significantly improve the performance and make the engine more user friendly. Here are some ideas for further improvements: Extend boolean queries to support OR and NOT. Store the index on disk: Rebuilding the index on every application restart may take a while. Large indexes may not fit in memory. Experiment with memory and CPU-efficient data formats for storing sets of document IDs. Take a look at Roaring Bitmaps. Support indexing multiple document fields. Sort results by relevance. The full source code is available on GitHub. I’m not a native English speaker and I’m trying to improve my language skills. Feel free to correct me if you spot any spelling or grammatical error!","link":"/2020/08/17/Let's_build_a_Full-Text_Search_engine/"},{"title":"Apache RocketMQ开发者指南","text":"RocketMQ是一个分布式消息和流数据平台，具有低延迟、高性能、高可靠性、万亿级容量和灵活的可扩展性。RocketMQ是2012年阿里巴巴开源的第三代分布式消息中间件，2016年11月21日，阿里巴巴向Apache软件基金会捐赠了RocketMQ；第二年2月20日，Apache软件基金会宣布Apache RocketMQ成为顶级项目。 这个开发者指南是帮助您快速了解,并使用 Apache RocketMQ 概念和特性 概念(Concept)：介绍RocketMQ的基本概念模型。 特性(Features)：介绍RocketMQ实现的功能特性。 架构设计 架构(Architecture)：介绍RocketMQ部署架构和技术架构。 设计(Design)：介绍RocketMQ关键机制的设计原理，主要包括消息存储、通信机制、消息过滤、负载均衡、事务消息等。 样例 样例(Example) ：介绍RocketMQ的常见用法，包括基本样例、顺序消息样例、延时消息样例、批量消息样例、过滤消息样例、事务消息样例等。 最佳实践 最佳实践（Best Practice）：介绍RocketMQ的最佳实践，包括生产者、消费者、Broker以及NameServer的最佳实践，客户端的配置方式以及JVM和linux的最佳参数配置。 消息轨迹指南(Message Trace)：介绍RocketMQ消息轨迹的使用方法。 权限管理(Auth Management)：介绍如何快速部署和使用支持权限控制特性的RocketMQ集群。 Dledger快速搭建(Quick Start)：介绍Dledger的快速搭建方法。 集群部署(Cluster Deployment)：介绍Dledger的集群部署方式。 运维管理 集群部署(Operation)：介绍单Master模式、多Master模式、多Master多slave模式等RocketMQ集群各种形式的部署方法以及运维工具mqadmin的使用方式。 API Reference（待补充） DefaultMQProducer API Reference","link":"/2022/05/04/RocketMQ-study-note-1/"},{"title":"Shell入门","text":"Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。 Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。 Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell Shell编程之Hello World编写一个hello world shell一般使用.sh作为后缀 #!/bin/bash # 使用/bin/sh来解释执行 # auto echo hello world! # 解释这个脚本是干什么的# by authors cuzz # 作者和时间一些信息echo &quot;hello world!&quot; 给脚本添加执行权限 &gt; chmod +x hello.sh Shell编程之变量Shell变量可以分为两类：局部变量和环境变量 #!/bin/bash# define path variables# by authors cuzzname=cuzz # 等号两边不能有空格echo &quot;my name is $name&quot; # 使用$引用 基本变量 echo $PWD # 当前路径echo $0 # 脚本名echo $1 # 第一个参数echo $2 # 第二个参数echo $? # 判断上一个命令是否正确echo $* # 所有参数echo $# # 参数的个数 Shell编程之if条件语句比较大小 #!/bin/bash# if test# by authors cuzznum=100# 计算使用两个小括号if (($num &gt; 10)); then echo &quot;this num greater than 10.&quot;else echo &quot;this num littler than 10.&quot;fi 逻辑运算符 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否不相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 目录 操作符 说明 举例 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 创建文件 #!/bin/bash# if test# by authors cuzzDIR=cuzzif [ ! -d $DIR ]; then # 都有空格 mkdir $DIR echo &quot;this $DIR create success.&quot;else echo &quot;this dir is exit.&quot;fi 测试文件是否存在 #!/bin/bash# if test# by authors cuzzfile=test.txtif [ ! -e $file ]; then echo &quot;OK&quot; &gt;&gt; $file # &gt;&gt;是追加内容 &gt;是覆盖内容else cat $filefi mysql备份 #!/bin/bash# auto backup mysql db# by authors cuzz# define backup pathBAK_DIR=/data/backup/`date +%Y%m%d` # 反引号可以把里面当作命令来解析 # mysqlMYSQLDB=testMYSQLUSER=rootMYSQLPW=123456MYSQLCMD=/usr/bin/mysqldump # 备份命令# 判断是否是rootif [ $UID -ne 0 ]; then echo &quot;Only root can execute Shell.&quot; exitfiif [ ! -d $BAK_DIR ]; then mkdir -p $BAK_DIR # -p 父目录不存在就创建 echo &quot;The $BAK_DIR create success.&quot;else echo &quot;This $BAK_DIR is exist.&quot;fi# mysql backup command$MYSQLCMD -u$MYSQLUSER -p$MYSQLPW -d $MYSQLDB &gt;$BAK_DIR/$MYSQLDB.sqlif [ $? -eq 0 ]; then echo &quot;backup success.&quot;else echo &quot;backup fail.&quot;fi Shell编程之for循环基本语句 #!/bin/bashfor i in `seq 1 15`do echo &quot;the number is $i.&quot;done 求和 #!/bin/bashsum=0for ((i=1; i&lt;=100; i++)) # 双括号用于运算相当与其他语言的单括号do sum=`expr $sum + $i` # expr用于计算doneecho &quot;$sum&quot; 打包，只能打包到最后一个，后面的会把前面的覆盖了 #!/bin/bashfor file in `find ./ -name &quot;*.sh&quot;`do tar -czf all.tgz $filedone Shell编程之while循环使用 #!/bin/bashi=0while [[ $i -lt 10 ]] # (( $i &lt; 10))是一样的do echo &quot;$i&quot; ((i++))done 结合read使用 #!/bin/bashwhile read line # 把读取的东西赋值给linedo echo $linedone &lt;/etc/hosts # 从哪里读取 Shell编程之数组Shell 数组用括号来表示，元素用”空格”符号分割开，语法格式如下： my_array=(A B &quot;C&quot; D) # 定义数组array_name[0]=value0 # 使用下标来定义array_name[1]=value1array_name[2]=value2${array_name[0]} # 读取第一个元素${my_array[*]} # 读取所有元素 ${my_array[@]} # 读取所有元素${#my_array[*]} # 读取数组长度${#my_array[@]} # 读取数组长度 Shell编程之函数无返回值得函数 sayHello(){ # 定义函数一 echo &quot;hello&quot;}function sayHelloWorld(){ # 定义函数二 echo &quot;hello world&quot;}sayhell # 使用函数 有返回值得，使用return只能返回0-255 function sum(){ returnValue=$(( $1 + $2 )) return $returnValue}sum 22 4echo $? 可以使用echo来传递参数 function length(){ str=$1 result=0 if [ &quot;$str&quot; != &quot;&quot; ] ; then result=${#str} fi echo &quot;$result&quot;}len=$(length &quot;abc123&quot;) # 调用echo &quot;The string's length is $len &quot; Shell编程之sed命令把test.txt中的old修改为new，要使用-i才能插入 &gt; sed -i 's/old/new/s' test.txt 在每行行前面添加一个cuzz &gt; sed -i sed 's/^/&amp;cuzz/g' test.txt 在每行的末尾添加一个cuzz &gt; sed -i 's/$/&amp; cuzz/g' test.txt 匹配某一行，在下方插入一行，找到cuzz这行在下方插入#### &gt; sed '/cuzz/a #######' test.txt 在之前添加一行，只要把a改成i &gt; sed '/cuzz/i #######' test.txt 打印 &gt; sed -n '/cuzz/p' test.txt # 打印含有cuzz这一行&gt; sed -n '1p' test.txt # 打印第一行&gt; sed -n '1,5p' text.txt # 打印1到5行 查找最大和最小值 number.txt 12 324 56 0034 -23 345345 349- 245 345 345 0989 0459 -25 命令 cat number.txt | sed 's/ /\\n/g' | grep -v &quot;^$&quot; | sort -nr | sed -n '1p;$p'sed 's/ /\\n/g' # 把所有空格换成换行grep -v &quot;^$&quot; # 去掉所有空格sort -nr # 降序排列sed -n '1p;$p # 找出第1行和最后一行 Shell编程之grep命令 -a ：将 binary 文件以 text 文件的方式搜寻数据 -c ：计算找到 ‘搜寻字符串’ 的次数 -i ：忽略大小写的不同，所以大小写视为相同 -n ：顺便输出行号 -v ：反向选择，亦即显示出没有 ‘搜寻字符串’ 内容的那一行 –color=auto ：可以将找到的关键词部分加上颜色的显示 egrep 和grep -E 相同，可以使用正则表达式 Shell编程之awk命令# 每行按空格或TAB分割cat test.txt | awk '{print $1}' # 行匹配语句 awk '' 只能用单引号# 指定分割awk -F #-F相当于内置变量FS, 指定分割字符cat test.txt | awk -F: '{print $1}' # 以分号分割# 指定添加某些内容cat test.txt | awk -F: '{print &quot;haha&quot; $1}' # 提前出来再添加haha Shell编程之find命令基本命令 find /dir -name &quot;test.txt&quot; # 在/dir目录下查找find . -name &quot;test.txt&quot; # 在当前目录下找 find . -maxdepth 1 -name &quot;text.txt&quot; # 只遍历一层find . -type f -name &quot;text&quot; # 指定类型find . -name &quot;text&quot; -mtime -1 # 指定时间find . -size +20M # 指定大小 查找并执行其他命令 find . -name &quot;text.txt&quot; -exec rm -rf {} \\; # 后面{} \\是固定格式","link":"/2018/10/04/Shell%E5%85%A5%E9%97%A8/"},{"title":"Spring注解驱动开发（二）","text":"The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 声明周期@Bean指定初始化和销毁方法Bean的生命周期Bean的创建、初始化和销毁是由容器帮我们管理的 我们可以自定义初始化和销毁方法，容器在进行到当前生命周期的时候来调用我买自定义的初始化和销毁方法 构造（对象创建） ​ 单实例： 在容器启动的时候创建 ​ 多实例： 在每次获取的时候创建对象 指定初始化方法初始化：对象创建完成后，并赋值化，调用初始化方法 销毁：单实例是在容器关闭的时候销毁，多实例容器不会管理这个Bean，容器不会调用销毁方法 编写一个Car类 /** * @Author: cuzz * @Date: 2018/9/23 21:20 * @Description: */public class Car { public Car () { System.out.println(&quot;car constructor...&quot;); } public void init() { System.out.println(&quot;car...init...&quot;); } public void destroy() { System.out.println(&quot;car...destroy...&quot;); }} 在xml中我们可以指定init-method和destroy-method方法，如 &lt;bean id=&quot;car&quot; class=&quot;com.cuzz.bean.Car&quot; init-method=&quot;init&quot; destroy-method=&quot;destroy&quot;&gt;&lt;/bean&gt; 使用注解我们可以 /** * @Author: cuzz * @Date: 2018/9/24 12:49 * @Description: 配置类 */@Configurationpublic class MainConfigOfLifecycle { @Bean(initMethod = &quot;init&quot;, destroyMethod = &quot;destroy&quot;) public Car car() { return new Car(); }} 测试 /** * @Author: cuzz * @Date: 2018/9/24 13:00 * @Description: */public class IOCTestLifeCycle { @Test public void test01() { // 创建ioc容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfLifecycle.class); System.out.println(&quot;容器创建完成...&quot;); // 关闭容器 System.out.println(&quot;---&gt;开始关闭容器&quot;); applicationContext.close(); System.out.println(&quot;---&gt;已经关闭容器&quot;); }} 可以看出先创建car，再调用init方法，在容器关闭时销毁实例 car constructor...car...init...容器创建完成...---&gt;开始关闭容器car...destroy...---&gt;已经关闭容器 在配置数据源的时候，有很多属性赋值，销毁的时候要把连接给断开 生命周期InitializingBean和DisposableBeanInitializingBean可以通过Bean实现InitializingBean来定义初始化逻辑，是设置好所有属性会调用afterPropertiesSet()方法 public interface InitializingBean { /** * Invoked by a BeanFactory after it has set all bean properties supplied * (and satisfied BeanFactoryAware and ApplicationContextAware). * &lt;p&gt;This method allows the bean instance to perform initialization only * possible when all bean properties have been set and to throw an * exception in the event of misconfiguration. * @throws Exception in the event of misconfiguration (such * as failure to set an essential property) or if initialization fails. */ void afterPropertiesSet() throws Exception;} DisposableBean可以通过Bean实现DisposableBean来定义销毁逻辑，会调用destroy()方法 public interface DisposableBean { /** * Invoked by a BeanFactory on destruction of a singleton. * @throws Exception in case of shutdown errors. * Exceptions will get logged but not rethrown to allow * other beans to release their resources too. */ void destroy() throws Exception;} 例子编写一个Cat类 /** * @Author: cuzz * @Date: 2018/9/24 13:36 * @Description: */public class Cat implements InitializingBean, DisposableBean{ public Cat() { System.out.println(&quot;cat constructor...&quot;); } @Override public void afterPropertiesSet() throws Exception { System.out.println(&quot;cat...init...&quot;); } @Override public void destroy() throws Exception { System.out.println(&quot;cat...destroy...&quot;); }} 测试 cat constructor...cat...init...容器创建完成...---&gt;开始关闭容器cat...destroy...---&gt;已经关闭容器 生命周期@PostContruct和@PreDestroy注解@PostContruct在Bean创建完成并且属性赋值完成，来执行初始化 @PreDestroy在容器销毁Bean之前通知我们进行清理工作 编写一个Dog类，并把他注入到配置类中 /** * @Author: cuzz * @Date: 2018/9/24 14:03 * @Description: */public class Dog { public Dog() { System.out.println(&quot;dog constructor...&quot;); } @PostConstruct public void postConstruct() { System.out.println(&quot;post construct...&quot;); } @PreDestroy public void preDestroy() { System.out.println(&quot;pre destroy...&quot;); }} 测试结果 dog constructor...post construct...容器创建完成...---&gt;开始关闭容器pre destroy...---&gt;已经关闭容器 生命周期BeanPostProscessor后置处理器我们先看看源码，解释的很清楚，BeanPostProscessor 中postProcessBeforeInitialization方法会在每一个bean对象的初始化方法调用之前回调；postProcessAfterInitialization方法会在每个bean对象的初始化方法调用之后被回调 。 /** * Factory hook that allows for custom modification of new bean instances, * e.g. checking for marker interfaces or wrapping them with proxies. * * &lt;p&gt;ApplicationContexts can autodetect BeanPostProcessor beans in their * bean definitions and apply them to any beans subsequently created. * Plain bean factories allow for programmatic registration of post-processors, * applying to all beans created through this factory. * * &lt;p&gt;Typically, post-processors that populate beans via marker interfaces * or the like will implement {@link #postProcessBeforeInitialization}, * while post-processors that wrap beans with proxies will normally * implement {@link #postProcessAfterInitialization}. */public interface BeanPostProcessor { /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;before&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's {@code afterPropertiesSet} * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if {@code null}, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet */ Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;after&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's {@code afterPropertiesSet} * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * &lt;p&gt;In case of a FactoryBean, this callback will be invoked for both the FactoryBean * instance and the objects created by the FactoryBean (as of Spring 2.0). The * post-processor can decide whether to apply to either the FactoryBean or created * objects or both through corresponding {@code bean instanceof FactoryBean} checks. * &lt;p&gt;This callback will also be invoked after a short-circuiting triggered by a * {@link InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation} method, * in contrast to all other BeanPostProcessor callbacks. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if {@code null}, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet * @see org.springframework.beans.factory.FactoryBean */ Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;} 编写一个MyBeanPostProcessor实现BeanPostProcessor接口 /** * @Author: cuzz * @Date: 2018/9/24 14:21 * @Description: 后置处理器，初始化前后进行处理工作 */public class MyBeanPostProcessor implements BeanPostProcessor{ @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { System.out.println(&quot;---&gt;postProcessBeforeInitialization...&quot; + beanName +&quot;==&gt;&quot; + bean); return bean; } @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { System.out.println(&quot;---&gt;postProcessAfterInitialization...&quot; + beanName +&quot;==&gt;&quot; + bean); return bean; }} 添加到配置中 @Configurationpublic class MainConfigOfLifecycle { @Bean public Cat cat() { return new Cat(); } @Bean public MyBeanPostProcessor myBeanPostProcessor() { return new MyBeanPostProcessor(); }} 测试 ---&gt;postProcessBeforeInitialization...org.springframework.context.event.internalEventListenerProcessor==&gt;org.springframework.context.event.EventListenerMethodProcessor@1dc67c2---&gt;postProcessAfterInitialization...org.springframework.context.event.internalEventListenerProcessor==&gt;org.springframework.context.event.EventListenerMethodProcessor@1dc67c2---&gt;postProcessBeforeInitialization...org.springframework.context.event.internalEventListenerFactory==&gt;org.springframework.context.event.DefaultEventListenerFactory@2bd765---&gt;postProcessAfterInitialization...org.springframework.context.event.internalEventListenerFactory==&gt;org.springframework.context.event.DefaultEventListenerFactory@2bd765cat constructor...---&gt;postProcessBeforeInitialization...cat==&gt;com.cuzz.bean.Cat@1d3b207cat...init...---&gt;postProcessAfterInitialization...cat==&gt;com.cuzz.bean.Cat@1d3b207容器创建完成...---&gt;开始关闭容器cat...destroy...---&gt;已经关闭容器 在实例创建之前后创建之后会被执行 生命周期BeanPostProcessor原理通过debug到populateBean，先给属性赋值在执行initializeBean方法 try { populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) { exposedObject = initializeBean(beanName, exposedObject, mbd); }} initializeBean方法时， protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) { Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) { // 执行before方法 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); } ... try { // 执行初始化 invokeInitMethods(beanName, wrappedBean, mbd); } if (mbd == null || !mbd.isSynthetic()) { // 执行after方法 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); } return wrappedBean;} Spring底层对BeanPostProcessor的使用： Bean赋值、注入其他组件、@Autowired、生命周期注解功能、@Async等等都使用到了BeanPostProcessor这个接口的实现类，很重要 总结Bean 的初始化顺序 首先执行 bean 的构造方法 BeanPostProcessor 的 postProcessBeforeInitialization 方法 InitializingBean 的 afterPropertiesSet 方法 @Bean 注解的 initMethod方法 BeanPostProcesso r的 postProcessAfterInitialization 方法 DisposableBean 的 destroy 方法 @Bean注解的 destroyMethod 方法","link":"/2018/09/24/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"Spring注解驱动开发（四）","text":"AOP面向切面编程AOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 底层实现Spring 的 AOP 的底层用到两种代理机制： JDK 的动态代理 ：类必须实现接口，所以是针对实现了接口的类产生代理. Cglib 的动态代理：针对没有实现接口的类产生代理，应用的是底层的字节码增强的技术生成当前类的子类对象 JDK 的动态代理 UserService接口，实现增删改查的功能 package com.cuzz.service;public interface UserService { void add(); void delete(); void update(); void get();} UserService接口的实现的类 public class UserServiceImpl implements UserService { @Override public void add() { System.out.println(&quot;添加一个user&quot;); } @Override public void delete() { System.out.println(&quot;删除一个user&quot;); } @Override public void update() { System.out.println(&quot;更新一个user&quot;); } @Override public void get() { System.out.println(&quot;查询一个user&quot;); }} 实现动态代理 package com.cuzz.service;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class UserServiceProxyFactory implements InvocationHandler{ private UserService us; public UserServiceProxyFactory(UserService us) { super(); this.us = us; } // 获得动态代理 public UserService getUserServiceProxy() { // 生成动态代理 UserService usProxy = (UserService) Proxy.newProxyInstance(UserServiceProxyFactory.class.getClassLoader(), UserServiceImpl.class.getInterfaces(), this); // 这个 this 就是实现 InvocationHandler 的对象 return usProxy; } @Override public Object invoke(Object arg0, Method method, Object[] arg2) throws Throwable { System.out.println(&quot;打开事务!&quot;); Object invoke = method.invoke(us, arg2); System.out.println(&quot;提交事务!&quot;); return invoke; }} 测试 public class TestDemo { @Test public void test01(){ UserService us = new UserServiceImpl(); UserServiceProxyFactory factory = new UserServiceProxyFactory(us); UserService usProxy = factory.getUserServiceProxy(); usProxy.add(); }} 输出 打开事务!添加一个user提交事务! Cglib 的动态代理 Cglib 的动态代理的代码实现 package com.cuzz.service;import java.lang.reflect.Method;import org.springframework.cglib.proxy.Enhancer;import org.springframework.cglib.proxy.MethodInterceptor;import org.springframework.cglib.proxy.MethodProxy;public class UserServiceProxyFactory2 implements MethodInterceptor { public UserService getUserServiceProxy(){ // 帮我们生成代理对象 Enhancer en = new Enhancer(); // 设置对谁进行代理 en.setSuperclass(UserServiceImpl.class); // 代理要做什么 en.setCallback(this); // 创建代理对象 UserService us = (UserService) en.create(); return us; } @Override public Object intercept(Object prxoyobj, Method method, Object[] arg, MethodProxy methodProxy) throws Throwable { // 打开事务 System.out.println(&quot;打开事务!&quot;); // 调用原有方法 Object returnValue = methodProxy.invokeSuper(prxoyobj, arg); // 提交事务 System.out.println(&quot;提交事务!&quot;); return returnValue; }} 测试 @Testpublic void test02() { UserServiceProxyFactory2 factory = new UserServiceProxyFactory2(); UserService usProxy = factory.getUserServiceProxy(); usProxy.add();} Spring的AOP开发(基于AspectJ)AOP的开发中的相关术语： Joinpoint(连接点)：所谓连接点是指那些被拦截到的点，在 spring 中这些点指的是方法，因为 spring 只支持方法类型的连接点 Pointcut(切入点)：所谓切入点是指我们要对哪些 Joinpoint 进行拦截的定义 Advice(通知/增强)：所谓通知是指拦截到 Joinpoint 之后所要做的事情就是通知.通知分为前置通知,后置通知,异常通知,最终通知,环绕通知(切面要完成的功能) Introduction(引介)：引介是一种特殊的通知在不修改类代码的前提下, Introduction 可以在运行期为类动态地添加一些方法或 Field Target(目标对象)：代理的目标对象 Weaving(织入)：是指把增强应用到目标对象来创建新的代理对象的过程，spring 采用动态代理织入，而 AspectJ 采用编译期织入和类装在期织入 Proxy（代理）：一个类被 AOP 织入增强后，就产生一个结果代理类 Aspect(切面)：是切入点和通知（引介）的结合 通知类型 前置通知 ：在目标方法执行之前执行 后置通知 ：在目标方法执行之后执行 环绕通知 ：在目标方法执行前和执行后执行 异常抛出通知：在目标方法执行出现异常的时候执行 最终通知 ：无论目标方法是否出现异常 最终通知都会执行 代码演示通知类，给切面的目标方法标注何时地运行，必须告诉 Spring 哪个类是切面类，添加注解 @Aspect @Aspect // 表示该类是一个通知类public class MyAdvice { // 前置通知 @Before(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void before(){ System.out.println(&quot;这是前置通知!!&quot;); } // 后置通知 @AfterReturning(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void afterReturning(){ System.out.println(&quot;这是后置通知(如果出现异常不会调用)!!&quot;); } // 环绕通知 @Around(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public Object around(ProceedingJoinPoint pjp) throws Throwable { System.out.println(&quot;这是环绕通知之前的部分!!&quot;); // 调用目标方法 Object proceed = pjp.proceed(); System.out.println(&quot;这是环绕通知之后的部分!!&quot;); return proceed; } // 异常通知 @AfterThrowing(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void afterException(){ System.out.println(&quot;出事啦!出现异常了!!&quot;); } // 后置通知 @After(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void after(){ System.out.println(&quot;这是后置通知(出现异常也会调用)!!&quot;); }} 配置类，将切面类和业务逻辑类都加入到容器中，给配置类加 @EnableAspectJAutoProxy 注解 /** * @Author: cuzz * @Date: 2019/2/10 20:43 * @Description: */@Configuration@EnableAspectJAutoProxypublic class MainConfigOfAOP { @Bean public UserService userService() { return new UserServiceImpl(); } @Bean public MyAdvice myAdvice() { return new MyAdvice(); }} 测试 @Testpublic void test03() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAOP.class); UserService userService = (UserService) applicationContext.getBean(&quot;userService&quot;); userService.add(); userService.delete(); userService.update(); userService.get();} 如果报错添加依赖 &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.4&lt;/version&gt; &lt;/dependency&gt;","link":"/2019/02/10/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"Spring注解驱动开发（三）","text":"The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 属性赋值@value赋值使用@Value赋值 基本数值 可以写SPEL表达式 #{} 可以${}获取配置文件信息（在运行的环境变量中的值） 使用xml时候导入配置文件是 &lt;context:property-placeholder location=&quot;classpath:person.properties&quot;/&gt; 使用注解可以在配置类添加一个@PropertySource注解把配置文件中k/v保存到运行的环境中 使用${key}来获取 /** * @Author: cuzz * @Date: 2018/9/24 18:43 * @Description: */@PropertySource(value = {&quot;classpath:/person.properties&quot;})@Configurationpublic class MainConfigOfPropertyValue { @Bean public Person person() { return new Person(); }} Person 类 @Datapublic class Person { @Value(&quot;vhuj&quot;) private String name; @Value(&quot;#{20-2}&quot;) private Integer age; @Value(&quot;${person.nickName}&quot;) private String nickName;} 测试 @Testpublic void test01() { printBean(applicationContext); System.out.println(&quot;---------------------------&quot;); Person person = (Person) applicationContext.getBean(&quot;person&quot;); System.out.println(person); System.out.println(&quot;---------------------------&quot;);} 输出 ---------------------------Person(name=vhuj, age=18, nickName=三三)--------------------------- 自动装配@Autowired@Qualifier@Primary自动转配： Spring利用依赖注入（DI），完成对IOC容器中各个组件的依赖关系赋值 @Autowired自动注入: a. 默认优先按照类型去容器中寻找对应的组件，如果找到去赋值 b. 如果找到到相同类型的组件，再将属性名（BookDao bookdao）作为组件的id去容器中查找 c. 接下来还可以使用@Qualifier(&quot;bookdao&quot;)明确指定需要装配的id d. 默认是必须的，我们可以指定 @Autowired(required=false)，指定非必须 @Primary让Spring自动装配时首先装配 自动装配@Resource和@InjectSpring还支持使用@Resource (JSR250) 和@Inject (JSR330) 注解，这两个是java规范 @Resource和@Autowired一样实现自动装配功能，默认是按组件名称进行装配的 没有支持@Primary和@Autowird(required=false)的功能 自动装配其他地方的自动装配@Autowired：构造器、参数、方法属性等 标注到方法位子上@Bean+方法参数，参数从容器中获取 /** * @Author: cuzz * @Date: 2018/9/24 20:57 * @Description: */public class Boss { // 属性 @Autowired private Car car; // 构造器 如果构造器只有一个有参构造器可以省略 @Autowired public Boss(@Autowired Car car) { } public Car getCar() { return car; } // set方法 @Autowired // 参数 public void setCar(@Autowired Car car) { this.car = car; }} 自动装配Aware注入Spring底层注解自定义组件想要使用Spring容器底层的一些组件（ApplicationContext，BeanFactory 等等），自定义组件实现xxxAware，在创建对象的时候会调用接口规定的方法注入相关的组件 /** * Marker superinterface indicating that a bean is eligible to be * notified by the Spring container of a particular framework object * through a callback-style method. Actual method signature is * determined by individual subinterfaces, but should typically * consist of just one void-returning method that accepts a single * argument. */public interface Aware {} 我们实现几个常见的Aware接口 /** * @Author: cuzz * @Date: 2018/9/25 10:18 * @Description: */@Componentpublic class Red implements BeanNameAware ,BeanFactoryAware, ApplicationContextAware { private ApplicationContext applicationContext; @Override public void setBeanName(String name) { System.out.println(&quot;当前Bean的名字: &quot; + name); } @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException { System.out.println(&quot;当前的BeanFactory: &quot; + beanFactory); } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext; System.out.println(&quot;传入的ioc: &quot; + applicationContext); }} 注入到配置中测试 /** * @Author: cuzz * @Date: 2018/9/25 10:28 * @Description: */public class IOCTestAware { @Test public void test01() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAware.class); }} 测试结果 当前Bean的名字: red当前的BeanFactory: org.springframework.beans.factory.support.DefaultListableBeanFactory@159c4b8: defining beans [org.springframework.context.annotation.internalConfigurationAnnotationProcessor,org.springframework.context.annotation.internalAutowiredAnnotationProcessor,org.springframework.context.annotation.internalRequiredAnnotationProcessor,org.springframework.context.annotation.internalCommonAnnotationProcessor,org.springframework.context.event.internalEventListenerProcessor,org.springframework.context.event.internalEventListenerFactory,mainConfigOfAware,red]; root of factory hierarchy传入的ioc: org.springframework.context.annotation.AnnotationConfigApplicationContext@1e89d68: startup date [Tue Sep 25 10:29:17 CST 2018]; root of context hierarchy 把Spring自定义组件注入到容器中 原理： public interface ApplicationContextAware extends Aware {} 通过 Debug 方式，定位到 org.springframework.context.support.ApplicationContextAwareProcessor#postProcessBeforeInitialization @Overridepublic Object postProcessBeforeInitialization(final Object bean, String beanName) throws BeansException { AccessControlContext acc = null; if (System.getSecurityManager() != null &amp;&amp; (bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware || bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware || bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)) { acc = this.applicationContext.getBeanFactory().getAccessControlContext(); } if (acc != null) { AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() { @Override public Object run() { invokeAwareInterfaces(bean); return null; } }, acc); } else { invokeAwareInterfaces(bean); // 调用 } 调用下面方法进行判断，每种 xxxAware 接口中只有一种方法，并调用相应的方法 private void invokeAwareInterfaces(Object bean) { if (bean instanceof Aware) { if (bean instanceof EnvironmentAware) { ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); } if (bean instanceof EmbeddedValueResolverAware) { ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); } if (bean instanceof ResourceLoaderAware) { ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); } if (bean instanceof ApplicationEventPublisherAware) { ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); } if (bean instanceof MessageSourceAware) { ((MessageSourceAware) bean).setMessageSource(this.applicationContext); } if (bean instanceof ApplicationContextAware) { ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); } }} xxxAware都是通过xxxProcessor来处理的 比如：ApplicationContextAware 对应 ApplicationContextAwareProcessor 自动装配@Profile环境搭建Profile是Spring为我们提供可以根据当前环境，动态的激活和切换一系组件的功能 a. 使用命令动态参数激活：虚拟机参数位子加载 -Dspring.profiles.active=test b. 使用代码激活环境 我们想配置类 /** * @Author: cuzz * @Date: 2018/9/25 10:47 * @Description: */@Configurationpublic class MainConfigOfProfile { @Profile(value = &quot;test&quot;) @Bean(value = &quot;testDataSource&quot;) public DataSource testDataSource() { System.out.println(&quot;testDataSource&quot;); return null; } @Profile(value = &quot;dev&quot;) @Bean(value = &quot;devDataSource&quot;) public DataSource devDataSource() { System.out.println(&quot;devDataSource&quot;); return null; }} 测试 /** * @Author: cuzz * @Date: 2018/9/25 10:59 * @Description: */public class IOCTestProfile { @Test public void test01() { // 1. 使用无参构造器创建一个applicationContext AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(); // 2. 设置要激活的环境 applicationContext.getEnvironment().setActiveProfiles(&quot;test&quot;); // 3. 注册主配置类 applicationContext.register(MainConfigOfProfile.class); // 4. 启动刷新容器 applicationContext.refresh(); }} 输出 testDataSource","link":"/2018/09/25/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"Spring 的复杂类型注入","text":"Spring 的类型注入先定义一个接口： public interface Animal {} 对应的有一些实现类： @Componentpublic class Dog implements Animal {}@Component(&quot;myCat&quot;)public class Cat implements Animal {} 我们用 Spring 比较常见的用类型注入和名称注入： @Resourceprivate Dog dog; // 按类型注入@Resource(&quot;myCat&quot;)private Cat myCat; // 按名称注入 然后今天在公司看到同事使用观察者模式的时候，使用了另外一种注入方式，注入的是List&lt;XXX&gt;： @Resourceprivate List&lt;Animal&gt; animalList; 这个时候注入的时候实现 Animal 这个接口的所有实现类 Spring 按类型自动注入Array、List、Set、MapSpring 按类型不仅仅注入类本身的，而且还可以注入Array、List、Set 和 Map 。 @Resourceprivate Animal[] animalArr;@Resourceprivate List&lt;Animal&gt; animalList;@Resourceprivate Set&lt;Animal&gt; animalSet;@Resourceprivate Map&lt;String, Animal&gt; animalMap; 我们写一个测试类看看： @Autowiredprivate void print() { System.out.println(Arrays.toString(animalArr)); System.out.println(animalList); System.out.println(animalSet); System.out.println(animalMap);} 发现输出： [com.cuzz.spring.impl.Cat@58cd06cb, com.cuzz.spring.impl.Dog@3be8821f][com.cuzz.spring.impl.Cat@58cd06cb, com.cuzz.spring.impl.Dog@3be8821f][com.cuzz.spring.impl.Cat@58cd06cb, com.cuzz.spring.impl.Dog@3be8821f]{myCat=com.cuzz.spring.impl.Cat@58cd06cb, dog=com.cuzz.spring.impl.Dog@3be8821f} 当为数组和集合的时候会把所有接口的实现类放入其中，当为 Map 时，key 对应的是 Bean 的名称，value 对应Bean。 源码分析先定位到这个方法org.springframework.beans.factory.support.DefaultListableBeanFactory#resolveDependency resolveDependency 方法中定位到根据类型查找依赖 doResolveDependency。 @Override@Nullablepublic Object resolveDependency(DependencyDescriptor descriptor, @Nullable String requestingBeanName, @Nullable Set&lt;String&gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) throws BeansException { // ... Object result = getAutowireCandidateResolver().getLazyResolutionProxyIfNecessary( descriptor, requestingBeanName); if (result == null) { result = doResolveDependency(descriptor, requestingBeanName, autowiredBeanNames, typeConverter); } return result; }} doResolveDependency 封装了依赖查找的各种情况，我们主要看 resolveMultipleBeans 方法。 @Nullablepublic Object doResolveDependency(DependencyDescriptor descriptor, @Nullable String beanName, @Nullable Set&lt;String&gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) throws BeansException { InjectionPoint previousInjectionPoint = ConstructorResolver.setCurrentInjectionPoint(descriptor); try { // ... // 集合依赖，如 Array、List、Set、Map。 Object multipleBeans = resolveMultipleBeans(descriptor, beanName, autowiredBeanNames, typeConverter); if (multipleBeans != null) { return multipleBeans; } // ... }} 最终调用resolveMultipleBeans方法 private Object resolveMultipleBeans(DependencyDescriptor descriptor, @Nullable String beanName, @Nullable Set&lt;String&gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) { Class&lt;?&gt; type = descriptor.getDependencyType(); // Stream 类型 if (descriptor instanceof StreamDependencyDescriptor) { Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, type, descriptor); if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } Stream&lt;Object&gt; stream = matchingBeans.keySet().stream() .map(name -&gt; descriptor.resolveCandidate(name, type, this)) .filter(bean -&gt; !(bean instanceof NullBean)); if (((StreamDependencyDescriptor) descriptor).isOrdered()) { stream = stream.sorted(adaptOrderComparator(matchingBeans)); } return stream; } // Array else if (type.isArray()) { Class&lt;?&gt; componentType = type.getComponentType(); ResolvableType resolvableType = descriptor.getResolvableType(); Class&lt;?&gt; resolvedArrayType = resolvableType.resolve(type); if (resolvedArrayType != type) { componentType = resolvableType.getComponentType().resolve(); } if (componentType == null) { return null; } Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, componentType, new MultiElementDescriptor(descriptor)); if (matchingBeans.isEmpty()) { return null; } if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter()); Object result = converter.convertIfNecessary(matchingBeans.values(), resolvedArrayType); if (result instanceof Object[]) { Comparator&lt;Object&gt; comparator = adaptDependencyComparator(matchingBeans); if (comparator != null) { Arrays.sort((Object[]) result, comparator); } } return result; } // 集合 else if (Collection.class.isAssignableFrom(type) &amp;&amp; type.isInterface()) { Class&lt;?&gt; elementType = descriptor.getResolvableType().asCollection().resolveGeneric(); if (elementType == null) { return null; } Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, elementType, new MultiElementDescriptor(descriptor)); if (matchingBeans.isEmpty()) { return null; } if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter()); Object result = converter.convertIfNecessary(matchingBeans.values(), type); if (result instanceof List) { if (((List&lt;?&gt;) result).size() &gt; 1) { Comparator&lt;Object&gt; comparator = adaptDependencyComparator(matchingBeans); if (comparator != null) { ((List&lt;?&gt;) result).sort(comparator); } } } return result; } // Map else if (Map.class == type) { ResolvableType mapType = descriptor.getResolvableType().asMap(); Class&lt;?&gt; keyType = mapType.resolveGeneric(0); if (String.class != keyType) { return null; } Class&lt;?&gt; valueType = mapType.resolveGeneric(1); if (valueType == null) { return null; } Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, valueType, new MultiElementDescriptor(descriptor)); if (matchingBeans.isEmpty()) { return null; } if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } return matchingBeans; } else { return null; }} 从源码发现，不仅仅可以注入数组、集合和Map，还可以注入 Stream。 总结Spring按类型注入不仅仅注入简单的Bean，还可以注入一些数组、集合、Map 以及 Stream。 如果想进一步了解这一块可以看看这篇文章Spring IoC 依赖注入（三）resolveDependency","link":"/2020/09/29/Spring%E7%9A%84%E5%A4%8D%E6%9D%82%E7%B1%BB%E5%9E%8B%E6%B3%A8%E5%85%A5/"},{"title":"ThreadLocal原理分析和拓展","text":"多线程访问同一个共享变量由于线程的执行顺序和变量的可见性原因会导致并发问题，我们一般会有两种解决思路： 一是对访问的变量进行加锁处理 二是每个线程都访问本线程的变量 本次我们重点分析Java中通过ThreadLocal实现的本地变量 ThreadLocal实现原理当使用ThreadLocal维护变量的时候，该变量存储在线程的本地，其他线程无法访问，做到了线程间的隔离，也就没有线程安全的问题了。 每一个Thread中都会有一个ThreadLocalMap对象， ThreadLocalMap 中有一个 Entry 数组 Entry中key是ThreadLocal对象实例 ，继承自WeakReference（弱引用），value就是我们要设置的值 我们首先来看一下 ThreadLocalMap 是一个静态内部类 static class ThreadLocalMap { // key是弱引用 static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; } } // 初始容量，必须为二的整数幂 private static final int INITIAL_CAPACITY = 16; // map中储存Entry的量 private Entry[] table; // 总共储存了多少对象 private int size = 0; // 下次扩容的数量 private int threshold; // Default to 0} 接下看看如何设置值 public void set(T value) { // 获取当前线程 Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); // 如果不为空就设置值，为空就创建 if (map != null) { map.set(this, value); } else { createMap(t, value); }}// 获取 ThreadLocalMapThreadLocalMap getMap(Thread t) { return t.threadLocals;}// 创建 ThreadLocalMapvoid createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue);} 内存泄漏原因 TheadLocal 本身不存储值，它只是做为一个key，来让线程从ThreadLocal中获取value ThreadLocalMap 是使用ThreadLocal的弱引用做为key的，一个对象如果只剩下弱引用（没有强引用），该对象在GC就会被回收 如果我们手动将 ThreadLocal A 的对象赋值为 null，这个 ThreadLocal A 就会被回收，ThreadLocalMap 中就会出现 key 为 null 的 Entry。 Java 程序没有办法访问这些 key 为 null 的Entry的value，如果当前线程迟迟不结束，使用的线程池，或者该线程需要执行一些耗时任务，在系统值就会出现一条强引用链，从 ThreadRef -&gt; Thread B -&gt; ThreadLocalMap -&gt; value -&gt; Obj C 这个value就无法回收，导致内存泄漏。 只有当前线程结束之后，ThreadRef 不存在栈中，强