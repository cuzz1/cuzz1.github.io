{"pages":[{"title":"","text":"cuzz’s blog由Hexo强力驱动，托管在github，采用next主题","link":"/README.html"},{"title":"关于","text":"自我介绍联系我： 微信：cuzz_2020 邮箱：cuzz1234@163.com","link":"/about/index.html"},{"title":"404","text":"","link":"/404/index.html"},{"title":"","text":"","link":"/categories/index.html"},{"title":"","text":"","link":"/tags/index.html"}],"posts":[{"title":"201811","text":"看到阮一峰老师写的每周技术分享，自己想写一个类似来记录一下自己，方便以后自己查找，我就每月总结一次。科研上我需要每个月要发一份总结导师，而这个总结主要是技术上的，也包括自己平时的所见所闻，希望自己能坚持写下去 总结springcloud-vue-project上一个月主要写了一个 Vue + SpringCloud 的项目，项目大部分写完了，对微服务的知识我那么一点点入门，主要架构图如下 面试想出去实习，投了两个面试，一个做 OMS 系统的物流公司 先是做了一套卷子，两道算法题比较简单，数据库感觉没答好，很久没有写 SQL 基础知识问得比较少，就问了一个AtomicInteger怎么保证线程安全，有道题目中我写了这个类 因为我有实习经历，就问了一些项目相关的，怎么解决项目中遇到的困难，一些常用的中间件熟不熟，能不能自己部署，Docker会不会用之类的，后面就和产品经历聊了聊，就快速的结束了 还有一个就是小米了，下周面试，希望能成功 Leetcode最近每天都会刷刷 leetcode，刚开始的时候痛不欲生，慢慢的越来越顺了，当然有一部分原因是为了面试，不过我觉得刷题有助于自己的代码能量，挺有意思的 工具SurfingkeysSurfingkeys 和现有的一些插件一样，让你尽可能的通过键盘来使用 Chrome/Firefox 浏览器，比如跳转网页，上下左右滚屏。但不只是给vim用户使用，Surfingkeys的基本特性是让你自己写一段 Javascript 脚本，然后通过 mapkey 映射到某些按键。之后当你按了那几个键以后，对应的Javascript 脚本就会被执行。 玩了一下，特别棒，解放鼠标 视频计算机科学速成课这是 Youtube 上很火的速成课，其中这门讲的是计算机相关的知识，一共40集，每集很短只有10分钟，但是知识量巨多，包含计算科学的各个方面 gitbub 地址 第 1 集：计算机早期历史 第 2 集：电子计算机 第 3 集：布尔逻辑和逻辑门 第 4 集：二进制 第 5 集：算数逻辑单元 - ALU 第 6 集：寄存器和内存 第 7 集：中央处理器（CPU) 第 8 集：指令和程序 第 9 集：高级 CPU 设计 第 10 集：早期的编程方式 第 11 集：编程语言发展史 第 12 集：编程基础 - 语句和函数 第 13 集：算法入门 第 14 集：数据结构 第 15 集：阿兰·图灵 第 16 集：软件工程 第 17 集：集成电路与摩尔定律 第 18 集：操作系统 第 19 集：内存&amp;储存介质 第 20 集：文件系统 第 21 集：压缩 第 22 集：命令行界面 第 23 集：屏幕与 2D 图形显示 第 24 集：冷战和消费主义 第 25 集：个人计算机革命 第 26 集：图形用户界面 (GUI) 第 27 集：3D 图形 第 28 集：计算机网络 第 29 集：互联网 第 30 集：万维网 第 31 集：计算机安全 第 32 集：黑客与攻击 第 33 集：加密 第 34 集：机器学习与人工智能 第 35 集：计算机视觉 第 37 集：机器人 第 38 集：计算机心理学 第 39 集：教育科技 第 40 集：奇点，天网，计算机的未来 中国通史-古代史《中国通史》以史诗般的宏大叙事手法，生动再现了中华文明从原始社会到二十一世纪初的完整发展历程。内容涉及历史、政治、经济、军事、哲学、宗教、文学、 艺术、语言、考古、天文、地理、科技、人物、民俗以及中外交流等各个方面，直观地再现了中华民族五千年文明历史全景，全面展示了华夏文明的古今传承。 写代码写累了看看，作为一个工科生，对历史知识了解的不多，这部记录篇值得看看，看看古代中国人民的聪明才智，看看一个朝代的兴盛衰败。 看点技术分享周刊这是阮老师技术分享周刊，每周五更新，里面分享了很多有用的工具和教程，非常值得关注。我每周都会第一时间查看，现在已经更新到33期了，如果有好的链接可以 issue Computer Science Learning Notes这是一个 Java 相关的知识库，总结的很好，排版也非常漂亮，不管是应付面试还是提升自己都很有帮助，一共包括十个版块","link":"/2018/11/30/201811/"},{"title":"201812","text":"总结这个月一边忙着实验，一边写代码，做计算的好处就是时间比较充裕，早上来到实验室用脚本把任务一提交就可以安心的写代码了 面试上个月到小米面试了，很遗憾没有面上，不过还是有点收获的，自己学着迷茫了，就去面试一下，看看有什么自己没有掌握好，更好的考验自己。 这次面试我的面试官主要问的很多基础的问题 自我介绍 对操作系统了不了解，说下队列 说下 Dubbo 算法 树的按层打印 把数值转化为中文大写金额 没有问 Java 的相关内容，自己答的不是很好，又有学习的动力了，回来就马上补这些知识 剑指Offer这个月把里面的题又刷了一遍，比起第一次刷代码更简洁了，时间复杂度也能优化更好，刷题还是很有意义的 视频汇编语言程序设计这是清华大学公开课，讲得挺简单易懂，自己对汇编程序过了一遍，对汇编有了一个简单的认识，汇编是对指令的一种抽象，更贴近机器，对代码有了一个新的认识 操作系统这也是清华大学公开课，由于自己对这些基础知识比较缺乏，现在在学校，还是要踏踏实实把这些基础知识学好，才能走得更远 看点CSAPP最近也在看 CSAPP 这本书，这个是对这本一个简单的提炼，先掌握主干再慢慢消化书上的内容，总结的很好 下月计划 看完《编码》 Leetcode 50 道 熟悉一下 Netty","link":"/2018/12/30/201812/"},{"title":"2019春招总结","text":"前言3 月份开始准备春招到现在已经 2 个多月了， 总结一下这个两个月的面试的一些情况，下面是我这个月面过的一些公司。 时间 公司 地点 2019/3/5 15:30 腾讯 视频 2019/3/9 19:30 腾讯 视频 2019/3/11 15:00 氦科技 现场 2019/3/12 14:00 航班管家 现场 2019/3/15 15:00 字节跳动 视频 2019/3/19 15:00 阿里巴巴 电话 2019/3/21 15:00 阿里巴巴 电话 2019/3/28 15:00 阿里巴巴 电话 2019/3/29 19:00 快手 笔试 2019/4/1 19:00 虎牙 笔试 2019/4/3 19:00 拼多多 笔试 2019/4/5 19:00 腾讯 笔试 2019/4/6 19:00 百度 笔试 2019/4/10 19:00 华为 笔试 2019/4/12 19:00 阿里巴巴 笔试 2019/4/14 19:00 完美世界 笔试 2019/4/15 10:00 华为 现场 2019/4/15 15:00 作业帮 笔试 2019/4/21 19:00 菜鸟 电话 2019/5/6 17:00 去哪儿 现场 2019/5/7 19:00 菜鸟 电话 一些面试没有答出的的题目有的面试已经过去很久了，我就把我印象比较深的题目列出来 HashMap 为什么使用红黑树而不使用平衡树？（菜鸟） 6大设计原则，什么是高内聚低耦合（菜鸟） 衡量垃圾收集器的指标有哪些，说说CMS收集器，CMS 为什么需要暂停 - stop the world？（菜鸟） 知道 C++ 的析构函数吗？在 JAVA 中调用 finalize 的会怎样？那你知道 finalize 有什么作用？（菜鸟） 说说一致性Hash算法，它解决了什么问题？（菜鸟） Dubbo 有哪些传输协议？（阿里） 最短路径？（阿里） HTTPS 加密过程，是怎么保证信息可靠的？（头条） Dubbo 有哪些负载均衡策略？（头条） 后记其实很多都是笔试挂了，自己刷了剑指offer 还有 leetcode 一些题，还是很难通过一些大公司的笔试题，最近在实习刷的比较少，有时候没手感，看到题目都是懵逼状态，所以还是要坚持刷题。 阿里面试时直接打电话过来，我一般都没有时间准备就开始面试了，最可惜的是阿里第三面的时候，我认为第三面会问比较多项目，然而他问了很多计算机基础的知识，比如红黑树、最短路径问题等，这些我都没答好，所以就凉凉了，自己在这方面还是比较薄弱，需要加强。 当然也收到了几个 offer，经历了这段面试，自己也学到了挺多，至少不再畏惧面试了，也知道了大厂需要什么样的人才，继续努力，秋招再来。","link":"/2019/05/07/2019%E6%98%A5%E6%8B%9B%E6%80%BB%E7%BB%93/"},{"title":"Java 中是如何实现线程通信？","text":"正常情况下，每个子线程完成各自的任务就可以结束了。不过有的时候，我们希望多个线程协同工作来完成某个任务，这时就涉及到了线程间通信了。 本文涉及到的知识点：thread.join(), object.wait(), object.notify(), CountdownLatch, CyclicBarrier, FutureTask, Callable 等。 原文链接：Java 中是如何实现线程通信？ 本文涉及代码：https://github.com/wingjay/HelloJava/blob/master/multi-thread/src/ForArticle.java 下面我从几个例子作为切入点来讲解下 Java 里有哪些方法来实现线程间通信。 如何让两个线程依次执行？ 那如何让两个线程按照指定方式有序交叉运行呢？ 四个线程 A B C D，其中 D 要等到 A B C 全执行完毕后才执行，而且 A B C 是同步运行的 三个运动员各自准备，等到三个人都准备好后，再一起跑 子线程完成某件任务后，把得到的结果回传给主线程 如何让两个线程依次执行？假设有两个线程，一个是线程 A，另一个是线程 B，两个线程分别依次打印 1-3 三个数字即可。我们来看下代码： private static void demo1() { Thread A = new Thread(new Runnable() { @Override public void run() { printNumber(&quot;A&quot;); } }); Thread B = new Thread(new Runnable() { @Override public void run() { printNumber(&quot;B&quot;); } }); A.start(); B.start();} 其中的 printNumber(String) 实现如下，用来依次打印 1, 2, 3 三个数字： private static void printNumber(String threadName) { int i=0; while (i++ &lt; 3) { try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(threadName + &quot; print: &quot; + i); }} 这时我们得到的结果是： B print: 1A print: 1B print: 2A print: 2B print: 3A print: 3 可以看到 A 和 B 是同时打印的。 那么，如果我们希望 B 在 A 全部打印 完后再开始打印呢？我们可以利用 thread.join() 方法，代码如下: private static void demo2() { Thread A = new Thread(new Runnable() { @Override public void run() { printNumber(&quot;A&quot;); } }); Thread B = new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;B 开始等待 A&quot;); try { A.join(); } catch (InterruptedException e) { e.printStackTrace(); } printNumber(&quot;B&quot;); } }); B.start(); A.start();} 得到的结果如下： B 开始等待 AA print: 1A print: 2A print: 3 B print: 1B print: 2B print: 3 A.join 把指定的线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行的线程。比如在线程B中调用了线程A的 join() 方法，直到线程A执行完毕后，才会继续执行线程B。 t.join(); 调用 join 方法，等待线程 t 执行完毕 t.join(1000); 等待 t 线程，等待时间是1000毫秒。 所以我们能看到 A.join() 方法会让 B 一直等待直到 A 运行完毕。 那如何让两个线程按照指定方式有序交叉运行呢？还是上面那个例子，我现在希望 A 在打印完 1 后，再让 B 打印 1, 2, 3，最后再回到 A 继续打印 2, 3。这种需求下，显然 Thread.join() 已经不能满足了。我们需要更细粒度的锁来控制执行顺序。 这里，我们可以利用 object.wait() 和 object.notify() 两个方法来实现。代码如下： /** * A 1, B 1, B 2, B 3, A 2, A 3 */private static void demo3() { Object lock = new Object(); Thread A = new Thread(new Runnable() { @Override public void run() { synchronized (lock) { System.out.println(&quot;A 1&quot;); try { lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;A 2&quot;); System.out.println(&quot;A 3&quot;); } } }); Thread B = new Thread(new Runnable() { @Override public void run() { synchronized (lock) { System.out.println(&quot;B 1&quot;); System.out.println(&quot;B 2&quot;); System.out.println(&quot;B 3&quot;); lock.notify(); } } }); A.start(); B.start();} 打印结果如下： A 1A waiting… B 1B 2B 3A 2A 3 正是我们要的结果。 那么，这个过程发生了什么呢？ 首先创建一个 A 和 B 共享的对象锁 lock = new Object(); 当 A 得到锁后，先打印 1，然后调用 lock.wait() 方法，交出锁的控制权，进入 wait 状态； 对 B 而言，由于 A 最开始得到了锁，导致 B 无法执行；直到 A 调用 lock.wait() 释放控制权后， B 才得到了锁； B 在得到锁后打印 1， 2， 3；然后调用 lock.notify() 方法，唤醒正在 wait 的 A; A 被唤醒后，继续打印剩下的 2，3。 为了更好理解，我在上面的代码里加上 log 方便读者查看。 private static void demo3() { Object lock = new Object(); Thread A = new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;INFO: A 等待锁 &quot;); synchronized (lock) { System.out.println(&quot;INFO: A 得到了锁 lock&quot;); System.out.println(&quot;A 1&quot;); try { System.out.println(&quot;INFO: A 准备进入等待状态，放弃锁 lock 的控制权 &quot;); lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;INFO: 有人唤醒了 A, A 重新获得锁 lock&quot;); System.out.println(&quot;A 2&quot;); System.out.println(&quot;A 3&quot;); } } }); Thread B = new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;INFO: B 等待锁 &quot;); synchronized (lock) { System.out.println(&quot;INFO: B 得到了锁 lock&quot;); System.out.println(&quot;B 1&quot;); System.out.println(&quot;B 2&quot;); System.out.println(&quot;B 3&quot;); System.out.println(&quot;INFO: B 打印完毕，调用 notify 方法 &quot;); lock.notify(); } } }); A.start(); B.start();} 打印结果如下: INFO: A 等待锁INFO: A 得到了锁 lockA 1INFO: A 准备进入等待状态，调用 lock.wait() 放弃锁 lock 的控制权INFO: B 等待锁INFO: B 得到了锁 lockB 1B 2B 3INFO: B 打印完毕，调用 lock.notify() 方法INFO: 有人唤醒了 A, A 重新获得锁 lockA 2A 3 四个线程 A B C D，其中 D 要等到 A B C 全执行完毕后才执行，而且 A B C 是同步运行的最开始我们介绍了 thread.join()，可以让一个线程等另一个线程运行完毕后再继续执行，那我们可以在 D 线程里依次 join A B C，不过这也就使得 A B C 必须依次执行，而我们要的是这三者能同步运行。 或者说，我们希望达到的目的是：A B C 三个线程同时运行，各自独立运行完后通知 D；对 D 而言，只要 A B C 都运行完了，D 再开始运行。针对这种情况，我们可以利用 CountdownLatch 来实现这类通信方式。它的基本用法是： 创建一个计数器，设置初始值，CountdownLatch countDownLatch = new CountDownLatch(2); 在 等待线程 里调用 countDownLatch.await() 方法，进入等待状态，直到计数值变成 0； 在 其他线程 里，调用 countDownLatch.countDown() 方法，该方法会将计数值减小 1； 当 其他线程 的 countDown() 方法把计数值变成 0 时，等待线程 里的 countDownLatch.await() 立即退出，继续执行下面的代码。 实现代码如下： private static void runDAfterABC() { int worker = 3; CountDownLatch countDownLatch = new CountDownLatch(worker); new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;D is waiting for other three threads&quot;); try { countDownLatch.await(); System.out.println(&quot;All done, D starts working&quot;); } catch (InterruptedException e) { e.printStackTrace(); } } }).start(); for (char threadName='A'; threadName &lt;= 'C'; threadName++) { final String tN = String.valueOf(threadName); new Thread(new Runnable() { @Override public void run() { System.out.println(tN + &quot; is working&quot;); try { Thread.sleep(100); } catch (Exception e) { e.printStackTrace(); } System.out.println(tN + &quot; finished&quot;); countDownLatch.countDown(); } }).start(); }} 下面是运行结果： D is waiting for other three threadsA is workingB is workingC is working A finishedC finishedB finishedAll done, D starts working 其实简单点来说，CountDownLatch 就是一个倒计数器，我们把初始计数值设置为3，当 D 运行时，先调用 countDownLatch.await() 检查计数器值是否为 0，若不为 0 则保持等待状态；当A B C 各自运行完后都会利用countDownLatch.countDown()，将倒计数器减 1，当三个都运行完后，计数器被减至 0；此时立即触发 D的 await() 运行结束，继续向下执行。 因此，CountDownLatch 适用于一个线程去等待多个线程的情况。 三个运动员各自准备，等到三个人都准备好后，再一起跑上面是一个形象的比喻，针对 线程 A B C 各自开始准备，直到三者都准备完毕，然后再同时运行 。也就是要实现一种线程之间互相等待的效果，那应该怎么来实现呢？ 上面的 CountDownLatch 可以用来倒计数，但当计数完毕，只有一个线程的 await() 会得到响应，无法让多个线程同时触发。 为了实现线程间互相等待这种需求，我们可以利用 CyclicBarrier 数据结构，它的基本用法是： 先创建一个公共 CyclicBarrier 对象，设置 同时等待 的线程数，CyclicBarrier cyclicBarrier = new CyclicBarrier(3); 这些线程同时开始自己做准备，自身准备完毕后，需要等待别人准备完毕，这时调用 cyclicBarrier.await(); 即可开始等待别人； 当指定的 同时等待 的线程数都调用了 cyclicBarrier.await();时，意味着这些线程都准备完毕好，然后这些线程才 同时继续执行。 实现代码如下，设想有三个跑步运动员，各自准备好后等待其他人，全部准备好后才开始跑： private static void runABCWhenAllReady() { int runner = 3; CyclicBarrier cyclicBarrier = new CyclicBarrier(runner); final Random random = new Random(); for (char runnerName='A'; runnerName &lt;= 'C'; runnerName++) { final String rN = String.valueOf(runnerName); new Thread(new Runnable() { @Override public void run() { long prepareTime = random.nextInt(10000) + 100; System.out.println(rN + &quot; is preparing for time: &quot; + prepareTime); try { Thread.sleep(prepareTime); } catch (Exception e) { e.printStackTrace(); } try { System.out.println(rN + &quot; is prepared, waiting for others&quot;); cyclicBarrier.await(); // 当前运动员准备完毕，等待别人准备好 } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } System.out.println(rN + &quot; starts running&quot;); // 所有运动员都准备好了，一起开始跑 } }).start(); }} 打印的结果如下： A is preparing for time: 4131B is preparing for time: 6349C is preparing for time: 8206 A is prepared, waiting for others B is prepared, waiting for others C is prepared, waiting for others C starts runningA starts runningB starts running 子线程完成某件任务后，把得到的结果回传给主线程实际的开发中，我们经常要创建子线程来做一些耗时任务，然后把任务执行结果回传给主线程使用，这种情况在 Java 里要如何实现呢？ 回顾线程的创建，我们一般会把 Runnable 对象传给 Thread 去执行。Runnable定义如下： public interface Runnable { public abstract void run();} 可以看到 run() 在执行完后不会返回任何结果。那如果希望返回结果呢？这里可以利用另一个类似的接口类 Callable： @FunctionalInterfacepublic interface Callable&lt;V&gt; { /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;} 可以看出 Callable 最大区别就是返回范型 V 结果。 那么下一个问题就是，如何把子线程的结果回传回来呢？在 Java 里，有一个类是配合 Callable 使用的：FutureTask，不过注意，它获取结果的 get 方法会阻塞主线程。 举例，我们想让子线程去计算从 1 加到 100，并把算出的结果返回到主线程。 private static void doTaskWithResultInWorker() { Callable&lt;Integer&gt; callable = new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { System.out.println(&quot;Task starts&quot;); Thread.sleep(1000); int result = 0; for (int i=0; i&lt;=100; i++) { result += i; } System.out.println(&quot;Task finished and return result&quot;); return result; } }; FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(callable); new Thread(futureTask).start(); try { System.out.println(&quot;Before futureTask.get()&quot;); System.out.println(&quot;Result: &quot; + futureTask.get()); System.out.println(&quot;After futureTask.get()&quot;); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); }} 打印结果如下： Before futureTask.get() Task startsTask finished and return result Result: 5050After futureTask.get() 可以看到，主线程调用 futureTask.get() 方法时阻塞主线程；然后 Callable 内部开始执行，并返回运算结果；此时 futureTask.get() 得到结果，主线程恢复运行。 这里我们可以学到，通过 FutureTask 和 Callable 可以直接在主线程获得子线程的运算结果，只不过需要阻塞主线程。当然，如果不希望阻塞主线程，可以考虑利用 ExecutorService，把 FutureTask 放到线程池去管理执行。 小结多线程是现代语言的共同特性，而线程间通信、线程同步、线程安全是很重要的话题。本文针对 Java 的线程间通信进行了大致的讲解，后续还会对线程同步、线程安全进行讲解。","link":"/2019/02/14/Java%20%E4%B8%AD%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%BA%BF%E7%A8%8B%E9%80%9A%E4%BF%A1%EF%BC%9F/"},{"title":"Java 中的锁","text":"Java中的锁分类在读很多并发文章中，会提及各种各样锁如公平锁，乐观锁等等，这篇文章介绍各种锁的分类。介绍的内容如下： 公平锁/非公平锁 可重入锁 独享锁/共享锁 互斥锁/读写锁 乐观锁/悲观锁 分段锁 偏向锁/轻量级锁/重量级锁 自旋锁 上面是很多锁的名词，这些分类并不是全是指锁的状态，有的指锁的特性，有的指锁的设计，下面总结的内容是对每个锁的名词进行一定的解释。 公平锁/非公平锁公平锁是指多个线程按照申请锁的顺序来获取锁。非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。对于Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。 可重入锁/不可重入锁最近正在阅读Java ReentrantLock源码，始终对可重入和不可重入概念理解不透彻，进行学习后记录在这里。 基础知识Java多线程的 wait() 方法和 notify() 方法。这两个方法是成对出现和使用的，要执行这两个方法，有一个前提就是，当前线程必须获其对象的monitor（俗称“锁”），否则会抛出 IllegalMonitorStateException 异常，所以这两个方法必须在同步块代码里面调用。 wait()：阻塞当前线程 notify()：唤起被wait()阻塞的线程 不可重入锁所谓不可重入锁，即若当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到被阻塞。我们尝试设计一个不可重入锁： public class Lock{ private boolean isLocked = false; public synchronized void lock() throws InterruptedException { while(isLocked){ wait(); } isLocked = true; } public synchronized void unlock(){ isLocked = false; notify(); }} 使用该锁： public class Count{ Lock lock = new Lock(); public void print(){ lock.lock(); doAdd(); lock.unlock(); } public void doAdd(){ lock.lock(); //do something lock.unlock(); }} 当前线程执行print()方法首先获取lock，接下来执行doAdd()方法就无法执行doAdd()中的逻辑，必须先释放锁。这个例子很好的说明了不可重入锁。 可重入锁接下来，我们设计一种可重入锁 public class Lock{ boolean isLocked = false; Thread lockedBy = null; int lockedCount = 0; public synchronized void lock() throws InterruptedException{ Thread thread = Thread.currentThread(); while(isLocked &amp;&amp; lockedBy != thread){ wait(); } isLocked = true; lockedCount++; lockedBy = thread; } public synchronized void unlock(){ if(Thread.currentThread() == this.lockedBy){ lockedCount--; if(lockedCount == 0){ isLocked = false; notify(); } } }} 所谓可重入，意味着线程可以进入它已经拥有的锁的同步代码块儿。 我们设计两个线程调用 print() 方法，第一个线程调用 print() 方法获取锁，进入 lock() 方法，由于初始 lockedBy 是 null，所以不会进入 while 而挂起当前线程，而是是增量 lockedCount 并记录 lockBy 为第一个线程。接着第一个线程进入 doAdd() 方法，由于同一进程，所以不会进入 while 而挂起，接着增量 lockedCount，当第二个线程尝试lock，由于 isLocked=true，所以他不会获取该锁，直到第一个线程调用两次 unlock() 将 lockCount 递减为0，才将标记为 isLocked 设置为 false。 可重入锁的概念和设计思想大体如此，Java 中的可重入锁 ReentrantLock 设计思路也是这样。 独享锁/共享锁独享锁是指该锁一次只能被一个线程所持有。共享锁是指该锁可被多个线程所持有。 对于Java ReentrantLock而言，其是独享锁。但是对于Lock的另一个实现类ReadWriteLock，其读锁是共享锁，其写锁是独享锁。 读锁的共享锁可保证并发读是非常高效的，读写，写读 ，写写的过程是互斥的。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 对于Synchronized而言，当然是独享锁。 互斥锁/读写锁上面讲的独享锁/共享锁就是一种广义的说法，互斥锁/读写锁就是具体的实现。 互斥锁在Java中的具体实现就是ReentrantLock 读写锁在Java中的具体实现就是ReadWriteLock 乐观锁/悲观锁乐观锁与悲观锁不是指具体的什么类型的锁，而是指看待并发同步的角度。悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的。 从上面的描述我们可以看出，悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。 悲观锁在Java中的使用，就是利用各种锁。 乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。 分段锁分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap 而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。 我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过 hashcode 来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。但是，在统计size的时候，可就是获取 hashmap 全局信息的时候，就需要获取所有的分段锁才能统计。分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。 偏向锁/轻量级锁/重量级锁偏向锁在没有实际竞争的情况下，还能够针对部分场景继续优化。如果不仅仅没有实际竞争，自始至终，使用锁的线程都只有一个，那么，维护轻量级锁都是浪费的。偏向锁的目标是，减少无竞争且只有一个线程使用锁的情况下，使用轻量级锁产生的性能消耗。轻量级锁每次申请、释放锁都至少需要一次CAS，但偏向锁只有初始化时需要一次CAS。 “偏向”的意思是，偏向锁假定将来只有第一个申请锁的线程会使用锁（不会有任何线程再来申请锁），因此，只需要在Mark Word中 CAS 记录owner（本质上也是更新，但初始值为空），如果记录成功，则偏向锁获取成功，记录锁状态为偏向锁，以后当前线程等于owner就可以零成本的直接获得锁；否则，说明有其他线程竞争，膨胀为轻量级锁。 偏向锁无法使用自旋锁优化，因为一旦有其他线程申请锁，就破坏了偏向锁的假定。 缺点： 同样的，如果明显存在其他线程申请锁，那么偏向锁将很快膨胀为轻量级锁。 不过这个副作用已经小的多。 如果需要，使用参数-XX:-UseBiasedLocking禁止偏向锁优化（默认打开）。 轻量级锁自旋锁的目标是降低线程切换的成本。如果锁竞争激烈，我们不得不依赖于重量级锁，让竞争失败的线程阻塞；如果完全没有实际的锁竞争，那么申请重量级锁都是浪费的。轻量级锁的目标是，减少无实际竞争情况下，使用重量级锁产生的性能消耗，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。 顾名思义，轻量级锁是相对于重量级锁而言的。使用轻量级锁时，不需要申请互斥量，仅仅将 Mark Word 中的部分字节CAS更新指向线程栈中的Lock Record，如果更新成功，则轻量级锁获取成功，记录锁状态为轻量级锁；否则，说明已经有线程获得了轻量级锁，目前发生了锁竞争（不适合继续使用轻量级锁），接下来膨胀为重量级锁。 Mark Word是对象头的一部分；每个线程都拥有自己的线程栈（虚拟机栈），记录线程和函数调用的基本信息。二者属于JVM的基础内容，此处不做介绍。 当然，由于轻量级锁天然瞄准不存在锁竞争的场景，如果存在锁竞争但不激烈，仍然可以用自旋锁优化，自旋失败后再膨胀为重量级锁。 重量级锁内置锁在Java中被抽象为监视器锁（monitor）。在JDK 1.6之前，监视器锁可以认为直接对应底层操作系统中的互斥量（mutex）。这种同步方式的成本非常高，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。因此，后来称这种锁为“重量级锁”。 小结 偏向锁、轻量级锁、重量级锁分配和膨胀的详细过程见后。会涉及一些Mark Word与CAS的知识。 偏向锁、轻量级锁、重量级锁适用于不同的并发场景： 偏向锁：无实际竞争，且将来只有第一个申请锁的线程会使用锁。 轻量级锁：无实际竞争，多个线程交替使用锁；允许短时间的锁竞争。 重量级锁：有实际竞争，且锁竞争时间长。 另外，如果锁竞争时间短，可以使用自旋锁进一步优化轻量级锁、重量级锁的性能，减少线程切换。 如果锁竞争程度逐渐提高（缓慢），那么从偏向锁逐步膨胀到重量锁，能够提高系统的整体性能。 自旋锁首先，内核态与用户态的切换上不容易优化。但通过自旋锁，可以减少线程阻塞造成的线程切换（包括挂起线程和恢复线程）。 如果锁的粒度小，那么锁的持有时间比较短（尽管具体的持有时间无法得知，但可以认为，通常有一部分锁能满足上述性质）。那么，对于竞争这些锁的而言，因为锁阻塞造成线程切换的时间与锁持有的时间相当，减少线程阻塞造成的线程切换，能得到较大的性能提升。具体如下： 当前线程竞争锁失败时，打算阻塞自己 不直接阻塞自己，而是自旋（空等待，比如一个空的有限for循环）一会 在自旋的同时重新竞争锁 如果自旋结束前获得了锁，那么锁获取成功；否则，自旋结束后阻塞自己 如果在自旋的时间内，锁就被旧owner释放了，那么当前线程就不需要阻塞自己（也不需要在未来锁释放时恢复），减少了一次线程切换。 “锁的持有时间比较短“这一条件可以放宽。实际上，只要锁竞争的时间比较短（比如线程1快释放锁的时候，线程2才会来竞争锁），就能够提高自旋获得锁的概率。这通常发生在锁持有时间长，但竞争不激烈的场景中。 典型的自旋锁实现的例子，可以参考自旋锁的实现 锁分配和膨胀过程![锁分配和膨胀过程](Java 中的锁\\4491294-e3bcefb2bacea224.png) 参考链接 Java中的锁分类 Java不可重入锁和可重入锁理解 浅谈偏向锁、轻量级锁、重量级锁","link":"/2019/02/13/Java%20%E4%B8%AD%E7%9A%84%E9%94%81/"},{"title":"Java 反射","text":"类加载器当程序有使用某个类时，如果该类还没有被加载到内存中，则系统会通过加载，连接，初始化三步来实现对这个类进行初始化 加载就是指将class文件读入内存，并为之创建一个Class对象，任何类被使用时系统都会建立一个Class对象 连接验证 是否有正确的内部结构，并和其他类协调一致准备 负责为类的静态成员分配内存，并设置默认初始化值解析 将类的二进制数据中的符号引用替换为直接引用 初始化对类的静态变量，静态代码块执行初始化操作类初始化时机 创建类的实例 类的静态变量，或者为静态变量赋值 类的静态方法 使用反射方式来强制创建某个类或接口对应的java.lang.Class对象 初始化某个类的子类 直接使用java.exe命令来运行某个主类类加载器 负责将.class文件加载到内在中，并为之生成对应的Class对象 虽然我们不需要关心类加载机制，但是了解这个机制我们就能更好的理解程序的运行类加载器的组成 Bootstrap ClassLoader 根类加载器也被称为引导类加载器，负责Java核心类的加载比如System，String等。在 JDK 中 JRE 的 lib 目录下 rt.jar 文件中 Extension ClassLoader 扩展类加载器负责 JRE 的扩展目录中 jar 包的加载。在 JDK 中 JRE 的 lib 目录下 ext 目录 System ClassLoader 系统类加载器负责在JVM启动时加载来自java命令的class文件，以及classpath环境变量所指定的jar包和类路径 通过这些描述就可以知道我们常用的类，都是由谁来加载完成的。 到目前为止我们已经知道把class文件加载到内存了，那么，如果我们仅仅站在这些class文件的角度，我们如何来使用这些class文件中的内容呢? 这就是我们反射要研究的内容 反射JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。要想解剖一个类,必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法.所以先要获取到每一个字节码文件对应的Class类型的对象 Class类阅读API的Class类得知，Class 没有公共构造方法。Class 对象是在加载类时由 Java 虚拟机以及通过调用类加载器中的 defineClass 方法自动构造的 获取Class对象的三种方式方式一: 通过Object类中的getObject()方法 Person p = new Person();Class c = p.getClass(); 方式二: 通过 类名.class 获取到字节码文件对象（任意数据类型都具备一个class静态属性,看上去要比第一种方式简单） Class c2 = Person.class; 方式三: 通过Class类中的方法（将类名作为字符串传递给Class类中的静态方法forName即可） Class c3 = Class.forName(&quot;cn.cuzz.Person&quot;); 注意：第三种和前两种的区别 前两种你必须明确Person类型 后面是指定这种类型的字符串就行(要包含包名)，这种扩展更强，我不需要知道你的类，我只提供字符串，按照配置文件加载就可以了 Person类public class Person { // 成员变量 public String name; public int age; private String address; // 构造方法 public Person() { System.out.println(&quot;空参数构造方法&quot;); } public Person(String name) { this.name = name; System.out.println(&quot;带有String的构造方法&quot;); } // 私有的构造方法 private Person(String name, int age){ this.name = name; this.age = age; System.out.println(&quot;带有String，int的构造方法&quot;); } public Person(String name, int age, String address){ this.name = name; this.age = age; this.address = address; System.out.println(&quot;带有String, int, String的构造方法&quot;); } // 成员方法 // 没有返回值没有参数的方法 public void method1(){ System.out.println(&quot;没有返回值没有参数的方法&quot;); } // 没有返回值，有参数的方法 public void method2(String name){ System.out.println(&quot;没有返回值，有参数的方法 name= &quot;+ name); } // 有返回值，没有参数 public int method3(){ System.out.println(&quot;有返回值，没有参数的方法&quot;); return 123; } // 有返回值，有参数的方法 public String method4(String name){ System.out.println(&quot;有返回值，有参数的方法&quot;); return &quot;哈哈&quot; + name; } // 私有方法 private void method5(){ System.out.println(&quot;私有方法&quot;); } @Override public String toString() { return &quot;Person [name=&quot; + name + &quot;, age=&quot; + age + &quot;, address=&quot; + address+ &quot;]&quot;; }} 通过反射获取构造方法并使用在反射机制中，把类中的成员（构造方法、成员方法、成员变量）都封装成了对应的类进行表示。其中，构造方法使用类Constructor表示。可通过Class类中提供的方法获取构造方法： 返回一个构造方法 public Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 获取public修饰, 指定参数类型所对应的构造方法 public Constructor&lt;T&gt; getDeclaredConstructor(Class&lt;?&gt;... parameterTypes) 获取指定参数类型所对应的构造方法(包含私有的) 返回多个构造方法 public Constructor&lt;?&gt;[] getConstructors() 获取所有的public 修饰的构造方法 public Constructor&lt;?&gt;[] getDeclaredConstructors() 获取所有的构造方法(包含私有的)package cn.cuzz;import java.lang.reflect.Constructor;public class Test { public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException, SecurityException { // 获取Class对象 包名.类 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取所有构造方法 // 只包括public Constructor[] cons = c.getConstructors(); // 即包括public也包括private Constructor[] conss = c.getDeclaredConstructors(); // 获取一个构造方法 // public Person() Constructor con1 = c.getConstructor(null); System.out.println(con1); // public Person(String name) Constructor con2 = c.getConstructor(String.class); System.out.println(con2); // private Person(String name, int age) Constructor con3 = c.getDeclaredConstructor(String.class, int.class); System.out.println(con3); // public Person(String name, int age, String address) Constructor con4 = c.getDeclaredConstructor(String.class, int.class, String.class); System.out.println(con4); }} 通过反射方式，获取构造方法，创建对象 获取构造方法，步骤如下： 获取到Class对象 获取指定的构造方法 通过构造方法类Constructor中的方法，创建对象public T newInstance(Object... initargs) package cn.cuzz;import java.lang.reflect.Constructor;public class Test2 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取指定构造器 Constructor con = c.getConstructor(String.class, int.class, String.class); // 通过构造方法中的Constructor的方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;, 18, &quot;武汉&quot;); System.out.println(obj); // Person [name=cuzz, age=18, address=武汉] }} 通过反射获取成员变量并使用在反射机制中，把类中的成员变量使用类Field表示。可通过Class类中提供的方法获取成员变量： 返回一个成员变量 public Field getField(String name) 获取指定的public修饰的变量 public Field getDeclaredField(String name) 获取指定的任意变量 返回多个成员变量 public Field[] getFields() 获取所有public 修饰的变量 public Field[] getDeclaredFields() 获取所有的 变量 (包含私有)package cn.cuzz;import java.lang.reflect.Field;public class Test3 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取多个成员变量 Field[] fields = c.getFields(); Field[] fieldss = c.getDeclaredFields(); // 一个变量 // public int age Field ageField = c.getField(&quot;age&quot;); System.out.println(ageField); // public int cn.cuzz.Person.age // private String address Field addressField = c.getDeclaredField(&quot;address&quot;); System.out.println(addressField); // private java.lang.String cn.cuzz.Person.address }} 通过反射，创建对象，获取指定的成员变量，进行赋值与获取值操作获取成员变量，步骤如下： 获取Class对象 获取构造方法 通过构造方法，创建对象 获取指定的成员变量（私有成员变量，通过setAccessible(boolean flag)方法暴力访问） 通过方法，给指定对象的指定成员变量赋值或者获取值public void set(Object obj, Object value)在指定对象obj中，将此 Field 对象表示的成员变量设置为指定的新值public Object get(Object obj)返回指定对象obj中，此 Field 对象表示的成员变量的值 package cn.cuzz;import java.lang.reflect.Constructor;import java.lang.reflect.Field;public class Test4 { public static void main(String[] args) throws IllegalAccessException, Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取构造方法 Constructor con = c.getConstructor(String.class); // 通过构造方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;); // 获取指定成员变量 // public String name Field nameField = c.getField(&quot;name&quot;); // public int age Field ageField = c.getField(&quot;age&quot;); // 赋值 nameField.set(obj, &quot;Cuzz&quot;); ageField.set(obj, 23); System.out.println(&quot;name = &quot;+ nameField.get(obj)); // name = Cuzz System.out.println(&quot;age = &quot;+ ageField.get(obj)); // age = 23 }} 通过反射获取成员方法并使用在反射机制中，把类中的成员方法使用类Method表示。可通过Class类中提供的方法获取成员方法： 返回获取一个方法： public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 获取 public 修饰的方法 public Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) 获取任意的方法，包含私有的 参数1: name 要查找的方法名称； 参数2： parameterTypes 该方法的参数类型 返回获取多个方法： public Method[] getMethods() 获取本类与父类中所有public 修饰的方法 public Method[] getDeclaredMethods() 获取本类中所有的方法(包含私有的)package cn.cuzz;import java.lang.reflect.Method;public class Test5 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取多个方法 Method[] methods = c.getMethods(); Method[] methodss = c.getDeclaredMethods(); // 获取一个方法： // public void method1() Method method = c.getMethod(&quot;method1&quot;, null); System.out.println(method); // public String method4(String name){ method = c.getMethod(&quot;method4&quot;, String.class); System.out.println(method); // 私有方法 // private void method5() method = c.getDeclaredMethod(&quot;method5&quot;, null); System.out.println(method); }} 通过反射，创建对象，调用指定的方法获取成员方法，步骤如下： 获取Class对象 获取构造方法 通过构造方法，创建对象 获取指定的方法 执行找到的方法(如果获取的是私有方法则要开启暴力访问m5.setAccessible(true)) public Object invoke(Object obj, Object... args) 执行指定对象obj中，当前Method对象所代表的方法，方法要传入的参数通过args指定 package cn.cuzz;import java.lang.reflect.Constructor;import java.lang.reflect.Method;public class Test6 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取指定构造器 Constructor con = c.getConstructor(String.class, int.class, String.class); // 通过构造方法中的Constructor的方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;, 18, &quot;武汉&quot;); // 获取指定的方法 Method m4 = c.getMethod(&quot;method4&quot;, String.class); // 执行找到的方法 Object result = m4.invoke(obj, &quot;2018/03/19&quot;); System.out.println(&quot;result = &quot; + result); // result = 哈哈2018/03/19 }} 反射练习 下面展示一下反射的利用场景。 泛型擦除思考，将已存在的ArrayList&lt;Integer&gt;集合中添加一个字符串数据，如何实现呢？ 我来告诉大家，其实程序编译后产生的.class文件中是没有泛型约束的，这种现象我们称为泛型的擦除。那么，我们可以通过反射技术，来完成向有泛型约束的集合中，添加任意类型的元素 package cn.cuzz;import java.lang.reflect.Method;import java.util.ArrayList;public class Test7 { public static void main(String[] args) throws Exception, SecurityException { ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); // 添加元素 list.add(&quot;cuzz&quot;); // list.add(23); 报错 // 通过反射技术，实现添加任意类型的元素 // 获取字节码文件对象 Class c = Class.forName(&quot;java.util.ArrayList&quot;); // 找到add()方法 Method addMethod = c.getMethod(&quot;add&quot;, Object.class); // 执行add()方法 addMethod.invoke(list, 23); System.out.println(list); //[cuzz, 23] }} 反射配置文件通过配置文件得到类名和要运行的方法名,用反射的操作类名得到对象和调用方法 实现步骤: 准备配置文件,键值对 IO流读取配置文件 Reader 文件中的键值对存储到集合中 Properties集合保存的键值对,就是类名和方法名 反射获取指定类的class文件对象 class文件对象,获取指定的方法 运行方法public class Test8 { public static void main(String[] args) throws Exception{ // IO流读取配置文件 FileReader r = new FileReader(&quot;config.properties&quot;); // 创建集合对象 Properties pro = new Properties(); // 调用集合方法load,传递流对象 pro.load(r); r.close(); // 通过键获取值 String className = pro.getProperty(&quot;className&quot;); String methodName = pro.getProperty(&quot;methodName&quot;); // 反射获取指定类的class文件对象 Class c = Class.forName(className); Object obj = c.newInstance(); // 获取指定的方法名 Method method = c.getMethod(methodName); method.invoke(obj); }} 配置文件# className=cn.cuzz.Student# methodName=studyclassName=cn.cuzz.TeachermethodName=teach# className=cn.cuzz.Worker# methodName=work","link":"/2019/02/11/Java%20%E5%8F%8D%E5%B0%84/"},{"title":"Java后端核心知识","text":"算法剑指 Offer 题解Leetcode 题解算法操作系统计算机操作系统Linux网络计算机网络HTTP Brief History of HTTP Socket面向对象设计模式面向对象思想数据库数据库系统原理SQLLeetcode-Database 题解MySQL MySQL数据类型及后面小括号的意义 RedisJavaJava 基础 聊聊引用和Threadlocal的那些事 Java 容器Java 并发 Java并发编程：volatile关键字解析 大白话聊聊Java并发面试问题之volatile到底是什么？ 大白话聊聊Java并发面试问题之Java 8如何优化CAS性能？ 大白话聊聊Java并发面试问题之谈谈你对AQS的理解？ 大白话聊聊Java并发面试问题之公平锁与非公平锁是啥？ 大白话聊聊Java并发面试问题之微服务注册中心的读写锁优化 Java 虚拟机 JVM中的新生代和老年代（Eden空间、两个Survior空间） Java对象结构与锁实现原理及MarkWord详解 Java I/O NIO 入门 框架Spring Spring事务传播行为详解 中间件Netty It’s all about buffers: zero-copy, mmap and Java NIO Efficient data transfer through zero copy Scalable IO in Java Netty 那些事儿 ——— Reactor模式详解 系统设计系统设计基础分布式集群攻击技术缓存消息队列工具GitDocker构建工具正则表达式","link":"/2019/02/23/Java%E5%90%8E%E7%AB%AF%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86/"},{"title":"LRUCache","text":"LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高” 。 代码： /** * @Author: cuzz * @Date: 2019/3/16 15:35 * @Description: LRU cache */public class LRUCache { private Map&lt;Integer, DLinkedList&gt; cache = new HashMap&lt;&gt;(); private int count; private int capacity; private DLinkedList head, tail; public LRUCache(int capacity) { this.count = 0; this.capacity = capacity; this.head = new DLinkedList(); this.tail = new DLinkedList(); head.next = tail; tail.pre = head; } public int get(int key) { DLinkedList node = cache.get(key); if (node == null) { return -1; } removeNode(node); addHead(node); return node.value; } public void put(int key, int value) { DLinkedList node = cache.get(key); if (node == null) { node = new DLinkedList(key, value); addHead(node); cache.put(key, node); count++; if (count &gt; capacity) { DLinkedList preTail = tail.pre; removeNode(preTail); cache.remove(preTail.key); count--; } } else { node.value = value; removeNode(node); addHead(node); } } // 移除给定的结点 private void removeNode(DLinkedList node) { DLinkedList pre = node.pre; DLinkedList next = node.next; pre.next = next; next.pre = pre; } // 把结点添加头节点 private void addHead(DLinkedList node) { DLinkedList next = head.next; head.next = node; node.next = next; next.pre = node; node.pre = head; } public static void main(String[] args) { LRUCache cache = new LRUCache(2); cache.put(1, 1); cache.put(2, 2); System.out.println(cache.get(1)); // 返回 1 cache.put(3, 3); // 使 2 作废 System.out.println(cache.get(2)); // 返回 -1 cache.put(4, 4); // 使 1 作废 System.out.println(cache.get(1)); // 返回 -1 未找到 System.out.println(cache.get(3)); // 返回 3 System.out.println(cache.get(4)); // 返回 4 }}class DLinkedList { int key; int value; DLinkedList pre; DLinkedList next; public DLinkedList() {}; public DLinkedList(int key, int value) { this.key = key; this.value = value; }}","link":"/2019/03/16/LRUCache/"},{"title":"Let&#39;s build a Full-Text Search engine","text":"这是一篇转载文章原文地址，原文讲述如何构建一个全文搜索引擎，用的 Go 实现的，本来想翻译一下，顺便用 Java 实现一下，由于翻译出来比较生硬，还是把原文放出来，顺便把我用 Java 实现的版本放在链接中Java实现版本。 Full-Text Search is one of those tools people use every day without realizing it. If you ever googled “golang coverage report” or tried to find “indoor wireless camera” on an e-commerce website, you used some kind of full-text search. Full-Text Search (FTS) is a technique for searching text in a collection of documents. A document can refer to a web page, a newspaper article, an email message, or any structured text. Today we are going to build our own FTS engine. By the end of this post, we’ll be able to search across millions of documents in less than a millisecond. We’ll start with simple search queries like “give me all documents that contain the word cat“ and we’ll extend the engine to support more sophisticated boolean queries. Note Most well-known FTS engine is Lucene (as well as Elasticsearch and Solr built on top of it). Why FTSBefore we start writing code, you may ask “can’t we just use grep or have a loop that checks if every document contains the word I’m looking for?“. Yes, we can. However, it’s not always the best idea. CorpusWe are going to search a part of the abstract of English Wikipedia. The latest dump is available at dumps.wikimedia.org. As of today, the file size after decompression is 913 MB. The XML file contains over 600K documents. Document example: &lt;title&gt;Wikipedia: Kit-Cat Klock&lt;/title&gt;&lt;url&gt;https://en.wikipedia.org/wiki/Kit-Cat_Klock&lt;/url&gt;&lt;abstract&gt;The Kit-Cat Klock is an art deco novelty wall clock shaped like a grinning cat with cartoon eyes that swivel in time with its pendulum tail.&lt;/abstract&gt; Loading documentsFirst, we need to load all the documents from the dump. The built-in encoding/xml package comes very handy: import ( &quot;encoding/xml&quot; &quot;os&quot;)type document struct { Title string `xml:&quot;title&quot;` URL string `xml:&quot;url&quot;` Text string `xml:&quot;abstract&quot;` ID int}func loadDocuments(path string) ([]document, error) { f, err := os.Open(path) if err != nil { return nil, err } defer f.Close() dec := xml.NewDecoder(f) dump := struct { Documents []document `xml:&quot;doc&quot;` }{} if err := dec.Decode(&amp;dump); err != nil { return nil, err } docs := dump.Documents for i := range docs { docs[i].ID = i } return docs, nil} Every loaded document gets assigned a unique identifier. To keep things simple, the first loaded document gets assigned ID=0, the second ID=1 and so on. First attemptSearching the contentNow that we have all documents loaded into memory, we can try to find the ones about cats. At first, let’s loop through all documents and check if they contain the substring cat: func search(docs []document, term string) []document { var r []document for _, doc := range docs { if strings.Contains(doc.Text, term) { r = append(r, doc) } } return r} On my laptop, the search phase takes 103ms - not too bad. If you spot check a few documents from the output, you may notice that the function matches caterpillar and category, but doesn’t match Cat with the capital C. That’s not quite what I was looking for. We need to fix two things before moving forward: Make the search case-insensitive (so Cat matches as well). Match on a word boundary rather than on a substring (so caterpillar and communication don’t match). Searching with regular expressionsOne solution that quickly comes to mind and allows implementing both requirements is regular expressions. Here it is - (?i)\\bcat\\b: (?i) makes the regex case-insensitive \\b matches a word boundary (position where one side is a word character and another side is not a word character) func search(docs []document, term string) []document { re := regexp.MustCompile(`(?i)\\b` + term + `\\b`) // Don't do this in production, it's a security risk. term needs to be sanitized. var r []document for _, doc := range docs { if re.MatchString(doc.Text) { r = append(r, doc) } } return r} Ugh, the search took more than 2 seconds. As you can see, things started getting slow even with 600K documents. While the approach is easy to implement, it doesn’t scale well. As the dataset grows larger, we need to scan more and more documents. The time complexity of this algorithm is linear - the number of documents required to scan is equal to the total number of documents. If we had 6M documents instead of 600K, the search would take 20 seconds. We need to do better than that. Inverted IndexTo make search queries faster, we’ll preprocess the text and build an index in advance. The core of FTS is a data structure called Inverted Index. The Inverted Index associates every word in documents with documents that contain the word. Example: documents = { 1: &quot;a donut on a glass plate&quot;, 2: &quot;only the donut&quot;, 3: &quot;listen to the drum machine&quot;,}index = { &quot;a&quot;: [1], &quot;donut&quot;: [1, 2], &quot;on&quot;: [1], &quot;glass&quot;: [1], &quot;plate&quot;: [1], &quot;only&quot;: [2], &quot;the&quot;: [2, 3], &quot;listen&quot;: [3], &quot;to&quot;: [3], &quot;drum&quot;: [3], &quot;machine&quot;: [3],} Below is a real-world example of the Inverted Index. An index in a book where a term references a page number: Text analysisBefore we start building the index, we need to break the raw text down into a list of words (tokens) suitable for indexing and searching. The text analyzer consists of a tokenizer and multiple filters. TokenizerThe tokenizer is the first step of text analysis. Its job is to convert text into a list of tokens. Our implementation splits the text on a word boundary and removes punctuation marks: func tokenize(text string) []string { return strings.FieldsFunc(text, func(r rune) bool { // Split on any character that is not a letter or a number. return !unicode.IsLetter(r) &amp;&amp; !unicode.IsNumber(r) })} &gt; tokenize(&quot;A donut on a glass plate. Only the donuts.&quot;)[&quot;A&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;Only&quot;, &quot;the&quot;, &quot;donuts&quot;] FiltersIn most cases, just converting text into a list of tokens is not enough. To make the text easier to index and search, we’ll need to do additional normalization. LowercaseIn order to make the search case-insensitive, the lowercase filter converts tokens to lower case. cAt, Cat and caT are normalized to cat. Later, when we query the index, we’ll lower case the search terms as well. This will make the search term cAt match the text Cat. func lowercaseFilter(tokens []string) []string { r := make([]string, len(tokens)) for i, token := range tokens { r[i] = strings.ToLower(token) } return r} &gt; lowercaseFilter([]string{&quot;A&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;Only&quot;, &quot;the&quot;, &quot;donuts&quot;})[&quot;a&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;the&quot;, &quot;donuts&quot;] Dropping common wordsAlmost any English text contains commonly used words like a, I, the or be. Such words are called stop words. We are going to remove them since almost any document would match the stop words. There is no “official” list of stop words. Let’s exclude the top 10 by the OEC rank. Feel free to add more: var stopwords = map[string]struct{}{ // I wish Go had built-in sets. &quot;a&quot;: {}, &quot;and&quot;: {}, &quot;be&quot;: {}, &quot;have&quot;: {}, &quot;i&quot;: {}, &quot;in&quot;: {}, &quot;of&quot;: {}, &quot;that&quot;: {}, &quot;the&quot;: {}, &quot;to&quot;: {},}func stopwordFilter(tokens []string) []string { r := make([]string, 0, len(tokens)) for _, token := range tokens { if _, ok := stopwords[token]; !ok { r = append(r, token) } } return r} &gt; stopwordFilter([]string{&quot;a&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;the&quot;, &quot;donuts&quot;})[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donuts&quot;] StemmingBecause of the grammar rules, documents may include different forms of the same word. Stemming reduces words into their base form. For example, fishing, fished and fisher may be reduced to the base form (stem) fish. Implementing a stemmer is a non-trivial task, it’s not covered in this post. We’ll take one of the existing modules: import snowballeng &quot;github.com/kljensen/snowball/english&quot;func stemmerFilter(tokens []string) []string { r := make([]string, len(tokens)) for i, token := range tokens { r[i] = snowballeng.Stem(token, false) } return r} &gt; stemmerFilter([]string{&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donuts&quot;})[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donut&quot;] Note A stem is not always a valid word. For example, some stemmers may reduce airline to airlin. Putting the analyzer togetherfunc analyze(text string) []string { tokens := tokenize(text) tokens = lowercaseFilter(tokens) tokens = stopwordFilter(tokens) tokens = stemmerFilter(tokens) return tokens} The tokenizer and filters convert sentences into a list of tokens: &gt; analyze(&quot;A donut on a glass plate. Only the donuts.&quot;)[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donut&quot;] The tokens are ready for indexing. Building the indexBack to the inverted index. It maps every word in documents to document IDs. The built-in map is a good candidate for storing the mapping. The key in the map is a token (string) and the value is a list of document IDs: type index map[string][]int Building the index consists of analyzing the documents and adding their IDs to the map: func (idx index) add(docs []document) { for _, doc := range docs { for _, token := range analyze(doc.Text) { ids := idx[token] if ids != nil &amp;&amp; ids[len(ids)-1] == doc.ID { // Don't add same ID twice. continue } idx[token] = append(ids, doc.ID) } }}func main() { idx := make(index) idx.add([]document{{ID: 1, Text: &quot;A donut on a glass plate. Only the donuts.&quot;}}) idx.add([]document{{ID: 2, Text: &quot;donut is a donut&quot;}}) fmt.Println(idx)} It works! Each token in the map refers to IDs of the documents that contain the token: map[donut:[1 2] glass:[1] is:[2] on:[1] only:[1] plate:[1]] QueryingTo query the index, we are going to apply the same tokenizer and filters we used for indexing: func (idx index) search(text string) [][]int { var r [][]int for _, token := range analyze(text) { if ids, ok := idx[token]; ok { r = append(r, ids) } } return r} &gt; idx.search(&quot;Small wild cat&quot;)[[24, 173, 303, ...], [98, 173, 765, ...], [[24, 51, 173, ...]] And finally, we can find all documents that mention cats. Searching 600K documents took less than a millisecond (18µs)! With the inverted index, the time complexity of the search query is linear to the number of search tokens. In the example query above, other than analyzing the input text, search had to perform only three map lookups. Boolean queriesThe query from the previous section returned a disjoined list of documents for each token. What we normally expect to find when we type small wild cat in a search box is a list of results that contain small, wild and cat at the same time. The next step is to compute the set intersection between the lists. This way we’ll get a list of documents matching all tokens. Luckily, IDs in our inverted index are inserted in ascending order. Since the IDs are sorted, it’s possible to compute the intersection between two lists in linear time. The intersection function iterates two lists simultaneously and collect IDs that exist in both: func intersection(a []int, b []int) []int { maxLen := len(a) if len(b) &gt; maxLen { maxLen = len(b) } r := make([]int, 0, maxLen) var i, j int for i &lt; len(a) &amp;&amp; j &lt; len(b) { if a[i] &lt; b[j] { i++ } else if a[i] &gt; b[j] { j++ } else { r = append(r, a[i]) i++ j++ } } return r} Updated search analyzes the given query text, lookups tokens and computes the set intersection between lists of IDs: func (idx index) search(text string) []int { var r []int for _, token := range analyze(text) { if ids, ok := idx[token]; ok { if r == nil { r = ids } else { r = intersection(r, ids) } } else { // Token doesn't exist. return nil } } return r} The Wikipedia dump contains only two documents that match small, wild and cat at the same time: &gt; idx.search(&quot;Small wild cat&quot;)130764 The wildcat is a species complex comprising two small wild cat species, the European wildcat (Felis silvestris) and the African wildcat (F. lybica).131692 Catopuma is a genus containing two Asian small wild cat species, the Asian golden cat (C. temminckii) and the bay cat. The search is working as expected! By the way, this is the first time I hear about catopuma, here is one of them: ConclusionsWe just built a Full-Text Search engine. Despite its simplicity, it can be a solid foundation for more advanced projects. I didn’t touch on a lot of things that can significantly improve the performance and make the engine more user friendly. Here are some ideas for further improvements: Extend boolean queries to support OR and NOT. Store the index on disk: Rebuilding the index on every application restart may take a while. Large indexes may not fit in memory. Experiment with memory and CPU-efficient data formats for storing sets of document IDs. Take a look at Roaring Bitmaps. Support indexing multiple document fields. Sort results by relevance. The full source code is available on GitHub. I’m not a native English speaker and I’m trying to improve my language skills. Feel free to correct me if you spot any spelling or grammatical error!","link":"/2020/08/17/Let's%20build%20a%20Full-Text%20Search%20engine/"},{"title":"Shell入门","text":"Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。 Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。 Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell Shell编程之Hello World编写一个hello world shell一般使用.sh作为后缀 #!/bin/bash # 使用/bin/sh来解释执行 # auto echo hello world! # 解释这个脚本是干什么的# by authors cuzz # 作者和时间一些信息echo &quot;hello world!&quot; 给脚本添加执行权限 &gt; chmod +x hello.sh Shell编程之变量Shell变量可以分为两类：局部变量和环境变量 #!/bin/bash# define path variables# by authors cuzzname=cuzz # 等号两边不能有空格echo &quot;my name is $name&quot; # 使用$引用 基本变量 echo $PWD # 当前路径echo $0 # 脚本名echo $1 # 第一个参数echo $2 # 第二个参数echo $? # 判断上一个命令是否正确echo $* # 所有参数echo $# # 参数的个数 Shell编程之if条件语句比较大小 #!/bin/bash# if test# by authors cuzznum=100# 计算使用两个小括号if (($num &gt; 10)); then echo &quot;this num greater than 10.&quot;else echo &quot;this num littler than 10.&quot;fi 逻辑运算符 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否不相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 目录 操作符 说明 举例 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 创建文件 #!/bin/bash# if test# by authors cuzzDIR=cuzzif [ ! -d $DIR ]; then # 都有空格 mkdir $DIR echo &quot;this $DIR create success.&quot;else echo &quot;this dir is exit.&quot;fi 测试文件是否存在 #!/bin/bash# if test# by authors cuzzfile=test.txtif [ ! -e $file ]; then echo &quot;OK&quot; &gt;&gt; $file # &gt;&gt;是追加内容 &gt;是覆盖内容else cat $filefi mysql备份 #!/bin/bash# auto backup mysql db# by authors cuzz# define backup pathBAK_DIR=/data/backup/`date +%Y%m%d` # 反引号可以把里面当作命令来解析 # mysqlMYSQLDB=testMYSQLUSER=rootMYSQLPW=123456MYSQLCMD=/usr/bin/mysqldump # 备份命令# 判断是否是rootif [ $UID -ne 0 ]; then echo &quot;Only root can execute Shell.&quot; exitfiif [ ! -d $BAK_DIR ]; then mkdir -p $BAK_DIR # -p 父目录不存在就创建 echo &quot;The $BAK_DIR create success.&quot;else echo &quot;This $BAK_DIR is exist.&quot;fi# mysql backup command$MYSQLCMD -u$MYSQLUSER -p$MYSQLPW -d $MYSQLDB &gt;$BAK_DIR/$MYSQLDB.sqlif [ $? -eq 0 ]; then echo &quot;backup success.&quot;else echo &quot;backup fail.&quot;fi Shell编程之for循环基本语句 #!/bin/bashfor i in `seq 1 15`do echo &quot;the number is $i.&quot;done 求和 #!/bin/bashsum=0for ((i=1; i&lt;=100; i++)) # 双括号用于运算相当与其他语言的单括号do sum=`expr $sum + $i` # expr用于计算doneecho &quot;$sum&quot; 打包，只能打包到最后一个，后面的会把前面的覆盖了 #!/bin/bashfor file in `find ./ -name &quot;*.sh&quot;`do tar -czf all.tgz $filedone Shell编程之while循环使用 #!/bin/bashi=0while [[ $i -lt 10 ]] # (( $i &lt; 10))是一样的do echo &quot;$i&quot; ((i++))done 结合read使用 #!/bin/bashwhile read line # 把读取的东西赋值给linedo echo $linedone &lt;/etc/hosts # 从哪里读取 Shell编程之数组Shell 数组用括号来表示，元素用”空格”符号分割开，语法格式如下： my_array=(A B &quot;C&quot; D) # 定义数组array_name[0]=value0 # 使用下标来定义array_name[1]=value1array_name[2]=value2${array_name[0]} # 读取第一个元素${my_array[*]} # 读取所有元素 ${my_array[@]} # 读取所有元素${#my_array[*]} # 读取数组长度${#my_array[@]} # 读取数组长度 Shell编程之函数无返回值得函数 sayHello(){ # 定义函数一 echo &quot;hello&quot;}function sayHelloWorld(){ # 定义函数二 echo &quot;hello world&quot;}sayhell # 使用函数 有返回值得，使用return只能返回0-255 function sum(){ returnValue=$(( $1 + $2 )) return $returnValue}sum 22 4echo $? 可以使用echo来传递参数 function length(){ str=$1 result=0 if [ &quot;$str&quot; != &quot;&quot; ] ; then result=${#str} fi echo &quot;$result&quot;}len=$(length &quot;abc123&quot;) # 调用echo &quot;The string's length is $len &quot; Shell编程之sed命令把test.txt中的old修改为new，要使用-i才能插入 &gt; sed -i 's/old/new/s' test.txt 在每行行前面添加一个cuzz &gt; sed -i sed 's/^/&amp;cuzz/g' test.txt 在每行的末尾添加一个cuzz &gt; sed -i 's/$/&amp; cuzz/g' test.txt 匹配某一行，在下方插入一行，找到cuzz这行在下方插入#### &gt; sed '/cuzz/a #######' test.txt 在之前添加一行，只要把a改成i &gt; sed '/cuzz/i #######' test.txt 打印 &gt; sed -n '/cuzz/p' test.txt # 打印含有cuzz这一行&gt; sed -n '1p' test.txt # 打印第一行&gt; sed -n '1,5p' text.txt # 打印1到5行 查找最大和最小值 number.txt 12 324 56 0034 -23 345345 349- 245 345 345 0989 0459 -25 命令 cat number.txt | sed 's/ /\\n/g' | grep -v &quot;^$&quot; | sort -nr | sed -n '1p;$p'sed 's/ /\\n/g' # 把所有空格换成换行grep -v &quot;^$&quot; # 去掉所有空格sort -nr # 降序排列sed -n '1p;$p # 找出第1行和最后一行 Shell编程之grep命令 -a ：将 binary 文件以 text 文件的方式搜寻数据 -c ：计算找到 ‘搜寻字符串’ 的次数 -i ：忽略大小写的不同，所以大小写视为相同 -n ：顺便输出行号 -v ：反向选择，亦即显示出没有 ‘搜寻字符串’ 内容的那一行 –color=auto ：可以将找到的关键词部分加上颜色的显示 egrep 和grep -E 相同，可以使用正则表达式 Shell编程之awk命令# 每行按空格或TAB分割cat test.txt | awk '{print $1}' # 行匹配语句 awk '' 只能用单引号# 指定分割awk -F #-F相当于内置变量FS, 指定分割字符cat test.txt | awk -F: '{print $1}' # 以分号分割# 指定添加某些内容cat test.txt | awk -F: '{print &quot;haha&quot; $1}' # 提前出来再添加haha Shell编程之find命令基本命令 find /dir -name &quot;test.txt&quot; # 在/dir目录下查找find . -name &quot;test.txt&quot; # 在当前目录下找 find . -maxdepth 1 -name &quot;text.txt&quot; # 只遍历一层find . -type f -name &quot;text&quot; # 指定类型find . -name &quot;text&quot; -mtime -1 # 指定时间find . -size +20M # 指定大小 查找并执行其他命令 find . -name &quot;text.txt&quot; -exec rm -rf {} \\; # 后面{} \\是固定格式","link":"/2018/10/04/Shell%E5%85%A5%E9%97%A8/"},{"title":"Spring注解驱动开发（三）","text":"The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 属性赋值@value赋值使用@Value赋值 基本数值 可以写SPEL表达式 #{} 可以${}获取配置文件信息（在运行的环境变量中的值） 使用xml时候导入配置文件是 &lt;context:property-placeholder location=&quot;classpath:person.properties&quot;/&gt; 使用注解可以在配置类添加一个@PropertySource注解把配置文件中k/v保存到运行的环境中 使用${key}来获取 /** * @Author: cuzz * @Date: 2018/9/24 18:43 * @Description: */@PropertySource(value = {&quot;classpath:/person.properties&quot;})@Configurationpublic class MainConfigOfPropertyValue { @Bean public Person person() { return new Person(); }} Person 类 @Datapublic class Person { @Value(&quot;vhuj&quot;) private String name; @Value(&quot;#{20-2}&quot;) private Integer age; @Value(&quot;${person.nickName}&quot;) private String nickName;} 测试 @Testpublic void test01() { printBean(applicationContext); System.out.println(&quot;---------------------------&quot;); Person person = (Person) applicationContext.getBean(&quot;person&quot;); System.out.println(person); System.out.println(&quot;---------------------------&quot;);} 输出 ---------------------------Person(name=vhuj, age=18, nickName=三三)--------------------------- 自动装配@Autowired@Qualifier@Primary自动转配： Spring利用依赖注入（DI），完成对IOC容器中各个组件的依赖关系赋值 @Autowired自动注入: a. 默认优先按照类型去容器中寻找对应的组件，如果找到去赋值 b. 如果找到到相同类型的组件，再将属性名（BookDao bookdao）作为组件的id去容器中查找 c. 接下来还可以使用@Qualifier(&quot;bookdao&quot;)明确指定需要装配的id d. 默认是必须的，我们可以指定 @Autowired(required=false)，指定非必须 @Primary让Spring自动装配时首先装配 自动装配@Resource和@InjectSpring还支持使用@Resource (JSR250) 和@Inject (JSR330) 注解，这两个是java规范 @Resource和@Autowired一样实现自动装配功能，默认是按组件名称进行装配的 没有支持@Primary和@Autowird(required=false)的功能 自动装配其他地方的自动装配@Autowired：构造器、参数、方法属性等 标注到方法位子上@Bean+方法参数，参数从容器中获取 /** * @Author: cuzz * @Date: 2018/9/24 20:57 * @Description: */public class Boss { // 属性 @Autowired private Car car; // 构造器 如果构造器只有一个有参构造器可以省略 @Autowired public Boss(@Autowired Car car) { } public Car getCar() { return car; } // set方法 @Autowired // 参数 public void setCar(@Autowired Car car) { this.car = car; }} 自动装配Aware注入Spring底层注解自定义组件想要使用Spring容器底层的一些组件（ApplicationContext，BeanFactory 等等），自定义组件实现xxxAware，在创建对象的时候会调用接口规定的方法注入相关的组件 /** * Marker superinterface indicating that a bean is eligible to be * notified by the Spring container of a particular framework object * through a callback-style method. Actual method signature is * determined by individual subinterfaces, but should typically * consist of just one void-returning method that accepts a single * argument. */public interface Aware {} 我们实现几个常见的Aware接口 /** * @Author: cuzz * @Date: 2018/9/25 10:18 * @Description: */@Componentpublic class Red implements BeanNameAware ,BeanFactoryAware, ApplicationContextAware { private ApplicationContext applicationContext; @Override public void setBeanName(String name) { System.out.println(&quot;当前Bean的名字: &quot; + name); } @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException { System.out.println(&quot;当前的BeanFactory: &quot; + beanFactory); } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext; System.out.println(&quot;传入的ioc: &quot; + applicationContext); }} 注入到配置中测试 /** * @Author: cuzz * @Date: 2018/9/25 10:28 * @Description: */public class IOCTestAware { @Test public void test01() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAware.class); }} 测试结果 当前Bean的名字: red当前的BeanFactory: org.springframework.beans.factory.support.DefaultListableBeanFactory@159c4b8: defining beans [org.springframework.context.annotation.internalConfigurationAnnotationProcessor,org.springframework.context.annotation.internalAutowiredAnnotationProcessor,org.springframework.context.annotation.internalRequiredAnnotationProcessor,org.springframework.context.annotation.internalCommonAnnotationProcessor,org.springframework.context.event.internalEventListenerProcessor,org.springframework.context.event.internalEventListenerFactory,mainConfigOfAware,red]; root of factory hierarchy传入的ioc: org.springframework.context.annotation.AnnotationConfigApplicationContext@1e89d68: startup date [Tue Sep 25 10:29:17 CST 2018]; root of context hierarchy 把Spring自定义组件注入到容器中 原理： public interface ApplicationContextAware extends Aware {} 通过 Debug 方式，定位到 org.springframework.context.support.ApplicationContextAwareProcessor#postProcessBeforeInitialization @Overridepublic Object postProcessBeforeInitialization(final Object bean, String beanName) throws BeansException { AccessControlContext acc = null; if (System.getSecurityManager() != null &amp;&amp; (bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware || bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware || bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)) { acc = this.applicationContext.getBeanFactory().getAccessControlContext(); } if (acc != null) { AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() { @Override public Object run() { invokeAwareInterfaces(bean); return null; } }, acc); } else { invokeAwareInterfaces(bean); // 调用 } 调用下面方法进行判断，每种 xxxAware 接口中只有一种方法，并调用相应的方法 private void invokeAwareInterfaces(Object bean) { if (bean instanceof Aware) { if (bean instanceof EnvironmentAware) { ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); } if (bean instanceof EmbeddedValueResolverAware) { ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); } if (bean instanceof ResourceLoaderAware) { ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); } if (bean instanceof ApplicationEventPublisherAware) { ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); } if (bean instanceof MessageSourceAware) { ((MessageSourceAware) bean).setMessageSource(this.applicationContext); } if (bean instanceof ApplicationContextAware) { ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); } }} xxxAware都是通过xxxProcessor来处理的 比如：ApplicationContextAware 对应 ApplicationContextAwareProcessor 自动装配@Profile环境搭建Profile是Spring为我们提供可以根据当前环境，动态的激活和切换一系组件的功能 a. 使用命令动态参数激活：虚拟机参数位子加载 -Dspring.profiles.active=test b. 使用代码激活环境 我们想配置类 /** * @Author: cuzz * @Date: 2018/9/25 10:47 * @Description: */@Configurationpublic class MainConfigOfProfile { @Profile(value = &quot;test&quot;) @Bean(value = &quot;testDataSource&quot;) public DataSource testDataSource() { System.out.println(&quot;testDataSource&quot;); return null; } @Profile(value = &quot;dev&quot;) @Bean(value = &quot;devDataSource&quot;) public DataSource devDataSource() { System.out.println(&quot;devDataSource&quot;); return null; }} 测试 /** * @Author: cuzz * @Date: 2018/9/25 10:59 * @Description: */public class IOCTestProfile { @Test public void test01() { // 1. 使用无参构造器创建一个applicationContext AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(); // 2. 设置要激活的环境 applicationContext.getEnvironment().setActiveProfiles(&quot;test&quot;); // 3. 注册主配置类 applicationContext.register(MainConfigOfProfile.class); // 4. 启动刷新容器 applicationContext.refresh(); }} 输出 testDataSource","link":"/2018/09/25/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"Spring注解驱动开发（二）","text":"The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 声明周期@Bean指定初始化和销毁方法Bean的生命周期Bean的创建、初始化和销毁是由容器帮我们管理的 我们可以自定义初始化和销毁方法，容器在进行到当前生命周期的时候来调用我买自定义的初始化和销毁方法 构造（对象创建） ​ 单实例： 在容器启动的时候创建 ​ 多实例： 在每次获取的时候创建对象 指定初始化方法初始化：对象创建完成后，并赋值化，调用初始化方法 销毁：单实例是在容器关闭的时候销毁，多实例容器不会管理这个Bean，容器不会调用销毁方法 编写一个Car类 /** * @Author: cuzz * @Date: 2018/9/23 21:20 * @Description: */public class Car { public Car () { System.out.println(&quot;car constructor...&quot;); } public void init() { System.out.println(&quot;car...init...&quot;); } public void destroy() { System.out.println(&quot;car...destroy...&quot;); }} 在xml中我们可以指定init-method和destroy-method方法，如 &lt;bean id=&quot;car&quot; class=&quot;com.cuzz.bean.Car&quot; init-method=&quot;init&quot; destroy-method=&quot;destroy&quot;&gt;&lt;/bean&gt; 使用注解我们可以 /** * @Author: cuzz * @Date: 2018/9/24 12:49 * @Description: 配置类 */@Configurationpublic class MainConfigOfLifecycle { @Bean(initMethod = &quot;init&quot;, destroyMethod = &quot;destroy&quot;) public Car car() { return new Car(); }} 测试 /** * @Author: cuzz * @Date: 2018/9/24 13:00 * @Description: */public class IOCTestLifeCycle { @Test public void test01() { // 创建ioc容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfLifecycle.class); System.out.println(&quot;容器创建完成...&quot;); // 关闭容器 System.out.println(&quot;---&gt;开始关闭容器&quot;); applicationContext.close(); System.out.println(&quot;---&gt;已经关闭容器&quot;); }} 可以看出先创建car，再调用init方法，在容器关闭时销毁实例 car constructor...car...init...容器创建完成...---&gt;开始关闭容器car...destroy...---&gt;已经关闭容器 在配置数据源的时候，有很多属性赋值，销毁的时候要把连接给断开 生命周期InitializingBean和DisposableBeanInitializingBean可以通过Bean实现InitializingBean来定义初始化逻辑，是设置好所有属性会调用afterPropertiesSet()方法 public interface InitializingBean { /** * Invoked by a BeanFactory after it has set all bean properties supplied * (and satisfied BeanFactoryAware and ApplicationContextAware). * &lt;p&gt;This method allows the bean instance to perform initialization only * possible when all bean properties have been set and to throw an * exception in the event of misconfiguration. * @throws Exception in the event of misconfiguration (such * as failure to set an essential property) or if initialization fails. */ void afterPropertiesSet() throws Exception;} DisposableBean可以通过Bean实现DisposableBean来定义销毁逻辑，会调用destroy()方法 public interface DisposableBean { /** * Invoked by a BeanFactory on destruction of a singleton. * @throws Exception in case of shutdown errors. * Exceptions will get logged but not rethrown to allow * other beans to release their resources too. */ void destroy() throws Exception;} 例子编写一个Cat类 /** * @Author: cuzz * @Date: 2018/9/24 13:36 * @Description: */public class Cat implements InitializingBean, DisposableBean{ public Cat() { System.out.println(&quot;cat constructor...&quot;); } @Override public void afterPropertiesSet() throws Exception { System.out.println(&quot;cat...init...&quot;); } @Override public void destroy() throws Exception { System.out.println(&quot;cat...destroy...&quot;); }} 测试 cat constructor...cat...init...容器创建完成...---&gt;开始关闭容器cat...destroy...---&gt;已经关闭容器 生命周期@PostContruct和@PreDestroy注解@PostContruct在Bean创建完成并且属性赋值完成，来执行初始化 @PreDestroy在容器销毁Bean之前通知我们进行清理工作 编写一个Dog类，并把他注入到配置类中 /** * @Author: cuzz * @Date: 2018/9/24 14:03 * @Description: */public class Dog { public Dog() { System.out.println(&quot;dog constructor...&quot;); } @PostConstruct public void postConstruct() { System.out.println(&quot;post construct...&quot;); } @PreDestroy public void preDestroy() { System.out.println(&quot;pre destroy...&quot;); }} 测试结果 dog constructor...post construct...容器创建完成...---&gt;开始关闭容器pre destroy...---&gt;已经关闭容器 生命周期BeanPostProscessor后置处理器我们先看看源码，解释的很清楚，BeanPostProscessor 中postProcessBeforeInitialization方法会在每一个bean对象的初始化方法调用之前回调；postProcessAfterInitialization方法会在每个bean对象的初始化方法调用之后被回调 。 /** * Factory hook that allows for custom modification of new bean instances, * e.g. checking for marker interfaces or wrapping them with proxies. * * &lt;p&gt;ApplicationContexts can autodetect BeanPostProcessor beans in their * bean definitions and apply them to any beans subsequently created. * Plain bean factories allow for programmatic registration of post-processors, * applying to all beans created through this factory. * * &lt;p&gt;Typically, post-processors that populate beans via marker interfaces * or the like will implement {@link #postProcessBeforeInitialization}, * while post-processors that wrap beans with proxies will normally * implement {@link #postProcessAfterInitialization}. */public interface BeanPostProcessor { /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;before&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's {@code afterPropertiesSet} * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if {@code null}, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet */ Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;after&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's {@code afterPropertiesSet} * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * &lt;p&gt;In case of a FactoryBean, this callback will be invoked for both the FactoryBean * instance and the objects created by the FactoryBean (as of Spring 2.0). The * post-processor can decide whether to apply to either the FactoryBean or created * objects or both through corresponding {@code bean instanceof FactoryBean} checks. * &lt;p&gt;This callback will also be invoked after a short-circuiting triggered by a * {@link InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation} method, * in contrast to all other BeanPostProcessor callbacks. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if {@code null}, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet * @see org.springframework.beans.factory.FactoryBean */ Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;} 编写一个MyBeanPostProcessor实现BeanPostProcessor接口 /** * @Author: cuzz * @Date: 2018/9/24 14:21 * @Description: 后置处理器，初始化前后进行处理工作 */public class MyBeanPostProcessor implements BeanPostProcessor{ @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { System.out.println(&quot;---&gt;postProcessBeforeInitialization...&quot; + beanName +&quot;==&gt;&quot; + bean); return bean; } @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { System.out.println(&quot;---&gt;postProcessAfterInitialization...&quot; + beanName +&quot;==&gt;&quot; + bean); return bean; }} 添加到配置中 @Configurationpublic class MainConfigOfLifecycle { @Bean public Cat cat() { return new Cat(); } @Bean public MyBeanPostProcessor myBeanPostProcessor() { return new MyBeanPostProcessor(); }} 测试 ---&gt;postProcessBeforeInitialization...org.springframework.context.event.internalEventListenerProcessor==&gt;org.springframework.context.event.EventListenerMethodProcessor@1dc67c2---&gt;postProcessAfterInitialization...org.springframework.context.event.internalEventListenerProcessor==&gt;org.springframework.context.event.EventListenerMethodProcessor@1dc67c2---&gt;postProcessBeforeInitialization...org.springframework.context.event.internalEventListenerFactory==&gt;org.springframework.context.event.DefaultEventListenerFactory@2bd765---&gt;postProcessAfterInitialization...org.springframework.context.event.internalEventListenerFactory==&gt;org.springframework.context.event.DefaultEventListenerFactory@2bd765cat constructor...---&gt;postProcessBeforeInitialization...cat==&gt;com.cuzz.bean.Cat@1d3b207cat...init...---&gt;postProcessAfterInitialization...cat==&gt;com.cuzz.bean.Cat@1d3b207容器创建完成...---&gt;开始关闭容器cat...destroy...---&gt;已经关闭容器 在实例创建之前后创建之后会被执行 生命周期BeanPostProcessor原理通过debug到populateBean，先给属性赋值在执行initializeBean方法 try { populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) { exposedObject = initializeBean(beanName, exposedObject, mbd); }} initializeBean方法时， protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) { Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) { // 执行before方法 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); } ... try { // 执行初始化 invokeInitMethods(beanName, wrappedBean, mbd); } if (mbd == null || !mbd.isSynthetic()) { // 执行after方法 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); } return wrappedBean;} Spring底层对BeanPostProcessor的使用： Bean赋值、注入其他组件、@Autowired、生命周期注解功能、@Async等等都使用到了BeanPostProcessor这个接口的实现类，很重要 总结Bean 的初始化顺序 首先执行 bean 的构造方法 BeanPostProcessor 的 postProcessBeforeInitialization 方法 InitializingBean 的 afterPropertiesSet 方法 @Bean 注解的 initMethod方法 BeanPostProcesso r的 postProcessAfterInitialization 方法 DisposableBean 的 destroy 方法 @Bean注解的 destroyMethod 方法","link":"/2018/09/24/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"Spring注解驱动开发（四）","text":"AOP面向切面编程AOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 底层实现Spring 的 AOP 的底层用到两种代理机制： JDK 的动态代理 ：类必须实现接口，所以是针对实现了接口的类产生代理. Cglib 的动态代理：针对没有实现接口的类产生代理，应用的是底层的字节码增强的技术生成当前类的子类对象 JDK 的动态代理 UserService接口，实现增删改查的功能 package com.cuzz.service;public interface UserService { void add(); void delete(); void update(); void get();} UserService接口的实现的类 public class UserServiceImpl implements UserService { @Override public void add() { System.out.println(&quot;添加一个user&quot;); } @Override public void delete() { System.out.println(&quot;删除一个user&quot;); } @Override public void update() { System.out.println(&quot;更新一个user&quot;); } @Override public void get() { System.out.println(&quot;查询一个user&quot;); }} 实现动态代理 package com.cuzz.service;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class UserServiceProxyFactory implements InvocationHandler{ private UserService us; public UserServiceProxyFactory(UserService us) { super(); this.us = us; } // 获得动态代理 public UserService getUserServiceProxy() { // 生成动态代理 UserService usProxy = (UserService) Proxy.newProxyInstance(UserServiceProxyFactory.class.getClassLoader(), UserServiceImpl.class.getInterfaces(), this); // 这个 this 就是实现 InvocationHandler 的对象 return usProxy; } @Override public Object invoke(Object arg0, Method method, Object[] arg2) throws Throwable { System.out.println(&quot;打开事务!&quot;); Object invoke = method.invoke(us, arg2); System.out.println(&quot;提交事务!&quot;); return invoke; }} 测试 public class TestDemo { @Test public void test01(){ UserService us = new UserServiceImpl(); UserServiceProxyFactory factory = new UserServiceProxyFactory(us); UserService usProxy = factory.getUserServiceProxy(); usProxy.add(); }} 输出 打开事务!添加一个user提交事务! Cglib 的动态代理 Cglib 的动态代理的代码实现 package com.cuzz.service;import java.lang.reflect.Method;import org.springframework.cglib.proxy.Enhancer;import org.springframework.cglib.proxy.MethodInterceptor;import org.springframework.cglib.proxy.MethodProxy;public class UserServiceProxyFactory2 implements MethodInterceptor { public UserService getUserServiceProxy(){ // 帮我们生成代理对象 Enhancer en = new Enhancer(); // 设置对谁进行代理 en.setSuperclass(UserServiceImpl.class); // 代理要做什么 en.setCallback(this); // 创建代理对象 UserService us = (UserService) en.create(); return us; } @Override public Object intercept(Object prxoyobj, Method method, Object[] arg, MethodProxy methodProxy) throws Throwable { // 打开事务 System.out.println(&quot;打开事务!&quot;); // 调用原有方法 Object returnValue = methodProxy.invokeSuper(prxoyobj, arg); // 提交事务 System.out.println(&quot;提交事务!&quot;); return returnValue; }} 测试 @Testpublic void test02() { UserServiceProxyFactory2 factory = new UserServiceProxyFactory2(); UserService usProxy = factory.getUserServiceProxy(); usProxy.add();} Spring的AOP开发(基于AspectJ)AOP的开发中的相关术语： Joinpoint(连接点)：所谓连接点是指那些被拦截到的点，在 spring 中这些点指的是方法，因为 spring 只支持方法类型的连接点 Pointcut(切入点)：所谓切入点是指我们要对哪些 Joinpoint 进行拦截的定义 Advice(通知/增强)：所谓通知是指拦截到 Joinpoint 之后所要做的事情就是通知.通知分为前置通知,后置通知,异常通知,最终通知,环绕通知(切面要完成的功能) Introduction(引介)：引介是一种特殊的通知在不修改类代码的前提下, Introduction 可以在运行期为类动态地添加一些方法或 Field Target(目标对象)：代理的目标对象 Weaving(织入)：是指把增强应用到目标对象来创建新的代理对象的过程，spring 采用动态代理织入，而 AspectJ 采用编译期织入和类装在期织入 Proxy（代理）：一个类被 AOP 织入增强后，就产生一个结果代理类 Aspect(切面)：是切入点和通知（引介）的结合 通知类型 前置通知 ：在目标方法执行之前执行 后置通知 ：在目标方法执行之后执行 环绕通知 ：在目标方法执行前和执行后执行 异常抛出通知：在目标方法执行出现异常的时候执行 最终通知 ：无论目标方法是否出现异常 最终通知都会执行 代码演示通知类，给切面的目标方法标注何时地运行，必须告诉 Spring 哪个类是切面类，添加注解 @Aspect @Aspect // 表示该类是一个通知类public class MyAdvice { // 前置通知 @Before(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void before(){ System.out.println(&quot;这是前置通知!!&quot;); } // 后置通知 @AfterReturning(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void afterReturning(){ System.out.println(&quot;这是后置通知(如果出现异常不会调用)!!&quot;); } // 环绕通知 @Around(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public Object around(ProceedingJoinPoint pjp) throws Throwable { System.out.println(&quot;这是环绕通知之前的部分!!&quot;); // 调用目标方法 Object proceed = pjp.proceed(); System.out.println(&quot;这是环绕通知之后的部分!!&quot;); return proceed; } // 异常通知 @AfterThrowing(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void afterException(){ System.out.println(&quot;出事啦!出现异常了!!&quot;); } // 后置通知 @After(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void after(){ System.out.println(&quot;这是后置通知(出现异常也会调用)!!&quot;); }} 配置类，将切面类和业务逻辑类都加入到容器中，给配置类加 @EnableAspectJAutoProxy 注解 /** * @Author: cuzz * @Date: 2019/2/10 20:43 * @Description: */@Configuration@EnableAspectJAutoProxypublic class MainConfigOfAOP { @Bean public UserService userService() { return new UserServiceImpl(); } @Bean public MyAdvice myAdvice() { return new MyAdvice(); }} 测试 @Testpublic void test03() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAOP.class); UserService userService = (UserService) applicationContext.getBean(&quot;userService&quot;); userService.add(); userService.delete(); userService.update(); userService.get();} 如果报错添加依赖 &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.4&lt;/version&gt; &lt;/dependency&gt;","link":"/2019/02/10/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"jQuery学习","text":"jQuery是一个快速、简洁的JavaScript框架 jQuery设计的宗旨是“write Less，Do More” 初识jQueryjQuery是一个快速、简洁的JavaScript框架，是继Prototype之后又一个优秀的JavaScript代码库（或JavaScript框架）。jQuery设计的宗旨是“write Less，Do More”，即倡导写更少的代码，做更多的事情。它封装JavaScript常用的功能代码，提供一种简便的JavaScript设计模式，优化HTML文档操作、事件处理、动画设计和Ajax交互 总结来说为下面三点： jQuery 是一个 JavaScript jQuery 极大地简化了 JavaScript 编程 jQuery 很容易学习 使用jQuery编写HelloWorld 下载jQuery库 引入jQuery&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;01-初识jQuery&lt;/title&gt; &lt;script src=&quot;js/jquery-1.11.3/jquery.js&quot;&gt;&lt;/script&gt;&lt;/head&gt; 编写helloWorld&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;02-jQuery-HelloWorld&lt;/title&gt; &lt;script src=&quot;js/jquery-1.11.3/jquery.js&quot;&gt;&lt;/script&gt; &lt;script&gt; // 原生js的固定写法 window.onload = function(ev) { }; // jQuery的固定写法 $(document).ready(function () { alert(&quot;Hello World&quot;); }); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; jQuery和js入口函数的区别&lt;script&gt; window.onload = function (ev) { // 通过原生的js入口函数可以拿到Dom元素 var img = document.getElementsByTagName(&quot;img&quot;)[0]; console.log(img); // 通过原生的js入口函数可以拿到dom元素的宽高 var width = window.getComputedStyle(img).width; console.log(width); }; $(document).ready(function () { // 通过jQuery入口函数可以拿到Dom元素 var $img = $(&quot;img&quot;)[0]; console.log($img); // 通过jQuery入口函数不能拿到dom元素的宽高 var $width = $img.width(); console.log($width); });&lt;/script&gt; 区别: 原生jQuery入口函数的加载模式不同 原生js会等到dom加载完毕，并且图片也加载完毕才会执行 jQuery会等到dom加载完毕，但不会等到图片也加载完毕就会执行 &lt;script&gt; window.onload = function (ev) { alert(&quot;hello cuzz&quot;); // 不会显示 }; window.onload = function (ev) { alert(&quot;hello cuxx&quot;); // 会显示 };&lt;/script&gt;&lt;script&gt; $(document).ready(function () { alert(&quot;hello cuzz&quot;); // 会显示 }); $(document).ready(function () { alert(&quot;hello cuxx&quot;); // 会显示 });&lt;/script&gt; 区别： 多个window.onload只会执行一次, 后面的会覆盖前面的 多个$(document).ready()会执行多次,后面的不会覆盖前面的 原因：jQuery框架本质是一个闭包，每次执行我们都会给ready函数传递一个新的函数，不同函数内部的数据不会相互干扰 &lt;script&gt; // 相当于这样写 var test1 = function () { alert(&quot;hello cuzz&quot;); } var test2 = function () { alert(&quot;hello cuxx&quot;); } $(document).ready(test1); $(document).ready(test2);&lt;/script&gt; 对比： window.onload $(document).ready() 执行时机 必须等待网页全部加载完毕(包括 图片等),然后再执行包裹代码 只需要等待网页中的DOM结构 加载完毕,就能执行包裹的代码 执行次数 只能执行一次,如果第二次,那么 第一次的执行会被覆盖 可以执行多次,第N次都不会被上 一次覆盖 简写方案 无 $(function () { }); jQuery的四种写法&lt;script&gt; // 第一种写法 $(document).ready(function () { alert(&quot;hello cuzz&quot;); }); // 第二种写法 jQuery(document).ready(function () { alert(&quot;hello cuzz&quot;); }); // 第三种写法 $(function () { alert(&quot;hello cuzz&quot;); }); // 第四种写法 jQuery(function () { alert(&quot;hello cuzz&quot;); });&lt;/script&gt; 推荐使用第三种写法 jQuery的核心函数 jQuery(callback)，当dom加载完成之后执行传入的回调函数&lt;script&gt; $(function () { alert(&quot;123&quot;); });&lt;/script&gt; jQuery([sel,[context]])，接收一个包含 CSS 选择器的字符串，然后用这个字符串去匹配一组元素,并包装成jQuery对象&lt;script&gt; $(function () { // 利用jQuery获取的div,得到的是一个jQuery对象 var $box = $(&quot;div&quot;); console.log($box); // 利用原生js语法获取的div,得到的是一个js对象 var box = document.getElementsByTagName(&quot;div&quot;); console.log(box); });&lt;/script&gt; 原生JS对象和jQuery对象相互转换 jQuery(html, [ownerDoc]) 根据 HTML 标记字符串，动态创建DOM 元素&lt;script&gt; $(function () { var $eles = $(&quot;&lt;p&gt;我是span&lt;/p&gt;&lt;u&gt;我是u&lt;/u&gt;&quot;); // 无论是jQuery找到的还是创建的,我们最终拿到的永远都是jQuery对象 console.log($eles); // 将创建好的DOM元素添加到body中 $(&quot;body&quot;).append($eles); });&lt;/script&gt; jQuery的本质是一个伪数组，有0到length-1的属性jQuery静态方法 静态方法&lt;script&gt; // 定义一个类 function AClass() { }; // 给这个类添加一个静态方法 AClass.staticMethod = function () { alert(&quot;staticMethod&quot;) }; // 静态方法的调用 AClass.staticMethod();&lt;/script&gt; 实例方法&lt;script&gt; // 定义一个类 function AClass() { } // 给这个类添加一个实例方法 AClass.prototype.instanceMethod = function () { alert(&quot;instanceMethod&quot;); } // 实例方法的调用 var a = new AClass(); a.instanceMethod();&lt;/script&gt; 常用静态方法 $.each(object, [callback])$(function () { // 遍历数组 var arr = [1, 3, 5, 7, 9]; // 通过原生方法遍历数组 // 第一个回调函数参数是遍历到的元素 // 第二个回调函数参数是当前遍历的索引 // 返回值: 没有返回值 var res = arr.forEach(function (ele, idx) { console.log(idx, ele); }); console.log(res); // 通过jQuery静态方法遍历数组 // 第一个回调函数参数是当前遍历的索引 // 第二个回调函数参数是遍历到的元素 // 返回值: 被遍历的数组 var $res2 = $.each(arr, function (idx, ele) { console.log(idx, ele); }); console.log($res2); // 遍历对象 var obj = {name: &quot;&quot;, age:&quot;33&quot;, gender:&quot;male&quot;}; // js对象没有forEach方法,所以通过forin方法遍历对象 for(var key in obj){ console.log(key, obj[key]); } // 通过jQuery静态方法遍历对象 $.each(obj,function (key, value) { console.log(key, value); });}); $.holdReady(hold)，传入true或false来暂停或则恢复ready()事件 $.trim(str) 去掉字符串起始和结尾的空格 $.isArray(obj) 判断是否是数组 $.isFunction(obj)判断是否是函数 $.isWindow(obj)判断是否是window对象学习网站在网上，发现菜鸟教程比较详细，排版也比较好，不再更新jQuery","link":"/2018/06/24/jQuery%E5%AD%A6%E4%B9%A0/"},{"title":"关于null的思考","text":"写代码的时候有个地方需要把 Integer 类型强转为 String Integer firstEventType = eventTask.getEventType1();String firstEventTypeName = eventTypeService.queryDescByCode(String.valueOf(firstEventType)); 当我点开 String#valueof 这个静态方式时 public static String valueOf(Object obj) { return (obj == null) ? &quot;null&quot; : obj.toString();} 当我们没有获取到 firstEventType 这个值时，为 null，此时它返回给我们的是字符串 “null” ，有时候就不符合我们的业务场景，最好是提前做空值判断。 看下面一个例子 Integer i = null;System.out.println(String.valueOf(i)); // 输出 nullSystem.out.println(String.valueOf(null)); // 空指针 感觉很奇怪，竟然输出结果不一样。 看看这两个重载方法 public static String valueOf(Object obj) { return (obj == null) ? &quot;null&quot; : obj.toString();}public static String valueOf(char data[]) { return new String(data);} 凭直觉来看以为String.valueOf(null) 会选择第一做为 valueOf(Object obj) 这个从载方法，然而选择的是valueOf(char data[]) 所以会报空指针异常。 下面是查到官方文档 https://docs.oracle.com/javase/specs/jls/se7/html/jls-15.html#jls-15.12.2.5 如果第一个方法处理的任何调用都可以传递给另一个没有编译时类型错误的调用，那么一个方法比另一个方法更具体。 从意思来看 valueOf(char data[]) 比 valueOf(Object obj) 更具体。 我们非常痛恨的 null 到底是什么 Java 语言定义 There is also a special null type, the type of the expression null, which has no name. Because the null type has no name, it is impossible to declare a variable of the null type or to cast to the null type. The null reference is the only possible value of an expression of null type. The null reference can always be cast to any reference type. In practice, the programmer can ignore the null type and just pretend that null is merely a special literal that can be of any reference type.","link":"/2019/06/03/%E5%85%B3%E4%BA%8Enull%E7%9A%84%E6%80%9D%E8%80%83/"},{"title":"堆排序","text":"今天看到一篇面经，算法题是手写堆排序，《算法》放在书架已经有一段时间了，想试试能不能写出来，然而并没有，所以记录一下 自顶到底构造堆这是一道 lintcode上面的题目堆化 构造一个堆只需要从左到右遍历数组，每次只要保证所遍历到的位子能满足堆的条件 public class Solution { /* * @param A: Given an integer array * @return: nothing */ public void heapify(int[] A) { for (int i = 0; i &lt; A.length; i++) { swim(A, i); } } // 上浮 private void swim(int[] A, int i) { while(i &gt; 0 &amp;&amp; A[i] &lt; A[(i-1) / 2]) { swap(A, i, (i-1) / 2); i = (i-1) / 2; } } private void swap(int[] A, int i, int j) { int temp = A[i]; A[i] = A[j]; A[j] = temp; }} 自底到顶构造堆而堆排序采用的是自底到顶构造堆，每次把第一个元素和最后一个元素交换，交换之后把第一个元素下沉，同时堆数组减一，下面是代码 public class Heap { private static void heapSort(int[] array) { int len = array.length - 1; for (int i = (len - 1) / 2; i &gt;= 0; i--) { sink(array, i, len); } printArr(array); while (len &gt;= 0) { swap(array, 0, len); sink(array, 0, --len); } } private static void sink(int[] array, int i, int len) { while (i * 2 + 1 &lt;= len) { int j = i * 2 + 1; if (j + 1 &lt;= len &amp;&amp; array[j+1] &gt; array[j]) j++; if (array[i] &gt; array[j]) break; swap(array, i, j); i = j; } } private static void swap(int[] array, int i, int j) { int temp = array[i]; array[i] = array[j]; array[j] = temp; } public static void main(String[] args) { int[] array = {2, 3, 1, 6, 4, 5, 2, 1}; heapSort(array); printArr(array); } private static void printArr(int[] array) { Arrays.stream(array).forEach(a -&gt; System.out.print(a + &quot; &quot;)); System.out.println(); }}","link":"/2018/11/23/%E5%A0%86%E6%8E%92%E5%BA%8F/"},{"title":"分布式事务框架Seata","text":"分布式基础CAP 定理CAP 定理指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可兼得。在分布式系统中，分区容错性是必须需要实现的。所以只能在一致性和可用性之间进行权衡（AP 或者 CP）。 BASE 理论BASE 是 Basically Available（基本可用）、Soft state（软状态）和 Eventually consistent（最终一致性）三个短语的缩写。是对 CAP 中 AP 的一个扩展 BA 基本可用：分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。 S 软状态：允许系统中存在中间状态，这个状态不影响系统可用性，这里指的是 CAP 中的不一致。 E 最终一致：最终一致是指经过一段时间后，所有节点数据都将会达到一致。 BASE 解决了 CAP 中理论没有网络延迟，在 BASE 中用软状态和最终一致，保证了延迟后的一致性。 BASE 和 ACID 是相反的，它完全不同于 ACID 的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。 分布式事务实现方式 XA 方案(两阶段提交) TCC 方案 本地消息表 可靠消息最终一致性方案 最大努力通知方案 Seata简介Seata (Simple Extensible Autonomous Transaction Architecture) 是阿里巴巴开源的分布式事务中间件，，解决微服务场景下面临的分布式事务问题。 具体看 Seata 官网： Seata主要由三个重要组件组成： Transaction Coordinator(TC)：管理全局的分支事务的状态，用于全局性事务的提交和回滚。 Transaction Manager(TM)：事务管理器，用于开启全局事务、提交或者回滚全局事务，是全局事务的开启者。 Resource Manager(RM)：资源管理器，用于分支事务上的资源管理，向 TC 注册分支事务，上报分支事务的状态，接受 TC 的命令来提交或者回滚分支事务。 Seata 两种模式Seata 关注的就是微服务架构下的数据一致性问题，是一整套的分布式事务解决方案。Seata 框架包含两种模式，一种是 AT 模式。AT 模式主要从数据分片的角度，关注多 DB 访问的数据一致性，当然也包括多服务下的多 DB 数据访问一致性问题。 另外一个就是 TCC 模式，TCC 模式主要关注业务拆分，在按照业务横向扩展资源时，解决微服务间调用的一致性问题，保证读资源访问的事务属性。 AT 模式AT 模式是通过两段提交的方式实现，AT 模式下，把每个数据库被当做是一个 Resource，Seata 里称为 DataSource Resource。业务通过 JDBC 标准接口访问数据库资源时，Seata 框架会对所有请求进行拦截，做一些操作。每个本地事务提交时，Seata RM（Resource Manager，资源管理器） 都会向 TC（Transaction Coordinator，事务协调器） 注册一个分支事务。当请求链路调用完成后，发起方通知 TC 提交或回滚分布式事务，进入二阶段调用流程。此时，TC 会根据之前注册的分支事务回调到对应参与者去执行对应资源的第二阶段。TC 是怎么找到分支事务与资源的对应关系呢？每个资源都有一个全局唯一的资源 ID，并且在初始化时用该 ID 向 TC 注册资源。在运行时，每个分支事务的注册都会带上其资源 ID。这样 TC 就能在二阶段调用时正确找到对应的资源。 这就是我们的 AT 模式。简单总结一下，就是把每个数据库当做一个 Resource，在本地事务提交时会去注册一个分支事务。 这种模式是对业务零入侵，并发没那么高。 TCC 模式TCC 模型是把锁的粒度完全交给业务处理，它需要每个子事务业务都实现Try-Confirm / Cancel 接口。 TCC 模式本质也是 2PC ，只是 TCC 在应用层控制。 Try: 尝试执行业务 完成所有业务检查（一致性） 预留必须业务资源（准隔离性） Confirm: 确认执行业务； 真正执行业务，不作任何业务检查 只使用Try阶段预留的业务资源 Confirm 操作满足幂等性 Cancel: 取消执行业务 释放Try阶段预留的业务资源 Cancel操作满足幂等性 这三个阶段，都会按本地事务的方式执行。不同于 XA 的 prepare ，TCC 无需将 XA 的投票期间的所有资源挂起，因此极大的提高了吞吐量。 那么对应到 TCC 模式里，也是一样的，Seata 框架把每组 TCC 接口当做一个 Resource，称为 TCC Resource。这套 TCC 接口可以是 RPC，也以是服务内 JVM 调用。在业务启动时，Seata 框架会自动扫描识别到 TCC 接口的调用方和发布方。如果是 RPC 的话，就是 sofa:reference、sofa:service、dubbo:reference、dubbo:service 等。 扫描到 TCC 接口的调用方和发布方之后。如果是发布方，会在业务启动时向 TC 注册 TCC Resource，与 DataSource Resource 一样，每个资源也会带有一个资源 ID。 如果是调用方，Seata 框架会给调用方加上切面，与 AT 模式一样，在运行时，该切面会拦截所有对 TCC 接口的调用。每调用一次 Try 接口，切面会先向 TC 注册一个分支事务，然后才去执行原来的 RPC 调用。当请求链路调用完成后，TC 通过分支事务的资源 ID 回调到正确的参与者去执行对应 TCC 资源的 Confirm 或 Cancel 方法。 在讲完了整个框架模型以后，大家可能会问 TCC 三个接口怎么实现。因为框架本身很简单，主要是扫描 TCC 接口，注册资源，拦截接口调用，注册分支事务，最后回调二阶段接口。最核心的实际上是 TCC 接口的实现逻辑。下面我将根据蚂蚁金服内部多年的实践来为大家分析怎么实现一个完备的 TCC 接口。 运行 Demo官方Demo 下面是 dubbo 的例子，运行后报错可以看到回滚信息： INFO [rpcDispatch_RMROLE_4_8] - onMessage:xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchType=AT,resourceId=jdbc:mysql://localhost:3306/fescar_demo?serverTimezone=UTC,applicationData=null INFO [rpcDispatch_RMROLE_4_8] - Branch Rollbacking: 10.116.22.63:8091:2016481020 2016481022 jdbc:mysql://localhost:3306/fescar_demo?serverTimezone=UTC INFO [rpcDispatch_RMROLE_4_8] - xid 10.116.22.63:8091:2016481020 branch 2016481022, undo_log deleted with GlobalFinished INFO [rpcDispatch_RMROLE_4_8] - Branch Rollbacked result: PhaseTwo_RollbackedDEBUG [rpcDispatch_RMROLE_4_8] - branch rollback result:xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchStatus=PhaseTwo_Rollbacked,result code =Success,getMsg =null INFO [rpcDispatch_RMROLE_4_8] - RmRpcClient sendResponse xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchStatus=PhaseTwo_Rollbacked,result code =Success,getMsg =nullDEBUG [rpcDispatch_RMROLE_4_8] - send response:xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchStatus=PhaseTwo_Rollbacked,result code =Success,getMsg =null,channel:[id: 0xc8027ef7, L:/127.0.0.1:62873 - R:/127.0.0.1:8091] 注意： 数据库驱动与 Mysql 版本一致 数据库 rul 添加时区 jdbc.account.url=jdbc:mysql://localhost:3306/fescar_demo?serverTimezone=UTC 参考链接Seata AT 模式分布式事务源码分析 分布式事务 Seata TCC 模式深度解析","link":"/2019/07/10/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%A1%86%E6%9E%B6Seata/"},{"title":"实习记录","text":"实习一段时间了，说说最近的感受吧 我是转行的，现在是一名材料计算的研究生，为什么要说材料计算呢，我是希望去面试的时候至少有计算这两个字，HR至少会觉得我跟计算机有点靠边，减少被HR给过滤掉 学java大概半年了，把java基础学完，在慕课网上找了一个实战课程，这是我部署上线的网站（还没写完），就去找实习了 由于是暑假，老师管的也没那么严，不用去实验室 刚开始的时候，不是很自信，在拉钩、Boss直聘和智联投简历，大概投了100来份，收到5-6个面试，武汉的夏天真的热，最气愤的是，遇到一两个培训机构，浪费时间，后来去面试都会在网上先查查，刚开始面试的都是一些小公司，小公司基本都是问你项目，然而我项目经验又不多，基本上都是回去等消息 接着面试了另一家小公司，公司的老板和我是一个学校的，跟我聊的也很不错，本来打算在这里实习的，后来收到良品的实习offer，就没去了，也跟这位学长沟通了，他也支持我 后来良品铺子打电话给我，让我去面试，良品铺子在武汉来说算比较大的企业，面试我的是一名架构师，大公司比较喜欢问基础，我对java基础掌握的还不错，答的也还可以，得到了他的认可，后面的面试就很轻松，他还主动要帮我加工资，后来我就认他当我师傅，真的很好，很感谢他 他还夸我基础挺好的，后来被我分配到外卖组，也是比较好的组，属于电商，所用的技术也是比较新 来组里又碰到了同一个学校的小师兄还是老乡，真是太幸运了，还有我组长，人都超级nice，也从他们那里学到很多 平时把需求做完，自己看看博客，看看书，学学公司所有的框架，发现公司用的框架很多都是阿里的，比起以前在工厂实习简直太爽了 实习这一段时间自己的提升真的很多，所以有机会一定要出去实习，平时我们部门还会组织技术分享，也可以增加自己的眼界，平时遇到问题，也可以快速寻求帮助，快速解决问题，知道一个公司是怎么开发产品的 最后收获最多的还是自信，刚开始觉得自己不是科班的有点不太自信，实习汇报完后小师兄说我学习能力比较强，上手快，不用让他操心，我的组长对我的评价说我达到2年的水平，哈哈，真的把我高兴坏了，我们的组长的boss也给我的评价也不错，我不是来炫耀这些，只是这些肯定给我很大的信心，让我在转行的道路上越走越有勇气，最后还是要靠自己努力，平时多写写代码，多看看书 最后感谢在我转行时所遇见的这些人。","link":"/2018/07/23/%E5%AE%9E%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"title":"实习结束篇","text":"昨天提交了离职信，完了成了一系列辞职手续 总经理找我聊了一会，谈了谈人生规划，很感谢他能给予我建议，也希望我毕业后能再回公司 先是和我师父告别，师父先是询问了我的情况，后来把我带到公司楼下聊了一会，询问了我一下规划，总结一下他给我提的意见 毕业刚出去，先去一线互联网城市，首先选择大厂，前三年不要太在意工资，主要是眼界 不要本末倒置，现在不要天天去背那些面试题和刷题，当前重要的是知识的沉淀，把公司用到的中间件，好好研究一下，不要只是看看，而要动手去搭建 不是科班出身的，身边缺少这种技术的氛围，平时多努力努力，多认识认识朋友 学校有项目，即使没报酬，也要去参与，多积累经验 然后是跟外卖组的人告别，感谢组长CJG，小师兄HL，以及CWZ，BW，NZ这些人对我的帮助，这一段时间在这里学习到了许多，感谢这些人 HL小师兄，也单独和我聊了聊，询问了我的情况，也给我一些工作经验，不能被人影响到自己，平时做事认真一点，不要担心犯错等 小师兄还送我下楼，最后小师兄拥抱一个就告别了 走到地铁站发现身上还有一张48的的士票还没报，又回公司了 然后又跟同事告别了一波","link":"/2018/09/10/%E5%AE%9E%E4%B9%A0%E7%BB%93%E6%9D%9F%E7%AF%87/"},{"title":"深入理解Java虚拟机（四）","text":"synchronized 字节码分析我们先来看一下一个简单的方法 /** * @Author: cuzz * @Date: 2019/3/4 13:34 * @Description: */public class MyTest02 { int x = 0; public void setX(int x) { this.x = x; }} 使用 javap -v com.cuzz.jvm.bytecode.MyTest02 命令，找到 setX 方法 public void setX(int); descriptor: (I)V flags: ACC_PUBLIC Code: stack=2, locals=2, args_size=2 0: aload_0 1: iload_1 2: putfield #2 // Field x:I 5: return LineNumberTable: line 12: 0 line 13: 5 LocalVariableTable: Start Length Slot Name Signature 0 6 0 this Lcom/cuzz/jvm/bytecode/MyTest02; 0 6 1 x I 如果我们在方法中添加 synchronzied 关键字 public class MyTest02 { int x = 0; public synchronized void setX(int x) { this.x = x; }} 我们再反编译一下 public synchronized void setX(int); descriptor: (I)V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=2, locals=2, args_size=2 0: aload_0 1: iload_1 2: putfield #2 // Field x:I 5: return LineNumberTable: line 12: 0 line 13: 5 LocalVariableTable: Start Length Slot Name Signature 0 6 0 this Lcom/cuzz/jvm/bytecode/MyTest02; 0 6 1 x I 对比这两个反编译的结果，我们发现在 flags 中多了 ACC_SYNCHRONIZED，不会出现 monitorenter 和 monitorexit。 如果我们是在方法体重添加 synchronized 关键字 public class MyTest02 { String lock = &quot;lock&quot;; int x = 0; public int getX() { synchronized (lock) { return x; } }} 我们反编译一下 找到 getX 方法 public int getX(); descriptor: ()I flags: ACC_PUBLIC Code: stack=2, locals=3, args_size=1 0: aload_0 1: getfield #3 // Field lock:Ljava/lang/String; 4: dup 5: astore_1 6: monitorenter 7: aload_0 8: getfield #4 // Field x:I 11: aload_1 12: monitorexit 13: ireturn 14: astore_2 15: aload_1 16: monitorexit 17: aload_2 18: athrow Exception table: from to target type 7 13 14 any 14 17 14 any LineNumberTable: line 17: 0 line 18: 7 line 19: 14 LocalVariableTable: Start Length Slot Name Signature 0 19 0 this Lcom/cuzz/jvm/bytecode/MyTest02; StackMapTable: number_of_entries = 1 frame_type = 255 /* full_frame */ offset_delta = 14 locals = [ class com/cuzz/jvm/bytecode/MyTest02, class java/lang/Object ] stack = [ class java/lang/Throwable ] 在 6 中出现 monitorenter，在 16 中出现 moniterexit","link":"/2019/03/04/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"生产者消费者","text":"维基百科解释： In computing, the producer–consumer problem[1][2] (also known as the bounded-buffer problem) is a classic example of a multi-process synchronization problem. The problem describes two processes, the producer and the consumer, who share a common, fixed-size buffer used as a queue. The producer’s job is to generate data, put it into the buffer, and start again. At the same time, the consumer is consuming the data (i.e., removing it from the buffer), one piece at a time. The problem is to make sure that the producer won’t try to add data into the buffer if it’s full and that the consumer won’t try to remove data from an empty buffer. import java.util.LinkedList;import java.util.List;import java.util.Random;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;/** * @Author: cuzz * @Date: 2019/4/6 13:03 * @Description: 生产者消费者 */public class ProducerConsumerDemo { public static void main(String[] args) { Container container = new Container(); ExecutorService executor = Executors.newFixedThreadPool(2); executor.execute(() -&gt; container.produce()); executor.execute(() -&gt; container.consume()); executor.shutdown(); }}class Container { private List&lt;Integer&gt; list = new LinkedList&lt;&gt;(); private final int MAX_SIZE = 5; private Random random = new Random(); public void produce() { while (true) { synchronized (this) { try { while (list.size() &gt;= MAX_SIZE) { wait(); } int i = random.nextInt(); System.out.println(&quot;produce...&quot; + i); list.add(i); notify(); Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } } } public void consume() { while (true) { try { synchronized (this) { while (list.isEmpty()) { wait(); } int i = list.remove(0); System.out.println(&quot;consume...&quot; + i); notify(); Thread.sleep(1000); } } catch (InterruptedException e) { e.printStackTrace(); } } }}","link":"/2019/04/06/%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85/"},{"title":"面试高频题","text":"如何控制线程打印顺序使用 join 方法如下面代码所示： public class ThreadDemo { public static void main(String[] args) throws InterruptedException { final Thread thread1 = new Thread(() -&gt; System.out.println(&quot;thread1&quot;)); final Thread thread2 = new Thread(() -&gt; System.out.println(&quot;thread2&quot;)); final Thread thread3 = new Thread(() -&gt; System.out.println(&quot;thread3&quot;)); thread1.start(); thread1.join(); thread2.start(); thread2.join(); thread3.start(); thread3.join(); }} 通过 join 方法去保证多线程的顺序的特性，join 主要让主线程等待子线程结束后才能继续运行。 使用 Executors.newpublic class ThreadDemo { public static void main(String[] args) throws InterruptedException { final Thread thread1 = new Thread(() -&gt; System.out.println(&quot;thread1&quot;)); final Thread thread2 = new Thread(() -&gt; System.out.println(&quot;thread2&quot;)); final Thread thread3 = new Thread(() -&gt; System.out.println(&quot;thread3&quot;)); ExecutorService executorService = Executors.newSingleThreadExecutor(); executorService.submit(thread1); executorService.submit(thread2); executorService.submit(thread3); executorService.shutdown(); }} 看看源码就知道了，使用阻塞队列来维护任务，是任务有序进行。 /** * Creates an Executor that uses a single worker thread operating * off an unbounded queue. (Note however that if this single * thread terminates due to a failure during execution prior to * shutdown, a new one will take its place if needed to execute * subsequent tasks.) Tasks are guaranteed to execute * sequentially, and no more than one task will be active at any * given time. Unlike the otherwise equivalent * {@code newFixedThreadPool(1)} the returned executor is * guaranteed not to be reconfigurable to use additional threads. * * @return the newly created single-threaded Executor */public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));} Java 中的 volatile 和 synchronized JMM（Java Memory Mode）：解决并发过程中可见性、原子性和有序性的问题。 并发过程中的两个关键问题 线程之间如何通信 共享内存：隐身通信 消息传递：显示通信，如 wait() / notify() / notifyall() 线程之间如何同步 线程同步指的是：程序用于控制不同线程先后顺序的机制。 在消息传递的并发模型中，由于消息的发送必需在消息接受之前，所以是隐式同步。 定位内存可见行问题 什么是内存共享 synchronized：可重入锁、互斥性和可见性 volatile：可以做到原子性、可见性不能做到复合操作的原子性 volatile 保证可见性原理 对于 volatile 修饰的变量进行写操作的时候，JVM 会向处理器发送一条 Lock 前缀的指令，会把这个变量所在缓存行的数据写回系统内存。 在多处理器的情况下，各个处理器会通过总线传过的的值来发现自己保存的值是不是过期了，实现缓存一致性。当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 synchronized 是关键字属于 JVM 层面，反应在字节码上是 monitorenter 和 monitorexit，其底层是通过 monitor 对象来完成，其实 wait/notify 等方法也是依赖 monitor 对象只有在同步快或方法中才能调用 wait/notify 等方法。 新建一个线程的几种方式 Thread Rannable Callable/Future ExectutorService 分布式锁的实现 通过数据库实现 使用 zookeeper 实现 基于 redis 实现 如果通过一个 swap 交换两个数public class SwapDemo { public static void main(String[] args) { Integer a = 1; Integer b = 2; System.out.println(&quot;before : a = &quot; + a + &quot;, &quot; + &quot;b = &quot; + b); swap(a, b); System.out.println(&quot;after : a = &quot; + a + &quot;, &quot; + &quot;b = &quot; + b); } private static void swap(Integer a, Integer b) { int temp = a; a = b; b = temp; }}// 输出// before : a = 1, b = 2// after : a = 1, b = 2 发现并没有交换，因为 Java 使用的值传递，传递的只是一个副本，如果是基本类型就基本类型副本，如果是引用类型就是引用类型的副本。 查看源码，发现 Integer 这个类有一个 final 成员变量。 /** * The value of the {@code Integer}. * * @serial */private final int value; 我们知道 final 修饰的变量不能修改，但是我们可以通过反射修改。 public class SwapDemo { public static void main(String[] args) throws Exception{ Integer a = 1; // 同 Integer.valueOf(1) Integer b = 2; System.out.println(&quot;before : a = &quot; + a + &quot;, &quot; + &quot;b = &quot; + b); swap(a, b); System.out.println(&quot;after : a = &quot; + a + &quot;, &quot; + &quot;b = &quot; + b); } private static void swap(Integer a, Integer b) throws NoSuchFieldException, IllegalAccessException { Field field = Integer.class.getDeclaredField(&quot;value&quot;); field.setAccessible(true); // 访问私有变量 Integer temp = new Integer(a.intValue()); // 因为 -128 ~ 127 会缓冲，所以要 new 出来 field.set(a, b.intValue()); field.set(b, temp); }}// 输出// before : a = 1, b = 2// after : a = 2, b = 1","link":"/2019/07/23/%E9%9D%A2%E8%AF%95%E9%AB%98%E9%A2%91%E9%A2%98/"},{"title":"Brief History of HTTP","text":"原文：https://hpbn.co/brief-history-of-http/ The Hypertext Transfer Protocol (HTTP) is one of the most ubiquitous and widely adopted application protocols on the Internet: it is the common language between clients and servers, enabling the modern web. From its simple beginnings as a single keyword and document path, it has become the protocol of choice not just for browsers, but for virtually every Internet-connected software and hardware application. In this chapter, we will take a brief historical tour of the evolution of the HTTP protocol. A full discussion of the varying HTTP semantics is outside the scope of this book, but an understanding of the key design changes of HTTP, and the motivations behind each, will give us the necessary background for our discussions on HTTP performance, especially in the context of the many upcoming improvements in HTTP/2. §HTTP 0.9: The One-Line ProtocolThe original HTTP proposal by Tim Berners-Lee was designed with simplicity in mind as to help with the adoption of his other nascent idea: the World Wide Web. The strategy appears to have worked: aspiring protocol designers, take note. In 1991, Berners-Lee outlined the motivation for the new protocol and listed several high-level design goals: file transfer functionality, ability to request an index search of a hypertext archive, format negotiation, and an ability to refer the client to another server. To prove the theory in action, a simple prototype was built, which implemented a small subset of the proposed functionality: Client request is a single ASCII character string. Client request is terminated by a carriage return (CRLF). Server response is an ASCII character stream. Server response is a hypertext markup language (HTML). Connection is terminated after the document transfer is complete. However, even that sounds a lot more complicated than it really is. What these rules enable is an extremely simple, Telnet-friendly protocol, which some web servers support to this very day: $&gt; telnet google.com 80Connected to 74.125.xxx.xxxGET /about/(hypertext response)(connection closed) The request consists of a single line: GET method and the path of the requested document. The response is a single hypertext document—no headers or any other metadata, just the HTML. It really couldn’t get any simpler. Further, since the previous interaction is a subset of the intended protocol, it unofficially acquired the HTTP 0.9 label. The rest, as they say, is history. From these humble beginnings in 1991, HTTP took on a life of its own and evolved rapidly over the coming years. Let us quickly recap the features of HTTP 0.9: Client-server, request-response protocol. ASCII protocol, running over a TCP/IP link. Designed to transfer hypertext documents (HTML). The connection between server and client is closed after every request. Note : Popular web servers, such as Apache and Nginx, still support the HTTP 0.9 protocol—in part, because there is not much to it! If you are curious, open up a Telnet session and try accessing google.com, or your own favorite site, via HTTP 0.9 and inspect the behavior and the limitations of this early protocol. §HTTP/1.0: Rapid Growth and Informational RFCThe period from 1991 to 1995 is one of rapid coevolution of the HTML specification, a new breed of software known as a “web browser,” and the emergence and quick growth of the consumer-oriented public Internet infrastructure. §The Perfect Storm: Internet Boom of the Early 1990s Building on Tim Berner-Lee’s initial browser prototype, a team at the National Center of Supercomputing Applications (NCSA) decided to implement their own version. With that, the first popular browser was born: NCSA Mosaic. One of the programmers on the NCSA team, Marc Andreessen, partnered with Jim Clark to found Mosaic Communications in October 1994. The company was later renamed Netscape, and it shipped Netscape Navigator 1.0 in December 1994. By this point, it was already clear that the World Wide Web was bound to be much more than just an academic curiosity. In fact, that same year the first World Wide Web conference was organized in Geneva, Switzerland, which led to the creation of the World Wide Web Consortium (W3C) to help guide the evolution of HTML. Similarly, a parallel HTTP Working Group (HTTP-WG) was established within the IETF to focus on improving the HTTP protocol. Both of these groups continue to be instrumental to the evolution of the Web. Finally, to create the perfect storm, CompuServe, AOL, and Prodigy began providing dial-up Internet access to the public within the same 1994–1995 time frame. Riding on this wave of rapid adoption, Netscape made history with a wildly successful IPO on August 9, 1995—the Internet boom had arrived, and everyone wanted a piece of it! The growing list of desired capabilities of the nascent Web and their use cases on the public Web quickly exposed many of the fundamental limitations of HTTP 0.9: we needed a protocol that could serve more than just hypertext documents, provide richer metadata about the request and the response, enable content negotiation, and more. In turn, the nascent community of web developers responded by producing a large number of experimental HTTP server and client implementations through an ad hoc process: implement, deploy, and see if other people adopt it. From this period of rapid experimentation, a set of best practices and common patterns began to emerge, and in May 1996 the HTTP Working Group (HTTP-WG) published RFC 1945, which documented the “common usage” of the many HTTP/1.0 implementations found in the wild. Note that this was only an informational RFC: HTTP/1.0 as we know it is not a formal specification or an Internet standard! Having said that, an example HTTP/1.0 request should look very familiar: $&gt; telnet website.org 80Connected to xxx.xxx.xxx.xxxGET /rfc/rfc1945.txt HTTP/1.0 (1)User-Agent: CERN-LineMode/2.15 libwww/2.17b3Accept: */*HTTP/1.0 200 OK (2)Content-Type: text/plainContent-Length: 137582Expires: Thu, 01 Dec 1997 16:00:00 GMTLast-Modified: Wed, 1 May 1996 12:45:26 GMTServer: Apache 0.84(plain-text response)(connection closed) Request line with HTTP version number, followed by request headers Response status, followed by response headers The preceding exchange is not an exhaustive list of HTTP/1.0 capabilities, but it does illustrate some of the key protocol changes: Request may consist of multiple newline separated header fields. Response object is prefixed with a response status line. Response object has its own set of newline separated header fields. Response object is not limited to hypertext. The connection between server and client is closed after every request. Both the request and response headers were kept as ASCII encoded, but the response object itself could be of any type: an HTML file, a plain text file, an image, or any other content type. Hence, the “hypertext transfer” part of HTTP became a misnomer not long after its introduction. In reality, HTTP has quickly evolved to become a hypermedia transport, but the original name stuck. In addition to media type negotiation, the RFC also documented a number of other commonly implemented capabilities: content encoding, character set support, multi-part types, authorization, caching, proxy behaviors, date formats, and more. Note : Almost every server on the Web today can and will still speak HTTP/1.0. Except that, by now, you should know better! Requiring a new TCP connection per request imposes a significant performance penalty on HTTP/1.0; see Three-Way Handshake, followed by Slow-Start. §HTTP/1.1: Internet StandardThe work on turning HTTP into an official IETF Internet standard proceeded in parallel with the documentation effort around HTTP/1.0 and happened over a period of roughly four years: between 1995 and 1999. In fact, the first official HTTP/1.1 standard is defined in RFC 2068, which was officially released in January 1997, roughly six months after the publication of HTTP/1.0. Then, two and a half years later, in June of 1999, a number of improvements and updates were incorporated into the standard and were released as RFC 2616. The HTTP/1.1 standard resolved a lot of the protocol ambiguities found in earlier versions and introduced a number of critical performance optimizations: keepalive connections, chunked encoding transfers, byte-range requests, additional caching mechanisms, transfer encodings, and request pipelining. With these capabilities in place, we can now inspect a typical HTTP/1.1 session as performed by any modern HTTP browser and client: $&gt; telnet website.org 80Connected to xxx.xxx.xxx.xxxGET /index.html HTTP/1.1 (1)Host: website.orgUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_4)... (snip)Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Encoding: gzip,deflate,sdchAccept-Language: en-US,en;q=0.8Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.3Cookie: __qca=P0-800083390... (snip)HTTP/1.1 200 OK (2)Server: nginx/1.0.11Connection: keep-aliveContent-Type: text/html; charset=utf-8Via: HTTP/1.1 GWADate: Wed, 25 Jul 2012 20:23:35 GMTExpires: Wed, 25 Jul 2012 20:23:35 GMTCache-Control: max-age=0, no-cacheTransfer-Encoding: chunked100 (3)&lt;!doctype html&gt;(snip)100(snip)0 (4)GET /favicon.ico HTTP/1.1 (5)Host: www.website.orgUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_4)... (snip)Accept: */*Referer: http://website.org/Connection: close (6)Accept-Encoding: gzip,deflate,sdchAccept-Language: en-US,en;q=0.8Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.3Cookie: __qca=P0-800083390... (snip)HTTP/1.1 200 OK (7)Server: nginx/1.0.11Content-Type: image/x-iconContent-Length: 3638Connection: closeLast-Modified: Thu, 19 Jul 2012 17:51:44 GMTCache-Control: max-age=315360000Accept-Ranges: bytesVia: HTTP/1.1 GWADate: Sat, 21 Jul 2012 21:35:22 GMTExpires: Thu, 31 Dec 2037 23:55:55 GMTEtag: W/PSA-GAu26oXbDi(icon data)(connection closed) Request for HTML file, with encoding, charset, and cookie metadata Chunked response for original HTML request Number of octets in the chunk expressed as an ASCII hexadecimal number (256 bytes) End of chunked stream response Request for an icon file made on same TCP connection Inform server that the connection will not be reused Icon response, followed by connection close Phew, there is a lot going on in there! The first and most obvious difference is that we have two object requests, one for an HTML page and one for an image, both delivered over a single connection. This is connection keepalive in action, which allows us to reuse the existing TCP connection for multiple requests to the same host and deliver a much faster end-user experience; see Optimizing for TCP. To terminate the persistent connection, notice that the second client request sends an explicit close token to the server via the Connection header. Similarly, the server can notify the client of the intent to close the current TCP connection once the response is transferred. Technically, either side can terminate the TCP connection without such signal at any point, but clients and servers should provide it whenever possible to enable better connection reuse strategies on both sides. Note : HTTP/1.1 changed the semantics of the HTTP protocol to use connection keepalive by default. Meaning, unless told otherwise (via Connection: close header), the server should keep the connection open by default. However, this same functionality was also backported to HTTP/1.0 and enabled via the Connection: Keep-Alive header. Hence, if you are using HTTP/1.1, technically you don’t need the Connection: Keep-Alive header, but many clients choose to provide it nonetheless. Additionally, the HTTP/1.1 protocol added content, encoding, character set, and even language negotiation, transfer encoding, caching directives, client cookies, plus a dozen other capabilities that can be negotiated on each request. We are not going to dwell on the semantics of every HTTP/1.1 feature. This is a subject for a dedicated book, and many great ones have been written already. Instead, the previous example serves as a good illustration of both the quick progress and evolution of HTTP, as well as the intricate and complicated dance of every client-server exchange. There is a lot going on in there! Note : For a good reference on all the inner workings of the HTTP protocol, check out O’Reilly’s HTTP: The Definitive Guide by David Gourley and Brian Totty. §HTTP/2: Improving Transport PerformanceSince its publication, RFC 2616 has served as a foundation for the unprecedented growth of the Internet: billions of devices of all shapes and sizes, from desktop computers to the tiny web devices in our pockets, speak HTTP every day to deliver news, video, and millions of other web applications we have all come to depend on in our lives. What began as a simple, one-line protocol for retrieving hypertext quickly evolved into a generic hypermedia transport, and now a decade later can be used to power just about any use case you can imagine. Both the ubiquity of servers that can speak the protocol and the wide availability of clients to consume it means that many applications are now designed and deployed exclusively on top of HTTP. Need a protocol to control your coffee pot? RFC 2324 has you covered with the Hyper Text Coffee Pot Control Protocol (HTCPCP/1.0)—originally an April Fools’ Day joke by IETF, and increasingly anything but a joke in our new hyper-connected world. The Hypertext Transfer Protocol (HTTP) is an application-level protocol for distributed, collaborative, hypermedia information systems. It is a generic, stateless, protocol that can be used for many tasks beyond its use for hypertext, such as name servers and distributed object management systems, through extension of its request methods, error codes and headers. A feature of HTTP is the typing and negotiation of data representation, allowing systems to be built independently of the data being transferred. RFC 2616: HTTP/1.1, June 1999 The simplicity of the HTTP protocol is what enabled its original adoption and rapid growth. In fact, it is now not unusual to find embedded devices—sensors, actuators, and coffee pots alike—using HTTP as their primary control and data protocols. But under the weight of its own success and as we increasingly continue to migrate our everyday interactions to the Web—social, email, news, and video, and increasingly our entire personal and job workspaces—it has also begun to show signs of stress. Users and web developers alike are now demanding near real-time responsiveness and protocol performance from HTTP/1.1, which it simply cannot meet without some modifications. To meet these new challenges, HTTP must continue to evolve, and hence the HTTPbis working group announced a new initiative for HTTP/2 in early 2012: There is emerging implementation experience and interest in a protocol that retains the semantics of HTTP without the legacy of HTTP/1.x message framing and syntax, which have been identified as hampering performance and encouraging misuse of the underlying transport. The working group will produce a specification of a new expression of HTTP’s current semantics in ordered, bi-directional streams. As with HTTP/1.x, the primary target transport is TCP, but it should be possible to use other transports. HTTP/2 charter, January 2012 The primary focus of HTTP/2 is on improving transport performance and enabling both lower latency and higher throughput. The major version increment sounds like a big step, which it is and will be as far as performance is concerned, but it is important to note that none of the high-level protocol semantics are affected: all HTTP headers, values, and use cases are the same. Any existing website or application can and will be delivered over HTTP/2 without modification: you do not need to modify your application markup to take advantage of HTTP/2. The HTTP servers will have to speak HTTP/2, but that should be a transparent upgrade for the majority of users. The only difference if the working group meets its goal, should be that our applications are delivered with lower latency and better utilization of the network link! Having said that, let’s not get ahead of ourselves. Before we get to the new HTTP/2 protocol features, it is worth taking a step back and examining our existing deployment and performance best practices for HTTP/1.1. The HTTP/2 working group is making fast progress on the new specification, but even if the final standard was already done and ready, we would still have to support older HTTP/1.1 clients for the foreseeable future—realistically, a decade or more.","link":"/2019/01/26/Brief%20History%20of%20HTTP/"},{"title":"Go语言入门笔记","text":"课程导论 特点 没有“对象”，没有继承，没有泛型，没有 try/catch 有接口，函数式编程，CSP 并发模型（goroutine + channel） 语法简单 基本语法 变量 选择，循环 指针，数组，容器 面向接口 结构体 duck typing 的概念 组合的思想 函数式编程 闭包的概念 工程化 资源管理，错误处理 测试和文档 性能调优 并发编程 goroutine 和 channel 理解调度器 基本语法HelloWorldpackage mainimport &quot;fmt&quot;func main() { fmt.Println(&quot;Hello World!&quot;)} 变量定义package mainimport &quot;fmt&quot;// 默认变量值func variableZeroValue() { var a int var s string fmt.Println(a, s)}// 定义变量值func variableInitialValue() { var a, b int = 3, 4 var s string = &quot;abc&quot; fmt.Println(a, b, s)}// 变量推断func variableTypeDeduction() { var a, b, c = 1, &quot;abc&quot;, true fmt.Println(a, b, c)}// 变量推断简写func variableShorter() { a, b, c := 1, &quot;abc&quot;, true fmt.Println(a, b, c)}// 全局变量var a = 1// 全局变量定义不能使用 :=// b := 2// 方便定义多个var ( b = &quot;abc&quot; c = 1 d = true)func main() { variableZeroValue() variableInitialValue() variableTypeDeduction() variableShorter()} 内建变量类型 bool, stiring (u)int, (u)int8, (u)int16, (u)int32, (u)int64, uintptr byte, rune float32, float64, complex64, complex128 常量与枚举package mainimport ( &quot;fmt&quot; &quot;math&quot;)func tri() { a, b := 3, 4 var c int // 先把 int 转 float64 再转回 int c = int(math.Sqrt(float64(a*a + b*b))) fmt.Println(c)}// 定义常量func consts() { var c int // 指定类型, 下面需要强转为 float64 // const a, b int = 3, 4 // c = int(math.Sqrt(float64(a*a + b*b))) // 不指定类型, 不需要强转为 float64 const a, b = 3, 4 c = int(math.Sqrt(a*a + b*b)) fmt.Println(c)}// 定义枚举func enums() { //const ( // cpp = 0 // java = 1 // python = 2 // golang = 3 //) // 使用 iota 自增加，与上面一样 const ( cpp = iota java python golang _ // 跳开 4 javascript ) fmt.Println(cpp, java, python, golang, javascript) // 0 1 2 3 5 // b, kb, mb, gb, tb, pb const ( b = 1 &lt;&lt; (10 * iota) kb mb gb tb pb ) fmt.Println(b, kb, mb, gb, tb, pb) // 1 1024 1048576 1073741824 1099511627776 1125899906842624}func main() { tri() consts() enums()} 条件语句package mainimport ( &quot;fmt&quot; &quot;io/ioutil&quot;)// iffunc read() { const filename = &quot;abc.txt&quot; // 读取文件 contents, err := ioutil.ReadFile(filename) if err != nil { fmt.Println(err) } else { fmt.Printf(&quot;%s\\n&quot;, contents) } // 也可以这样写 if contents, err := ioutil.ReadFile(filename); err != nil { fmt.Println(err) } else { fmt.Printf(&quot;%s\\n&quot;, contents) }}// switchfunc eval(a, b int, op string) int { var result int // switch 会自动 break, 除非使用 fallthrough switch op { case &quot;+&quot;: result = a + b case &quot;-&quot;: result = a - b case &quot;*&quot;: result = a * b case &quot;/&quot;: result = a / b default: panic(&quot;unsupported operator: &quot; + op) } return result}// switchfunc grade(score int) string { // switch 后面没有表达式 switch { case score &lt; 0 || score &gt; 100: panic(&quot;wrong score&quot;) case score &lt; 60: return &quot;E&quot; case score &lt; 70: return &quot;D&quot; case score &lt; 80: return &quot;C&quot; case score &lt; 90: return &quot;B&quot; case score &lt;= 100: return &quot;A&quot; } return &quot;&quot;}func main() { read() fmt.Println(eval(1, 2, &quot;+&quot;)) // 3 grade(100)} 循环package mainimport ( &quot;bufio&quot; &quot;fmt&quot; &quot;os&quot; &quot;strconv&quot;)// 转为二进制func convertToBin(n int) string { res := &quot;&quot; for ; n &gt; 0; n /= 2 { lsb := n % 2 res = strconv.Itoa(lsb) + res } return res}// 打印文件func printFile(fileName string) { file, err := os.Open(fileName) if err != nil { panic(err) } scanner := bufio.NewScanner(file) for scanner.Scan() { fmt.Println(scanner.Text()) }}// 死循环func forever() { for { fmt.Println(&quot;forever&quot;) }}func main() { fmt.Println( convertToBin(5), convertToBin(13), ) printFile(&quot;abc.txt&quot;); forever()} 函数package mainimport ( &quot;fmt&quot; &quot;math&quot;)// 返回多个值func div(a, b int) (int, int) { return a / b, a % b}// 可以对返回值命名func div2(a, b int) (q, r int) { return a / b, a % b}// 返回 errorfunc eval(a, b int, op string) (int, error) { switch op { case &quot;+&quot;: return a + b, nil case &quot;-&quot;: return a - b, nil case &quot;*&quot;: return a * b, nil case &quot;/&quot;: return a / b, nil default: return 0, fmt.Errorf(&quot;unsupported opration: %s&quot;, op) }}// 使用函数式编程func apply(op func(int, int) int, a, b int) int { return op(a, b)}// 可变参数func sum(numbers ...int) int { sum := 0 for i := range numbers { sum += numbers[i] } return sum}func pow(a, b int) int { return int(math.Pow(float64(a), float64(b)))}func main() { i, i2 := div(5, 3) fmt.Println(i, i2) q, r := div2(5, 3) fmt.Println(q, r) res, err := eval(1, 2, &quot;&amp;&quot;) // unsupported opration: &amp; if err != nil { fmt.Println(err) } else { fmt.Println(res) } fmt.Println(apply(pow, 2, 2)) // 4 fmt.Println(sum(1, 2, 3, 4)) // 10} 指针package mainimport &quot;fmt&quot;// 使用指针func swap(a *int, b *int) { *b, *a = *a, *b}func swap2(a, b int) (int, int) { return b, a}func main() { a, b := 3, 4 swap(&amp;a, &amp;b) fmt.Println(a, b) // 4 3 a, b = 3, 4 a, b = swap2(a, b) fmt.Println(a, b) // 4 3} 数组、切片和容器数组package mainimport &quot;fmt&quot;// 数组定义func defineArray() { // 定义数组的方法 var arr1 [5]int arr2 := [3]int{1, 3, 5} arr3 := [...]int{2, 4, 6, 8} fmt.Println(arr1, arr2, arr3) // [0 0 0 0 0] [1 3 5] [2 4 6 8] // 定义二维数组 var grid [2][3]int fmt.Println(grid) // [[0 0 0] [0 0 0]]}// 遍历数组func printArray() { arr := [...]int{2, 4, 6, 8} for i := 0; i &lt; len(arr); i++ { fmt.Println(arr[i]) } // 通过 range 可以获取下标 for i := range arr { fmt.Println(arr[i]) } // 获取下标和值 for i, v := range arr { fmt.Println(i, v) } // 只获取值, 可以使用 _ 来省略变量 for _, v := range arr { fmt.Println(v) }}// [3]int 和 [5]int 是不同的类型func printArray2(arr [5]int) { fmt.Println(arr)}// 数组是值类型func printArray3(arr [5]int) { arr[0] = 100 fmt.Println(arr) // [100, 0, 0, 0, 0]}// 传递指针func printArray4(arr *[5]int) { arr[0] = 100 fmt.Println(*arr) // [100, 0, 0, 0, 0]}func main() { defineArray() printArray() var arr1 [5]int // arr2 := [3]int{1, 3, 5} // arr3 := [...]int{2, 4, 6, 8, 10} // [3]int 和 [5]int 是不同的类型 printArray2(arr1) // 在函数里面改变数组的值 // printArray2(arr2) // cannot use arr2 (type [3]int) as type [5]int in argument to printArray2 // 在函数里改变了数组第一个值, 后面打印还是不变，每次传递数组都是一个副本 printArray3(arr1) fmt.Println(arr1) // [0, 0, 0, 0, 0] // 传递地址过去就会改变 printArray4(&amp;arr1) fmt.Println(arr1) // [100, 0, 0, 0, 0]} 切片package mainimport &quot;fmt&quot;// 切片func mySlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} fmt.Println(&quot;arr[2:6] = &quot;, arr[2:6]) // arr[2:6] = [2 3 4 5] fmt.Println(&quot;arr[:6] = &quot;, arr[:6]) // arr[2:6] = [2 3 4 5] fmt.Println(&quot;arr[2:] = &quot;, arr[2:]) // arr[2:] = [2 3 4 5 6 7] fmt.Println(&quot;arr[:] = &quot;, arr[:]) // arr[:] = [0 1 2 3 4 5 6 7]}// 更新func updateSlice(slice []int) { slice[0] = 2019}// 扩展func extendSlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} // 我们知道 s1 只有 4 个元素, 但是 s2 还是能 s1 := arr[2:6] s2 := s1[3:5] fmt.Println(s1) // [2 3 4 5] fmt.Println(s2) // [5 6] fmt.Printf(&quot;len=%d, cap=%d&quot;, len(s1), cap(s1)) // len=4, cap=6}// 添加func appendSlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} // 添加元素如果超过了 cap, 系统会重新分配更大的底层数组 // 由于值的传递关系, 必须接受 append 的返回值 s1 := arr[2:6] s2 := append(s1, 100) s3 := append(s2, 100) s4 := append(s3, 100) s5 := append(s4, 100) fmt.Println(s1, s2, s3, s4, s5) // [2 3 4 5] [2 3 4 5 100] [2 3 4 5 100 100] [2 3 4 5 100 100 100] [2 3 4 5 100 100 100 100]}// 创建 slicefunc createSlice() { // 0. 创建一个空的 slice var s []int // 发现 cap 是从 1 2 4 8 16 32... 扩大 for i := 0; i &lt; 100; i++ { s = append(s, 1+2*i) printSlice(s) } // 1. 创建一个带有值的 slice s1 := []int{1, 2, 3, 4, 5} printSlice(s1) // len=5, cap=5, slice=[1 2 3 4 5] // 2. 创建一个 cap = 16 s2 := make([]int, 16) printSlice(s2) // len=16, cap=16, slice=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] // 3. 创建一个 len = 10, cap = 32 s3 := make([]int, 10, 32) // len=10, cap=32, slice=[0 0 0 0 0 0 0 0 0 0] printSlice(s3)}// 复制func copySlice() { src := []int{1, 2, 3} dst := make([]int, 16) fmt.Println(dst) // [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] copy(dst, src) fmt.Println(dst) // [1 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0]}// 删除func deleteSlice() { // 删除下标为3的元素 s := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s = append(s[:3], s[4:]...) // s[4:]... 转换为可变参数 fmt.Println(s) // [0 1 2 4 5 6 7 8] // 删除第一个 s1 := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s1 = s1[1:] fmt.Println(s1) // [1 2 3 4 5 6 7 8] // 删除最后一个 s2 := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s2 = s2[:len(s2) - 1] fmt.Println(s2) // [0 1 2 3 4 5 6 7]}func printSlice(s []int) { fmt.Printf(&quot;len=%d, cap=%d, slice=%v \\n&quot;, len(s), cap(s), s)}func main() { mySlice() arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} slice1 := arr[:] fmt.Println(&quot;Before update: &quot;, slice1) // Before update: [0 1 2 3 4 5 6 7] updateSlice(slice1) fmt.Println(&quot;After update: &quot;, slice1) // After update: [2019 1 2 3 4 5 6 7] extendSlice() appendSlice() createSlice() copySlice() deleteSlice()} Mappackage mainimport &quot;fmt&quot;// 定义 mapfunc defineMap() { // 定义一个带默认值的 map m1 := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } // 定义一个 empty map m2 := make(map[string]string) // 定义一个 nil map var m3 map[string]string fmt.Println(m1, m2, m3) // map[a:A b:B] map[] map[]}// 遍历 mapfunc traversingMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } // 打印 key value for k, v := range m { fmt.Println(k, v) } // 只打印 key for k := range m { fmt.Println(k) } // 只打印 value for _, v := range m { fmt.Println(v) }}// 判断是否存在func containMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } value, ok := m[&quot;c&quot;] if ok { fmt.Println(value) } else { fmt.Println(&quot;不存在&quot;) } if value, ok := m[&quot;b&quot;]; ok { fmt.Println(value) } else { fmt.Println(&quot;不存在&quot;) }}// 删除元素func deleteMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } fmt.Println(m) // map[a:A b:B] delete(m, &quot;a&quot;) fmt.Println(m) // map[b:B]}func main() { defineMap() traversingMap() containMap() deleteMap()} 例题：查找最长不重复子串 package mainimport &quot;fmt&quot;// 查早最长不重复子串func lengthOfSubString(s string) int { start := 0 maxLength := 0 lastOccuredMap := make(map[rune]int) for i, ru := range []rune(s) { if lastI, ok := lastOccuredMap[ru]; ok &amp;&amp; lastI &gt;= start { start = lastI + 1 } if i-start+1 &gt; maxLength { maxLength = i - start + 1 } lastOccuredMap[ru] = i } return maxLength}func main() { fmt.Println(lengthOfSubString(&quot;aaa&quot;)) fmt.Println(lengthOfSubString(&quot;abab&quot;)) fmt.Println(lengthOfSubString(&quot;abc&quot;)) fmt.Println(lengthOfSubString(&quot;abcabc&quot;))} 字符和字符串处理package mainimport &quot;fmt&quot;func runeTest() { s := &quot;cuzz是我!&quot; for i, b := range []byte(s) { fmt.Printf(&quot;(%d %X %c) &quot;, i, b, b) } fmt.Println() for i, u := range s { fmt.Printf(&quot;(%d %X %c) &quot;, i, u, u) } fmt.Println() for i, r := range []rune(s) { fmt.Printf(&quot;(%d %X %c) &quot;, i, r, r) } // 输出 // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 E6 æ) (5 98 ) (6 AF ¯) (7 E6 æ) (8 88 ) (9 91 ) (10 21 !) // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 662F 是) (7 6211 我) (10 21 !) // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 662F 是) (5 6211 我) (6 21 !) // 说明 range s 使用的 utf-8 遍历, 但是观察下标发现不是连续的 // ascii 转为 utf-8 如:(4 E6) (5 98) (6 AF) -&gt; (4 662F) // 使用 []rune() 转换可以使下标连续输出}func main() { runeTest()} 面向对象 go 语言仅支持封装，不支持继承和多态 go 语言没有 class，只有 struct 结构体和方法package mainimport ( &quot;fmt&quot;)// 定义结构体, 小写对外不可见type treeNode struct { value int left, right *treeNode}// setter, 错误, 由于 go 是传值, 不会改变func (node treeNode) setVal(value int) { node.value = value}func (node *treeNode) setValue(value int) { node.value = value}// 给结构体定义方法 node.print()func (node treeNode) print() { fmt.Println(node.value)}// 普通的方法 print(node)func print(node treeNode) { fmt.Println(node.value)}// 定义一个工厂方法func createNode(value int) *treeNode { return &amp;treeNode{value: value}}// 遍历func (node *treeNode) traverse() { if node == nil { return } node.left.traverse() node.print() node.right.traverse()}func main() { // 定义一个空的结构体 var node treeNode fmt.Println(node) // {0 &lt;nil&gt; &lt;nil&gt;} // 使用构造器定义一个结构体 node2 := treeNode{ value: 1, left: &amp;treeNode{}, // 取地址 right: new(treeNode), // new() 获取的是地址 } fmt.Println(node2) // {1 0xc00000c0c0 0xc00000c0a0} // 使用工厂方法创建 node3 := treeNode{ value: 0, } node3.left = createNode(1) node3.right = createNode(2) fmt.Println(node3) // {0 0xc00008e0a0 0xc00008e0c0} // 区别 node.print() // 0 print(node) // 0 // 不会改变, go 是传值 node.setVal(1) node.print() // 0 // 会改变 node.setValue(1) node.print() // 1 fmt.Println() // 中顺遍历 0 // 1 2 node3.traverse() // 1 0 2} 包和封装 包 每个目录一个包 main 包包含可执行入口 为结构定义的方法必须放在同一包内 可以是不同的文件 封装 一般使用驼峰命名 首字母大写表示 public 首字母小写表示 private Queue.go package queueimport &quot;fmt&quot;type Queue []intfunc (q *Queue) Push(v int) { *q = append(*q, v)}func (q *Queue) Pop() int { head := (*q)[0] *q = (*q)[1:] return head}func (q *Queue) Head() int { return (*q)[0]}func (q *Queue) IsEmpty() bool { return len(*q) == 0}func (q *Queue) Print() { for _, v := range *q { fmt.Print(v, &quot; &quot;) } fmt.Println()} test.go package mainimport ( &quot;awesomeProject/queue&quot; &quot;fmt&quot;)func main() { // 定义一个有默认值的队列 q := queue.Queue{1} q.Push(2) q.Push(3) q.Push(4) q.Print() // 1 2 3 4 fmt.Println(q.Pop()) // 1 q.Print() // 2 3 4 q.Pop() q.Pop() q.Pop() fmt.Println(q.IsEmpty()) // true} 项目结构环境变量： GOROOT：go语言自带的类库 GOPATH：用户源代码目录 src：源文件 pkg：build 的之后的中间文件 bin：可执行文件 接口duck typing “像鸭子走路，像鸭子叫…”，那么就是鸭子 描述事物的外部行为而非内部结构 严格说 go 属于结构化类型系统，类似 duck typing 接口定义和实现定义一个假的发送请求，有一个 Get 方法 package mocktype Retriever struct { Contents string}func (r Retriever) Get(url string) string { return url + &quot;hi, cuzz...&quot;} 定义一个真正发送请求，有一个 Get 方法 package workimport ( &quot;net/http&quot; &quot;net/http/httputil&quot; &quot;time&quot;)type Retriever struct { UserAgent string TimeOut time.Duration}func (r Retriever) Get(url string) string { resp, err := http.Get(url) if err != nil { panic(err) } result, err := httputil.DumpResponse(resp, true) resp.Body.Close() if err != nil { panic(err) } return string(result)} 测试 package mainimport ( &quot;awesomego/retriever/mock&quot; &quot;awesomego/retriever/work&quot; &quot;fmt&quot;)// 定义一个接口type Retriever interface { Get(url string) string}// 传入接口func download(r Retriever) string { return r.Get(&quot;http://blog.cuzz.site&quot;)}func main() { // 接口定义 // var mockRetriever Retriever // mockRetriever = mock.Retriever{} mockRetriever := mock.Retriever{} fmt.Println(download(mockRetriever)) workRetriever := work.Retriever{} fmt.Println(download(workRetriever))} 我们发现在接口是调用放定义的，结构体中的接口也是隐式的，结构体满足接口中的方法，就可以说这个结构体实现了这个接口。 接口的值类型在golang中，接口值是由两部分组成的，一部分是接口的类型，另一部分是该类型对应的值，我们称其为动态类型和动态值。 func main() { mockRetriever := mock.Retriever{} fmt.Printf(&quot;%T, %v\\n&quot;, mockRetriever, mockRetriever) // mock.Retriever, {} workRetriever := work.Retriever{} fmt.Printf(&quot;%T, %v\\n&quot;, workRetriever, workRetriever) // work.Retriever, { 0s}} 接口组合package main// 定义一个接口type Retriever interface { Get(url string) string}// 定义另一个接口type Poster interface { Post(url string, params map[string]string)}// 接口组合type RetrieverAndPoster interface { Retriever Poster // 也可以定义其他方法 AnotherMethod()}func main() {} 常用系统接口1、Stringer Stringer接口中的 string 相当与 Java #toString 方法 package workimport ( &quot;fmt&quot; &quot;time&quot;)type Retriever struct { UserAgent string TimeOut time.Duration}func (r Retriever) String() string { return fmt.Sprintf(&quot;UserAgent: %v, TimeOut: %v&quot;, r.UserAgent, r.TimeOut)} 测试 package mainimport ( &quot;awesomego/retriever/work&quot; &quot;fmt&quot; &quot;time&quot;)func main() { workRetriever := work.Retriever{&quot;Mozilla/5.0&quot;, time.Minute} fmt.Println(workRetriever) // UserAgent: Mozilla/5.0, TimeOut: 1m0s} 2、Reader type Reader interface { Read(p []byte) (n int, err error)} 3、Writer type Writer interface { Write(p []byte) (n int, err error)} 函数式编程 函数是一等公民：参数，变量，返回值都可以是函数 高级函数 闭包 package mainimport &quot;fmt&quot;// 定义一个 adder 函数, 没有参数, 返回值是一个函数func adder() func(int) int { sum := 0 return func(v int) int { sum += v return sum }}// 定义斐波那契数列func fibonacci() func() int{ a, b := 0, 1 return func() int { a, b = b, a + b fmt.Println(a) return a }}func main() { a := adder() for i := 0; i &lt; 10; i++ { fmt.Printf(&quot;0 + 1 + ... + %d = %d\\n&quot;, i, a(i)) } f := fibonacci() f() // 1 f() // 1 f() // 2 f() // 3 f() // 5} 资源管理与出错处理defer 调用你可以在 Go 函数中添加多个defer语句，当函数执行到最后时，这些 defer 语句会按照逆序执行（即最后一个defer语句将最先执行），最后该函数返回。特别是当你在进行一些打开资源的操作时，遇到错误需要提前返回，在返回前你需要关闭相应的资源，不然很容易造成资源泄露等问题。如下代码所示，我们一般写打开一个资源是这样操作的： func CopyFile(dst, src string) (w int64, err error) { srcFile, err := os.Open(src) if err != nil { return } defer srcFile.Close() dstFile, err := os.Create(dst) if err != nil { return } defer dstFile.Close() return io.Copy(dstFile, srcFile)} 错误处理错误处理是任何语言都需要考虑到的问题，而 Go 语言在错误处理上解决得更为完善，优雅的错误处理机制是 Go 语言的一大特点。 1、error Go 语言引入了一个错误处理的标准模式，即error接口，该接口定义如下： type error interface { Error() string} 对于大多数函数，如果要返回错误，可以将error作为多返回值的最后一个： func foo(param int)(ret int, err error) { ... } 调用时的代码： n, err := foo(0)if err != nil { // 错误处理} else { // 使用返回值n} 2、panic 停止当前函数执行 一直向上返回，执行每一层的 defer 如果没有遇见 recover，程序退出 3、recover 仅在 defer 中调用 获取 panic 的值 如果无法处理，可以重新 panic package mainimport ( &quot;fmt&quot;)func tryRecover() { // 匿名函数里 defer func() { r := recover() if err, ok := r.(error); ok { fmt.Println(&quot;Error occurred: &quot;, err) } else { panic(fmt.Sprintf(&quot;I don't know what to do: %v&quot;, r)) } }() a := 1 b := 0 fmt.Println(a / b) // runtime error: integer divide by zero // panic(errors.New(&quot;this is an error&quot;)) // panic(123) // 如果不是一个错误的话就, 再次 panic 出去}func main() { tryRecover() } 并发编程goroutine1、协程 轻量级“线程” 非抢占式多任务处理，由协程主动交出控制权 编译器/解释器/虚拟器层面的多任务 多个协程可能在一个或者多个线程上运行 package mainimport ( &quot;fmt&quot; &quot;time&quot;)func test() { // 此时, 不会输出, main 先退出了, 必须让 main sleep for i := 0; i &lt; 1000; i++ { // 匿名函数 go func(i int) { for { fmt.Printf(&quot;From %d\\n&quot;, i) } }(i) } time.Sleep(time.Millisecond)}func test2() { // 此时不会退出, 因为不能交出控制权 var arr [10]int for i := 0; i &lt; 10; i++ { // 匿名函数 go func(i int) { arr[i]++ }(i) } time.Sleep(time.Millisecond)}func main() { test() test2()} 2、go 语言中的调度器 协程可以相互通信 channelchannel是goroutine之间互相通讯的东西。类似我们 Unix 上的管道（可以在进程间传递消息），用来goroutine之间发消息和接收消息。其实，就是在做goroutine之间的内存共享。channel是类型相关的，也就是说一个channel只能传递一种类型的值，这个类型需要在channel声明时指定。 package mainimport ( &quot;fmt&quot; &quot;time&quot;)// 定义chanfunc defineChan() { // 声名一个传递int型的channel // var a chan int // 初始化一个int型channel a := make(chan int) // 从channel中获取 go func() { for { z := &lt;-a fmt.Println(z) } }() a &lt;- 1 time.Sleep(time.Millisecond)}// 定义带缓存chanfunc bufChan() { // 初始化一个int型channel a := make(chan int, 3) // 从channel中获取 go func() { for { //z, ok := &lt;-a //if !ok { // break //} //fmt.Println(z) // 或者使用这种, 确保发送完成 for z := range a { fmt.Println(z) } } }() a &lt;- 1 a &lt;- 2 a &lt;- 3 a &lt;- 4 close(a) // 关闭了的话, 就一直发送0 time.Sleep(time.Millisecond)}// 如何使用func chanDemo() { // 定义一个只能收数据的channel, 把数据放到channel中 var channels [10]chan&lt;- int for i := 0; i &lt; len(channels); i++ { channels[i] = createWorker(i) } // 向channel中写数据 for i := 0; i &lt; len(channels); i++ { channels[i] &lt;- 'a' + i } time.Sleep(time.Millisecond)}func createWorker(i int) chan&lt;- int { c := make(chan int) go func() { for { fmt.Printf(&quot;Worker %d received %c\\n&quot;, i, &lt;-c) } }() return c}func main() { defineChan() bufChan() chanDemo()} 使用 Channel 等待任务结束package mainimport ( &quot;fmt&quot;)type worker struct { in chan int done chan bool // 使用done来通信确定完成}func chanDemo() { var channels [10]worker for i := 0; i &lt; len(channels); i++ { channels[i] = createWorker(i) } // 向channel中写数据 for i := 0; i &lt; len(channels); i++ { channels[i].in &lt;- 'a' + i &lt;-channels[i].done // 等待channel完成 }}func createWorker(i int) worker { w := worker{ in: make(chan int), done: make(chan bool), } go func() { for in := range w.in { fmt.Printf(&quot;Worker %d received %c\\n&quot;, i, in) w.done &lt;- true } }() return w}func main() { chanDemo()} 使用 select 进行调度package mainimport ( &quot;fmt&quot; &quot;math/rand&quot; &quot;time&quot;)func selectDemo() { var c1, c2 chan int c1, c2 = createChan(), createChan() for { select { case n := &lt;-c1: fmt.Printf(&quot;from c1, val: %d\\n&quot;, n) case n := &lt;-c2: fmt.Printf(&quot;from c2, val: %d\\n&quot;, n) } }}func createChan() chan int { out := make(chan int) go func() { i := 0 for { time.Sleep(time.Duration(rand.Intn(1000)) * time.Millisecond) i++ out &lt;- i } }() return out}func main() { selectDemo()}","link":"/2019/10/11/Go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"},{"title":"JVM 面试","text":"JVM 垃圾回收的时候如何确定垃圾？知道什么是 GC Roots ? 什么是垃圾 简单来说就是内存中已经不在被使用到的空间就是垃圾 要进行垃圾回收，如何判断一个对象是否可以被回收？ 引用计数法 枚举根节点做可达性分析 为了解决引用计数法的循环引用问题，Java 使用了可达性算法。 跟踪收集器采用的为集中式的管理方式，全局记录对象之间的引用状态，执行时从一些列GC Roots的对象做为起点，从这些节点向下开始进行搜索所有的引用链，当一个对象到GC Roots 没有任何引用链时，则证明此对象是不可用的。 图中，对象Object6、Object7、Object8虽然互相引用，但他们的GC Roots是不可到达的，所以它们将会被判定为是可回收的对象。 哪些对象可以作为 GC Roots 的对象： 虚拟机栈（栈帧中的局部变量区，也叫局部变量表）中引用的对象 方法区中的类静态属性引用的对象 方法去常量引用的对象 本地方法栈中 JNI (Native方法)引用的对象 你说你做过 JVM 调优和参数配置，请问如果盘点查看 JVM 系统默认值？JVM 的参数类型 标配参数 -version -help X 参数（了解） -Xint：解释执行 -Xcomp：第一次使用就编译成本地代码 -Xmixed：混合模式 XX 参数 Boolean 类型：-XX：+ 或者 - 某个属性值（+ 表示开启，- 表示关闭） -XX:+PrintGCDetails：打印 GC 收集细节 -XX:-PrintGCDetails：不打印 GC 收集细节 -XX:+UseSerialGC：使用了串行收集器 -XX:-UseSerialGC：不使用了串行收集器 KV 设置类型：-XX:key=value -XX:MetaspaceSize=128m -XX:MaxTenuringThreshold=15 jinfo 举例，如何查看当前运行程序的配置 public class HelloGC { public static void main(String[] args) { System.out.println(&quot;hello GC...&quot;); try { Thread.sleep(Integer.MAX_VALUE); } catch (InterruptedException e) { e.printStackTrace(); } }} 我们可以使用 jps -l 命令，查出进程 id 1923 org.jetbrains.jps.cmdline.Launcher1988 sun.tools.jps.Jps1173 org.jetbrains.kotlin.daemon.KotlinCompileDaemon32077 com.intellij.idea.Main1933 com.cuzz.jvm.HelloGC32382 org.jetbrains.idea.maven.server.RemoteMavenServer 在使用 jinfo -flag PrintGCDetails 1933 命令查看 -XX:-PrintGCDetails 可以看出默认是不打印 GC 收集细节也可是使用jinfo -flags 1933 查看所以的参数 两个经典参数：-Xms 和 - Xmx（如 -Xms1024m） -Xms 等价于 -XX:InitialHeapSize -Xmx 等价于 -XX:MaxHeapSize 盘点家底查看 JVM 默认值 查看初始默认值：-XX:+PrintFlagsInitialcuzz@cuzz-pc:~/Project/demo$ java -XX:+PrintFlagsInitial[Global flags] intx ActiveProcessorCount = -1 {product} uintx AdaptiveSizeDecrementScaleFactor = 4 {product} uintx AdaptiveSizeMajorGCDecayTimeScale = 10 {product} uintx AdaptiveSizePausePolicy = 0 {product} uintx AdaptiveSizePolicyCollectionCostMargin = 50 {product} uintx AdaptiveSizePolicyInitializingSteps = 20 {product} uintx AdaptiveSizePolicyOutputInterval = 0 {product} uintx AdaptiveSizePolicyWeight = 10 {product} ... 查看修改更新：-XX:+PrintFlagsFinalbool UsePSAdaptiveSurvivorSizePolicy = true {product}bool UseParNewGC = false {product}bool UseParallelGC := true {product}bool UseParallelOldGC = true {product}bool UsePerfData = true {product}bool UsePopCountInstruction = true {product}bool UseRDPCForConstantTableBase = false {C2 product} = 与 := 的区别是，一个是默认，一个是人物改变或者 jvm 加载时改变的参数 打印命令行参数(可以看默认垃圾回收器)：-XX:+PrintCommandLineFlagscuzz@cuzz-pc:~/Project/demo$ java -XX:+PrintCommandLineFlags-XX:InitialHeapSize=128789376 -XX:MaxHeapSize=2060630016 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 你平时工作用过的 JVM 常用的基本配置参数有哪些？ -Xms 初始大小内存，默认为物理内存 1/64 等价于 -XX:InitialHeapSize -Xmx 最大分配内存，默认为物理内存的 1/4 等价于 -XX:MaxHeapSize -Xss 设置单个线程栈的大小，一般默认为 512-1024k 等价于 -XX:ThreadStackSize -Xmn 设置年轻代的大小 整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小，持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。 -XX:MetaspaceSize 设置元空间大小（元空间的本质和永久代类似，都是对 JVM 规范中的方法区的实现，不过元空间于永久代之间最大区别在于，元空间并不在虚拟中，而是使用本地内存，因此默认情况下，元空间的大小仅受本地内存限制） 元空间默认比较小，我们可以调大一点 -XX:+PrintGCDetails 输出详细 GC 收集日志信息 设置 JVM 参数为： -Xms10m -Xmx10m -XX:+PrintGCDetails 代码 public class HelloGC { public static void main(String[] args) { byte[] bytes = new byte[20 * 1024 * 1024]; }} 打印结果 [GC (Allocation Failure) [PSYoungGen: 1231K-&gt;448K(2560K)] 1231K-&gt;456K(9728K), 0.0015616 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [GC (Allocation Failure) [PSYoungGen: 448K-&gt;384K(2560K)] 456K-&gt;392K(9728K), 0.0016999 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 384K-&gt;0K(2560K)] [ParOldGen: 8K-&gt;358K(7168K)] 392K-&gt;358K(9728K), [Metaspace: 3028K-&gt;3028K(1056768K)], 0.0066696 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] 358K-&gt;358K(9728K), 0.0005321 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] [ParOldGen: 358K-&gt;340K(7168K)] 358K-&gt;340K(9728K), [Metaspace: 3028K-&gt;3028K(1056768K)], 0.0051543 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] Heap PSYoungGen total 2560K, used 81K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 3% used [0x00000000ffd00000,0x00000000ffd14668,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 340K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 4% used [0x00000000ff600000,0x00000000ff655188,0x00000000ffd00000) Metaspace used 3060K, capacity 4496K, committed 4864K, reserved 1056768K class space used 336K, capacity 388K, committed 512K, reserved 1048576KException in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at com.cuzz.jvm.HelloGC.main(HelloGC.java:12) GC FullGC -XX:SurvivorRatio 设置新生代中 eden 和 S0/S1 空间比例 默认 -XX:SurvivorRatio=8，Eden : S0 : S1 = 8 : 1 : 1 -XX:NewRatio 配置年轻代和老年代在堆结构的占比 默认 -XX:NewRatio=2 新生代占1，老年代占2，年轻代占整个堆的 1/3 -XX:MaxTenuringThreshold 设置垃圾最大年龄 强引用、软引用、弱引用和虚引用分别是什么？在Java语言中，除了基本数据类型外，其他的都是指向各类对象的对象引用；Java中根据其生命周期的长短，将引用分为4类。 强引用 特点：我们平常典型编码Object obj = new Object()中的obj就是强引用。通过关键字new创建的对象所关联的引用就是强引用。 当JVM内存空间不足，JVM宁愿抛出OutOfMemoryError运行时错误（OOM），使程序异常终止，也不会靠随意回收具有强引用的“存活”对象来解决内存不足的问题。对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为 null，就是可以被垃圾收集的了，具体回收时机还是要看垃圾收集策略。 软引用 特点：软引用通过SoftReference类实现。 软引用的生命周期比强引用短一些。只有当 JVM 认为内存不足时，才会去试图回收软引用指向的对象：即JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。后续，我们可以调用ReferenceQueue的poll()方法来检查是否有它所关心的对象被回收。如果队列为空，将返回一个null,否则该方法返回队列中前面的一个Reference对象。 应用场景：软引用通常用来实现内存敏感的缓存。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 代码验证我设置 JVM 参数为 -Xms10m -Xmx10m -XX:+PrintGCDetails public class SoftReferenceDemo { public static void main(String[] args) { Object obj = new Object(); SoftReference&lt;Object&gt; softReference = new SoftReference&lt;&gt;(obj); obj = null; try { // 分配 20 M byte[] bytes = new byte[20 * 1024 * 1024]; } catch (Exception e) { e.printStackTrace(); } finally { System.out.println(&quot;软引用：&quot; + softReference.get()); } }} 输出 [GC (Allocation Failure) [PSYoungGen: 1234K-&gt;448K(2560K)] 1234K-&gt;456K(9728K), 0.0016748 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 448K-&gt;384K(2560K)] 456K-&gt;392K(9728K), 0.0018398 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 384K-&gt;0K(2560K)] [ParOldGen: 8K-&gt;358K(7168K)] 392K-&gt;358K(9728K), [Metaspace: 3030K-&gt;3030K(1056768K)], 0.0057246 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] 358K-&gt;358K(9728K), 0.0006038 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] [ParOldGen: 358K-&gt;340K(7168K)] 358K-&gt;340K(9728K), [Metaspace: 3030K-&gt;3030K(1056768K)], 0.0115080 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 软引用：nullException in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at com.cuzz.jvm.SoftReferenceDemo.main(SoftReferenceDemo.java:21)Heap PSYoungGen total 2560K, used 98K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 4% used [0x00000000ffd00000,0x00000000ffd18978,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 340K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 4% used [0x00000000ff600000,0x00000000ff6552f8,0x00000000ffd00000) Metaspace used 3067K, capacity 4496K, committed 4864K, reserved 1056768K class space used 336K, capacity 388K, committed 512K, reserved 1048576K 发现当内存不够的时候就会被回收。 弱引用 特点：弱引用通过WeakReference类实现。 弱引用的生命周期比软引用短。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。由于垃圾回收器是一个优先级很低的线程，因此不一定会很快回收弱引用的对象。弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 应用场景：弱应用同样可用于内存敏感的缓存。 代码验证 public class WeakReferenceDemo { public static void main(String[] args) { Object obj = new Object(); WeakReference&lt;Object&gt; weakReference = new WeakReference&lt;&gt;(obj); System.out.println(obj); System.out.println(weakReference.get()); obj = null; System.gc(); System.out.println(&quot;GC之后....&quot;); System.out.println(obj); System.out.println(weakReference.get()); }} 输出 java.lang.Object@1540e19djava.lang.Object@1540e19dGC之后....nullnull 值得注意的是 String name = &quot;cuzz&quot; 这种会放入永久代，以及 Integer age = 1 在 int 中 -128 到 127 会被缓存，所以是强引用，然后 GC 也不会被回收。 引用队列 public class ReferenceQueueDemo { public static void main(String[] args) throws InterruptedException { Object obj = new Object(); ReferenceQueue&lt;Object&gt; referenceQueue = new ReferenceQueue&lt;&gt;(); WeakReference&lt;Object&gt; weakReference = new WeakReference&lt;&gt;(obj, referenceQueue); System.out.println(obj); System.out.println(weakReference.get()); System.out.println(weakReference); obj = null; System.gc(); Thread.sleep(500); System.out.println(&quot;GC之后....&quot;); System.out.println(obj); System.out.println(weakReference.get()); System.out.println(weakReference); }} 输出 java.lang.Object@1540e19djava.lang.Object@1540e19djava.lang.ref.WeakReference@677327b6GC之后....nullnulljava.lang.ref.WeakReference@677327b6 会把该对象的包装类即weakReference放入到ReferenceQueue里面，我们可以从queue中获取到相应的对象信息，同时进行额外的处理。比如反向操作，数据清理等。 虚引用 特点：虚引用也叫幻象引用，通过PhantomReference类来实现。无法通过虚引用访问对象的任何属性或函数。幻象引用仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。ReferenceQueue queue = new ReferenceQueue ();PhantomReference pr = new PhantomReference (object, queue);程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取一些程序行动。 应用场景：可用来跟踪对象被垃圾回收器回收的活动，当一个虚引用关联的对象被垃圾收集器回收之前会收到一条系统通知。 请谈谈你对 OOM 的认识？ java.lang.StackOverflowError 在一个函数中调用自己就会产生这个错误 java.lang.OutOfMemoryError : Java heap space new 一个很大对象 java.lang.OutOfMemoryError : GC overhead limit exceeded 执行垃圾收集的时间比例太大， 有效的运算量太小，默认情况下,，如果GC花费的时间超过 **98%**， 并且GC回收的内存少于 **2%**， JVM就会抛出这个错误。 java.lang.OutOfMemoryError : Direct buffer memory配置参数：-Xms10m -Xmx10m -XX:+PrintGCDetails -XX:MaxDirectMemorySize=5m public class DirectBufferDemo { public static void main(String[] args) { System.out.println(&quot;maxDirectMemory : &quot; + sun.misc.VM.maxDirectMemory() / (1024 * 1024) + &quot;MB&quot;); ByteBuffer byteBuffer = ByteBuffer.allocateDirect(6 * 1024 * 1024); }} 输出 maxDirectMemory : 5MB[GC (System.gc()) [PSYoungGen: 1315K-&gt;464K(2560K)] 1315K-&gt;472K(9728K), 0.0008907 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [Full GC (System.gc()) [PSYoungGen: 464K-&gt;0K(2560K)] [ParOldGen: 8K-&gt;359K(7168K)] 472K-&gt;359K(9728K), [Metaspace: 3037K-&gt;3037K(1056768K)], 0.0060466 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Direct buffer memory at java.nio.Bits.reserveMemory(Bits.java:694) at java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:123) at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311) at com.cuzz.jvm.DirectBufferDemo.main(DirectBufferDemo.java:17)Heap PSYoungGen total 2560K, used 56K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 2% used [0x00000000ffd00000,0x00000000ffd0e170,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 359K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 5% used [0x00000000ff600000,0x00000000ff659e28,0x00000000ffd00000) Metaspace used 3068K, capacity 4496K, committed 4864K, reserved 1056768K class space used 336K, capacity 388K, committed 512K, reserved 1048576K java.lang.OutOfMemoryError : unable to create new native thread 创建线程数太多了 java.lang.OutOfMemoryError : Metaspace Java 8 之后的版本使用元空间（Metaspace）代替了永久代，元空间是方法区在 HotSpot 中的实现，它与持久代最大的区别是：元空间并不在虚拟机中的内存中而是使用本地内存。 元空间存放的信息： 虚拟机加载的类信息 常量池 静态变量 即时编译后的代码 具体的实现可以看看这个帖子：几种手动OOM的方式 GC 垃圾回收算法和垃圾收集器的关系？谈谈你的理解？ 四种 GC 垃圾回收算法 引用计数 复制回收 标记清除 标记整理 GC 算法是内存回收的方法论，垃圾收集其就是算法的落实的实现。 目前为止还没有完美的收集器的出现，更加没有万能的收集器，只是针对具体应用最适合的收集器，进行分代收集。 串行垃圾回收器（Serial） 它为单线程环境设计且只使用一个线程进行垃圾回收，会暂停所有的用户线程，所以不适合服务环境。 并行垃圾回收器（Parallel） 多个垃圾收集线程并行工作，此时用户线程是暂停的，用于科学计算、大数据处理等弱交互场景。 并发垃圾回收器（CMS） 用户线程和垃圾收集线程同时执行（不一定是并行，可能是交替执行），不需要停顿用户线程，互联网公司多用它，适用对相应时间有要求的场景。 G1 垃圾回收器 G1 垃圾回收器将堆内存分割成不同的区域然后并发的对其进行垃圾回收。 怎么查看服务器默认垃圾收集器是哪个？生产是如何配置垃圾收集器？谈谈你对垃圾收集器的理解？ 怎么查看服务器默认垃圾收集器是哪个？ Java -XX:+PrintCommandLineFlags Java 的 GC 回收的类型主要有： UseSerialGC，UseParallelGC，UseConcMarkSweepGC，UseParNewGC，UseParallelOldGC，UseG1GC Java 8 以后基本不使用 Serial Old 垃圾收集器 参数说明 DefNew : Default New Generation Tenured : Old ParNew : Parallel New Generation PSYoungGen : Parallel Scavenge ParOldGen : Parallel Old Generation Server/Client 模式分别是什么意思 最主要的差别在于：-Server模式启动时，速度较慢，但是一旦运行起来后，性能将会有很大的提升。 当虚拟机运行在-client模式的时候，使用的是一个代号为C1的轻量级编译器, 而-server模式启动的虚拟机采用相对重量级，代号为C2的编译器，C2比C1编译器编译的相对彻底，服务起来之后,性能更高。 所以通常用于做服务器的时候我们用服务端模式，如果你的电脑只是运行一下java程序，就客户端模式就可以了。当然这些都是我们做程序优化程序才需要这些东西的，普通人并不关注这些专业的东西了。其实服务器模式即使编译更彻底，然后垃圾回收优化更好，这当然吃的内存要多点相对于客户端模式。 新生代 串行 GC (Serial/ Serital Copying) 并行 GC (ParNew) 并行回收 GC (Parallel/ Parallel Scanvenge) 老年代 串行 GC (Serial Old/ Serial MSC) 并行 GC (Parallel Old/ Parallel MSC) 并发标记清除 GC (CMS) 是一种以获取最短回收停顿时间为目标的收集器，适合应用在互联网站或者 B/S 系统的服务器上，这个类应用尤其重视服务器的响应速度，希望系统停顿时间最短。 CMS 非常适合堆内存大、CPU 核数多的服务器端应用，也是 G1 出现之前大型应用首选收集器。 并发停顿比较少，并发指的是与用户线程一起执行。 过程 初始标记（initail mark）：只是标记一下 GC Roots 能直接关联的对象，速度很快，需要暂停所有的工作线程 并发标记（concurrent mark 和用户线程一起）：进行 GC Roots 的跟踪过程，和用户线程一起工作，不需要暂停工作线程。 重新标记（remark）：为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。 并发清除（concurrent sweep 和用户线程一起）：清除 GC 不可达对象，和用户线程一起工作，不需要暂停工作线程，基于标记结果，直接清除。由于耗时最长的并发标记和并发清除过程中，垃圾收集线程和用户线程可以一起并发工作，所以总体来看 CMS 收集器的内存回收和用户线程是一起并发地执行。 优缺点 优点：并发收集停顿低 缺点：并发执行对 CPU 资源压力大，采用的标记清除算法会导致大量碎片 由于并发进行， CMS 在收集与应用线程会同时增加对堆内存的占用，也就是说，CMS 必须要在老年代堆用尽之前完成垃圾回收，否者 CMS 回收失败，将触发担保机制，串行老年代收集器将会以 STW 的方式进行一次 GC，从而造成较大的停顿时间。 标记清除算法无法整理空间碎片，老年代空间会随着应用时长被逐渐耗尽，最后将不得不通过担保机制对堆内存进行压缩。CMS 也提供了参数 -XX:CMSFullGCsBeForeCompaction (默认0，即每次都进行内存整理) 来指定多少次 CMS 收集之后，进行一次压 垃圾收集器配置代码总结 配置新生代收集器，老年代收集器会自动配置上。 如何选择垃圾收集器 单 CPU 或者小内存，单机程序：-XX:UseSerialGC 多 CPU 需要最大吞吐量，如后台计算型应用：-XX:UseParallelGC 或者 -XX:UseParallelOldGC 多 CPU 追求低停顿时间，需要快速响应，如互联网应用：-XX:+UseConcMarkSweepGC G1 垃圾收集器你了解吗？ 以前收集器的特点 年轻代和老年代是各自独立且连续的内存块 年轻代收集器使用 eden + S0 + S1 进行复制算法 老年代收集必须扫描整个老年代区域 都是以尽可能的少而快速地执行 GC 为设计原则 G1 是什么 G1 是一种面向服务端的垃圾收集器，应用在多核处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能的满足垃圾收集器的暂停时间要求。 像 CMS 收集器一样，能与应用程序线程并发执行，整理空闲空间更快，需要更多的时间来预测 GC 停顿时间，不希望牺牲大量的吞吐性能，不需要更大的 JAVA Heap。 G1 收集器的设计目的是取代 CMS 收集器，同时与 CMS 相比，G1 垃圾收集器是一个有整理内存过程的垃圾收集器，不会产生很多内存碎片。G1 的 Stop The World 更可控，G1 在停顿上添加了预测机制，用户可以指定期望的停顿时间。 G1 是在 2012 年才在 jdk.1.7u4 中可以呀用，在 jdk9 中将 G1 变成默认垃圾收集器来代替 CMS。它是以款面向服务应用的收集器。 主要改变是 Eden、Survivor 和 Tenured 等内存区域不再是连续的，而是变成了一个个大小一样的 region，每个 region 从 1M 到 32M 不等，一个 region 有可能属于 Eden、Survivor 或者 Tenured 内存区域。 特点 G1 能充分利用多 CPU、多核环境硬件优势，尽量缩短 STW。 G1 整体采用标记-整理算法，局部是通过是通过复制算法，不会产生内存碎片。 宏观上看 G1 之中不在区分年轻代和老年代，被内存划分为多个独立的子区域。 G1 收集器里面讲整个的内存区域混合在一起，但其本身依然在小范围内要进行年轻代和老年代的区分。保留了新生代和老年代，但她们不在是物理隔离，而是一部分 Region 的集合且不需要 Region 是连续的，也就是说依然会采用不同的 GC 方式来处理不同的区域。 G1 虽然也是分代收集器，但整个内存分区不存在物理上的年轻代和老年代的区别，也不需要完全独立的 Survivor to space 堆做复制准备。G1 只有逻辑上的分代概念，或者说每个分区都可能随 G1 的运行在不同代之间前后切换。 底层原理 Region 区域化垃圾收集器：最大好处是化整为零，避免全内存扫描，只需要按照区域来进行扫描即可。 RegionG1的内存结构和传统的内存空间划分有比较的不同。G1将内存划分成了多个大小相等的Region（默认是512K），Region逻辑上连续，物理内存地址不连续。同时每个Region被标记成E、S、O、H，分别表示Eden、Survivor、Old、Humongous。其中E、S属于年轻代，O与H属于老年代。H表示Humongous。从字面上就可以理解表示大的对象（下面简称H对象）。当分配的对象大于等于Region大小的一半的时候就会被认为是巨型对象。H对象默认分配在老年代，可以防止GC的时候大对象的内存拷贝。通过如果发现堆内存容不下H对象的时候，会触发一次GC操作。 回收步骤 参看：G1从入门到放弃 四步过程 生产环境服务器变慢，诊断思路和性能评估谈谈？ 整机：top CPU：vmstat 内存：free 硬盘：df 磁盘IO：iostat 网络IO：ifstat 假如生产环境出现 CPU 过高，请谈谈你的分析思路和定位？ 先用 top 命令找出 CPU 占比最高的 ps -ef 或者 jps 进一步定位，得知是一个怎么样的一个后台程序 定位到具体的线程或代码 ps -mp 11111 -o THREAD,tid,time -m 显示所有的线程 -p 进程使用cpu的时间 -o 该参数后是用户自定义格式 将需要的线程 ID 转化为 16 进制格式 jstat &lt;进程ID&gt; | grep &lt;线程ID(16进制)&gt; -A60 对于 JDK 自带的 JVM 监控和性能分析工具用过哪些？一般机是怎么用到的？下一篇重点介绍。 参考链接 强引用、软引用、弱引用、幻象引用有什么区别？(评论) G1从入门到放弃","link":"/2019/05/10/JVM%E9%9D%A2%E8%AF%95/"},{"title":"Java8的深入与实战","text":"Lambda 表达式和函数式接口Lambda 表达式定义： Lambda: In programming languages such as Lisp, Python and Ruby lambda is an operator used to denote anonymous functions or closures, following the usage of lambda calculus. 为何需要使用 Lambda 表达式： 在 Java 中，我们无法将函数作为一个参数传递给一个方法，也无法声明一个返回一个函数的方法。 在 JavaScript 中，函数的参数是一个函数，返回值是另一个函数的情况是非常常见的，JavaScript 是一门典型的函数式语言。 我们通过一个例子来引入： /** * @Author: cuzz * @Date: 2019/8/11 14:55 * @Description: */public class Test1 { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6); for (int i = 0; i &lt; list.size(); i++) { System.out.println(list.get(i)); } System.out.println(&quot;-----------------&quot;); for (int val : list) { System.out.println(val); } System.out.println(&quot;-----------------&quot;); list.forEach(new Consumer&lt;Integer&gt;() { @Override public void accept(Integer integer) { System.out.println(integer); } }); }} 这是 3 种遍历集合的方式，第一就是简单的遍历，第二种是我们是常说的增强 for 循环遍历。第三种就是 Java 8 新增的方法，先看看 Consumer 这个接口。 package java.util.function;import java.util.Objects;@FunctionalInterfacepublic interface Consumer&lt;T&gt; { void accept(T t); default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; { accept(t); after.accept(t); }; }} 注解上是一个函数式接口，我们看看这个接口的作用。 package java.lang;import java.lang.annotation.*;/** * An informative annotation type used to indicate that an interface * type declaration is intended to be a &lt;i&gt;functional interface&lt;/i&gt; as * defined by the Java Language Specification. * * Conceptually, a functional interface has exactly one abstract * method. Since {@linkplain java.lang.reflect.Method#isDefault() * default methods} have an implementation, they are not abstract. If * an interface declares an abstract method overriding one of the * public methods of {@code java.lang.Object}, that also does * &lt;em&gt;not&lt;/em&gt; count toward the interface's abstract method count * since any implementation of the interface will have an * implementation from {@code java.lang.Object} or elsewhere. * * 有且只有一个抽象方法的接口，如果有重写 Object 中的方法，那也是可以的。 * * &lt;p&gt;Note that instances of functional interfaces can be created with * lambda expressions, method references, or constructor references. * * 函数式接口可以通过 lambda 表达式、方法引用和构造方法引用来创建。 * * &lt;p&gt;If a type is annotated with this annotation type, compilers are * required to generate an error message unless: * * &lt;ul&gt; * &lt;li&gt; The type is an interface type and not an annotation type, enum, or class. * &lt;li&gt; The annotated type satisfies the requirements of a functional interface. * &lt;/ul&gt; * * &lt;p&gt;However, the compiler will treat any interface meeting the * definition of a functional interface as a functional interface * regardless of whether or not a {@code FunctionalInterface} * annotation is present on the interface declaration. * * 编译器会对满足定义函数式接口的接口当做函数式接口，不管它有没有 @FunctionalInterface 注解声明。 * * @jls 4.3.2. The Class Object * @jls 9.8 Functional Interfaces * @jls 9.4.3 Interface Method Body * @since 1.8 */@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface FunctionalInterface {} 函数式接口可以通过 lambda 表达式、方法引用和构造方法引用来创建。 lambda 表达式：() -&gt; System.out.println(i) 方法引用：System.out::print 构造方法引用：new::ArrayList 用一个例子来说明什么是函数式接口。 @FunctionalInterfaceinterface Cons { void print(); String toString();}/** * @Author: cuzz * @Date: 2019/8/11 16:13 * @Description: */public class Test2 { public void test(Cons func) { func.print(); } public static void main(String[] args) { Test2 test2 = new Test2(); test2.test(() -&gt; System.out.println(&quot;xxx&quot;)); Cons func = () -&gt; System.out.println(&quot;yyy&quot;); test2.test(func); System.out.println(func.getClass()); // 输出 class com.cuzz.Test2$$Lambda$2/2074407503 System.out.println(func.getClass().getSuperclass()); // 输出 class java.lang.Object }} 可以说明3点： 函数式接口只有一个非重写 Object 的抽象方法 lambda 表达式就是一个匿名类 对于一个函数式接口，我们并不关心这个抽象方法的名称。 从Consumer深入理解函数式接口和方法引用我们回到这个例子当中 public class Test1 { public static void main(String[] args) { list.forEach(new Consumer&lt;Integer&gt;() { @Override public void accept(Integer integer) { System.out.println(integer); } }); }} 先看看 Iterable#forEach 这个方法，是 Iterable 这个接口这的默认方法，在 Java 8 中接口中是允许默认方法。对于 Iterable#forEach 是对每个元素执行给定的动作。 public interface Iterable&lt;T&gt; { /** * Returns an iterator over elements of type {@code T}. * * @return an Iterator. */ Iterator&lt;T&gt; iterator(); /** * Performs the given action for each element of the {@code Iterable} * until all elements have been processed or the action throws an * exception. Unless otherwise specified by the implementing class, * actions are performed in the order of iteration (if an iteration order * is specified). Exceptions thrown by the action are relayed to the * caller. * * 对每个元素执行给定的动作。 * * @implSpec * &lt;p&gt;The default implementation behaves as if: * &lt;pre&gt;{@code * for (T t : this) * action.accept(t); * }&lt;/pre&gt; * * @param action The action to be performed for each element * @throws NullPointerException if the specified action is null * @since 1.8 */ default void forEach(Consumer&lt;? super T&gt; action) { Objects.requireNonNull(action); for (T t : this) { action.accept(t); } } default Spliterator&lt;T&gt; spliterator() { return Spliterators.spliteratorUnknownSize(iterator(), 0); }} 看看 Consumer 是什么 package java.util.function;import java.util.Objects;/** * Represents an operation that accepts a single input argument and returns no * result. Unlike most other functional interfaces, {@code Consumer} is expected * to operate via side-effects. * * 表示一个操作接受单一输入参数，无返回结果。 * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #accept(Object)}. * * @param &lt;T&gt; the type of the input to the operation * * @since 1.8 */@FunctionalInterfacepublic interface Consumer&lt;T&gt; { /** * Performs this operation on the given argument. * * @param t the input argument */ void accept(T t); /** * Returns a composed {@code Consumer} that performs, in sequence, this * operation followed by the {@code after} operation. If performing either * operation throws an exception, it is relayed to the caller of the * composed operation. If performing this operation throws an exception, * the {@code after} operation will not be performed. * * @param after the operation to perform after this operation * @return a composed {@code Consumer} that performs in sequence this * operation followed by the {@code after} operation * @throws NullPointerException if {@code after} is null */ default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; { accept(t); after.accept(t); }; }} lambda 表达式的作用： lambda 表达式为 Java 添加了缺失的函数式编程特性，使我们能将函数当做一等公民看待。 在将函数作为一等公民的语言中，lambda 表达式的类型是函数。但在 Java 中，lambda 表达式是对象，它们必须依附于一类特别的对象（函数式接口）； Lambda 表达式的深入对于 lambda 表达式需要根据上下文来推断，我们并不知道 () -&gt; {} 是什么，不知道对应的参数，方法是什么，只用通过前面的 Cons 定义才知道。 @FunctionalInterfaceinterface Cons1 { void print1();}@FunctionalInterfaceinterface Cons2 { void print2();}/** * @Author: cuzz * @Date: 2019/8/11 16:13 * @Description: */public class Test2 { public static void main(String[] args) { Cons1 cons1 = () -&gt; {}; Cons2 cons2 = () -&gt; {}; System.out.println(cons1.getClass().getInterfaces()[0]); // interface com.cuzz.Cons1 System.out.println(cons2.getClass().getInterfaces()[0]); // interface com.cuzz.Cons2 }} 我们先看一个排序的例子： /** * @Author: cuzz * @Date: 2019/8/12 23:09 * @Description: 排序 */public class Test4 { public static void main(String[] args) { List&lt;String&gt; list = Arrays.asList(&quot;cuzz&quot;, &quot;faker&quot;, &quot;mlxg&quot;); Collections.sort(list, (String s1, String s2) -&gt; { return s2.compareTo(s1); }); // 1 Collections.sort(list, (s1, s2) -&gt; s2.compareTo(s1)); // 2 }} 从 1 到 2 简化了很多，修饰符 String 和 return 都可以省略。Java Lambda 表达式是一种匿名函数，它没有声明方法，也没有访问修饰符、返回值和名字。 Lambda 表达式作用： 传递行为，而不仅仅是值 提升抽象层次 API 重用性好 更加灵活 Lambda 基本语法： Java 中的 Lambda 表达式基本语法 如：(argument) -&gt; {body} 省略类型：(arg1, arg2, ...) -&gt; {body} 有类型：(type1 arg1, type2 arg2, ...) -&gt; {body} Lambda 示例说明 (int a, int b) -&gt; {return a + b;} () -&gt; System.out.println(&quot;hello world&quot;) (String s) -&gt; {System.out.println(s);} () -&gt; 42 () -&gt; {return &quot;cuzz&quot;}; Lambda结构 一个 Lambda 表达式可以有零个或多个参数 参数的类型既可以明确声明，也可以根据上下文来推断，如：(int a) 与 (a) 效果相同 所有的参数需包含在圆括号内，参数之间用逗号相隔。如：(a, b) 或 (String a, int b float c) 空圆括号表示参数集为空，如：() -&gt; 42 当只有一个参数，且其类型可推导时，圆括号可以省略，如：a -&gt; return a * a Lambda 表达式的主题可以包含零条或多条语句 如果 Lambda 表达式的主体只有一条语句，花括号可以省略，匿名函数的返回类型与该主体表达式一致 如果 Lambda 表达式的主体包含一条以上语句，表达式必须使用花括号 Function直接先看源码 /** * Represents a function that accepts one argument and produces a result. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #apply(Object)}. * * @param &lt;T&gt; the type of the input to the function * @param &lt;R&gt; the type of the result of the function * * @since 1.8 */@FunctionalInterfacepublic interface Function&lt;T, R&gt; { /** * Applies this function to the given argument. * * @param t the function argument * @return the function result */ R apply(T t); default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) { Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v)); } default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t)); } /** * Returns a function that always returns its input argument. * * @param &lt;T&gt; the type of the input and output objects to the function * @return a function that always returns its input argument */ static &lt;T&gt; Function&lt;T, T&gt; identity() { return t -&gt; t; }} 可以看出 Function 有一个抽象方法和两个默认方法以及一个静态方法。 （1） Function#apply Stream#map 里就是接受一个 Function，对于 Function 意思就是从一个映射到另一个。下面例子就是把字符串映射到大写。对于 String::toUpperCase 使用的是方法引用。 /** * @Author: cuzz * @Date: 2019/8/11 23:13 * @Description: */public class Test3 { public static void main(String[] args) { List&lt;String&gt; list = Arrays.asList(&quot;cuzz&quot;, &quot;faker&quot;, &quot;mlxg&quot;); list.stream().map(item -&gt; item.toUpperCase()).forEach(item -&gt; System.out.println(item)); list.stream().map(String::toUpperCase).forEach(System.out::println); Function&lt;String, String&gt; function = String::toUpperCase; System.out.println(function.getClass()); }} 我们看一个例子： /** * @Author: cuzz * @Date: 2019/8/13 0:08 * @Description: */public class FunctionTest { public static void main(String[] args) { FunctionTest function= new FunctionTest(); int res1 = function.compute(100, target -&gt; target * target); int res2 = function.compute(100, target -&gt; target + 1); System.out.println(res1); // 10000 System.out.println(res2); // 101 int res3 = function.pow(100); int res4 = function.addOne(100); System.out.println(res3); // 10000 System.out.println(res4); // 101 } public int compute(int a, Function&lt;Integer, Integer&gt; function) { return function.apply(a); } public int pow(int a) { return a * a; } public int addOne(int a) { return a + 1; }} 看看 #compute 这个方法，第二个参数传递的是行为，而不是具体的值。 我们本来要定义两个方法，pow 和 addOne 现在把这种行为传递进来。 （2）Function#compose 和 Function#andThen /** * Returns a composed function that first applies the {@code before} * function to its input, and then applies this function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of input to the {@code before} function, and to the * composed function * @param before the function to apply before this function is applied * @return a composed function that first applies the {@code before} * function and then applies this function * @throws NullPointerException if before is null * * @see #andThen(Function) */default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) { Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v));}/** * Returns a composed function that first applies this function to * its input, and then applies the {@code after} function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of output of the {@code after} function, and of the * composed function * @param after the function to apply after this function is applied * @return a composed function that first applies this function and then * applies the {@code after} function * @throws NullPointerException if after is null * * @see #compose(Function) */default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t));} compose方法是一个默认方法，这个方法接收一个 function 作为参数，将参数 function 执行的结果作为参数给调用的 function，以此来实现两个function组合的功能。 andThen 方法也是接收一个 function 作为参数，与 compse 不同的是，先执行本身的 apply 方法，将执行的结果作为参数给参数中的 function。 /** * @Author: cuzz * @Date: 2019/8/20 23:59 * @Description: #compose and #andThen test */public class FunctionTest2 { public static void main(String[] args) { FunctionTest2 test = new FunctionTest2(); System.out.println(test.compute1(2, value -&gt; value * 2, value -&gt; value * value)); // 8 System.out.println(test.compute2(2, value -&gt; value * 2, value -&gt; value * value)); // 16 } public int compute1(int a, Function&lt;Integer, Integer&gt; function1, Function&lt;Integer, Integer&gt; function2) { return function1.compose(function2).apply(a); } public int compute2(int a, Function&lt;Integer, Integer&gt; function1, Function&lt;Integer, Integer&gt; function2) { return function1.andThen(function2).apply(a); }} 发现 compute1 是先执行第二个 Function 再执行第一，compute2 相反。 BiFunction先看源码 /** * Represents a function that accepts two arguments and produces a result. * This is the two-arity specialization of {@link Function}. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #apply(Object, Object)}. * * @param &lt;T&gt; the type of the first argument to the function * @param &lt;U&gt; the type of the second argument to the function * @param &lt;R&gt; the type of the result of the function * * @see Function * @since 1.8 */@FunctionalInterfacepublic interface BiFunction&lt;T, U, R&gt; { /** * Applies this function to the given arguments. * * @param t the first function argument * @param u the second function argument * @return the function result */ R apply(T t, U u); /** * Returns a composed function that first applies this function to * its input, and then applies the {@code after} function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of output of the {@code after} function, and of the * composed function * @param after the function to apply after this function is applied * @return a composed function that first applies this function and then * applies the {@code after} function * @throws NullPointerException if after is null */ default &lt;V&gt; BiFunction&lt;T, U, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t, U u) -&gt; after.apply(apply(t, u)); }} 我看一个例子 /** * @Author: cuzz * @Date: 2019/8/21 7:36 * @Description: */public class BiFunctionTest { public static void main(String[] args) { BiFunctionTest test = new BiFunctionTest(); // 加法 System.out.println(test.add(1, 2)); System.out.println(test.compute(1, 2, (a, b) -&gt; a + b)); // 减法 System.out.println(test.subtract(1, 2)); System.out.println(test.compute(1, 2, (a, b) -&gt; a - b)); } public int compute(int a, int b, BiFunction&lt;Integer, Integer, Integer&gt; biFunction) { return biFunction.apply(a, b); } public int add(int a, int b) { return a + b; } public int subtract(int a, int b) { return a - b; }} 以前我们定义一个四则运算需要需要先定义方法，现在通过 BiFunction 可以把这种行为传递进来。 Predicate（1）源码 /** * Represents a predicate (boolean-valued function) of one argument. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #test(Object)}. * * @param &lt;T&gt; the type of the input to the predicate * * @since 1.8 */@FunctionalInterfacepublic interface Predicate&lt;T&gt; { /** * Evaluates this predicate on the given argument. * * @param t the input argument * @return {@code true} if the input argument matches the predicate, * otherwise {@code false} */ boolean test(T t); /** * Returns a composed predicate that represents a short-circuiting logical * AND of this predicate and another. When evaluating the composed * predicate, if this predicate is {@code false}, then the {@code other} * predicate is not evaluated. * * &lt;p&gt;Any exceptions thrown during evaluation of either predicate are relayed * to the caller; if evaluation of this predicate throws an exception, the * {@code other} predicate will not be evaluated. * * @param other a predicate that will be logically-ANDed with this * predicate * @return a composed predicate that represents the short-circuiting logical * AND of this predicate and the {@code other} predicate * @throws NullPointerException if other is null */ default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) { Objects.requireNonNull(other); return (t) -&gt; test(t) &amp;&amp; other.test(t); } /** * Returns a predicate that represents the logical negation of this * predicate. * * @return a predicate that represents the logical negation of this * predicate */ default Predicate&lt;T&gt; negate() { return (t) -&gt; !test(t); } /** * Returns a composed predicate that represents a short-circuiting logical * OR of this predicate and another. When evaluating the composed * predicate, if this predicate is {@code true}, then the {@code other} * predicate is not evaluated. * * &lt;p&gt;Any exceptions thrown during evaluation of either predicate are relayed * to the caller; if evaluation of this predicate throws an exception, the * {@code other} predicate will not be evaluated. * * @param other a predicate that will be logically-ORed with this * predicate * @return a composed predicate that represents the short-circuiting logical * OR of this predicate and the {@code other} predicate * @throws NullPointerException if other is null */ default Predicate&lt;T&gt; or(Predicate&lt;? super T&gt; other) { Objects.requireNonNull(other); return (t) -&gt; test(t) || other.test(t); } /** * Returns a predicate that tests if two arguments are equal according * to {@link Objects#equals(Object, Object)}. * * @param &lt;T&gt; the type of arguments to the predicate * @param targetRef the object reference with which to compare for equality, * which may be {@code null} * @return a predicate that tests if two arguments are equal according * to {@link Objects#equals(Object, Object)} */ static &lt;T&gt; Predicate&lt;T&gt; isEqual(Object targetRef) { return (null == targetRef) ? Objects::isNull : object -&gt; targetRef.equals(object); }} （2）例子 以前我们根据不同的条件筛选数据需要些多个方法，现在只要先定义一个这种接受行为的方法。 /** * @Author: cuzz * @Date: 2019/8/21 23:35 * @Description: Predicate test */public class PredicateTest { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); PredicateTest test = new PredicateTest(); // 查找奇数 test.findOdd(list); test.conditionFilter(list, i -&gt; i % 2 != 0); // 查找偶数 test.findEven(list); test.conditionFilter(list, i -&gt; i % 2 == 0); } public void conditionFilter(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate) { for (int i : list) { if (predicate.test(i)) { System.out.print(i + &quot; &quot;); } } System.out.println(); } public void findOdd(List&lt;Integer&gt; list) { for (int i : list) { if (i % 2 != 0) { System.out.print(i + &quot; &quot;); } } System.out.println(); } public void findEven(List&lt;Integer&gt; list) { for (int i : list) { if (i % 2 == 0) { System.out.print(i + &quot; &quot;); } } System.out.println(); }} （3）Predicate#and 和 Predicate#or public class PredicateTest { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); PredicateTest test = new PredicateTest(); // 查找 大于 3 的奇数 test.conditionFilter2(list, i -&gt; i &gt; 3, i -&gt; i % 2 != 0); } public void conditionFilter2(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate1, Predicate&lt;Integer&gt; predicate2) { for (int i : list) { if (predicate1.and(predicate2).test(i)) { System.out.print(i + &quot; &quot;); } } System.out.println(); }} Supplier（1）不接受参数，返回一个值。 /** * Represents a supplier of results. * * &lt;p&gt;There is no requirement that a new or distinct result be returned each * time the supplier is invoked. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #get()}. * * @param &lt;T&gt; the type of results supplied by this supplier * * @since 1.8 */@FunctionalInterfacepublic interface Supplier&lt;T&gt; { /** * Gets a result. * * @return a result */ T get();} （2）例子 /** * @Author: cuzz * @Date: 2019/8/22 23:32 * @Description: */public class SupplierTest { public static void main(String[] args) { Supplier&lt;Student&gt; supplier1 = () -&gt; new Student(); Supplier&lt;Student&gt; supplier2 = Student::new; }}@Dataclass Student { private String name = &quot;cuzz&quot;; private int age = 20;} Optional参考： 使用 Java 8 Optional 的正确姿势","link":"/2019/08/11/Java8%E7%9A%84%E6%B7%B1%E5%85%A5%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"title":"Netty 源码分析（一）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. 先看一个例子服务端MyServer 类 /** * @Author: cuzz * @Date: 2019/1/1 19:44 * @Description: */public class MyServer { public static void main(String[] args) throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); ChannelFuture channelFuture = bootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } }} MyServerinitializer 类 /** * @Author: cuzz * @Date: 2019/1/1 20:06 * @Description: */public class MyServerinitializer extends ChannelInitializer&lt;SocketChannel&gt; { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)); pipeline.addLast(new LengthFieldPrepender(4)); pipeline.addLast(new StringDecoder(CharsetUtil.UTF_8)); pipeline.addLast(new StringEncoder(CharsetUtil.UTF_8)); pipeline.addLast(new MyServerHandler()); }} MyServerHandler 类 /** * @Author: cuzz * @Date: 2019/1/1 20:23 * @Description: */public class MyServerHandler extends SimpleChannelInboundHandler&lt;String&gt;{ @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { System.out.println(ctx.channel().remoteAddress() + &quot;: &quot; + msg); ctx.channel().writeAndFlush(&quot;from server: &quot; + UUID.randomUUID()); } /** * 出现异常关闭连接 * @param ctx * @param cause * @throws Exception */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 客服端MyClient 类 /** * @Author: cuzz * @Date: 2019/1/1 20:31 * @Description: */public class MyClient { public static void main(String[] args) throws Exception { EventLoopGroup eventLoopGroup = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap(); bootstrap.group(eventLoopGroup) .channel(NioSocketChannel.class) .handler(new MyClientInitializer()); ChannelFuture channelFuture = bootstrap.connect(&quot;localhost&quot;,8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { eventLoopGroup.shutdownGracefully(); } }} MyClientInitializer 类 /** * @Author: cuzz * @Date: 2019/1/1 20:40 * @Description: */public class MyClientInitializer extends ChannelInitializer&lt;SocketChannel&gt;{ @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)); pipeline.addLast(new LengthFieldPrepender(4)); pipeline.addLast(new StringDecoder(CharsetUtil.UTF_8)); pipeline.addLast(new StringEncoder(CharsetUtil.UTF_8)); pipeline.addLast(new MyClientHandler()); }} MyClientHandler 类 /** * @Author: cuzz * @Date: 2019/1/1 20:42 * @Description: */public class MyClientHandler extends SimpleChannelInboundHandler&lt;String&gt;{ @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { System.out.println(ctx.channel().remoteAddress() + &quot;: &quot; + msg); ctx.writeAndFlush(&quot;from clinet: &quot; + UUID.randomUUID()); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { ctx.writeAndFlush(&quot;来自客户端的连接！！！&quot;); }} 初始化EventLoopGroup创建一个 bossGroup 和 workGroup EventLoopGroup bossGroup = new NioEventLoopGroup();EventLoopGroup workGroup = new NioEventLoopGroup(); EventLoopGroup 翻译过来叫事件循环组，其本身就是一个死循环 bossGroup 是把接受连接，把连接转发给 workGroup ，workGroup 是真正完成用户请求处理的类 EventLoopGroup 是一个接口，在后面循环的过程中可以选择把 Channel 注册上 /** * Special {@link EventExecutorGroup} which allows registering {@link Channel}s that get * processed for later selection during the event loop. * */public interface EventLoopGroup extends EventExecutorGroup { @Override EventLoop next(); ChannelFuture register(Channel channel); ChannelFuture register(ChannelPromise promise);} NioEventLoopGroup// 他是一个基于NIO的选择器的对象 public class NioEventLoopGroup extends MultithreadEventLoopGroup { // 0 public NioEventLoopGroup() { this(0); } // 1 public NioEventLoopGroup(int nThreads) { this(nThreads, (Executor) null); } // 2 public NioEventLoopGroup(int nThreads, Executor executor) { this(nThreads, executor, SelectorProvider.provider()); }} MultithreadEventExecutorGroup最终会跳到MultithreadEventExecutorGroup 中的一个构造器中 protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) { } // 1 if (executor == null) { executor = new ThreadPerTaskExecutor(newDefaultThreadFactory()); } children = new EventExecutor[nThreads]; for (int i = 0; i &lt; nThreads; i ++) { boolean success = false; try { children[i] = newChild(executor, args); success = true; } catch (Exception e) { // TODO: Think about if this is a good exception type throw new IllegalStateException(&quot;failed to create a child event loop&quot;, e); } finally { if (!success) { for (int j = 0; j &lt; i; j ++) { children[j].shutdownGracefully(); } for (int j = 0; j &lt; i; j ++) { EventExecutor e = children[j]; try { while (!e.isTerminated()) { e.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS); } } catch (InterruptedException interrupted) { // Let the caller handle the interruption. Thread.currentThread().interrupt(); break; } } } } } chooser = chooserFactory.newChooser(children); final FutureListener&lt;Object&gt; terminationListener = new FutureListener&lt;Object&gt;() { @Override public void operationComplete(Future&lt;Object&gt; future) throws Exception { if (terminatedChildren.incrementAndGet() == children.length) { terminationFuture.setSuccess(null); } } }; for (EventExecutor e: children) { e.terminationFuture().addListener(terminationListener); } Set&lt;EventExecutor&gt; childrenSet = new LinkedHashSet&lt;EventExecutor&gt;(children.length); Collections.addAll(childrenSet, children); readonlyChildren = Collections.unmodifiableSet(childrenSet); } ThreadPerTaskExecutor代码1中，executor = new ThreadPerTaskExecutor(newDefaultThreadFactory());，跟进去 public final class ThreadPerTaskExecutor implements Executor { private final ThreadFactory threadFactory; public ThreadPerTaskExecutor(ThreadFactory threadFactory) { if (threadFactory == null) { throw new NullPointerException(&quot;threadFactory&quot;); } this.threadFactory = threadFactory; } @Override public void execute(Runnable command) { threadFactory.newThread(command).start(); }} 这里用到了工厂方法和命令模式，通过传入一个command调用工厂方法 Executorpublic interface Executor { /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the {@code Executor} implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution * @throws NullPointerException if command is null */ void execute(Runnable command);} 这是在java.util.concurrent 下的一个接口，最主要的实现方式把一个task传入，新建一个线程运行 class ThreadPerTaskExecutor implements Executor { public void execute(Runnable r) { new Thread(r).start(); }} 也可以通过一系列的限制，比如序列化等一下操作 class SerialExecutor implements Executor { final Queue&lt;Runnable&gt; tasks = new ArrayDeque&lt;Runnable&gt;(); final Executor executor; Runnable active; SerialExecutor(Executor executor) { this.executor = executor; } public synchronized void execute(final Runnable r) { tasks.offer(new Runnable() { public void run() { try { r.run(); } finally { scheduleNext(); } } }); if (active == null) { scheduleNext(); } } protected synchronized void scheduleNext() { if ((active = tasks.poll()) != null) { executor.execute(active); } }} 其中非常常用用的几个实现如：ExecutorService，ThreadPoolExecutor 下面是官方文档 The Executor implementations provided in this package implement ExecutorService, which is a more extensive interface. The ThreadPoolExecutor class provides an extensible thread pool implementation. The Executors class provides convenient factory methods for these Executors.The Executor implementations provided in this package implement ExecutorService, which is a more extensive interface. The ThreadPoolExecutor class provides an extensible thread pool implementation. The Executors class provides convenient factory methods for these Executors. 回顾一下 MyServer 中启动的代码 try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); ChannelFuture channelFuture = bootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync();} finally { bossGroup.shutdownGracefully(); bossGroup.shutdownGracefully();} ServerBootstrappublic class ServerBootstrap extends AbstractBootstrap&lt;ServerBootstrap, ServerChannel&gt; { ... } ServerBootstrap 是 Bootstrap子类，容易的地启动一个 ServerChannel ServerChannel接受一个即将到来的连接，创建子 Channel /** * A {@link Channel} that accepts an incoming connection attempt and creates * its child {@link Channel}s by accepting them. {@link ServerSocketChannel} is * a good example. */public interface ServerChannel extends Channel { // This is a tag interface.} 其有很多实现的子类，其中 NioServerSocketChannel 是我们比较关注的 方法链bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); .group(bossGroup, workGroup) 我们把 bossGroup 和 workGroup 传入进去，由于是方法链，肯定返回本身，跟踪下去 /** * Set the {@link EventLoopGroup} for the parent (acceptor) and the child (client). These * {@link EventLoopGroup}'s are used to handle all the events and IO for {@link ServerChannel} and * {@link Channel}'s. */public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) { super.group(parentGroup); if (childGroup == null) { throw new NullPointerException(&quot;childGroup&quot;); } if (this.childGroup != null) { throw new IllegalStateException(&quot;childGroup set already&quot;); } this.childGroup = childGroup; return this;} 这个步，就是给 bossGroup 和 workGroup 赋值给 ServerBootstrap 的实例 .channel(NioServerSocketChannel.class) 方法，接受的是一个 class 对象，一般接受 class 对象大多数与反射有关系 /** * The {@link Class} which is used to create {@link Channel} instances from. * You either use this or {@link #channelFactory(io.netty.channel.ChannelFactory)} if your * {@link Channel} implementation has no no-args constructor. */public B channel(Class&lt;? extends C&gt; channelClass) { if (channelClass == null) { throw new NullPointerException(&quot;channelClass&quot;); } return channelFactory(new ReflectiveChannelFactory&lt;C&gt;(channelClass));} 进入 channelFactory 方法 /** * {@link io.netty.channel.ChannelFactory} which is used to create {@link Channel} instances from * when calling {@link #bind()}. This method is usually only used if {@link #channel(Class)} * is not working for you because of some more complex needs. If your {@link Channel} implementation * has a no-args constructor, its highly recommend to just use {@link #channel(Class)} for * simplify your code. */@SuppressWarnings({ &quot;unchecked&quot;, &quot;deprecation&quot; })public B channelFactory(io.netty.channel.ChannelFactory&lt;? extends C&gt; channelFactory) { return channelFactory((ChannelFactory&lt;C&gt;) channelFactory);} 如果有无参数的构造方法推荐使用，这样可以简化代码 Q：为什么必须要有无参数构造方法呢？ A : 一般来说，获取一个实例如下生成，所以必须有无参数构造方法 Class class = Class.forName(className);Object object = class.newInstance(); // 只能调用无参构造函数 我们在来看看 NioServerSocketChannel A {@link io.netty.channel.socket.ServerSocketChannel} implementation which uses NIO selector based implementation to accept new connections. .childHandler(new MyServerinitializer()); 设置用于请求的 Handler /** * Set the {@link ChannelHandler} which is used to serve the request for the {@link Channel}'s. */public ServerBootstrap childHandler(ChannelHandler childHandler) { if (childHandler == null) { throw new NullPointerException(&quot;childHandler&quot;); } this.childHandler = childHandler; return this;} 这里其实有 handler 和 childHandler 一个是给 bossGroup 使用的，一个是给 workGroup 使用的 启动ChannelFuture channelFuture = bootstrap.bind(8899).sync(); ChannelFutureChannelFuture 先是继承了自己提供的 Future ，自身的 Future 又继承 java.util.concurrent.Future&lt;V&gt; ，我们先看看 JUC 中 Future 和 FutureTask JUC.Future看看其中几个主要的方法，从方法名也知道是做什么的 public interface Future&lt;V&gt; { boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;} 文档： A Future represents the result of an asynchronous computation. Methods are provided to check if the computation is complete, to wait for its completion, and to retrieve the result of the computation. The result can only be retrieved using method get when the computation has completed, blocking if necessary until it is ready. Cancellation is performed by the cancel method. Additional methods are provided to determine if the task completed normally or was cancelled. Once a computation has completed, the computation cannot be cancelled. If you would like to use a Future for the sake of cancellability but not provide a usable result, you can declare types of the form Future&lt;?&gt; and return null as a result of the underlying task. 使用： interface ArchiveSearcher { String search(String target); }class App { ExecutorService executor = ... ArchiveSearcher searcher = ... void showSearch(final String target) throws InterruptedException { Future&lt;String&gt; future = executor.submit(new Callable&lt;String&gt;() { public String call() { return searcher.search(target); } }); displayOtherThings(); // do other things while searching try { displayText(future.get()); // use future } catch (ExecutionException ex) { cleanup(); return; } }} JUC.FutureTask The FutureTask class is an implementation of Future that implements Runnable, and so may be executed by an Executor. For example, the above construction with submit could be replaced by: FutureTask&lt;String&gt; future = new FutureTask&lt;String&gt;(new Callable&lt;String&gt;() { public String call() { return searcher.search(target); }});executor.execute(future); 可以通过 Executor 的实例去执行，最后再从 future 中获取 Netty.Futurepublic interface Future&lt;V&gt; extends java.util.concurrent.Future&lt;V&gt; { boolean isSuccess(); boolean isCancellable(); Throwable cause(); /** * Adds the specified listener to this future. The * specified listener is notified when this future is * {@linkplain #isDone() done}. If this future is already * completed, the specified listener is notified immediately. */ Future&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); /** * Adds the specified listeners to this future. The * specified listeners are notified when this future is * {@linkplain #isDone() done}. If this future is already * completed, the specified listeners are notified immediately. */ Future&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); /** * Removes the first occurrence of the specified listener from this future. * The specified listener is no longer notified when this * future is {@linkplain #isDone() done}. If the specified * listener is not associated with this future, this method * does nothing and returns silently. */ Future&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); /** * Removes the first occurrence for each of the listeners from this future. * The specified listeners are no longer notified when this * future is {@linkplain #isDone() done}. If the specified * listeners are not associated with this future, this method * does nothing and returns silently. */ Future&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); // 等待Future完成 Future&lt;V&gt; sync() throws InterruptedException; Future&lt;V&gt; syncUninterruptibly(); Future&lt;V&gt; await() throws InterruptedException; Future&lt;V&gt; awaitUninterruptibly(); boolean await(long timeout, TimeUnit unit) throws InterruptedException; boolean await(long timeoutMillis) throws InterruptedException; boolean awaitUninterruptibly(long timeout, TimeUnit unit); boolean awaitUninterruptibly(long timeoutMillis); V getNow(); @Override boolean cancel(boolean mayInterruptIfRunning);} 我们主要看看 xxListener 方法，一后缀为 Listener 使用了观察者模式 它比 JUC.Future 更厉害的是就因为这个 Listener ，虽然 JUC.Future 可以调用 get() 方法，获取异步结果，但是我们不知道什么时候去调用，调用早了就堵塞在那里；而 Netty.Future 使用了观察者模式，当完成时会自动触发 ChannelFuture我们回到 ChannelFuture ，都重写了 Netty.Future 中的方法，返回值是 Future 的子类，java5或者以前，必须一样，java7以后可以不同，但是必须是父类返回值的派生类 public interface ChannelFuture extends Future&lt;Void&gt; { /** * Returns a channel where the I/O operation associated with this * future takes place. */ Channel channel(); @Override ChannelFuture addListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); @Override ChannelFuture addListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); @Override ChannelFuture removeListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); @Override ChannelFuture removeListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); @Override ChannelFuture sync() throws InterruptedException; @Override ChannelFuture syncUninterruptibly(); @Override ChannelFuture await() throws InterruptedException; @Override ChannelFuture awaitUninterruptibly(); 文档： io.netty.channelpublic interface ChannelFutureextends Future The result of an asynchronous Channel I/O operation. All I/O operations in Netty are asynchronous. It means any I/O calls will return immediately with no guarantee that the requested I/O operation has been completed at the end of the call. Instead, you will be returned with a ChannelFuture instance which gives you the information about the result or status of the I/O operation. A ChannelFuture is either uncompleted or completed. When an I/O operation begins, a new future object is created. The new future is uncompleted initially - it is neither succeeded, failed, nor cancelled because the I/O operation is not finished yet. If the I/O operation is finished either successfully, with failure, or by cancellation, the future is marked as completed with more specific information, such as the cause of the failure. Please note that even failure and cancellation belong to the completed state. +---------------------------+ | Completed successfully | +---------------------------+ +----&gt; isDone() = true |+--------------------------+ | | isSuccess() = true || Uncompleted | | +===========================++--------------------------+ | | Completed with failure || isDone() = false | | +---------------------------+| isSuccess() = false |----+----&gt; isDone() = true || isCancelled() = false | | | cause() = non-null || cause() = null | | +===========================++--------------------------+ | | Completed by cancellation | | +---------------------------+ +----&gt; isDone() = true | | isCancelled() = true | +---------------------------+ Various methods are provided to let you check if the I/O operation has been completed, wait for the completion, and retrieve the result of the I/O operation. It also allows you to add ChannelFutureListeners so you can get notified when the I/O operation is completed. 推荐使用监听器而不是等待的方法 // BAD - NEVER DO THIS@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) { ChannelFuture future = ctx.channel().close(); future.awaitUninterruptibly(); // Perform post-closure operation // ...}// GOOD@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) { ChannelFuture future = ctx.channel().close(); future.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) { // Perform post-closure operation // ... } });} 不要混淆连接超时和等待超时 // BAD - NEVER DO THISBootstrap b = ...;ChannelFuture f = b.connect(...);f.awaitUninterruptibly(10, TimeUnit.SECONDS);if (f.isCancelled()) { // Connection attempt cancelled by user} else if (!f.isSuccess()) { // You might get a NullPointerException here because the future // might not be completed yet. f.cause().printStackTrace();} else { // Connection established successfully}// GOODBootstrap b = ...;// Configure the connect timeout option.b.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 10000);ChannelFuture f = b.connect(...);f.awaitUninterruptibly();// Now we are sure the future is completed.assert f.isDone();if (f.isCancelled()) { // Connection attempt cancelled by user} else if (!f.isSuccess()) { f.cause().printStackTrace();} else { // Connection established successfully} bind()方法当我们调用 bind 方法时，才真正的启动服务器 ChannelFuture channelFuture = bootstrap.bind(8899).sync(); 通过一些判断最终到 doBind 方法上 private ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) { return regFuture; } if (regFuture.isDone()) { // At this point we know that the registration was complete and successful. ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; } else { // Registration future is almost always fulfilled already, but just in case it's not. final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { Throwable cause = future.cause(); if (cause != null) { // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an // IllegalStateException once we try to access the EventLoop of the Channel. promise.setFailure(cause); } else { // Registration was successful, so set the correct executor to use. // See https://github.com/netty/netty/issues/2586 promise.registered(); doBind0(regFuture, channel, localAddress, promise); } } }); return promise; }} initAndRegister()方法这个主要是初始化和注册，比较复杂，后续在分析 加油！！！","link":"/2019/01/03/Netty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"Netty 源码分析（三）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. addLast 方法io.netty.channel.DefaultChannelPipeline#addLast @Overridepublic final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) { final AbstractChannelHandlerContext newCtx; synchronized (this) { checkMultiplicity(handler); newCtx = newContext(group, filterName(name, handler), handler); addLast0(newCtx); // 是把 ChannelHandlerContext 添加进去 // If the registered is false it means that the channel was not registered on an eventloop yet. // In this case we add the context to the pipeline and add a task that will call // ChannelHandler.handlerAdded(...) once the channel is registered. if (!registered) { newCtx.setAddPending(); callHandlerCallbackLater(newCtx, true); return this; } EventExecutor executor = newCtx.executor(); if (!executor.inEventLoop()) { newCtx.setAddPending(); executor.execute(new Runnable() { @Override public void run() { callHandlerAdded0(newCtx); } }); return this; } } callHandlerAdded0(newCtx); return this;} AbstractChannelHandlerContext 定义了一个上下文，找到实现的一个接口 ChannelHandlerContext io.netty.channel.ChannelHandlerContext 文档：https://netty.io/5.0/api/io/netty/channel/ChannelHandlerContext.html 接下来我分析一下 ChannelHandlerContext ，PipeLine，Handler 这三者的关系 这篇文章写的很清楚 https://blog.csdn.net/u010853261/article/details/54574440 ChannelHandlerContext每个ChannelHandler被添加到ChannelPipeline后，都会创建一个ChannelHandlerContext并与之创建的ChannelHandler关联绑定。ChannelHandlerContext允许ChannelHandler与其他的ChannelHandler实现进行交互。ChannelHandlerContext不会改变添加到其中的ChannelHandler，因此它是安全的 下图显示了ChannelHandlerContext、ChannelHandler、ChannelPipeline的关系： ![20170116160400326](Netty 源码分析（三）/20170116160400326.png) 最后我们看到 private void addLast0(AbstractChannelHandlerContext newCtx) { AbstractChannelHandlerContext prev = tail.prev; newCtx.prev = prev; newCtx.next = tail; prev.next = newCtx; tail.prev = newCtx;} 我们的双向链表链表维护的是 ChannelHandlerContext 对象，而ChannelHandlerContext 包装了 ChannelHandler 我们回到 addLast 方法上 p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) throws Exception { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) { pipeline.addLast(handler); } ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); }}); 进入 ChannelInitializer 类中，我们看 #initChannel 方法，说这个方法当 Channel 注册时会被调用，一旦掉用完就会被移除 ChannelPipeline，这是因为只需要把里面封装的 Handler 添加到 ChannelPipeline，因为他本身就不一个 Handler io.netty.channel.ChannelInitializerprotected abstract void initChannel(C ch) This method will be called once the Channel was registered. After the method returns this instance will be removed from the ChannelPipeline of the Channel. 下面是移除代码 private boolean initChannel(ChannelHandlerContext ctx) throws Exception { if (initMap.putIfAbsent(ctx, Boolean.TRUE) == null) { // Guard against re-entrance. try { initChannel((C) ctx.channel()); } catch (Throwable cause) { // Explicitly call exceptionCaught(...) as we removed the handler before calling initChannel(...). // We do so to prevent multiple calls to initChannel(...). exceptionCaught(ctx, cause); } finally { remove(ctx); } return true; } return false;}private void remove(ChannelHandlerContext ctx) { try { ChannelPipeline pipeline = ctx.pipeline(); if (pipeline.context(this) != null) { pipeline.remove(this); } } finally { initMap.remove(ctx); }} ChannelHandlerContext.attr(..) == Channel.attr(..)https://netty.io/wiki/new-and-noteworthy-in-4.1.html Both Channel and ChannelHandlerContext implement the interface AttributeMap to enable a user to attach one or more user-defined attributes to them. What sometimes made a user confused was that a Channel and a ChannelHandlerContext had its own storage for the user-defined attributes. For example, even if you put an attribute ‘KEY_X’ via Channel.attr(KEY_X).set(valueX), you will never find it via ChannelHandlerContext.attr(KEY_X).get() and vice versa. This behavior is not only confusing but also is waste of memory. To address this issue, we decided to keep only one map per Channel internally. AttributeMap always uses AttributeKey as its key. AttributeKey ensures uniqueness between each key, and thus there’s no point of having more than one attribute map per Channel. As long as a user defines its own AttributeKey as a private static final field of his or her ChannelHandler, there will be no risk of duplicate keys. 注意：现在这两个关联的是一个Map callHandlerCallbackLater![1547566461118](Netty 源码分析（三）/1547566461118.png) 我们回到 #addLast 方法上，这个时候是还没有注册的，进入这个 #callHandlerCallbackLater 方法，把稍后调用 Handler 回调，封装成一个 task private void callHandlerCallbackLater(AbstractChannelHandlerContext ctx, boolean added) { assert !registered; PendingHandlerCallback task = added ? new PendingHandlerAddedTask(ctx) : new PendingHandlerRemovedTask(ctx); PendingHandlerCallback pending = pendingHandlerCallbackHead; if (pending == null) { pendingHandlerCallbackHead = task; } else { // Find the tail of the linked-list. while (pending.next != null) { pending = pending.next; } pending.next = task; }} 注册我们回到io.netty.bootstrap.AbstractBootstrap#initAndRegister final ChannelFuture initAndRegister() { Channel channel = null; try { channel = channelFactory.newChannel(); init(channel); } catch (Throwable t) { if (channel != null) { // channel can be null if newChannel crashed (eg SocketException(&quot;too many open files&quot;)) channel.unsafe().closeForcibly(); } // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); } ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) { if (channel.isRegistered()) { channel.close(); } else { channel.unsafe().closeForcibly(); } } 前面的初始化初始化已经有一点的了解，现在我来看注册，这里有#config，#group 和 #register 这三个方法，我们一个一个分析 ChannelFuture regFuture = config().group().register(channel); config 方法/** * Returns the {@link AbstractBootstrapConfig} object that can be used to obtain the current config * of the bootstrap. */public abstract AbstractBootstrapConfig&lt;B, C&gt; config(); 返回了一个 ServerbootstrapConfig 对象 group 方法/** * Returns the configured {@link EventLoopGroup} or {@code null} if non is configured yet. */@SuppressWarnings(&quot;deprecation&quot;)public final EventLoopGroup group() { return bootstrap.group();} 返回一个 NioEventLoopGroup 对象，这个时候返回的是一个调用的是他的父类MultithreadEventLoopGroup的 register 方法io.netty.channel.MultithreadEventLoopGroup#register(io.netty.channel.Channel) 最终会调用 io.netty.channel.SingleThreadEventLoop#register(io.netty.channel.Channel) 的注册方法 我们来看看这个类 io.netty.channel.SingleThreadEventLoop io.netty.channelpublic abstract class SingleThreadEventLoopextends SingleThreadEventExecutorimplements EventLoopAbstract base class for EventLoops that execute all its submitted tasks in a single thread. io.netty.channel.AbstractChannel.AbstractUnsafe#register @Overridepublic final void register(EventLoop eventLoop, final ChannelPromise promise) { if (eventLoop == null) { throw new NullPointerException(&quot;eventLoop&quot;); } if (isRegistered()) { promise.setFailure(new IllegalStateException(&quot;registered to an event loop already&quot;)); return; } if (!isCompatible(eventLoop)) { promise.setFailure( new IllegalStateException(&quot;incompatible event loop type: &quot; + eventLoop.getClass().getName())); return; } AbstractChannel.this.eventLoop = eventLoop; // 如果是当前线程就让它执行 if (eventLoop.inEventLoop()) { register0(promise); // 如果不是的话就放到线程池中注册 } else { try { eventLoop.execute(new Runnable() { @Override public void run() { register0(promise); } }); } catch (Throwable t) { logger.warn( &quot;Force-closing a channel whose registration task was not accepted by an event loop: {}&quot;, AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); } }} 先理解一下线程 Netty 中的线程模型 一个 EventLoopGroup 当中会包含多个 EventLoop 一个 EventLoop 在它的整个生命周期当中都只会与唯一一个 Thread 进行绑定 所有 EventLoop 所处理的各种 I/O 事件都是将在他所关联的那个 Thread 上进行处理 一个 Channel 在它的整个生命周期中只会注册在一个 EventLoop 上 一个 EventLoop 在运行过程中，会被分配给一或者多个 Channel 重要结论： 在Netty 中 Channel 的实现是线程安全的，基于此，我们可以存储一个 Channel 的引用，并且在需要向远程端点发送数据时，通过这个引用来调用 Channel 相应的方法，即便是当时有很多线程都在使用它也不会出现多线程的问题，而且消息一点会按照这个顺序发送出去 我们在业务开发中，不要将执行耗时的任务放入到 EventLoop 的执行队列中，因为它会堵塞该线程的所有Channel 上的其它执行任务，如果我们需要进行阻塞调用或则是耗时操作，那么我们需要使用一个专门的EventExectutor(业务线程池) 通常会有两种实现方式： 在 ChannelHandler 的回调方法中，使用自己定义的业务线程池，这样就可以实现异步调用 借助于 Netty 提供的向 ChannelPipeline 添加ChannelHandler是调用的addLast方法来传递 EventExecutorGroup 说明：如果addLast(handler)的方法是由I/O线程所执行的，如果addLast(eventExectutorGroup, handler)的方法，那么就是由参数中的group的线程组来执行 io.netty.channel.AbstractChannel.AbstractUnsafe#register0 private void register0(ChannelPromise promise) { try { // check if the channel is still open as it could be closed in the mean time when the register // call was outside of the eventLoop if (!promise.setUncancellable() || !ensureOpen(promise)) { return; } boolean firstRegistration = neverRegistered; doRegister(); // 这个方法 neverRegistered = false; registered = true; // Ensure we call handlerAdded(...) before we actually notify the promise. This is needed as the // user may already fire events through the pipeline in the ChannelFutureListener. pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); pipeline.fireChannelRegistered(); // Only fire a channelActive if the channel has never been registered. This prevents firing // multiple channel actives if the channel is deregistered and re-registered. if (isActive()) { if (firstRegistration) { pipeline.fireChannelActive(); } else if (config().isAutoRead()) { // This channel was registered before and autoRead() is set. This means we need to begin read // again so that we process inbound data. // // See https://github.com/netty/netty/issues/4805 beginRead(); } } } catch (Throwable t) { // Close the channel directly to avoid FD leak. closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); }} io.netty.channel.nio.AbstractNioChannel#doRegister 看到 doXxx 开头的方法就知道是认真工作的 @Overrideprotected void doRegister() throws Exception { boolean selected = false; for (;;) { try { selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; } catch (CancelledKeyException e) { if (!selected) { // Force the Selector to select now as the &quot;canceled&quot; SelectionKey may still be // cached and not removed because no Select.select(..) operation was called yet. eventLoop().selectNow(); selected = true; } else { // We forced a select operation on the selector before but the SelectionKey is still cached // for whatever reason. JDK bug ? throw e; } } }} 与我们前面写的 NIO 逻辑是一样的 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); syncpublic class MyServer { public static void main(String[] args) throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_KEEPALIVE, false) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); ChannelFuture channelFuture = bootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } }} 我们回到我们编写的 Server 中，需要绑定，之后需要调用 #sync 表示这个方法需要同步，要不然还没绑定完成就返回了 ChannelFuture ，里面的结果或者状态是还没有完成的，加了 #sync 就能保证完成 ChannelFuture channelFuture = bootstrap.bind(8899).sync(); 在我们正常开发是流程就会停在下面，就卡住了 channelFuture.channel().closeFuture().sync(); 当我们调用关闭就会到 finally 中，会执行优雅关闭 到此我们启动过程基本分析完了","link":"/2019/01/16/Netty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"Netty 源码分析（五）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. ReferenceCountedio.netty.util.ReferenceCounted 引用计数文档 public interface ReferenceCountedA reference-counted object that requires explicit deallocation.When a new ReferenceCounted is instantiated, it starts with the reference count of 1. retain() increases the reference count, and release() decreases the reference count. If the reference count is decreased to 0, the object will be deallocated explicitly, and accessing the deallocated object will usually result in an access violation.If an object that implements ReferenceCounted is a container of other objects that implement ReferenceCounted, the contained objects will also be released via release() when the container’s reference count becomes 0. 我们看看其中的方法 public interface ReferenceCounted { /** * Returns the reference count of this object. If {@code 0}, it means this object has been deallocated. */ int refCnt(); /** * Increases the reference count by {@code 1}. */ ReferenceCounted retain(); /** * Increases the reference count by the specified {@code increment}. */ ReferenceCounted retain(int increment); /** * Records the current access location of this object for debugging purposes. * If this object is determined to be leaked, the information recorded by this operation will be provided to you * via {@link ResourceLeakDetector}. This method is a shortcut to {@link #touch(Object) touch(null)}. */ ReferenceCounted touch(); /** * Records the current access location of this object with an additional arbitrary information for debugging * purposes. If this object is determined to be leaked, the information recorded by this operation will be * provided to you via {@link ResourceLeakDetector}. */ ReferenceCounted touch(Object hint); /** * Decreases the reference count by {@code 1} and deallocates this object if the reference count reaches at * {@code 0}. * * @return {@code true} if and only if the reference count became {@code 0} and this object has been deallocated */ boolean release(); /** * Decreases the reference count by the specified {@code decrement} and deallocates this object if the reference * count reaches at {@code 0}. * * @return {@code true} if and only if the reference count became {@code 0} and this object has been deallocated */ boolean release(int decrement);} AbstractReferenceCountedByteBufio.netty.buffer.AbstractReferenceCountedByteBuf 我们先来看两个比较重要的方法，retain() 和 release() 方法 retain()io.netty.buffer.AbstractReferenceCountedByteBuf#retain() retain() 方法可以使引用计数加一 @Overridepublic ByteBuf retain() { return retain0(1);}@Overridepublic ByteBuf retain(int increment) { return retain0(checkPositive(increment, &quot;increment&quot;));}private ByteBuf retain0(int increment) { for (;;) { int refCnt = this.refCnt; final int nextCnt = refCnt + increment; // 如果 refCnt = 0 的时候 nextCont = increment，就就应该被回收 // Ensure we not resurrect (which means the refCnt was 0) and also that we encountered an overflow. if (nextCnt &lt;= increment) { throw new IllegalReferenceCountException(refCnt, increment); } // 这里使用到了自旋锁 if (refCntUpdater.compareAndSet(this, refCnt, nextCnt)) { break; } } return this;} java.util.concurrent.atomic.AtomicIntegerFieldUpdater public abstract class AtomicIntegerFieldUpdaterextends ObjectA reflection-based utility that enables atomic updates to designated volatile int fields of designated classes. This class is designed for use in atomic data structures in which several fields of the same node are independently subject to atomic updates.Note that the guarantees of the compareAndSet method in this class are weaker than in other atomic classes. Because this class cannot ensure that all uses of the field are appropriate for purposes of atomic access, it can guarantee atomicity only with respect to other invocations of compareAndSet and set on the same updater. AtomicIntegerFieldUpdater要点的总结： 更新器必须是int类型的变量，不能是其他包装类型 更新器的更新必须是volatile类型的变量，确保线程之间的共享变量时的立即可见性 变量不能是static的，必须是实例变量，因为Unsafe.objectFieldOffset() 方法不支持静态变量（CAS操作本质是通过对象实例的偏移来直接进行赋值） 更新器只能修改它可见范围内的变量，因为更新器是通过反射来得到这个变量，如果变量不可见就会报错 如果更新的变量时包装类型，那么可以使用AtomicReferenceFieldUpdater来进行更新 java.util.concurrent.atomic.AtomicIntegerFieldUpdater#compareAndSet public abstract boolean compareAndSet(T obj, int expect, int update)Atomically sets the field of the given object managed by this updater to the given updated value if the current value == the expected value. This method is guaranteed to be atomic with respect to other calls to compareAndSet and set, but not necessarily with respect to other changes in the field.Parameters:obj - An object whose field to conditionally setexpect - the expected valueupdate - the new value 一个不安全的更新 /** * @Author: cuzz * @Date: 2019/1/19 15:40 * @Description: */public class AtomicUpdateTest { public static void main(String[] args) { Person person = new Person(); for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { try { Thread.sleep(20); } catch (InterruptedException e) { e.printStackTrace(); } System.out.print(person.age++ + &quot; &quot;); // 1 6 7 5 4 2 3 1 8 9 }).start(); } }}class Person{ int age = 1;} 使用AtomicIntegerFieldUpdater /** * @Author: cuzz * @Date: 2019/1/19 15:40 * @Description: */public class AtomicUpdateTest { public static void main(String[] args) { AtomicIntegerFieldUpdater&lt;Person&gt; fieldUpdater = AtomicIntegerFieldUpdater.newUpdater(Person.class, &quot;age&quot;); Person person = new Person(); for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { try { Thread.sleep(20); } catch (InterruptedException e) { e.printStackTrace(); } System.out.print(fieldUpdater.getAndIncrement(person) + &quot; &quot;); // 1 4 3 2 5 6 7 10 9 8 }).start(); } }}class Person{ volatile int age = 1;} 大概有以下两种字段适合用Atomic*FieldUpdater: 大多数用到这个字段的代码是在读取字段的值, 但仍然有通过CAS更新字段值的需求. 这个时候用AtomicInteger的话每个直接读取这个字段的地方都要多一次.get()调用, 用volatile又满足不了需求, 所以就用到了AtomicIntegerFieldUpdater 这个字段所属的类会被创建大量的实例对象, 如果用AtomicInteger, 每个实例里面都要创建AtomicInteger对象, 从而多出内存消耗. 比如一个链表类的Node, 用AtomicReference保存next显然是不合适的. 原文：https://blog.csdn.net/u012415542/article/details/80646605 private static final AtomicIntegerFieldUpdater&lt;AbstractReferenceCountedByteBuf&gt; refCntUpdater = AtomicIntegerFieldUpdater.newUpdater(AbstractReferenceCountedByteBuf.class, &quot;refCnt&quot;); Reference counted objects引用计数文档：Reference counted objects Netty 处理器重要概念 Netty 的处理器可以分为两类：入站处理器和出站处理器 入站处理器的顶层是 ChannelnboundHandler，出站处理器的顶层是 ChannelOutboundHandler 数据处理时常用的各种解码器本质上都是处理器 编解码器：无论我们向网络中写入的数据是什么类型，数据在网络中传递时，其都是以字节流的形式呈现，将数据有原本的字节流的操作成为编码（encode），将数据有字节转化为它原本的格式或是其它的操作成为解码（decode），编码统一称为（codec） 编码：本质上是一种出站处理器，因此，编码一定是一种 ChannelOutboundHandler 解码：本质上是一种入站处理器，因此，解码一定是一种 ChannelInboundHandler 在 Netty 中，编码器通常以 xxxEncoder命名；解码器通常以xxxDecoder命名 编写一个Long类型的解码器编写一个解码器在客服端与服务端传输一个 Long 型的数据，Netty 为我们提供了 ByteToMessageDecoder io.netty.handler.codec.ByteToMessageDecoder io.netty.handler.codecpublic abstract class ByteToMessageDecoderextends ChannelInboundHandlerAdapterChannelInboundHandlerAdapter which decodes bytes in a stream-like fashion from one ByteBuf to an other Message type. For example here is an implementation which reads all readable bytes from the input ByteBuf and create a new ByteBuf. public class SquareDecoder extends ByteToMessageDecoder { @Override public void decode(ChannelHandlerContext ctx, ByteBuf in, List out) throws Exception { out.add(in.readBytes(in.readableBytes())); } } Frame detectionGenerally frame detection should be handled earlier in the pipeline by adding a DelimiterBasedFrameDecoder, FixedLengthFrameDecoder, LengthFieldBasedFrameDecoder, or LineBasedFrameDecoder.If a custom frame decoder is required, then one needs to be careful when implementing one with ByteToMessageDecoder. Ensure there are enough bytes in the buffer for a complete frame by checking ByteBuf.readableBytes(). If there are not enough bytes for a complete frame, return without modifying the reader index to allow more bytes to arrive.To check for complete frames without modifying the reader index, use methods like ByteBuf.getInt(int). One MUST use the reader index when using methods like ByteBuf.getInt(int). For example calling in.getInt(0) is assuming the frame starts at the beginning of the buffer, which is not always the case. Use in.getInt(in.readerIndex()) instead.PitfallsBe aware that sub-classes of ByteToMessageDecoder MUST NOT annotated with @Sharable.Some methods such as ByteBuf.readBytes(int) will cause a memory leak if the returned buffer is not released or added to the out List. Use derived buffers like ByteBuf.readSlice(int) to avoid leaking memory. MyByteToLongDecoder /** * @Author: cuzz * @Date: 2019/1/22 12:16 * @Description: */public class MyByteToLongDecoder extends ByteToMessageDecoder{ @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception { System.out.println(&quot;decode invoked!&quot;); System.out.println(in.readableBytes()); if (in.readableBytes() &gt;= 8) { out.add(in.readLong()); } }} MyLongToByteEncoder /** * @Author: cuzz * @Date: 2019/1/22 12:23 * @Description: */public class MyLongToByteEncoder extends MessageToByteEncoder&lt;Long&gt;{ @Override protected void encode(ChannelHandlerContext ctx, Long msg, ByteBuf out) throws Exception { System.out.println(&quot;encoder invoked!&quot;); System.out.println(msg); out.writeLong(msg); }} 重要结论： 无论是编码器还是解码器，其所接收的消息类型必须要与待处理的参数保持一致，否则该编码器或则解码器不会被执行 在解码器进行数据解码时，一定要记得判断缓冲（ByteBuf）中的数据是否足够，否则将会产生一些问题 ReplayingDecoder文档：https://netty.io/4.1/api/io/netty/handler/codec/ReplayingDecoder.html 如果我们使用这个继承这个编码器，他会自动帮我判断是否可读，代码也简单，简化了我们的判断 public class MyByteToLongDecoder2 extends ReplayingDecoder&lt;Void&gt; { @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception { System.out.println(&quot;MyByteToLongDecoder2 decode invoked!&quot;); out.add(in.readLong()); }} LengthFieldBasedFrameDecoderio.netty.handler.codec.LengthFieldBasedFrameDecoder 文档：https://netty.io/4.1/api/io/netty/handler/codec/LengthFieldBasedFrameDecoder.html 这是一个常用语自定义协议的解码器 TCP 粘包拆包如果我写的自定义协议没有对粘包和拆包做特殊处理的话就会产生粘包和拆包现象 ![timg](Netty 源码分析（五）\\timg.jpg) 粘包、拆包发生原因发生TCP粘包或拆包有很多原因，现列出常见的几点，可能不全面，欢迎补充，1、要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。2、待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。3、要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。4、接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。粘包、拆包解决办法通过以上分析，我们清楚了粘包或拆包发生的原因，那么如何解决这个问题呢？解决问题的关键在于如何给每个数据包添加边界信息，常用的方法有如下几个：1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。 作者：wxy941011来源：CSDN原文：https://blog.csdn.net/wxy941011/article/details/80428470版权声明：本文为博主原创文章，转载请附上博文链接！ 自定义协议解决粘包和拆包一个 Person 协议类 /** * @Author: cuzz * @Date: 2019/1/22 16:00 * @Description: 这是一个关于 Person 的协议 */public class PersonProtocol { private int length; private byte[] content; public int getLength() { return length; } public void setLength(int length) { this.length = length; } public byte[] getContent() { return content; } public void setContent(byte[] content) { this.content = content; }} 解码处理器 /** * @Author: cuzz * @Date: 2019/1/22 16:04 * @Description: */public class MyPersonDecoder extends ReplayingDecoder&lt;Void&gt;{ @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception { System.out.println(&quot;MyPersonDecoder decode invoked!&quot;); // Gets a 32-bit integer at the current {@code readerIndex} // and increases the {@code readerIndex} by {@code 4} in this buffer. int length = in.readInt(); byte[] content = new byte[length]; // Transfers this buffer's data to the specified destination starting at // the current {@code readerIndex} and increases the {@code readerIndex} // by the number of the transferred bytes (= {@code dst.length} in.readBytes(content); // 把内容添加到协议中 PersonProtocol personProtocol = new PersonProtocol(); personProtocol.setLength(length); personProtocol.setContent(content); out.add(personProtocol); }} 编码处理器 /** * @Author: cuzz * @Date: 2019/1/22 16:12 * @Description: */public class MyPersonEncoder extends MessageToByteEncoder&lt;PersonProtocol&gt;{ @Override protected void encode(ChannelHandlerContext ctx, PersonProtocol msg, ByteBuf out) throws Exception { System.out.println(&quot;MyPersonEncoder encoder invoked!&quot;); // 消息头 out.writeInt(msg.getLength()); // 消息体 out.writeBytes(msg.getContent()); }} 服务端 /** * @Author: cuzz * @Date: 2019/1/22 16:39 * @Description: */public class MyServer { public static void main(String[] args) throws Exception{ EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workGroup = new NioEventLoopGroup(); try { ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new MyPersonDecoder()); pipeline.addLast(new MyPersonEncoder()); pipeline.addLast(new MyServerHandler()); } }); ChannelFuture channelFuture = serverBootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); } }}/** * @Author: cuzz * @Date: 2019/1/22 16:16 * @Description: */public class MyServerHandler extends SimpleChannelInboundHandler&lt;PersonProtocol&gt;{ private int count; @Override protected void channelRead0(ChannelHandlerContext ctx, PersonProtocol msg) throws Exception { int length = msg.getLength(); byte[] content = msg.getContent(); System.out.println(&quot;服务端接收到的数据：&quot;); System.out.println(&quot;长度：&quot; + length); System.out.println(&quot;内容：&quot; + new String(content, Charset.forName(&quot;utf-8&quot;))); System.out.println(&quot;服务器接收到的消息数量：&quot; + (++this.count)); PersonProtocol personProtocol = new PersonProtocol(); String resp = &quot;hello, world&quot;; personProtocol.setLength(resp.getBytes(&quot;utf-8&quot;).length); personProtocol.setContent(resp.getBytes(&quot;utf-8&quot;)); ctx.writeAndFlush(personProtocol); }} 客服端 public class MyClient { public static void main(String[] args) throws Exception { EventLoopGroup eventLoopGroup = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap(); bootstrap.group(eventLoopGroup) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new MyPersonDecoder()); pipeline.addLast(new MyPersonEncoder()); pipeline.addLast(new MyClientHandler()); } }); ChannelFuture channelFuture = bootstrap.connect(&quot;localhost&quot;,8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { eventLoopGroup.shutdownGracefully(); } }}/** * @Author: cuzz * @Date: 2019/1/22 16:25 * @Description: */public class MyClientHandler extends SimpleChannelInboundHandler&lt;PersonProtocol&gt;{ private int count; @Override protected void channelRead0(ChannelHandlerContext ctx, PersonProtocol msg) throws Exception { int length = msg.getLength(); byte[] content = msg.getContent(); System.out.println(&quot;客户端接收的消息：&quot;); System.out.println(&quot;消息的长度：&quot; + length); System.out.println(&quot;消息的内容：&quot; + new String(content, Charset.forName(&quot;utf-8&quot;))); System.out.println(&quot;客户端接收到的消息数量：&quot; + (++count)); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { for (int i = 0; i &lt; 10; i++) { String messageToBeSend = &quot;send form client&quot;; PersonProtocol personProtocol = new PersonProtocol(); personProtocol.setLength(messageToBeSend.getBytes(&quot;utf-8&quot;).length); personProtocol.setContent(messageToBeSend.getBytes(&quot;utf-8&quot;)); ctx.writeAndFlush(personProtocol); } } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 总结这里关于 Netty 的这五篇分析都是看的圣思园张龙老师的课程自己所写下的笔记，自己对 Netty 有了简单的认识，也对 NIO 有了更深的了解，最主要的学会看英文文档，看官方文档很重要，不要惧怕，慢慢的就感觉还是文档写的最清楚，最有价值。老师还提到需要多记录，因此我也把一些重要的知识点记录下来，方便以后查找。当然以后还要加强学习，多看看 Netty 官方文档和例子，加强练习。","link":"/2019/01/22/Netty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%94%EF%BC%89/"},{"title":"Netty 源码分析（四）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. ChannelPromiseio.netty.channel.ChannelPromise 前面我们分析了 ChannelFuture ，看看ChannelPromise 的作用 /** * Special {@link ChannelFuture} which is writable. */public interface ChannelPromise extends ChannelFuture, Promise&lt;Void&gt; { ... } 这是一个可以写入的 ChannelFuture ，我先看看 Promise 这个类 Promiseio.netty.util.concurrent.Promise public interface Promise&lt;V&gt; extends Future&lt;V&gt; { /** * Marks this future as a success and notifies all * listeners. * * If it is success or failed already it will throw an {@link IllegalStateException}. */ Promise&lt;V&gt; setSuccess(V result); /** * Marks this future as a success and notifies all * listeners. * * @return {@code true} if and only if successfully marked this future as * a success. Otherwise {@code false} because this future is * already marked as either a success or a failure. */ boolean trySuccess(V result); /** * Marks this future as a failure and notifies all * listeners. * * If it is success or failed already it will throw an {@link IllegalStateException}. */ Promise&lt;V&gt; setFailure(Throwable cause); /** * Marks this future as a failure and notifies all * listeners. * * @return {@code true} if and only if successfully marked this future as * a failure. Otherwise {@code false} because this future is * already marked as either a success or a failure. */ boolean tryFailure(Throwable cause); /** * Make this future impossible to cancel. * * @return {@code true} if and only if successfully marked this future as uncancellable or it is already done * without being cancelled. {@code false} if this future has been cancelled already. */ boolean setUncancellable(); @Override Promise&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); @Override Promise&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); @Override Promise&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); @Override Promise&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); @Override Promise&lt;V&gt; await() throws InterruptedException; @Override Promise&lt;V&gt; awaitUninterruptibly(); @Override Promise&lt;V&gt; sync() throws InterruptedException; @Override Promise&lt;V&gt; syncUninterruptibly();} JDK 所提供的的 Future 只能通过手工的方式检查执行结果，而这个操作是会阻塞的；Netty 则对 ChannelFutre 进行了增强，通过 ChannelFutureListener 以回调的方式来获取执行结果，去除了手工检查阻塞的操作，值得注意的是，ChannelFutrureListener 的 operationComplete 方法是由I/O线程执行的，因此要注意的是不要在这里执行耗时操作，否则需要通过另外的线程或线程池来执行 ChannelInboundHandlerAdapterio.netty.channel.ChannelInboundHandlerAdapter io.netty.channelpublic class ChannelInboundHandlerAdapterextends ChannelHandlerAdapter implements ChannelInboundHandlerAbstract base class for ChannelInboundHandler implementations which provide implementations of all of their methods. This implementation just forward the operation to the next ChannelHandler in the ChannelPipeline. Sub-classes may override a method implementation to change this. Be aware that messages are not released after the channelRead(ChannelHandlerContext, Object) method returns automatically. If you are looking for a ChannelInboundHandler implementation that releases the received messages automatically, please see SimpleChannelInboundHandler. 这里使用了适配器模式 ChannelInboundHandlerio.netty.channel.ChannelInboundHandler /** * {@link ChannelHandler} which adds callbacks for state changes. This allows the user * to hook in to state changes easily. */public interface ChannelInboundHandler extends ChannelHandler { /** * The {@link Channel} of the {@link ChannelHandlerContext} was registered with its {@link EventLoop} */ void channelRegistered(ChannelHandlerContext ctx) throws Exception; /** * The {@link Channel} of the {@link ChannelHandlerContext} was unregistered from its {@link EventLoop} */ void channelUnregistered(ChannelHandlerContext ctx) throws Exception; /** * The {@link Channel} of the {@link ChannelHandlerContext} is now active */ void channelActive(ChannelHandlerContext ctx) throws Exception; /** * The {@link Channel} of the {@link ChannelHandlerContext} was registered is now inactive and reached its * end of lifetime. */ void channelInactive(ChannelHandlerContext ctx) throws Exception; /** * Invoked when the current {@link Channel} has read a message from the peer. */ void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception; /** * Invoked when the last message read by the current read operation has been consumed by * {@link #channelRead(ChannelHandlerContext, Object)}. If {@link ChannelOption#AUTO_READ} is off, no further * attempt to read an inbound data from the current {@link Channel} will be made until * {@link ChannelHandlerContext#read()} is called. */ void channelReadComplete(ChannelHandlerContext ctx) throws Exception; /** * Gets called if an user event was triggered. */ void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception; /** * Gets called once the writable state of a {@link Channel} changed. You can check the state with * {@link Channel#isWritable()}. */ void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception; /** * Gets called if a {@link Throwable} was thrown. */ @Override @SuppressWarnings(&quot;deprecation&quot;) void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception;} SimpleChannelInboundHandlerio.netty.channel.SimpleChannelInboundHandler 我们在写自己的 Handler 的时候长会继承这个 SimpleChannelInboundHandler public class MyServerHandler extends SimpleChannelInboundHandler&lt;String&gt;{ @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { System.out.println(ctx.channel().remoteAddress() + &quot;: &quot; + msg); ctx.channel().writeAndFlush(&quot;from server: &quot; + UUID.randomUUID()); } /** * 出现异常关闭连接 * @param ctx * @param cause * @throws Exception */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 我们看看这个文档 io.netty.channelpublic abstract class SimpleChannelInboundHandlerextends ChannelInboundHandlerAdapterChannelInboundHandlerAdapter which allows to explicit only handle a specific type of messages. For example here is an implementation which only handle String messages. public class StringHandler extends SimpleChannelInboundHandler&lt;String&gt; { @Override protected void channelRead0(ChannelHandlerContext ctx, String message) throws Exception { System.out.println(message); }} Be aware that depending of the constructor parameters it will release all handled messages by passing them to ReferenceCountUtil.release(Object). In this case you may need to use ReferenceCountUtil.retain(Object) if you pass the object to the next handler in the ChannelPipeline.Forward compatibility notice 我们可以通过泛型指定消息类型 @Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { boolean release = true; try { if (acceptInboundMessage(msg)) { @SuppressWarnings(&quot;unchecked&quot;) I imsg = (I) msg; channelRead0(ctx, imsg); } else { release = false; ctx.fireChannelRead(msg); } } finally { if (autoRelease &amp;&amp; release) { // 把这个消息计数减一，当减为0就丢弃 ReferenceCountUtil.release(msg); } }}/** * &lt;strong&gt;Please keep in mind that this method will be renamed to * {@code messageReceived(ChannelHandlerContext, I)} in 5.0.&lt;/strong&gt; * * Is called for each message of type {@link I}. * * @param ctx the {@link ChannelHandlerContext} which this {@link SimpleChannelInboundHandler} * belongs to * @param msg the message to handle * @throws Exception is thrown if an error occurred */protected abstract void channelRead0(ChannelHandlerContext ctx, I msg) throws Exception; 给我们强制转换为特定的类型，再调用 channelRead0 方法，这是一个抽象方法，需要我们自己去实现 ReferenceCountedio.netty.util.ReferenceCounted io.netty.utilpublic interface ReferenceCountedA reference-counted object that requires explicit deallocation.When a new ReferenceCounted is instantiated, it starts with the reference count of 1. retain() increases the reference count, and release() decreases the reference count. If the reference count is decreased to 0, the object will be deallocated explicitly, and accessing the deallocated object will usually result in an access violation.If an object that implements ReferenceCounted is a container of other objects that implement ReferenceCounted, the contained objects will also be released via release() when the container’s reference count becomes 0. ctx.channel().write()和ctx.write()的区别在 Netty 中有两种发消息的方式，可以直接写到 Channel 中，也可以写到与 ChannelHandler 所关联的那个 ChannelHandlerContext 中，对于 ctx.channel().write() 方式来说，消息会从 ChannelPipeline 的末尾开始流动，对于 ctx.write() 来说，消息将从 ChannelPipeline 中的下一个 ChannelHandler 开始流动 这篇博客个解释了 https://blog.csdn.net/FishSeeker/article/details/78447684 结论： ChannelHandlerContext 与 ChannelHandler 之间的关联绑定关系是永远不会发生改变的，因此对其进行缓存时没有任何问题的 对于与 Channel 的同名方法来说， ChannelHandlerContext 的方法将会产生更短的事件流，所以我们因该在可能的情况下利用这个特性来提升性能 Java NIONIO 总结使用 NIO 进行文件读取所涉及的步骤： 从 FileInputStream 对象获取到 Channel 对象 创建 Buffer 将数据从 Channel 中读取到Buffer中 ![20190118000012](Netty 源码分析（四）\\20190118000012.png) 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity flip() 方法： 将 limit 值设置为当前的 position 将 position 设置 0 clear() 方法： 将 limit 设置为capacity 将 position 设置为0 compact() 方法： 将所有未读的数据复制到 buffer 起始的位置处 将 position 设置为最后一个未读元素的后面 将 limit 设置为 capacity 现在buffer 就准备好了，但是不会覆盖未读的数据 Java NIO中，关于DirectBuffer，HeapBuffer的疑问？ DirectBuffer 属于堆外存，那应该还是属于用户内存，而不是内核内存？ FileChannel 的read(ByteBuffer dst)函数,write(ByteBuffer src)函数中，如果传入的参数是HeapBuffer类型,则会临时申请一块DirectBuffer,进行数据拷贝，而不是直接进行数据传输，这是出于什么原因？ 答案： https://www.zhihu.com/question/57374068/answer/152691891 Java NIO中的direct buffer（主要是DirectByteBuffer）其实是分两部分的： Java | native |DirectByteBuffer | malloc'd[ address ] -+-&gt; [ data ] | 其中 DirectByteBuffer 自身是一个Java对象，在Java堆中；而这个对象中有个long类型字段address，记录着一块调用 malloc() 申请到的native memory。 所以回到题主的问题： \\1. DirectBuffer 属于堆外存，那应该还是属于用户内存，而不是内核内存？ DirectByteBuffer 自身是（Java）堆内的，它背后真正承载数据的buffer是在（Java）堆外——native memory中的。这是 malloc() 分配出来的内存，是用户态的。 \\2. FileChannel 的read(ByteBuffer dst)函数,write(ByteBuffer src)函数中，如果传入的参数是HeapBuffer类型,则会临时申请一块DirectBuffer,进行数据拷贝，而不是直接进行数据传输，这是出于什么原因？ 题主看的是OpenJDK的 sun.nio.ch.IOUtil.write(FileDescriptor fd, ByteBuffer src, long position, NativeDispatcher nd) 的实现对不对： static int write(FileDescriptor fd, ByteBuffer src, long position, NativeDispatcher nd) throws IOException{ if (src instanceof DirectBuffer) return writeFromNativeBuffer(fd, src, position, nd); // Substitute a native buffer int pos = src.position(); int lim = src.limit(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); ByteBuffer bb = Util.getTemporaryDirectBuffer(rem); try { bb.put(src); bb.flip(); // Do not update src until we see how many bytes were written src.position(pos); int n = writeFromNativeBuffer(fd, bb, position, nd); if (n &gt; 0) { // now update src src.position(pos + n); } return n; } finally { Util.offerFirstTemporaryDirectBuffer(bb); }} 这里其实是在迁就OpenJDK里的HotSpot VM的一点实现细节。 HotSpot VM里的GC除了CMS之外都是要移动对象的，是所谓“compacting GC”。 如果要把一个Java里的 byte[] 对象的引用传给native代码，让native代码直接访问数组的内容的话，就必须要保证native代码在访问的时候这个 byte[] 对象不能被移动，也就是要被“pin”（钉）住。 可惜HotSpot VM出于一些取舍而决定不实现单个对象层面的object pinning，要pin的话就得暂时禁用GC——也就等于把整个Java堆都给pin住。HotSpot VM对JNI的Critical系API就是这样实现的。这用起来就不那么顺手。 所以 Oracle/Sun JDK / OpenJDK 的这个地方就用了点绕弯的做法。它假设把 HeapByteBuffer 背后的 byte[] 里的内容拷贝一次是一个时间开销可以接受的操作，同时假设真正的I/O可能是一个很慢的操作。 于是它就先把 HeapByteBuffer 背后的 byte[] 的内容拷贝到一个 DirectByteBuffer 背后的native memory去，这个拷贝会涉及 sun.misc.Unsafe.copyMemory() 的调用，背后是类似 memcpy() 的实现。这个操作本质上是会在整个拷贝过程中暂时不允许发生GC的，虽然实现方式跟JNI的Critical系API不太一样。（具体来说是 Unsafe.copyMemory() 是HotSpot VM的一个intrinsic方法，中间没有safepoint所以GC无法发生）。 然后数据被拷贝到native memory之后就好办了，就去做真正的I/O，把 DirectByteBuffer 背后的native memory地址传给真正做I/O的函数。这边就不需要再去访问Java对象去读写要做I/O的数据了。 ByteBuf文档：https://netty.io/4.1/api/index.html 我们看第一个例子 public class ByteBufTest01 { public static void main(String[] args) { final ByteBuf buffer = Unpooled.buffer(10); for (int i = 0, index = 120; i &lt; 10; i++) { buffer.writeByte(index + i); } for (int i = 0; i &lt; 10; i++) { System.out.println(buffer.getByte(i)); } }} 输出： 120121122123124125126127-128-127 我们来看看这个方法的文档 /** * Sets the specified byte at the current {@code writerIndex} * and increases the {@code writerIndex} by {@code 1} in this buffer. * The 24 high-order bits of the specified value are ignored. * * @throws IndexOutOfBoundsException * if {@code this.writableBytes} is less than {@code 1} */public abstract ByteBuf writeByte(int value); 虽然传入的一个 int 值，可是它会丢弃高位的 24 bit，我们知道 int 是 4 字节（32 bit），丢弃 3 字节 （24 bit），就保留到 1 字节（8 bit） 我们要看下一个例子 public class ByteBufTest02 { public static void main(String[] args) { ByteBuf byteBuf = Unpooled.copiedBuffer(&quot;hello world&quot;, Charset.forName(&quot;utf-8&quot;)); // 判断是否为堆缓存，如果是堆缓存，返回true if (byteBuf.hasArray()) { byte[] bytes = byteBuf.array(); System.out.println(new String(bytes, Charset.forName(&quot;utf-8&quot;))); System.out.println(byteBuf); System.out.println(byteBuf.arrayOffset()); // 可读字节第一偏移量 System.out.println(byteBuf.readerIndex()); System.out.println(byteBuf.writerIndex()); System.out.println(byteBuf.capacity()); } }} 输出： hello world UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeHeapByteBuf(ridx: 0, widx: 11, cap: 33)001133 ridx 表示读的 index，widx 表示写的 index 我们来看看复合 Buffer public class ByteBufTest03 { public static void main(String[] args) { // 新建一个复合 buffer CompositeByteBuf compositeByteBuf = Unpooled.compositeBuffer(); ByteBuf heapBuf = Unpooled.buffer(10); ByteBuf directBuf = Unpooled.directBuffer(8); compositeByteBuf.addComponent(heapBuf); compositeByteBuf.addComponent(directBuf); compositeByteBuf.forEach(System.out::println); // 输出 // UnpooledSlicedByteBuf(ridx: 0, widx: 0, cap: 0/0, unwrapped: UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeHeapByteBuf(ridx: 0, widx: 0, cap: 10)) // UnpooledSlicedByteBuf(ridx: 0, widx: 0, cap: 0/0, unwrapped: UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf(ridx: 0, widx: 0, cap: 8)) }} Netty 提供的 3 种缓冲区heap buffer（堆缓冲区）： 这是最常见的类型，ByteBuf 将数据存储到 JVM 的堆空间中，并且将实际的数据放到 byte 数组中来实现的 优点：由于数据是存储在 JVM 的堆中，因此可以快速的创建和快速的释放，并且它提供了 直接访问内部字节数组的方法 缺点：每次读写数据时，都需要先将数据复制到直接缓冲中再进行网络传输 direct buffer（直接缓冲区）： 在堆之外直接分配内存空间，直接缓冲区并不会占用堆的容量空间，因为他是有操作系统在本地内存进行的数据分配 优点：在使用 Socket 进行数据传输时，性能非常好，因为数据直接位于操作系统的本地内存中，所以不需要从 JVM 将数据复制到直接缓冲区 缺点：因为 Direct Buffer 是直接在操作系统内存中的，所以内存空间分配与释放要比堆空间更加复杂，而且速度要慢一些 Netty 通过提供内存池来解决这个问题，直接缓冲区并不支持通过字节数组的方式来访问数据 重点：对于后端的业务消息的编解码来说，推荐使用 HeapByteBuf；对于 I/O 通信的读写缓冲区，我们推荐使用 DirectBytebuf composite buffer（符合缓冲区）： 复合缓冲区实际上是将多个缓冲区实例组合起来，并向外提供一个统一视图。像是一个缓冲区的 List JDK 的 ByteBuffer 与 Netty 的 ByteBuf 之间的差异比对 Netty 的 ByteBuf 采用了读写分离的策略（readerIndex 和 writeerIndex），一个初始化（里面尚未有任何数据）的 ByteBuf 的 readerIndex 与 writerIndex 的值都为0 当数索引与写索引处于同一个位置时，如果我们继续读取，那么就会抛出 IndexOutOfBoundsException 对于ByteBuf 的任何读写操作都会分别单独维护读索引和写索引，MaxCapacity 最大的容量默认为Integer.MAX_VALUE ![ByteBuf internal segmentation](Netty 源码分析（四）\\ByteBuf internal segmentation.jpg) JDK 的 ByteBuffer的缺点： final byte[] hb; 这是JDK的ByteBuffer对象中用于储存的对象声明，可以看到，其字节数组布尔声明为final的，也就是长度是固定不变的，一旦分配好后就不能动态扩容与收缩，而且当储存的数据字节很大时就很有可能出现IndexOutOfBoundsException，如果要预防着个异常，那就需要再储存之前完全确定好待储存的字节的大小，如果ByteBuffer的空间不足，我们只有一种解决方案，那就是创建新的ByteBuffer对象，然后再将之前的ByteBuffer中的数据复制过去，这一切操作都需要由开发者自己来手动完成的 ByteBuffer 只使用一个position 指针来标识位置信息，在进行读写切换时就需要调用flip方法或则是rewind 方法，使用很不方便 Netty 的 ByteBuf 的优点： 储存字节的数组是动态的，其最大值默认是Integer.MAX_VALUE，这里的动态性是体现在write方法中的，write方法执行会判断buffer容量，如果不足则会自动扩容 ByteBuf的读写索引是完成分开的，使用起来很方便 // io.netty.buffer.AbstractByteBuf#writeByte @Override public ByteBuf writeByte(int value) { ensureWritable0(1); // 会先判断是否够写入一个字节 _setByte(writerIndex++, value); return this; }// io.netty.buffer.AbstractByteBuf#ensureWritable0// 会自动扩容 final void ensureWritable0(int minWritableBytes) { ensureAccessible(); if (minWritableBytes &lt;= writableBytes()) { return; } if (minWritableBytes &gt; maxCapacity - writerIndex) { throw new IndexOutOfBoundsException(String.format( &quot;writerIndex(%d) + minWritableBytes(%d) exceeds maxCapacity(%d): %s&quot;, writerIndex, minWritableBytes, maxCapacity, this)); } // Normalize the current capacity to the power of 2. int newCapacity = alloc().calculateNewCapacity(writerIndex + minWritableBytes, maxCapacity); // Adjust to the new capacity. capacity(newCapacity); }","link":"/2019/01/19/Netty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"Spring注解驱动开发（一）","text":"The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 组件注册@Configuration和@Bean的注入使用xml方式我们一起注入一个bean使用xml来配置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;bean id=&quot;person&quot; class=&quot;com.cuzz.bean.Person&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;cuzz&quot;&gt;&lt;/property&gt; &lt;property name=&quot;age&quot; value=&quot;18&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 我可以使用ClassPathXmlApplicationContext来获取 /** * @Author: cuzz * @Date: 2018/9/23 10:48 * @Description: */public class MainTest { public static void main(String[] args) { ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;); // 用id获取 Person bean = (Person) applicationContext.getBean(&quot;person&quot;); System.out.println(bean); }} 输出Person(name=cuzz, age=18) 注解编写一个配置类 /** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration // 告诉Spring这是一个配置类public class MainConfig { // 给容器中注册一个Bean,类型为返回值类型,id默认用方法名 // 也可以指定id @Bean(value = &quot;person01&quot;) public Person person() { return new Person(&quot;vhsj&quot;, 16); }} 可以通过AnnotationConfigApplicationContext来获取，并且获取id /** * @Author: cuzz * @Date: 2018/9/23 10:59 * @Description: */public class MainTest { public static void main(String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class); Person person = (Person) context.getBean(Person.class); System.out.println(person); String[] names = context.getBeanNamesForType(Person.class); for (String name: names) { System.out.println(name); } }} 输出 Person(name=vhsj, age=16)person01 由于给bean添加一个一个value，可以改变默认id 组件注册@ComponentScan使用xml只要标注了注解就能扫描到如： @Controller @Service @Repository @Component &lt;context:component-scan base-package=&quot;com.cuzz&quot;&gt;&lt;/context:component-scan&gt; 注解在配置类中添加 /** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration // 告诉Spring这是一个配置类@ComponentScan(value = &quot;com.cuzz&quot;) // 指定包public class MainConfig { } 添加controller、service等 测试 /** * @Author: cuzz * @Date: 2018/9/23 13:03 * @Description: */public class IOCTest { @Test public void test01() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) { System.out.println(name); } }} 输出结果 org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfigbookControllerbookDaobookServiceperson01 可以看出添加@Controller @Service @Repository @C omponent注解的都可以扫描到 还可以指定添加某些类，和排除某些类，进入ComponentScan注解中有下面两个方法 ComponentScan.Filter[] includeFilters() default {};ComponentScan.Filter[] excludeFilters() default {};includeFilters = Filter[] ：指定扫描的时候只需要包含哪些组件excludeFilters = Filter[] ：指定扫描的时候按照什么规则排除那些组件 配置类，排除Controller @Configuration // 告诉Spring这是一个配置类@ComponentScan(value = &quot;com.cuzz&quot;, excludeFilters = { @ComponentScan.Filter(type = FilterType.ANNOTATION, classes = {Controller.class})})public class MainConfig {} 运行测试方法，可以得出没有Controller类的 org.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfigbookDaobookServiceperson01 自定义TypeFilter指定过滤规则第一和第二比较常用 FilterType.ANNOTATION：按照注解FilterType.ASSIGNABLE_TYPE：按照给定的类型；FilterType.ASPECTJ：使用ASPECTJ表达式FilterType.REGEX：使用正则指定FilterType.CUSTOM：使用自定义规则 新建一个MyTypeFilte类实现TypeFilter接口 /** * @Author: cuzz * @Date: 2018/9/23 15:03 * @Description: */public class MyTypeFilter implements TypeFilter{ /** * metadataReader：读取到的当前正在扫描的类的信息 * metadataReaderFactory:可以获取到其他任何类信息的 */ @Override public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException { // 获取当前类注解的信息 AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata(); // 获取当前正在扫描的类的类信息 ClassMetadata classMetadata = metadataReader.getClassMetadata(); // 获取当前类资源（类的路径） Resource resource = metadataReader.getResource(); String className = classMetadata.getClassName(); System.out.println(&quot;---&gt;&quot;+className); // 这些类名中包含er就返回true if(className.contains(&quot;er&quot;)){ return true; } return false; }} 使用自定义注解记得需要关闭默认过滤器useDefaultFilters = false /** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration @ComponentScan(value = &quot;com.cuzz&quot;, includeFilters = @ComponentScan.Filter(type = FilterType.CUSTOM, classes = MyTypeFilter.class), useDefaultFilters = false)public class MainConfig { // 给容器中注册一个Bean,类型为返回值类型,id默认用方法名 // 也可以指定id @Bean(value = &quot;person01&quot;) public Person person() { return new Person(&quot;vhsj&quot;, 16); }} 测试 ---&gt;com.cuzz.AppTest---&gt;com.cuzz.bean.MainTest---&gt;com.cuzz.config.IOCTest---&gt;com.cuzz.config.MainTest---&gt;com.cuzz.App---&gt;com.cuzz.bean.Person---&gt;com.cuzz.config.MyTypeFilter---&gt;com.cuzz.controller.BookController---&gt;com.cuzz.dao.BookDao---&gt;com.cuzz.sevice.BookServiceorg.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig // 不是扫描的 person // 这个是在bean中myTypeFilter // 有erbookController // 有erbookService // 有erperson01 // 这个是在bean中 组件注册@Scope设置作用域Spring的bean默认是单例的@Testpublic void test02() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) { System.out.println(name); } Object bean = applicationContext.getBean(&quot;person&quot;); Object bean2 = applicationContext.getBean(&quot;person&quot;); System.out.println(bean == bean2); // 输出true} Scope的四个范围ConfigurableBeanFactory#SCOPE_PROTOTYPE // 多实例 每次获取时创建对象，不会放在ioc容器中ConfigurableBeanFactory#SCOPE_SINGLETON // 单实例 ioc容器启动是创建对象，以后从容器中获取WebApplicationContext#SCOPE_REQUEST // web同一次请求创建一个实例WebApplicationContext#SCOPE_SESSION // web同一个session创建一个实例 如果我们把Scope修改 /** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: */@Configurationpublic class MainConfig2 { @Scope(value = &quot;prototype&quot;) @Bean public Person person() { return new Person(&quot;vhuj&quot;, 25); }} 则测试输出false 组件注册@Lazy-bean懒加载懒加载懒加载的是针对单实例Bean，默认是在容器启动的时创建的，我们可以设置懒加载容器启动是不创建对象，在第一次使用（获取）Bean创建对象，并初始化 测试先给添加一个@Lazy注解 @Configurationpublic class MainConfig2 { @Lazy @Bean public Person person() { System.out.println(&quot;给容器中添加Person...&quot;); return new Person(&quot;vhuj&quot;, 25); }} 编写一个测试方法 @Testpublic void test03() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); System.out.println(&quot;ioc容器创建完成...&quot;); Object bean = applicationContext.getBean(&quot;person&quot;);} 输出 ioc容器创建完成...给容器中添加Person... 添加一个@Lazy是在第一次获取时，创建对象，以后获取就不需要创建了，直接从容器中获取，因为它是单实例 组件注册@Conditional按条件注册按照一定条件进行判断，满足条件给容器中注册Bean 编写自己的Condition类如果系统是windows，给容器中注入”bill” 如果系统是linux，给容器中注入”linus” 编写WindowCondition类并重写matches方法 /** * @Author: cuzz * @Date: 2018/9/23 20:30 * @Description: 判断是否是windows */ public class WindowCondition implements Condition{ /** * @param context 判断条件 * @param metadata 注释信息 * @return boolean */ @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { Environment environment = context.getEnvironment(); String property = environment.getProperty(&quot;os.name&quot;); if (property.contains(&quot;Windows&quot;)) { return true; } return false; } } context有以下方法 // 能获取ioc使用的beanfactoryConfigurableListableBeanFactory beanFactory = context.getBeanFactory();// 能获取到类加载器ClassLoader classLoader = context.getClassLoader();// 获取到环境变量Environment environment = context.getEnvironment();// 获取到Bean定义的注册类BeanDefinitionRegistry registry = context.getRegistry(); 配置类添加Bean添加Condition条件 @Configurationpublic class MainConfig2 { @Conditional({WindowCondition.class}) @Bean(&quot;bill&quot;) public Person person01() { return new Person(&quot;Bill Gates&quot;, 60); } @Conditional({LinuxCondition.class}) @Bean(&quot;linux&quot;) public Person person02() { return new Person(&quot;linus&quot;, 45); }} 测试@Testpublic void test04() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); // 获取环境变量 ConfigurableEnvironment environment = applicationContext.getEnvironment(); String property = environment.getProperty(&quot;os.name&quot;); System.out.println(property); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) { System.out.println(name); } // key 是id Map&lt;String, Person&gt; map = applicationContext.getBeansOfType(Person.class); System.out.println(map);} 发现只有“bill”这个Bean被注入 Windows 7org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2bill{bill=Person(name=Bill Gates, age=60)} 组件注册@Improt给容器中快速导入一个组件@Import导入@Import可以导入第三方包，或则自己写的类，比较方便，Id默认为全类名 比如我们新建一个类 /** * @Author: cuzz * @Date: 2018/9/23 21:08 * @Description: */public class Color {} 我们只需要在配置类添加一个@Import把这个类导入 @Import({Color.class})@Configurationpublic class MainConfig2 {} ImportSelector接口导入的选择器返回导入组件需要的全类名的数组 public interface ImportSelector { /** * Select and return the names of which class(es) should be imported based on * the {@link AnnotationMetadata} of the importing @{@link Configuration} class. */ String[] selectImports(AnnotationMetadata importingClassMetadata);} 编写一个MyImportSelector类实现ImportSelector接口 /** * @Author: cuzz * @Date: 2018/9/23 21:15 * @Description: */public class MyImportSelector implements ImportSelector{ // 返回值就导入容器组件的全类名 // AnnotationMetadata:当前类标注的@Import注解类的所有注解信息 @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) { return new String[] {&quot;com.cuzz.bean.Car&quot;}; }} 在配置类中，通过@Import导入 /** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: 配置类 */@Import({Color.class, MyImportSelector.class})@Configurationpublic class MainConfig2 {} 测试结果，com.cuzz.bean.Car注入了 org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2com.cuzz.bean.Colorcom.cuzz.bean.Car ImportBeanDefinitionRegistrar接口选择器public interface ImportBeanDefinitionRegistrar { /** * Register bean definitions as necessary based on the given annotation metadata of * the importing {@code @Configuration} class. * &lt;p&gt;Note that {@link BeanDefinitionRegistryPostProcessor} types may &lt;em&gt;not&lt;/em&gt; be * registered here, due to lifecycle constraints related to {@code @Configuration} * class processing. * @param importingClassMetadata annotation metadata of the importing class * @param registry current bean definition registry */ public void registerBeanDefinitions( AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry);} 编写一个ImportBeanDefinitionRegistrar实现类 /** * @Author: cuzz * @Date: 2018/9/23 21:29 * @Description: */public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar { /** * @param importingClassMetadata 当前类的注解信息 * @param registry 注册类 */ @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { // 查询容器 boolean b = registry.containsBeanDefinition(&quot;com.cuzz.bean.Car&quot;); // 如果有car, 注册一个汽油类 if (b == true) { // 需要添加一个bean的定义信息 RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Petrol.class); // 注册一个bean, 指定bean名 registry.registerBeanDefinition(&quot;petrol&quot;, rootBeanDefinition); } }} 配置类 /** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: 配置类 */@Import({Color.class, MyImportSelector.class, MyImportBeanDefinitionRegistrar.class})@Configurationpublic class MainConfig2 {} 测试结果，出现了petrol org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2com.cuzz.bean.Colorcom.cuzz.bean.Car petrol 组件注册使用FactoryBean注册组件编写一个ColorFactoryBean类 /** * @Author: cuzz * @Date: 2018/9/23 21:55 * @Description: Spring定义的工厂Bean */public class ColorFactoryBean implements FactoryBean&lt;Color&gt; { // 返回一个Color对象 @Override public Color getObject() throws Exception { return new Color(); } @Override public Class&lt;?&gt; getObjectType() { return Color.class; } // 是否为单例 @Override public boolean isSingleton() { return true; }} 注入到容器中 @Beanpublic ColorFactoryBean colorFactoryBean() { return new ColorFactoryBean();} 测试 @Testpublic void test05() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); Object bean = applicationContext.getBean(&quot;colorFactoryBean&quot;); // 工厂bean调用的是getClass()方法 System.out.println(&quot;colorFactoryBean的类型是: &quot; + bean.getClass());} 输出，发现此时的bean调用的方法是getObjectType方法 colorFactoryBean的类型是: class com.cuzz.bean.Color 如果需要获取BeanFactory本身，可以在id前面加一个“&amp;”标识 @Testpublic void test05() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); Object bean = applicationContext.getBean(&quot;colorFactoryBean&quot;); // 工厂bean调用的是getClass()方法 System.out.println(&quot;colorFactoryBean的类型是: &quot; + bean.getClass()); Object bean2 = applicationContext.getBean(&quot;&amp;colorFactoryBean&quot;); // 工厂bean调用的是getClass()方法 System.out.println(&quot;colorFactoryBean的类型是: &quot; + bean2.getClass());} 此时输出 colorFactoryBean的类型是: class com.cuzz.bean.ColorcolorFactoryBean的类型是: class com.cuzz.bean.ColorFactoryBean 总结给容器中注册组件： 包扫描 + 组件组件（@Controller / @Service / @Repository / @Component） @Bean[导入第三方包组件] @Import[快速给容器中导入一个组件] @Import（要导入到容器中的组件），容器中就会自动注册这个组件，id 默认是全类名 ImportSelector，返回需要导入的组件的全类名数组 ImportBeanDefinitionRegistrar，手动注册bean到容器中 使用 Spring 提供的 FactoryBean （工厂Bean） 默认获取到的是工厂 bean 调用的 getObject 创建的对象 要获取工厂 Bean 本身，我们需要个 id 前面加一个 &amp; 符号，如 &amp;colorFactoryBean","link":"/2018/09/23/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"数据库","text":"数据库架构数据库架构可以分为存储文件系统和程序实例两大块，而程序实例根据不同的功能又可以分为如下小模块。 索引模块常见的问题有： 为什么要使用索引 什么样的信息能成为索引 索引的数据结构 密集索引和稀疏索引的区别 为什么要使用索引使用索引就像查字典一样，可以快速查询数据 什么样的信息能成为索引主键、唯一键以及普通键等 索引的数据结构 生成索引，建立二叉查找树进行二分查找 生成索引，建立 B Tree 结构结构进行查找 生成索引，建立 B+ Tree 结构进行查找 生成索引，建立 Hash 结构进行查找 什么是 B Tree 索引？B-Tree 是为磁盘等外存储设备设计的一种平衡查找树。因此在讲 B-Tree 之前先了解下磁盘的相关知识。 系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。 InnoDB存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。InnoDB 存储引擎中默认每个页的大小为 16 KB，可通过参数 innodb_page_size 将页的大小设置为 4K、8K、16K ，在 MySQL 中可通过如下命令查看页的大小： mysql&gt; show variables like 'innodb_page_size'; 而系统一个磁盘块的存储空间往往没有这么大，因此 InnoDB 每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小 16KB 。InnoDB 在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘 I/O 次数，提高查询效率。 B-Tree 结构的数据可以让系统高效的找到数据所在的磁盘块。为了描述B-Tree，首先定义一条记录为一个二元组 [key, data] ，key 为记录的键值，对应表中的主键值，data 为一行记录中除主键外的数据。对于不同的记录，key值互不相同。 一棵 m 阶的 B-Tree 有如下特性： 每个节点最多有 m 个孩子 除了根节点和叶子节点外，其它每个节点至少有 Ceil(m/2) 个孩子 若根节点不是叶子节点，则至少有 2 个孩子 所有叶子节点都在同一层，且不包含其它关键字信息 每个非叶子节点包含 n 个关键字信息（P0,P1,…Pn, k1,…kn） 关键字的个数 n 满足：ceil(m/2)-1 &lt;= n &lt;= m-1 ki(i=1,…n) 为关键字，且关键字升序排序 Pi(i=0,…n) 为指向子树根节点的指针。P(i-1) 指向的子树的所有节点关键字均小于 ki ，但都大于 k(i-1) B-Tree 中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个 3 阶的 B-Tree： 每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的 key 和三个指向子树根节点的 point ，point 存储的是子节点所在磁盘块的地址。两个 key 划分成的三个范围域，对应三个 point 指向的子树的数据的范围域。 以根节点为例，key 为 17 和 35 ，P1 指针指向的子树的数据范围为小于 17 ，P2 指针指向的子树的数据范围为 [17~35] ，P3 指针指向的子树的数据范围为大于 35 。 模拟查找 key 为 29 的过程： 1、根据根节点找到磁盘块 1 ，读入内存。【磁盘I/O操作第1次】 2、比较 key 29 在区间（17,35），找到磁盘块 1 的指针 P2 。 3、根据 P2 指针找到磁盘块 3 ，读入内存。【磁盘I/O操作第2次】 4、比较 key 29 在区间（26,30），找到磁盘块3的指针P2。 5、根据 P2 指针找到磁盘块 8 ，读入内存。【磁盘I/O操作第3次】 6、在磁盘块 8 中的 key 列表中找到 eky 29 。 分析上面过程，发现需要 3 次磁盘 I/O 操作，和 3 次内存查找操作。由于内存中的 key 是一个有序表结构，可以利用二分法查找提高效率。而 3 次磁盘 I/O 操作是影响整个 B-Tree 查找效率的决定因素。B-Tree 相对于 AVLTree 缩减了节点个数，使每次磁盘 I/O 取到内存的数据都发挥了作用，从而提高了查询效率。 什么是 B+Tree 索引？B+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构，InnoDB存储引擎就是用 B+Tree 实现其索引结构。 从上一节中的 B-Tree 结构图中可以看到，每个节点中不仅包含数据的 key 值，还有 data 值。而每一个页的存储空间是有限的，如果 data 数据较大时将会导致每个节点（即一个页）能存储的 key 的数量很小，当存储的数据量很大时同样会导致 B-Tree 的深度较大，增大查询时的磁盘 I/O 次数，进而影响查询效率。在 B+Tree 中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储 key 值信息，这样可以大大加大每个节点存储的 key 值数量，降低 B+Tree 的高度。 B+Tree 相对于 B-Tree 有几点不同： 非叶子节点只存储键值信息。 所有叶子节点之间都有一个链指针。 数据记录都存放在叶子节点中。 B+ Tree 更适合用来做存储索引： B+ 数的磁盘读写代价更低 B+ 数的查询效率更加稳定 B+ 数更有利于对数据库的扫描（范围查询） 将上一节中的 B-Tree 优化，由于 B+Tree 的非叶子节点只存储键值信息，假设每个磁盘块能存储 4 个键值及指针信息，则变成 B+Tree 后其结构如下图所示： 磁盘块4中的10数据，画错了，范围在[K[i], K[i+1])，左闭右开 通常在 B+Tree 上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构。因此可以对 B+Tree 进行两种查找运算：一种是对于主键的范围查找和分页查找，另一种是从根节点开始，进行随机查找。 可能上面例子中只有 22 条数据记录，看不出 B+Tree 的优点，下面做一个推算： InnoDB 存储引擎中页的大小为 16KB，一般表的主键类型为 INT（占用4个字节） 或 BIGINT（占用8个字节），指针类型也一般为 4 或 8 个字节，也就是说一个页（B+Tree 中的一个节点）中大概存储 16KB/(8B+8B)=1K 个键值（因为是估值，为方便计算，这里的 K 取值为〖10〗^3）。也就是说一个深度为 3 的 B+Tree 索引可以维护10^3 10^3 10^3 = 10亿 条记录。 实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree 的高度一般都在 24 层。MySQL 的 InnoDB 存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要 13 次磁盘 I/O 操作。 什么是 hash 索引？基于哈希表实现，优点是查找非常快。如下图 ： 哈希索引就是采用一定的哈希算法，将键值换算成新的哈希值，检索时不需要想B+Tree那样从根结点开始查找，而是经过计算直接定位，所以速度很快。 但是也有限制： 只支持精确查找，不能用于部分查找和范围查找。无法排序和分组。因为原来有序的键值经过哈希算法很可能打乱。 如果哈希冲突很多，查找速度很慢。比如在有大量重复键值的情况下。 不能利用部分索引查询 不能 聚集索引与非聚集索引 MyISAM 索引与 InnoDB 索引的区别？ InnoDB 索引是聚簇索引，MyISAM 索引是非聚簇索引。 InnoDB 的主键索引的叶子节点存储着行数据，因此主键索引非常高效。 MyISAM 索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。 InnoDB 非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效 如何定位并优化慢查询的 Sql需要具体场景具体分析，其大致思路 根据慢日志定位到慢查询的 sql 使用 explain 等工具分析 sql 修改 sql 或者尽量让 sql 走索引 定位慢查询sql开启慢查询日志即可 文件方式配置 MySQL 慢查询的方法： 查询 MySQL 慢查询状态的方法： SHOW VARIABLES LIKE '%query%'; 在 mysql 配置文件 my.cnf 中增加： log-slow-queries=/opt/data/slowquery.loglong_query_time=2 log-queries-not-using-indexes 命令方式配置 MySQL 慢查询的方法： set global slow_query_log=on; set global long_query_time=1; set global slow_query_log_file=‘/opt/data/slow_query.log’; 解析 MySQL 慢查询日志的方法，按照 sql 执行时间最长的前 20 条 sql： mysqldumpslow -s t -t 20 -g 'select' /opt/data/slowquery.log 在 log 中就能找到慢查询的 sql。 Explian 关键字 Explain命令在解决数据库性能上是第一推荐使用命令，大部分的性能问题可以通过此命令来简单的解决，Explain可以用来查看SQL语句的执行效 果，可以帮助选择更好的索引和优化查询语句，写出更好的优化语句。 Explain语法：explain select … from … [where …] 例如：explain select * from news; 输出： +----+-------------+-------+-------+-------------------+---------+---------+-------+------| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+-------+-------------------+---------+---------+-------+------ 下面对各个属性进行了解： 1、id：这是SELECT的查询序列号 2、select_type：select_type就是select的类型，可以有以下几种： SIMPLE：简单SELECT(不使用UNION或子查询等) PRIMARY：最外面的SELECT UNION：UNION中的第二个或后面的SELECT语句 DEPENDENT UNION：UNION中的第二个或后面的SELECT语句，取决于外面的查询 UNION RESULT：UNION的结果。 SUBQUERY：子查询中的第一个SELECT DEPENDENT SUBQUERY：子查询中的第一个SELECT，取决于外面的查询 DERIVED：导出表的SELECT(FROM子句的子查询) 3、table：显示这一行的数据是关于哪张表的 4、type：这列最重要，显示了连接使用了哪种类别,有无使用索引，是使用Explain命令分析性能瓶颈的关键项之一。 结果值从好到坏依次是： system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL 一般来说，得保证查询至少达到range级别，最好能达到ref，否则就可能会出现性能问题。 5、possible_keys：列指出MySQL能使用哪个索引在该表中找到行 6、key：显示MySQL实际决定使用的键（索引）。如果没有选择索引，键是NULL 7、key_len：显示MySQL决定使用的键长度。如果键是NULL，则长度为NULL。使用的索引的长度。在不损失精确性的情况下，长度越短越好 8、ref：显示使用哪个列或常数与key一起从表中选择行。 9、rows：显示MySQL认为它执行查询时必须检查的行数。 10、Extra：包含MySQL解决查询的详细信息，也是关键参考项之一。 Distinct一旦MYSQL找到了与行相联合匹配的行，就不再搜索了 Not existsMYSQL 优化了LEFT JOIN，一旦它找到了匹配LEFT JOIN标准的行， 就不再搜索了 Range checked for each Record（index map:#）没有找到理想的索引，因此对于从前面表中来的每一 个行组合，MYSQL检查使用哪个索引，并用它来从表中返回行。这是使用索引的最慢的连接之一 Using filesort看 到这个的时候，查询就需要优化了。MYSQL需要进行额外的步骤来发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来 排序全部行 Using index列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表 的全部的请求列都是同一个索引的部分的时候 Using temporary看到这个的时候，查询需要优化了。这 里，MYSQL需要创建一个临时表来存储结果，这通常发生在对不同的列集进行ORDER BY上，而不是GROUP BY上 Using where使用了WHERE从句来限制哪些行将与下一张表匹配或者是返回给用户。如果不想返回表中的全部行，并且连接类型ALL或index， 这就会发生，或者是查询有问题 其他一些Tip： 当type 显示为 “index” 时，并且Extra显示为 “Using Index”， 表明使用了覆盖索引。 联合索引的最左匹配原则的成因看看如下博客即可 联合索引的最左前缀匹配原则 mysql索引最左匹配原则的理解? 索引是建立得越多越好的吗 数据量小的表不需要建立索引，建立会增加额外的索引开销 数据变更需要维护索引，因此更多的索引意味着更多的维护成本 更多的索引意味着也需要更多的空间 锁模块常见问题 MyISAM 与 InnoDB 关于锁方面的区别是什么 数据库事务的四大特性 事务隔离级别以及各级别下的并发访问问题 InnoDB 可重复读隔离级别下如何避免幻读 RC、RR 级别下的 InnoDB 的非堵塞如果实现 MyISAM 与 InnoDB 关于锁方面的区别是什么 MyISAM 默认用的是表级锁，不支持行级锁 InnoDB 默认用的是行级锁，也支持表级锁 数据库锁的分类 按锁的粒度划分，可分为表级锁、行级锁和页级锁 按锁的级别划分，可分为共享锁和排他锁 按加锁的方式划分，可分为自动锁和显示锁 按操作划分，可分为 DML 锁和 DDL 锁 按使用方式划分，可分为乐观锁和悲观锁 ACID1. 原子性（Atomicity）事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。 回滚可以用回滚日志来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。 2. 一致性（Consistency）数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。 3. 隔离性（Isolation）一个事务所做的修改在最终提交以前，对其它事务是不可见的。 4. 持久性（Durability）一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。 使用重做日志来保证持久性。 并发一致性问题在并发环境下，事务的隔离性很难保证，因此会出现很多并发一致性问题。 丢失修改T1 和 T2 两个事务都对一个数据进行修改，T1 先修改，T2 随后修改，T2 的修改覆盖了 T1 的修改。 读脏数据T1 修改一个数据，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。 不可重复读T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。 幻影读T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。 隔离级别未提交读（READ UNCOMMITTED）事务中的修改，即使没有提交，对其它事务也是可见的。 提交读（READ COMMITTED）一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。 可重复读（REPEATABLE READ）保证在同一个事务中多次读取同样数据的结果是一样的。 可串行化（SERIALIZABLE）强制事务串行执行。 隔离级别 脏读 不可重复读 幻影读 加锁读 未提交读 √ √ √ × 提交读 × √ √ × 可重复读 × × √ × 可串行化 × × × √ 参考链接 数据库系统原理","link":"/2019/02/22/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"title":"深入理解Java虚拟机（一）","text":"类加载机制在 Java 代码中，类型（类，接口，枚举）的加载、连接（验证，准备，解析）与初始化过程都是在程序运行期间完成的，提供了更大的灵活性，增加了更多的可能性 类加载器深入剖析Java 虚拟机与程序的生命周期 在如下几种情况下，Java 虚拟机将结束生命周期 执行了 System.exit() 方法 程序正常执行结束 程序在执行的过程中遇到了异常或则错误而异常终止 由于操作系统出现了错误，导致 Java 虚拟机进程结束 类的加载、连接与初始化 加载：查找并加载类的二进制数据 连接 验证：确保被加载的类的正确性 准备：为类的静态变量分配内存，并将其初始化为默认值 解析：把类中的符号引用转化为直接引用 初始化：为静态变量赋予正确的初始值 使用（类的实例化）： 为新的对象分配内存 为实例变量赋默认值 为实例变量赋予正确的初始值 Java 编译器为它编译的每一个类都至少生成一个实例初始化方法，在 Java 的 class 文件中，这这实例初始方法被称为 &lt;init&gt; ，对源代码中的每一个类的构造方法，java 编译器都产生一个 &lt;init&gt; 方法 Java 程序对类的使用方式可以分为两种： 主动使用 创建类的实例 访问某个类或接口的静态变量，或则对该静态变量赋值 调用类的静态方法 反射（如 Class.forName(&quot;com.cuzz.Test&quot;)） 初始化一个子类 Java 虚拟机启动时被标明为启动类的类 被动使用 所有的 Java 虚拟机实现必须在每个类或接口被 Java 程序首次主动使用时才初始化他们 我们来看一段代码 public class MyTest01 { public static void main(String[] args) { System.out.println(Child1.str); }}class Parent1 { public static String str = &quot;hello world&quot;; static { System.out.println(&quot;Parent1 static block&quot;); }}class Child1 extends Parent1 { static { System.out.println(&quot;Child1 static block&quot;); }} 输出 Parent1 static blockhello world 对于静态代码块，只有定义该字段的类才会被初始化，这个 Child1.str 是子类调用父类的静态字段，所以子类不会被初始化，父类才会被初始化，这是对 Parent1 的主动使用，对于这个例子只是用了 Child1 的名字，并没有主动使用 Child1 这个类 我们在来看看有没有被加载到虚拟机中，在 VM options : -XX:+TraceClassLoading 在运行 ...[Loaded com.cuzz.jvm.classloader.Parent1 from file:/E:/project/learn-demo/demo-10-jvm-lecture/out/production/classes/][Loaded com.cuzz.jvm.classloader.Child1 from file:/E:/project/learn-demo/demo-10-jvm-lecture/out/production/classes/]Parent1 static blockhello world[Loaded java.lang.Shutdown from E:\\deployer\\jdk8\\jre\\lib\\rt.jar][Loaded java.lang.Shutdown$Lock from E:\\deployer\\jdk8\\jre\\lib\\rt.jar] 发现这两个类已经被加载到虚拟中 再看一个例子 public class MyTest01 { public static void main(String[] args) { System.out.println(Child1.str2); }}class Parent1 { public static String str = &quot;hello world&quot;; static { System.out.println(&quot;Parent1 static block&quot;); }}class Child1 extends Parent1 { public static String str2 = &quot;welcome&quot;; static { System.out.println(&quot;Child1 static block&quot;); }} 输出 Parent1 static blockChild1 static blockwelcome 当我们初始一个子类，我们会先初始化父类，所以会线输出父类的静态代码块 如果我们加上 final 变为常量 /** * @Author: cuzz * @Date: 2019/1/25 19:16 * @Description: */public class MyTest02 { public static void main(String[] args) { System.out.println(Parent2.str); }}class Parent2 { public static final String str = &quot;hello world&quot;; static { System.out.println(&quot;Parent2 static block&quot;); }} 输出 hello world 常量在编译阶段会存入到调用这个常量的方法所在的类的常量池中（也就是说会存入MyTest02这个类中），本质上，调用类并没有直接引用到定义常量的类，因此并不会触发定义常量的类的初始化 注意：这里指的是将常量存放到了 MyTest02 的常量池中，之后 MyTest02 与 Parent2 就没有任何关系了，甚至我们可以将 Parent 的 class 文件删除 我们进入 classes 目录下使用：javap -c com.cuzz.jvm.classloader.MyTest02 命令反编译一下 Compiled from &quot;MyTest02.java&quot;public class com.cuzz.jvm.classloader.MyTest02 { public com.cuzz.jvm.classloader.MyTest02();// (1) Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #4 (2) // String hello world (3) 5: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return} 是构造方法 ldc 助记符表示将 int，float 或 String 类型的值从常量池中推送至栈顶 可以看出Parent2.str 已经转化为 hello world 注：当 int 取值-15采用iconst指令，取值-128127采用 bipush 指令，取值-3276832767采用 sipush 指令，取值-21474836482147483647采用 ldc 指令 我们在看一个例子 public class MyTest03 { public static void main(String[] args) { System.out.println(Parent3.str); }}class Parent3 { public static final String str = UUID.randomUUID().toString(); static { System.out.println(&quot;Parent3 static block&quot;); }} 输出 Parent3 static blockbee2f54d-8960-46d0-b5d7-02666fcf4a14 相比于上一个例子，我们发现输出了静态代码块，说明 Parent3 这个类被初始化了，当一个常量的值并非编译期间可以确定的，那么器值就不会放到调用类的常量池中，这是在程序运行时，会导致主动使用这个常量所在的类，会导致这给类初始化 再看一个例子 public class MyTest04 { public static void main(String[] args) { Parent4[] parent4s = new Parent4[1]; System.out.println(&quot;---------&quot;); System.out.println(parent4s.getClass()); System.out.println(parent4s.getClass().getSuperclass()); System.out.println(&quot;---------&quot;); int[] ints = new int[1]; System.out.println(ints.getClass()); System.out.println(ints.getClass().getSuperclass()); }}class Parent4 { static { System.out.println(&quot;Parent4 static block&quot;); }} 输出 ---------class [Lcom.cuzz.jvm.classloader.Parent4;class java.lang.Object---------class [Iclass java.lang.ObjectProcess finished with exit code 0 对于数组实例来说，其类型是由 JVM 在运行期动态生成的，表示为 [Lcom.cuzz.jvm.classloader.Parent4 这种形式，动态生成的类型，其父类型就是 Object 对于数组来说，JavaDoc 经常将构成的数组元素称为 Component，实际上就是将数组降低一个维度的类型 我们使用 javap -c com.cuzz.jvm.classloader.MyTest04 进行反编译 public class com.cuzz.jvm.classloader.MyTest04 { public com.cuzz.jvm.classloader.MyTest04(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: iconst_1 1: anewarray #2 // class com/cuzz/jvm/classloader/Parent4 4: astore_1 5: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 8: ldc #4 // String --------- 10: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 13: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 16: aload_1 17: invokevirtual #6 // Method java/lang/Object.getClass:()Ljava/lang/Class; 20: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V 23: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 26: aload_1 27: invokevirtual #6 // Method java/lang/Object.getClass:()Ljava/lang/Class; 30: invokevirtual #8 // Method java/lang/Class.getSuperclass:()Ljava/lang/Class; 33: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V 36: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 39: ldc #4 // String --------- 41: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 44: iconst_1 45: newarray int 47: astore_2 48: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 51: aload_2 52: invokevirtual #6 // Method java/lang/Object.getClass:()Ljava/lang/Class; 55: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V 58: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 61: aload_2 62: invokevirtual #6 // Method java/lang/Object.getClass:()Ljava/lang/Class; 65: invokevirtual #8 // Method java/lang/Class.getSuperclass:()Ljava/lang/Class; 68: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V 71: return} 里面有两个助记符 anewarray ：表示创建一个引用类型的（如类、接口、数组）数组，并将其值压入栈顶 newarray：表示创建一个指定的原始类型（如int、float、char等）数组，并将其引用值压入栈顶 下一个例子 public class MyTest05 { public static void main(String[] args) { System.out.println(Child5.j); }}interface Parent5 { int i = 5;}interface Child5 extends Parent5 { int j = 55;} 编译之后我们把 Parent5.class 文件删掉，还能打印出 55，说明当一个接口在初始化时，并不要求其父接口都完成初始化，如果我们把 Child5.class 文件也删掉，也能打印出 55，原来接口中的修饰符默认为 public static final 说明接口中的值是一个常量，不需要加载到 JVM 中，也就没有初始化。 public class MyTest05 { public static void main(String[] args) { System.out.println(Child5.j); }}interface Parent5 { public static Thread thread = new Thread() { { System.out.println(&quot;Parent5 static block&quot;); } };}class Child5 implements Parent5 { public static int j = 55;} 此时也也是输出 55 ，也没有初始化 Child5 接口 Parent5 下一例子 public class MyTest06 { public static void main(String[] args) { Singleton singleton = Singleton.newSingleton(); System.out.println(Singleton.counter1); System.out.println(Singleton.counter2); }}class Singleton { public static int counter1; private static Singleton singleton = new Singleton(); private Singleton() { counter1++; // counter1 = 1 counter2++; // counter2 = 1 } public static int counter2 = 0; // 此时又把值赋值为 0 public static Singleton newSingleton() { return singleton; }} 此时输出 10 为什么会这样呢，准备阶段 counter1 和 counter2 的初始值都是 0 ，初始化阶段从上往下赋值，后面 counter2 又赋值为 0 我们再来回顾一下 public class MyTest09 { static { System.out.println(&quot;MyTest09 static block&quot;); } public static void main(String[] args) { System.out.println(Child9.j); }}class Parent9 { public static int i = 9; static { System.out.println(&quot;Parent9 static block&quot;); }}class Child9 extends Parent9 { public static int j = 99; static { System.out.println(&quot;Child9 static block&quot;); }} 输出 MyTest09 static blockParent9 static blockChild9 static block99 我们多输出点信息 public class MyTest09 { static { System.out.println(&quot;MyTest09 static block&quot;); } public static void main(String[] args) { Parent9 parent9; // 不会初始化 System.out.println(&quot;-------------&quot;); parent9 = new Parent9(); System.out.println(&quot;-------------&quot;); System.out.println(Parent9.i); System.out.println(&quot;-------------&quot;); System.out.println(Child9.j); }}class Parent9 { public static int i = 9; static { System.out.println(&quot;Parent9 static block&quot;); }}class Child9 extends Parent9 { public static int j = 99; static { System.out.println(&quot;Child9 static block&quot;); }} 输出结果 MyTest09 static block-------------Parent9 static block-------------9-------------Child9 static block99 在看一个例子 public class MyTest12 { public static void main(String[] args) throws Exception{ ClassLoader classLoader = ClassLoader.getSystemClassLoader(); Class&lt;?&gt; clazz = classLoader.loadClass(&quot;com.cuzz.jvm.classloader.CL&quot;); System.out.println(&quot;--------------&quot;); clazz = Class.forName(&quot;com.cuzz.jvm.classloader.CL&quot;); }}class CL { static { System.out.println(&quot;CL static block&quot;); }} 输出 --------------CL static block 说明调用 ClassLoader 类的 loadClass 方法加载一个类，并不是对类的主动使用，不会导致类的初始化，而通过 Class.forName 方法是通过反射机制，会对类初始化 类的加载类的加载是指将类的 .class 文件中的二进制数据读入到内存中，将其运行时数据区的方法区内，然后在内存中创建一个 java.lang.Class 对象（规范中并未说明Class对象位于哪里，HotSpot 虚拟机将其放在了方法区中）用来封装类在方法区内的数据结构 加载 .class 文件的方式 从本地系统中直接加载 .class 文件 通过网络下载的 .class 文件 从 zip，jar 等归档文件中加载 .class 文件 从专有数据库中提取 .class 文件 将 Java 源文件动态编译为 .class 文件 类的加载器 类的加载器分类： Java 虚拟机自带的加载器 根加载器（Bootstrap） 拓展类加载器（Extension） 应用加载器（Application） 用户自定义的类加载器 java.lang.ClassLoader 的子类 用户定制类的加载方法 注意：类的加载并不需要等到某个类被首次主动使用时再加载它；JVM 规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载过程中遇到了 .class 文件缺失或存在错误，类加载器必须在程序首次主动使用该类才报告错误，如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误 看一个例子 public class MyTest07 { public static void main(String[] args) throws Exception { Class&lt;?&gt; clazz = Class.forName(&quot;java.lang.String&quot;); System.out.println(clazz.getClassLoader()); Class&lt;?&gt; clazz1 = Class.forName(&quot;com.cuzz.jvm.classloader.C&quot;); System.out.println(clazz1.getClassLoader()); }}class C { } 输出 nullsun.misc.Launcher$AppClassLoader@dad5dc 看看 getClassLoader 的文档 Returns the class loader for the class. Some implementations may use null to represent the bootstrap class loader. This method will return null in such implementations if this class was loaded by the bootstrap class loader. 说明输出 null 说明 java.lang.String 是根加载器加载的 获取 ClassLoader 的途径 获得当前类 ClassLoader clazz.getClassLoader() 获得当前线程上下文的 ClassLoader Thread.currentThread().getContextClassLoader() 获取系统的 ClassLoader ClassLoader.getSystemClassLoader() 获取调用者的 ClassLoader DriverManger.getCallerClassLoader() 类的验证类的验证的内容： 类文件的结构检查 语义检查 字节码验证 二进制兼容性的验证 类的初始化时机当 Java 虚拟机在初始化一个类时，要求它的所有父类都已经被初始化，但是这条规则并不适用于接口 在初始化一个类时，并不会先初始化它所实现的接口 在初始化一个接口时，并不会先初始化它的父接口 因此，一个父接口并不会因为它的子接口或者实现类的初始化而初始化，只有当程序首次使用特定接口的静态变量时，才会导致该接口的初始化 JVM参数设置非稳态选项使用说明: -XX:+&lt;option&gt; 启用 option -XX:-&lt;option&gt; 不启用 option -XX:&lt;option&gt;=&lt;number&gt; 设定option的值为数字类型，可跟单位，例如 32k, 1024m, 2g -XX:&lt;option&gt;=&lt;string&gt; 设定option的值为字符串，例如-XX:HeapDumpPath=./dump.core","link":"/2019/01/27/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"深入理解Java虚拟机（三）","text":"Java 字节码代码编译结果从本地机器码转变为字节码，是存储格式发展的一小步，确是编程语言发展的一大步。 字节码文件剖析我们从一段简单的代码来入手 public class MyTest01 { private int a = 0; public int getA() { return a; } public void setA(int a) { this.a = a; }} 我要要看一下 java 文件对应的 class 文件的结构，定位到工程的 out\\production\\classes 下边执行： javap -c com.cuzz.jvm.bytecode.Mytest01 警告: 二进制文件com.cuzz.jvm.bytecode.Mytest01包含com.cuzz.jvm.bytecode.MyTest01Compiled from &quot;MyTest01.java&quot;public class com.cuzz.jvm.bytecode.MyTest01 { public com.cuzz.jvm.bytecode.MyTest01(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: aload_0 5: iconst_0 6: putfield #2 // Field a:I 9: return public int getA(); Code: 0: aload_0 1: getfield #2 // Field a:I 4: ireturn public void setA(int); Code: 0: aload_0 1: iload_1 2: putfield #2 // Field a:I 5: return} 我们如果需要获得更多信息可以使用如下命令： javap -verbose com.cuzz.jvm.bytecode.Mytest01 警告: 二进制文件com.cuzz.jvm.bytecode.Mytest01包含com.cuzz.jvm.bytecode.MyTest01Classfile /E:/project/learn-demo/demo-10-jvm-lecture/out/production/classes/com/cuzz/jvm/bytecode/Mytest01.class Last modified 2019-2-3; size 492 bytes MD5 checksum cceeac51ae7b6fc46c60faf834de5932 Compiled from &quot;MyTest01.java&quot;public class com.cuzz.jvm.bytecode.MyTest01 minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #4.#20 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #3.#21 // com/cuzz/jvm/bytecode/MyTest01.a:I #3 = Class #22 // com/cuzz/jvm/bytecode/MyTest01 #4 = Class #23 // java/lang/Object #5 = Utf8 a #6 = Utf8 I #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 LocalVariableTable #12 = Utf8 this #13 = Utf8 Lcom/cuzz/jvm/bytecode/MyTest01; #14 = Utf8 getA #15 = Utf8 ()I #16 = Utf8 setA #17 = Utf8 (I)V #18 = Utf8 SourceFile #19 = Utf8 MyTest01.java #20 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V #21 = NameAndType #5:#6 // a:I #22 = Utf8 com/cuzz/jvm/bytecode/MyTest01 #23 = Utf8 java/lang/Object{ public com.cuzz.jvm.bytecode.MyTest01(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: aload_0 5: iconst_0 6: putfield #2 // Field a:I 9: return LineNumberTable: line 8: 0 line 10: 4 LocalVariableTable: Start Length Slot Name Signature 0 10 0 this Lcom/cuzz/jvm/bytecode/MyTest01; public int getA(); descriptor: ()I flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: getfield #2 // Field a:I 4: ireturn LineNumberTable: line 13: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/cuzz/jvm/bytecode/MyTest01; public void setA(int); descriptor: (I)V flags: ACC_PUBLIC Code: stack=2, locals=2, args_size=2 0: aload_0 1: iload_1 2: putfield #2 // Field a:I 5: return LineNumberTable: line 17: 0 line 18: 5 LocalVariableTable: Start Length Slot Name Signature 0 6 0 this Lcom/cuzz/jvm/bytecode/MyTest01; 0 6 1 a I}SourceFile: &quot;MyTest01.java&quot; 我们也可以使用二进制文件查看器查看class文件的16进制信息（winhex下载）： 16文件查看器里边第一行的CA 就是一个字节的容量（8位bit）: 使用 javap -verbos 命令分析一个字节码文件时，将会分析该字节码文件的魔数、版本号、常量池、类信息、类的构造方法信息、类变量与成员变量等信息。 魔数：所有的.class字节码文件的前4个字节都是魔数，魔数值为固定值：0xCAFEBABE (詹姆斯.高斯林设计的，蕴意：咖啡宝贝，java 的图标是咖啡。 魔数之后的4个字节为版本信息，前2个字节表示 minor versio（次版本号），后两个字节表示 major version（主版本号）。 这里的版本号为 00 00 00 34，换算成十进制，表示次版本号为0，主版本号为52。 字节常量池剖析常量池（constant pool）：紧接着主版本号之后的就是常量池入口。一个 Java 类中定义的很多信息都是由常量池来维护和描述的，可以将常量池看作是 Class 文件的资源仓库，比如说 Java 类中定义的方法与变量信息，都是存储在常量池中。常量池中的主要储存两类常量：字面量与符号引用。字面量如文本字符串，Java 中声明为 final 的常量值等，而符号引用如类和接口的全局限定名，字段的名称和描述符，方法的名称和描述符等。 常量池的总体结构：Java 类所对应的常量池主要由常量池数量与常量池数组（常量表）这两部分共同构成。常量池数量紧跟在主版本号后面，占据 2 个字节；常量池数组紧跟在常量池数量之后。常量池数组与一般的数组不同的是，常量池数组中不同的元素类型、结构都是不同的，长度当然也就不同；但是，每一种元素的第一个数据都是一个 u1 类型，该字节是一个标志位，占据 1 个字节。JVM 在解析常量池时，会根据这个 u1 类型来获取元素的具体类型。 值得注意的是，常量池数组中元素的个数 = 常量池数 - 1 （其中0暂时不使用）。对应的是 00 18 转化为十进制为24个常量，而我们看到只有23个。目的是满足某些常量池索引值的数据在特定情况下需要表达“不引用任何一个常量”的含义；根本原因在于，索引 0 也是一个常量（保留常量），只不过它不位于常量表中，这个常量就对应 null 值，所以，常量池的索引从 1 开始而不是 0 。 Constant pool: #1 = Methodref #4.#20 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #3.#21 // com/cuzz/jvm/bytecode/MyTest01.a:I #3 = Class #22 // com/cuzz/jvm/bytecode/MyTest01 #4 = Class #23 // java/lang/Object #5 = Utf8 a #6 = Utf8 I #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 LocalVariableTable #12 = Utf8 this #13 = Utf8 Lcom/cuzz/jvm/bytecode/MyTest01; #14 = Utf8 getA #15 = Utf8 ()I #16 = Utf8 setA #17 = Utf8 (I)V #18 = Utf8 SourceFile #19 = Utf8 MyTest01.java #20 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V #21 = NameAndType #5:#6 // a:I #22 = Utf8 com/cuzz/jvm/bytecode/MyTest01 #23 = Utf8 java/lang/Object Class 文件结构中常量池数据类型的结构表 在 JVM 规范中，每一个变量/字段都有描述信息，描述信息主要的作用是描述字段的数据类型、方法的参数列表（包括数量、类型与顺序）与返回值。根据描述符规则，基本数据类型和代表无返回的 void 类型都是用一个大写字符来表示，对象类型则使用字符 L 加对象的全限定名称来表示。为了压缩字节码文件的体积，对于基本数据类型，JVM 都只使用一个大写字母来表示，如下所示：B - byte，C - char，D - double，F - float，I - int，J - long，S - short，Z - boolean，V - void，L - 对象类型，如 Ljava/lang/String;。 对于数组类型来说，没一个维度使用前置 [ 来表示，如 int [] 被记录为 [I ，String[][] 被记录为 [[Ljava/lang/String;。 用描述符描述方法时，按照先参数列表，后返回值的顺序来描述。参数列表按照参数的严格顺序放在一组括号内，如方法：String getRealNameByIdAndNickName(int id, String name) 的描述符为：(I, Ljava/lang/String;) Ljava/lang/String; 我们来分析前面几个常量，如图： 我反编译出来的文件对比： Constant pool: #1 = Methodref #4.#20 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #3.#21 // com/cuzz/jvm/bytecode/MyTest01.a:I #3 = Class #22 // com/cuzz/jvm/bytecode/MyTest01 #4 = Class #23 // java/lang/Object #5 = Utf8 a #6 = Utf8 I #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code#10 = Utf8 LineNumberTable#11 = Utf8 LocalVariableTable#12 = Utf8 this#13 = Utf8 Lcom/cuzz/jvm/bytecode/MyTest01;#14 = Utf8 getA#15 = Utf8 ()I#16 = Utf8 setA#17 = Utf8 (I)V#18 = Utf8 SourceFile#19 = Utf8 MyTest01.java#20 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V#21 = NameAndType #5:#6 // a:I#22 = Utf8 com/cuzz/jvm/bytecode/MyTest01#23 = Utf8 java/lang/Object 0A 00 04 00 14，如图中的标注出来，0A 对应值为10，在上表的常量中 CONSTANT_Methodref_info 中，那么后边的2个字节 00 04 （十进制4）就是 U2（第一个index），即指向声明方法的类描述符 CONSTANT_Class_info 的索引项，而第二个索引（第二个index）00 14（十进制20） 指向名称及类型描述符 CONSTANT_NameAndType_info 的索引项。类描述指向 #4 ，#4 又指向 #23，所以描述为 java/lang/Object，而名称以及类型描述符指向 #20，#20 有指向 #7 和 #8，&quot;&lt;init&gt;&quot;:()V 表示为构造方法。 09 00 03 00 15 ，09 是标志位对用的是 CONSTANT_Fieldref_info，第一个索引指向的是声明字段的类或接口描述符，CONSTANT_Class_info 的索引项，根上面一样分析。 07 00 16 ， 00 16 十进制是22 ，07是常量 CONSTANT_CLass_info，只有一个index，指向的是指定权限定名常量项的索引， 00 16 是十进制22。 07 00 17 ，07是常量 CONSTANT_CLass_info，只有一个index，指向的是指定权限定名常量项的索引，00 17 十进制是23。 01 00 01 61，01 是 CONSTANT_Utf8_info，后面 00 01 这两个字节表示长度，最后 61 （十进制为97）的表示 ASCII 中带索引，在 ASCII 中为字母 a。 01 00 01 为 I。 等等 Java 字节码结构 Class 字节码中有两种数据类型 字节数据直接量：这是基本的数据类型，共细分为 u1、u2、u4、u8 这四种，分别代表连续的 1 个字节、2 个字节、4 个字节和8 个字节。 表（数组）：表示有多个基本数据或其他表，按照既定顺序组成的大的数据集合。表示有结构的，它的结构体现在，组成表的成分所在的位置和顺序都已经严格定义好的。 访问标志访问标志（Access_Flag）信息包括该 Class 文件是类还是接口，是否被定义成 public，是否是 abstract，如果是类，是否被声明成 final。通过上面的源代码，我们可以知道该文件是类并且是 public。 常量池之后两个字节就是访问标志，我们这个类中是 0x 00 21 ，从上面来看并没有，原来它是 0x 00 20 和 0x 00 01 的并集，表示 ACC_PUBLIC 与 ACC_SUPER。 类索引、父类索引与接口索引 00 03 是类索引，指向 #3 表示是一个类，其名字为 com/cuzz/jvm/bytecode/MyTest01 00 04 是父亲索引，指向 #4 表示是一个类，其名字是 java/lang/Object 00 00 是接口，表示没有接口 字段表集合字段表用于描述类和接口中声明的变量。这里的字段包含了类级别变量以及实例变量，但不包括方法内部声明的局部变量。 如下图 00 01 是成员变量的数量，后面接着就是 field_info 成员变量信息 field_info { u2 access_flags; // 0002 表示私有 private u2 name_index; // 0005 表示 a u2 descriptor_index; // 0006 表示 I u2 attributes_count; // 0000 没有 attribute_info attributes[attributes_count];} 方法表刚开始的 00 03 表示有三个方法，除了getter/setter 还有默认构造方法 methods_count { u2 access_flags; // 0001 表示 public u2 name_index; // 0007 指向常量池中 #7 的常量为 &lt;init&gt; u2 descriptor_index; // 0008 指向常量池中 #8 的常量为 ()V u2 attributes_count; // 0001 表示一个属性 attribute_info attributes[attributes_count];} 方法中的属性结构 attribute_info { u2 attribute_name_index; // 0009 指向常量池中 #9 为 Code u4 attribute_length; // 0000 0038 表示长度为 0x38 为 56 长度的字节 u1 info[attribute_length];} Code 结构Code attribute 的作用是保存该方法的结构，如所对应的字节码 Code_attribute { u2 attribute_name_index; u4 attribute_length; u2 max_stack; u2 max_locals; u4 code_length; u1 code[code_length]; u2 exception_table_length; { u2 start_pc; u2 end_pc; u2 handler_pc; u2 catch_type; } exception_table[exception_table_length]; u2 attributes_count; attribute_info attributes[attributes_count];} attribute_length 表示 attribute 所包含的字节数，不包含 attribute_name_index 和 attribute_length 字段 max_stack 表示这个方法运行的任何时刻所能达到的操作数栈的最大深度 max_locals 表示方法执行期间创建的局部变量的数目，包含用来表示传入的参数的局部变量 code_length 表示该方法所包含的字节码的字节数以及具体的指令码，具体字节码即是该方法被调用时，虚拟机所执行的字节码 exception_table 表示存放的是处理异常的信息 每个 exception_table 表由 start_pc，end_pc，handler_pc，catch_type 组成 start_pc 和 end_pc 表示在 code 数组中的从 start_pc 到 end_pc 处（包含 start_pc，不包含 end_pc）的指令抛出的异常会由这个表项来处理 handler_pc 表示处理异常的代码的开始处，catch_type 表示会被处理的异常类型，它指向常量池中的一个异常类，当 catch_type 为 0 时，表示处理所有的异常 字节码查看工具https://github.com/ingokegel/jclasslib","link":"/2019/02/06/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"计算机网络","text":"计算机网络体系结构 OSI其中表示层和会话层用途如下： 表示层 ：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。 会话层 ：建立及管理会话。 五层协议没有表示层和会话层，而是将这些功能留给应用程序开发者处理。 五层协议 应用层 ：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等。数据单位为报文。 传输层 ：为进程提供通用数据传输服务。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的应用层协议。运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务。 网络层 ：为主机提供数据传输服务。而传输层协议是为主机中的进程提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据报封装成分组。 数据链路层 ：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。 物理层 ：考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。 TCP/IP它只有四层，相当于五层协议中数据链路层和物理层合并为网络接口层。 TCP/IP 体系结构不严格遵循 OSI 分层概念，应用层可能会直接使用 IP 层或者网络接口层。 TCP/IP 是 Internet上的标准通信协议集，该协议集由数十个具有层次结构的协议组成，其中 TCP 和 IP 是该协议集中的两个最重要的核心协议。TCP/IP协议族按层次可分为以下四层：应用层、传输层、网络层和网络接口层，各层对应的 PDU 数据单元的名称如下图所示。 小结OSI 七层体系结构具有概念清楚、理论完整的特点，是一个理论上的国际标准，但却不是事实上的国际标准；而具有简单易用特点的 TCP/IP 四层体系结构则是事实上的标准。 需要指出的是，五层体系结构虽然综合了 OSI 和 TCP/IP 的优点，但其只是为了学术学习研究而提出的，没有具体的实际意义。 说说 TCP 的三次握手这一到很常见的面试题。 传输控制协议 TCP 简介 面向连接的、可靠的基于字节流的传输层通信协议 将应用层的数据流分割成报文段并发送给目标节点的 TCP 层 数据包都是由序号，对方收到则发送 ACK 确认，未收到则重传 使用校验和来检验数据在传输过程中是否有误 TCP 报文头 源端口、目的端口 ：标记进程。 序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 连接标志（TCP Flags）：表示控制功能，下面是常见的连接标志。 确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。 同步 SYN ：在连接建立时用来同步序号。当 SYN=a1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 三次握手 在 TCP/IP 协议中， TCP 协议提供可靠的连接服务，采用三次握手建立一个连接。 假设 A 为客户端，B 为服务器端。 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。 对于建链接的3次握手主要是要初始化Sequence Number 的初始值。通信的双方要互相通知对方自己的初始化的 Sequence Number（缩写为ISN：Inital Sequence Number）——所以叫SYN，全称Synchronize Sequence Numbers。也就上图中的 x 和 y。这个号要作为以后的数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输的问题而乱序（TCP会用这个序号来拼接数据）。 关于建连接时SYN超时试想一下，如果server端接到了 client 发的 SYN 后回了 SYN-ACK 后 client 掉线了，server 端没有收到 client 回来的ACK，那么，这个连接处于一个中间状态，即没成功，也没失败。于是，server 端如果在一定时间内没有收到的TCP会重发 SYN-ACK。在Linux下，默认重试次数为5次，重试的间隔时间从 1s 开始每次都翻售，5 次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 2^6 -1 = 63s，TCP才会把断开这个连接。 关于SYN Flood攻击一些恶意的人就为此制造了SYN Flood攻击，给服务器发了一个SYN后，就下线了，于是服务器需要默认等 63s 才会断开连接，这样，攻击者就可以把服务器的 syn 连接的队列耗尽，让正常的连接请求不能处理。于是，Linux下给了一个叫 tcp_syncookies 的参数来应对这个事——当SYN队列满了后，TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后服务端可以通过cookie建连接（即使你不在SYN队列中）。 请注意，请先千万别用 tcp_syncookies 来处理正常的大负载的连接的情况。因为，synccookies 是妥协版的TCP协议，并不严谨。对于正常的请求，你应该调整三个TCP参数可供你选择。 第一个是：tcp_synack_retries 可以用他来减少重试次数； 第二个是：tcp_max_syn_backlog，可以增大SYN连接数； 第三个是：tcp_abort_on_overflow 处理不过来干脆就直接拒绝连接了 ； 保活机制 向对方发送保活探测报文，如果未收到响应则继续发送 尝试次数达到保活探测数仍然未收到响应则中断连接 谈谈四次挥手 以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。 A 发送连接释放报文，FIN=1。 B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。 当 B 不再需要连接时，发送连接释放报文，FIN=1。 A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。 B 收到 A 的确认后释放连接。 四次挥手的原因客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。 TCP连接是全双工的，服务端可以发送数据到客户端，客户端也可以发送数据到服务端，发送方和接收方都需要两次挥手才能关闭 。 TIME_WAIT客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由： 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。 TCP 和 UDP 的区别前面我们说了 TCP 现在我们来认识一下 UDP。 UPD 的特点 面向非连接的 不维护连接状态，支持同时向多个客户端传输相同的消息 数据包报头只有 8 个字节，额外开销较小 吞吐量只受限于数据生成率、传输速率以及机器性能 尽最大努力交付，不保证可靠交付，不需要维持复杂的链接状态表 面向报文，不对应用程序提交的报文信息进行拆分或则合并 对比 TCP 是面向连接的；UDP 是无连接的。 TCP 是可靠的；UDP 是不可靠的。 TCP 只支持点对点通信；UDP 支持一对一、一对多、多对一、多对多的通信模式。 TCP 是面向字节流的；UDP 是面向报文的。 TCP 有拥塞控制机制；UDP 没有拥塞控制，适合媒体通信。 TCP 首部开销(20 个字节)，比 UDP 的首部开销(8 个字节)要大。 TCP 的滑动窗口首先明确： TCP滑动窗口分为接受窗口，发送窗口。 滑动窗口协议是传输层进行流控的一种措施，接收方通过通告发送方自己的窗口大小，从而控制发送方的发送速度，从而达到防止发送方发送速度过快而导致自己被淹没的目的。 重要概念对ACK的再认识，ack通常被理解为收到数据后给出的一个确认ACK，ACK包含两个非常重要的信息： 一是期望接收到的下一字节的序号n，该n代表接收方已经接收到了前n-1字节数据，此时如果接收方收到第n+1字节数据而不是第n字节数据，接收方是不会发送序号为n+2的ACK的。举个例子，假如接收端收到1-1024字节，它会发送一个确认号为1025的ACK,但是接下来收到的是2049-3072，它是不会发送确认号为3072的ACK,而依旧发送1025的ACK。 二是当前的窗口大小m，如此发送方在接收到ACK包含的这两个数据后就可以计算出还可以发送多少字节的数据给对方，假定当前发送方已发送到第x字节，则可以发送的字节数就是y=m-(x-n).这就是滑动窗口控制流量的基本原理 重点：发送方根据收到ACK当中的期望收到的下一个字节的序号n以及窗口m，还有当前已经发送的字节序号x，算出还可以发送的字节数。 发送端窗口的第一个字节序号一定是ACK中期望收到的下一个字节序号，比如下图： 上图52 53 54 55 字节都是可以新发送的字节序。 接受端窗口的第一个字节序之前一定是已经完全接收的，后面窗口里面的数据都是希望接受的，窗口后面的数据都是不希望接受的。 TCP的滑动窗口分为接收窗口和发送窗口 不分析这两种窗口就讨论是不妥当的。 TCP的滑动窗口主要有两个作用，一是提供TCP的可靠性，二是提供TCP的流控特性。同时滑动窗口机制还体现了TCP面向字节流的设计思路。TCP 段中窗口的相关字段。 TCP的Window是一个16bit位字段，它代表的是窗口的字节容量，也就是TCP的标准窗口最大为2^16-1=65535个字节。 另外在TCP的选项字段中还包含了一个TCP窗口扩大因子，option-kind为3，option-length为3个字节，option-data取值范围0-14。窗口扩大因子用来扩大TCP窗口，可把原来16bit的窗口，扩大为31bit。 滑动窗口基本原理对于TCP会话的发送方，任何时候在其发送缓存内的数据都可以分为4类，“已经发送并得到对端ACK的”，“已经发送但还未收到对端ACK的”，“未发送但对端允许发送的”，“未发送且对端不允许发送”。“已经发送但还未收到对端ACK的”和“未发送但对端允许发送的”这两部分数据称之为发送窗口。 当收到接收方新的ACK对于发送窗口中后续字节的确认是，窗口滑动，滑动原理如下图。 当收到ACK=36时窗口滑动。 2）对于TCP的接收方，在某一时刻在它的接收缓存内存在3种。“已接收”，“未接收准备接收”，“未接收并未准备接收”（由于ACK直接由TCP协议栈回复，默认无应用延迟，不存在“已接收未回复ACK”）。其中“未接收准备接收”称之为接收窗口。 发送窗口与接收窗口关系TCP是双工的协议，会话的双方都可以同时接收、发送数据。TCP会话的双方都各自维护一个“发送窗口”和一个“接收窗口”。其中各自的“接收窗口”大小取决于应用、系统、硬件的限制（TCP传输速率不能大于应用的数据处理速率）。各自的“发送窗口”则要求取决于对端通告的“接收窗口”，要求相同。 滑动窗口实现面向流的可靠性 最基本的传输可靠性来源于“确认重传”机制。 TCP的滑动窗口的可靠性也是建立在“确认重传”基础上的。 发送窗口只有收到对端对于本段发送窗口内字节的ACK确认，才会移动发送窗口的左边界。 接收窗口只有在前面所有的段都确认的情况下才会移动左边界。当在前面还有字节未接收但收到后面字节的情况下，窗口不会移动，并不对后续字节确认。以此确保对端会对这些数据重传。 滑动窗口的流控特性TCP的滑动窗口是动态的，我们可以想象成小学常见的一个数学题，一个水池，体积V，每小时进水量V1，出水量V2。当水池满了就不允许再注入了，如果有个液压系统控制水池大小，那么就可以控制水的注入速率和量。这样的水池就类似TCP的窗口。应用根据自身的处理能力变化，通过本端TCP接收窗口大小控制来对对对端的发送窗口流量限制。 应用程序在需要（如内存不足）时，通过API通知TCP协议栈缩小TCP的接收窗口。然后TCP协议栈在下个段发送时包含新的窗口大小通知给对端，对端按通知的窗口来改变发送窗口，以此达到减缓发送速率的目的。 HTTPHTTP 协议，是 Hyper Text Transfer Protocol（超文本传输协议）的缩写，是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。 主要特点如下： 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有 GET、HEAD、POST 等等。每种方法规定了客户与服务器联系的类型不同。由于 HTTP 协议简单，使得 HTTP 服务器的程序规模小，因而通信速度很快。 数据格式灵活：HTTP 允许传输任意类型的数据对象。正在传输的类型由Content-Type 加以标记。 无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 无状态：HTTP 协议是无状态协议。无状态，是指协议对于事务处理没有记忆能力。无状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 支持 B/S 及 C/S 模式。 GET 和 POST 区别从三个层面来解答： Http 报文层面：GET 将请求信息放在 URL中，POST 方法报文中 数据库层面：GET 符合幂等性和安全性，POST 不符合 其他层面：GET 可以被缓存、被存储（书签），而 POST 不行 Cookie 和 Session 的区别Cookie 简介： 是由服务器发给客户端的特殊信息，以文本的形式存放在客户端 客户端再次请求的时候，会把 Cookie 回发给服务端 服务器接收到后，会解析 Cookie 生成与客户端相对的内容 Cookiet 的设置以及发送过程： Session 简介： 服务端的机制，在服务端保存的信息 解析客户端请求并操作 Session id ，按需保存状态信息 Session 的实现方式： 使用 Cookie 来实现 使用 URL 回写来实现，每次在 URL 添加 Session id 信息 区别： Cookie 数据存放在客户端的浏览器上，Session 数据存放在服务器上 Session 相对于 Cookie 更安全 若考虑减轻服务器负担，应当使用 Cookie HTTP 和 HTTPs 的区别 SSL (Security Sockets Layer) 安全套接层 为网络通信提供安全及数据完整性的一种安全协议 是操作系统对外的 API，SSL 3.0 更名为 TLS 采用身份验证和数据加密来保证网络的通信的安全和数据的完整性 区别 HTTPS 需要到 CA 申请证书，HTTP 不需要 HTTPS 密文传输，HTTP 明文传输 连接方式不同，HTTPS 默认使用 443 端口，HTTP 使用 80 端口 HTTPS = HTTP + 加密 + 认证 + 完整性保护，较 HTTP 安全 其他内容 一 、基础概念 URI 请求和响应报文 二、HTTP 方法 GET HEAD POST PUT PATCH DELETE OPTIONS CONNECT TRACE 三、HTTP 状态码 1XX 信息 2XX 成功 3XX 重定向 4XX 客户端错误 5XX 服务器错误 四、HTTP 首部 通用首部字段 请求首部字段 响应首部字段 实体首部字段 五、具体应用 连接管理 Cookie 缓存 内容协商 内容编码 范围请求 分块传输编码 多部分对象集合 虚拟主机 通信数据转发 六、HTTPs 加密 认证 完整性保护 HTTPs 的缺点 七、HTTP/2.0 HTTP/1.x 缺陷 二进制分帧层 服务端推送 首部压缩 八、HTTP/1.1 新特性 九、GET 和 POST 比较 作用 参数 安全 幂等性 可缓存 XMLHttpRequest 浏览器输入地址回车后发生的事情 DNS解析 TCP连接 发送HTTP请求 服务器处理请求并返回HTTP报文 浏览器解析渲染页面 连接结束 Socket 通信TCP/IP（Transmission Control Protocol/Internet Protocol）即传输控制协议/网间协议，是一个工业标准的协议集，它是为广域网（WANs）设计的。UDP（User Data Protocol，用户数据报协议）是与TCP相对应的协议。它是属于 TCP/IP 协议族中的一种。 这里有一张图，表明了这些协议的关系。 TCP/IP协议族包括运输层、网络层、链路层。现在你知道TCP/IP与UDP的关系了吧。 **Socket在哪里呢？ ** 上图我们没有看到 Socket 的影子，那么它到底在哪里呢？还是用图来说话，一目了然。 Socket 是什么呢？ Socket 是应用层与 TCP/IP 协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket 其实就是一个门面模式，它把复杂的 TCP/IP 协议族隐藏在 Socket 接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。 Socket 通信原理 先从服务器端说起。服务器端先初始化Socket，然后与端口绑定(bind)，对端口进行监听(listen)，调用accept阻塞，等待客户端连接。在这时如果有个客户端初始化一个Socket，然后连接服务器(connect)，如果连接成功，这时客户端与服务器端的连接就建立了。客户端发送数据请求，服务器端接收请求并处理请求，然后把回应数据发送给客户端，客户端读取数据，最后关闭连接，一次交互结束。 TCP 实现服务端 /** * @Author: cuzz * @Date: 2019/2/19 22:36 * @Description: */public class TCPServer { public static void main(String[] args) throws IOException { // 创建socket，并将socket绑定到65000端口 ServerSocket serverSocket = new ServerSocket(65000); // 死循环，使socket一直等待并处理客户端发过来的请求 while (true) { // 监听6500端口，直到客户端返回连接信息后才返回 Socket socket = serverSocket.accept(); // 获取客户端请求信息后，执行相关逻辑 new LengthCalculator(socket).start(); } }}class LengthCalculator extends Thread { private Socket socket; public LengthCalculator(Socket socket) { this.socket = socket; } @Override public void run() { try { // 获取socket的输出流 OutputStream os = socket.getOutputStream(); // 获取socket的输入流 InputStream is = socket.getInputStream(); byte[] bytes = new byte[1024]; int len = 0; StringBuilder sb = new StringBuilder(); while ((len = is.read(bytes)) != -1) { os.write(bytes, 0 , len); System.out.println(new String(bytes, 0 , len)); } // 不要忘记关闭输入输出流 os.close(); is.close(); socket.close(); } catch (IOException e) { e.printStackTrace(); } }} 客服端 public class TCPClinet { public static void main(String[] args) throws IOException { // 创建socket，并指定连接的是ip和端口号 Socket socket = new Socket(&quot;127.0.0.1&quot;, 65000); // 获取输出流 OutputStream os = socket.getOutputStream(); // 获取输入流 InputStream is = socket.getInputStream(); os.write(&quot;hello world&quot;.getBytes()); int len = 0; byte[] bytes = new byte[1024]; len = is.read(bytes); String content = new String(bytes, 0, len); System.out.println(content); is.close(); os.close(); socket.close(); }} UDP 实现服务端 public class UDPServer { public static void main(String[] args) throws Exception { // 服务端接受客户端发送的数据报 DatagramSocket socket = new DatagramSocket(65001); //监听的端口号 byte[] buff = new byte[100]; //存储从客户端接受到的内容 DatagramPacket packet = new DatagramPacket(buff, buff.length); //接受客户端发送过来的内容，并将内容封装进DatagramPacket对象中 socket.receive(packet); byte[] data = packet.getData(); //从DatagramPacket对象中获取到真正存储的数据 //将数据从二进制转换成字符串形式 String content = new String(data, 0, packet.getLength()); System.out.println(content); //将要发送给客户端的数据转换成二进制 byte[] sendedContent = String.valueOf(content.length()).getBytes(); // 服务端给客户端发送数据报 //从DatagramPacket对象中获取到数据的来源地址与端口号 DatagramPacket packetToClient = new DatagramPacket(sendedContent, sendedContent.length, packet.getAddress(), packet.getPort()); socket.send(packetToClient); //发送数据给客户端 }} 客服端 public class UDPClient { public static void main(String[] args) throws Exception { // 客户端发数据报给服务端 DatagramSocket socket = new DatagramSocket(); // 要发送给服务端的数据 byte[] buf = &quot;Hello World&quot;.getBytes(); // 将IP地址封装成InetAddress对象 InetAddress address = InetAddress.getByName(&quot;127.0.0.1&quot;); // 将要发送给服务端的数据封装成DatagramPacket对象 需要填写上ip地址与端口号 DatagramPacket packet = new DatagramPacket(buf, buf.length, address, 65001); // 发送数据给服务端 socket.send(packet); // 客户端接受服务端发送过来的数据报 byte[] data = new byte[100]; // 创建DatagramPacket对象用来存储服务端发送过来的数据 DatagramPacket receivedPacket = new DatagramPacket(data, data.length); // 将接受到的数据存储到DatagramPacket对象中 socket.receive(receivedPacket); // 将服务器端发送过来的数据取出来并打印到控制台 String content = new String(receivedPacket.getData(), 0, receivedPacket.getLength()); System.out.println(content); }} 参考链接 计算机网络 计算机网络体系结构综述（下） TCP 的那些事儿 TCP协议的滑动窗口具体是怎样控制流量的？ Socket通信原理","link":"/2019/02/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"title":"Netty 源码分析（二）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. 先来看一个NIO网络编程服务端/** * @Author: cuzz * @Date: 2019/1/7 15:39 * @Description: */public class NioServer { // 储存客户端连接 private static Map&lt;String, SocketChannel&gt; clientMap = new HashMap&lt;&gt;(); public static void main(String[] args) throws IOException { ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); ServerSocket serverSocket = serverSocketChannel.socket(); serverSocket.bind(new InetSocketAddress(8899)); Selector selector = Selector.open(); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) { try { selector.select(); Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); selectionKeys.forEach(selectionKey -&gt; { try { if (selectionKey.isAcceptable()) { // 可以读 read(selector, selectionKey); } else if (selectionKey.isReadable()) { // 可以写 write(selector, selectionKey); } } catch (IOException e) { e.printStackTrace(); } }); selectionKeys.clear(); // 别忘了清空 } catch (Exception e) { e.printStackTrace(); } } } private static void write(Selector selector, SelectionKey selectionKey) throws IOException{ SocketChannel client = (SocketChannel) selectionKey.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(512); int read = client.read(byteBuffer); if (read &gt; 0) { byteBuffer.flip(); Charset charset = Charset.forName(&quot;utf-8&quot;); String receiveMessage = String.valueOf(charset.decode(byteBuffer).array()); System.out.println(client + &quot;: &quot; + receiveMessage); String key = null; for (Map.Entry&lt;String, SocketChannel&gt; entry : clientMap.entrySet()) { if (entry.getValue() == client) { key = entry.getKey(); break; } } for (Map.Entry&lt;String, SocketChannel&gt; entry : clientMap.entrySet()) { SocketChannel value = entry.getValue(); ByteBuffer writeBuffer = ByteBuffer.allocate(1024); writeBuffer.put((key + &quot; :&quot; + receiveMessage).getBytes()); writeBuffer.flip(); value.write(writeBuffer); } } } private static void read(Selector selector, SelectionKey selectionKey) throws IOException{ ServerSocketChannel server = (ServerSocketChannel) selectionKey.channel(); System.out.println(server); SocketChannel client = server.accept(); client.configureBlocking(false); client.register(selector, SelectionKey.OP_READ); String key = UUID.randomUUID().toString(); // 保存客户端 clientMap.put(key, client); }} 客服端/** * @Author: cuzz * @Date: 2019/1/8 17:10 * @Description: */public class NioClient { public static void main(String[] args){ try { SocketChannel socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); Selector selector = Selector.open(); socketChannel.register(selector, SelectionKey.OP_CONNECT); socketChannel.connect(new InetSocketAddress(&quot;127.0.0.1&quot;,8899)); while (true) { selector.select(); Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); for (SelectionKey selectionKey : selectionKeys ) { if (selectionKey.isConnectable()) { SocketChannel client = (SocketChannel) selectionKey.channel(); if (client.isConnectionPending()) { client.finishConnect(); System.out.println(client); ByteBuffer writeBuffer = ByteBuffer.allocate(512); writeBuffer.put((LocalDateTime.now() + &quot; 连接成功&quot;).getBytes()); writeBuffer.flip(); client.write(writeBuffer); ExecutorService executorService = Executors.newSingleThreadExecutor(); executorService.submit(() -&gt; { while (true) { InputStreamReader inputStreamReader = new InputStreamReader(System.in); BufferedReader bf = new BufferedReader(inputStreamReader); String message = bf.readLine(); ByteBuffer buffer = ByteBuffer.allocate(512); buffer.put(message.getBytes()); buffer.flip(); client.write(buffer); } }); } client.register(selector, SelectionKey.OP_READ); } else if (selectionKey.isReadable()) { SocketChannel client = (SocketChannel) selectionKey.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); int read = client.read(byteBuffer); if (read &gt; 0) { String message = new String(byteBuffer.array()); System.out.println(message); } } } selectionKeys.clear(); } } catch (Exception e) { e.printStackTrace(); } }} 代码还是比较复杂的，Netty 内部就是把这些细节给封装起来了 Reactor模式翻译过来为反应器模式，可以先看看由 Doug Lea 写的 Scalable IO in Java ，更好的理解 Netty 的设计模式 还有一篇博客也写得很好，介绍相关理论模型，使用场景，基本组件、整体架构， 这可能是目前最透彻的Netty原理架构解析 Netty 那些事儿 ——— Reactor模式详解 Netty Reactor 工作架构图 ![reactor](Netty 源码分析（二）/reactor.png) bind() 方法前面通过 .channel(NioServerSocketChannel.class) 是为了通过反射创建一个 NioServerSocketChannel 对象 NioServerSocketChannel使用反射创建 NioServerSocketChannel 肯定是通过无参数构造器，在调用 newSocket(DEFAULT_SELECTOR_PROVIDER) 所以这是一个静态方法，返回一个 ServerSocketChannel /** * A {@link io.netty.channel.socket.ServerSocketChannel} implementation which uses * NIO selector based implementation to accept new connections. */public class NioServerSocketChannel extends AbstractNioMessageChannel implements io.netty.channel.socket.ServerSocketChannel { private static final ChannelMetadata METADATA = new ChannelMetadata(false, 16); private static final SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider(); private static ServerSocketChannel newSocket(SelectorProvider provider) { try { /** * Use the {@link SelectorProvider} to open {@link SocketChannel} and so remove condition in * {@link SelectorProvider#provider()} which is called by each ServerSocketChannel.open() otherwise. * * See &lt;a href=&quot;https://github.com/netty/netty/issues/2308&quot;&gt;#2308&lt;/a&gt;. */ return provider.openServerSocketChannel(); } catch (IOException e) { throw new ChannelException( &quot;Failed to open a server socket.&quot;, e); } } private final ServerSocketChannelConfig config; /** * Create a new instance */ public NioServerSocketChannel() { this(newSocket(DEFAULT_SELECTOR_PROVIDER)); } /** * Create a new instance using the given {@link SelectorProvider}. */ public NioServerSocketChannel(SelectorProvider provider) { this(newSocket(provider)); } /** * Create a new instance using the given {@link ServerSocketChannel}. */ public NioServerSocketChannel(ServerSocketChannel channel) { super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket()); } ...} AbstractNioChannel我们回到调用的这个构造方法上 public NioServerSocketChannel(ServerSocketChannel channel) { super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket());} 一直调用父类，把 SelectionKey.OP_ACCEPT 设置上，还有设置非堵塞，是不出是很熟悉，这都是对 NIO 进行封装 io.netty.channel.nio.AbstractNioChannel#AbstractNioChannel protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) { super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try { ch.configureBlocking(false); } catch (IOException e) { ... }} 再调用父类，就是设置 Id 和创建管道 io.netty.channel.AbstractChannel protected AbstractChannel(Channel parent) { this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline();} NioServerSocketChannelConfig我们在回到这个构造方法上，我们重点来看看这个， NioServerSocketChannelConfig 这是一个配置类，Netty 的各种各样的信息都是体现在这个里面 public NioServerSocketChannel(ServerSocketChannel channel) { super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket());} 把自己和刚开始创建的 NIOSocketChannel 的 ServerSocket 对象传入进去 io.netty.channel.DefaultChannelConfig public DefaultChannelConfig(Channel channel) { this(channel, new AdaptiveRecvByteBufAllocator());} 传了一个 AdaptiveRecvByteBufAllocator 翻译过来可以叫可适配的接受字节缓冲适配器 AdaptiveRecvByteBufAllocatorio.netty.channel.AdaptiveRecvByteBufAllocator 文档： The RecvByteBufAllocator that automatically increases and decreases the predicted buffer size on feed back.It gradually increases the expected number of readable bytes if the previous read fully filled the allocated buffer. It gradually decreases the expected number of readable bytes if the read operation was not able to fill a certain amount of the allocated buffer two times consecutively. Otherwise, it keeps returning the same prediction. 构造方法，默认是1024，最小是63，最大是65536 /** * Creates a new predictor with the default parameters. With the default * parameters, the expected buffer size starts from {@code 1024}, does not * go down below {@code 64}, and does not go up above {@code 65536}. */public AdaptiveRecvByteBufAllocator() { this(DEFAULT_MINIMUM, DEFAULT_INITIAL, DEFAULT_MAXIMUM);} 我们在看看里面的内部类 private final class HandleImpl extends MaxMessageHandle { private final int minIndex; private final int maxIndex; private int index; private int nextReceiveBufferSize; private boolean decreaseNow; public HandleImpl(int minIndex, int maxIndex, int initial) { this.minIndex = minIndex; this.maxIndex = maxIndex; index = getSizeTableIndex(initial); nextReceiveBufferSize = SIZE_TABLE[index]; } @Override public int guess() { return nextReceiveBufferSize; } private void record(int actualReadBytes) { if (actualReadBytes &lt;= SIZE_TABLE[Math.max(0, index - INDEX_DECREMENT - 1)]) { if (decreaseNow) { index = Math.max(index - INDEX_DECREMENT, minIndex); nextReceiveBufferSize = SIZE_TABLE[index]; decreaseNow = false; } else { decreaseNow = true; } } else if (actualReadBytes &gt;= nextReceiveBufferSize) { index = Math.min(index + INDEX_INCREMENT, maxIndex); nextReceiveBufferSize = SIZE_TABLE[index]; decreaseNow = false; } } @Override public void readComplete() { record(totalBytesRead()); }} 其父亲 MaxMessageHandle 中，根据记录中的分配，计算出下一次分配的内存 @Overridepublic ByteBuf allocate(ByteBufAllocator alloc) { return alloc.ioBuffer(guess());} 根据系统的支持返回是堆内内存还是堆外内存 @Overridepublic ByteBuf ioBuffer(int initialCapacity) { if (PlatformDependent.hasUnsafe()) { return directBuffer(initialCapacity); } return heapBuffer(initialCapacity);} Pipeline我们回到前面管道的创建 io.netty.channel.AbstractChannel protected AbstractChannel(Channel parent) { this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline();} io.netty.channel.DefaultChannelPipeline#DefaultChannelPipeline protected DefaultChannelPipeline(Channel channel) { this.channel = ObjectUtil.checkNotNull(channel, &quot;channel&quot;); succeededFuture = new SucceededChannelFuture(channel, null); voidPromise = new VoidChannelPromise(channel, true); tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head;} 这里维护了一个上下文，并且把 Channel 对象赋值给自己，所以 Channel 和 Pipeline 是相互引用的 ChannelPipelineio.netty.channel.ChannelPipeline 文档： A list of ChannelHandlers which handles or intercepts inbound events and outbound operations of a Channel. ChannelPipeline implements an advanced form of the Intercepting Filter pattern to give a user full control over how an event is handled and how the ChannelHandlers in a pipeline interact with each other. Creation of a pipeline Each channel has its own pipeline and it is created automatically when a new channel is created. How an event flows in a pipeline The following diagram describes how I/O events are processed by ChannelHandlers in a ChannelPipeline typically. An I/O event is handled by either a ChannelInboundHandler or a ChannelOutboundHandler and be forwarded to its closest handler by calling the event propagation methods defined in ChannelHandlerContext, such as ChannelHandlerContext.fireChannelRead(Object) and ChannelHandlerContext.write(Object). I/O Request via Channel or ChannelHandlerContext |+---------------------------------------------------+---------------+| ChannelPipeline | || \\|/ || +---------------------+ +-----------+----------+ || | Inbound Handler N | | Outbound Handler 1 | || +----------+----------+ +-----------+----------+ || /|\\ | || | \\|/ || +----------+----------+ +-----------+----------+ || | Inbound Handler N-1 | | Outbound Handler 2 | || +----------+----------+ +-----------+----------+ || /|\\ . || . . || ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|| [ method call] [method call] || . . || . \\|/ || +----------+----------+ +-----------+----------+ || | Inbound Handler 2 | | Outbound Handler M-1 | || +----------+----------+ +-----------+----------+ || /|\\ | || | \\|/ || +----------+----------+ +-----------+----------+ || | Inbound Handler 1 | | Outbound Handler M | || +----------+----------+ +-----------+----------+ || /|\\ | |+---------------+-----------------------------------+---------------+ | \\|/+---------------+-----------------------------------+---------------+| | | || [ Socket.read() ] [ Socket.write() ] || || Netty Internal I/O Threads (Transport Implementation) |+-------------------------------------------------------------------+ An inbound event is handled by the inbound handlers in the bottom-up direction as shown on the left side of the diagram. An inbound handler usually handles the inbound data generated by the I/O thread on the bottom of the diagram. The inbound data is often read from a remote peer via the actual input operation such as SocketChannel.read(ByteBuffer). If an inbound event goes beyond the top inbound handler, it is discarded silently, or logged if it needs your attention. An outbound event is handled by the outbound handler in the top-down direction as shown on the right side of the diagram. An outbound handler usually generates or transforms the outbound traffic such as write requests. If an outbound event goes beyond the bottom outbound handler, it is handled by an I/O thread associated with the Channel. The I/O thread often performs the actual output operation such as SocketChannel.write(ByteBuffer) For example, let us assume that we created the following pipeline: ChannelPipeline p = ...;p.addLast(&quot;1&quot;, new InboundHandlerA());p.addLast(&quot;2&quot;, new InboundHandlerB());p.addLast(&quot;3&quot;, new OutboundHandlerA());p.addLast(&quot;4&quot;, new OutboundHandlerB());p.addLast(&quot;5&quot;, new InboundOutboundHandlerX()); In the example above, the class whose name starts with Inbound means it is an inbound handler. The class whose name starts with Outbound means it is a outbound handler. In the given example configuration, the handler evaluation order is 1, 2, 3, 4, 5 when an event goes inbound. When an event goes outbound, the order is 5, 4, 3, 2, 1. On top of this principle, ChannelPipeline skips the evaluation of certain handlers to shorten the stack depth: 3 and 4 don’t implement ChannelInboundHandler, and therefore the actual evaluation order of an inbound event will be: 1, 2, and 5. 1 and 2 don’t implement ChannelOutboundHandler, and therefore the actual evaluation order of a outbound event will be: 5, 4, and 3. If 5 implements both ChannelInboundHandler and ChannelOutboundHandler, the evaluation order of an inbound and a outbound event could be 125 and 543 respectively. Forwarding an event to the next handler As you might noticed in the diagram shows, a handler has to invoke the event propagation methods in ChannelHandlerContext to forward an event to its next handler. Those methods include: Inbound event propagation methods ChannelHandlerContext.fireChannelRegistered() hannelHandlerContext.fireChannelActive() ChannelHandlerContext.fireChannelRead(Object) ChannelHandlerContext.fireChannelReadComplete() ChannelHandlerContext.fireExceptionCaught(Throwable) ChannelHandlerContext.fireUserEventTriggered(Object) ChannelHandlerContext.fireChannelWritabilityChanged() ChannelHandlerContext.fireChannelInactive() ChannelHandlerContext.fireChannelUnregistered() Outbound event propagation methods: ChannelHandlerContext.bind(SocketAddress, ChannelPromise) ChannelHandlerContext.connect(SocketAddress, SocketAddress, ChannelPromise) ChannelHandlerContext.write(Object, ChannelPromise) ChannelHandlerContext.flush() ChannelHandlerContext.read() ChannelHandlerContext.disconnect(ChannelPromise) ChannelHandlerContext.close(ChannelPromise) ChannelHandlerContext.deregister(ChannelPromise) and the following example shows how the event propagation is usually done: public class MyInboundHandler extends ChannelInboundHandlerAdapter { @Override public void channelActive(ChannelHandlerContext ctx) { System.out.println(&quot;Connected!&quot;); ctx.fireChannelActive(); }}public class MyOutboundHandler extends ChannelOutboundHandlerAdapter { @Override public void close(ChannelHandlerContext ctx, ChannelPromise promise) { System.out.println(&quot;Closing ..&quot;); ctx.close(promise); }} Building a pipeline (重点) A user is supposed to have one or more ChannelHandlers in a pipeline to receive I/O events (e.g. read) and to request I/O operations (e.g. write and close). For example, a typical server will have the following handlers in each channel’s pipeline, but your mileage may vary depending on the complexity and characteristics of the protocol and business logic: Protocol Decoder - translates binary data (e.g. ByteBuf) into a Java object. Protocol Encoder - translates a Java object into binary data. Business Logic Handler - performs the actual business logic (e.g. database access). and it could be represented as shown in the following example: static final EventExecutorGroup group = new DefaultEventExecutorGroup(16);...ChannelPipeline pipeline = ch.pipeline();pipeline.addLast(&quot;decoder&quot;, new MyProtocolDecoder());pipeline.addLast(&quot;encoder&quot;, new MyProtocolEncoder());// Tell the pipeline to run MyBusinessLogicHandler's event handler methods// in a different thread than an I/O thread so that the I/O thread is not blocked by// a time-consuming task.// If your business logic is fully asynchronous or finished very quickly, you don't// need to specify a group.pipeline.addLast(group, &quot;handler&quot;, new MyBusinessLogicHandler()); 注：可以使用重载这个方法添加一个事件循环组 group 去执行耗时的任务，获取在 MyBusinessLogicHandler 中把耗时部分异步处理，这样就不会堵塞 IO 线程 Thread safety A ChannelHandler can be added or removed at any time because a ChannelPipeline is thread safe. For example, you can insert an encryption handler when sensitive information is about to be exchanged, and remove it after the exchange. 对于传统的过滤器如 SpringMVC 比如我们配置了 Filter1 Filter2 Filter3 过滤器，请求和返回都要经过滤器这3个过滤器，而管道可以选择的其中某些作为请求的过滤器，一些作为返回的过滤器，不一定要一样，入站的处理器专门处理入站的，出站的处理器专门处理出站的 init() 方法io.netty.bootstrap.ServerBootstrap#init @Overridevoid init(Channel channel) throws Exception { final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options0(); synchronized (options) { setChannelOptions(channel, options, logger); } final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs0(); synchronized (attrs) { for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) { @SuppressWarnings(&quot;unchecked&quot;) AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); } } ...} ChannelOption类图 ![1547524182709](Netty 源码分析（二）/1547524182709.png) io.netty.channelpublic class ChannelOptionextends AbstractConstant&lt;ChannelOption&gt; A ChannelOption allows to configure a ChannelConfig in a type-safe way. Which ChannelOption is supported depends on the actual implementation of ChannelConfig and may depend on the nature of the transport it belongs to. Type parameters: - the type of the value which is valid for the ChannelOption ChannelOption &lt;T&gt; 主要维护 TCP/IP 的一些底层的设定，T 表示值的类型 ChannelOption 继承了 AbstractConstant， AbstractConstant 有是 Constant 的一个基本的实现 io.netty.util.Constant io.netty.utilpublic interface Constant&lt;T extends Constant&gt;extends Comparable A singleton which is safe to compare via the == operator. Created and managed by ConstantPool. Type parameters: - the type of objects that this object may be compared to 我们可以知道这个常量是由 ConstantPool 来维持的，我看看他是怎么起作用的 io.netty.util.ConstantPool public abstract class ConstantPool&lt;T extends Constant&lt;T&gt;&gt; { private final ConcurrentMap&lt;String, T&gt; constants = PlatformDependent.newConcurrentHashMap(); private final AtomicInteger nextId = new AtomicInteger(1); /** * Shortcut of {@link #valueOf(String) valueOf(firstNameComponent.getName() + &quot;#&quot; + secondNameComponent)}. */ public T valueOf(Class&lt;?&gt; firstNameComponent, String secondNameComponent) { if (firstNameComponent == null) { throw new NullPointerException(&quot;firstNameComponent&quot;); } if (secondNameComponent == null) { throw new NullPointerException(&quot;secondNameComponent&quot;); } return valueOf(firstNameComponent.getName() + '#' + secondNameComponent); } /** * Returns the {@link Constant} which is assigned to the specified {@code name}. * If there's no such {@link Constant}, a new one will be created and returned. * Once created, the subsequent calls with the same {@code name} will always return the previously created one * (i.e. singleton.) * * @param name the name of the {@link Constant} */ public T valueOf(String name) { checkNotNullAndNotEmpty(name); return getOrCreate(name); } /** * Get existing constant by name or creates new one if not exists. Threadsafe * * @param name the name of the {@link Constant} */ private T getOrCreate(String name) { T constant = constants.get(name); if (constant == null) { final T tempConstant = newConstant(nextId(), name); constant = constants.putIfAbsent(name, tempConstant); if (constant == null) { return tempConstant; } } return constant; } /** * Returns {@code true} if a {@link AttributeKey} exists for the given {@code name}. */ public boolean exists(String name) { checkNotNullAndNotEmpty(name); return constants.containsKey(name); } /** * Creates a new {@link Constant} for the given {@code name} or fail with an * {@link IllegalArgumentException} if a {@link Constant} for the given {@code name} exists. */ public T newInstance(String name) { checkNotNullAndNotEmpty(name); return createOrThrow(name); } /** * Creates constant by name or throws exception. Threadsafe * * @param name the name of the {@link Constant} */ private T createOrThrow(String name) { T constant = constants.get(name); if (constant == null) { final T tempConstant = newConstant(nextId(), name); constant = constants.putIfAbsent(name, tempConstant); if (constant == null) { return tempConstant; } } throw new IllegalArgumentException(String.format(&quot;'%s' is already in use&quot;, name)); } private static String checkNotNullAndNotEmpty(String name) { ObjectUtil.checkNotNull(name, &quot;name&quot;); if (name.isEmpty()) { throw new IllegalArgumentException(&quot;empty name&quot;); } return name; } protected abstract T newConstant(int id, String name); @Deprecated public final int nextId() { return nextId.getAndIncrement(); }} 我们先看这个创建方法 /** * Get existing constant by name or creates new one if not exists. Threadsafe * * @param name the name of the {@link Constant} */private T getOrCreate(String name) { T constant = constants.get(name); if (constant == null) { final T tempConstant = newConstant(nextId(), name); constant = constants.putIfAbsent(name, tempConstant); if (constant == null) { return tempConstant; } } return constant;} 这里使用了双重检验机制，这个常量池保存的值是一个 T extends Constant&lt;T&gt; 包装过后的 io.netty.util.ConstantPool#newConstant 新建一个常量是由子类完成的，我们回到 ChannelOption 类中，**ChannelOption 是不保存值的，只是维护键的包装** AttributeKeyio.netty.util.AttributeKey io.netty.utilpublic final class AttributeKeyextends AbstractConstant&lt;AttributeKey&gt; Key which can be used to access Attribute out of the AttributeMap. Be aware that it is not be possible to have multiple keys with the same name. Type parameters: - the type of the Attribute which can be accessed via this AttributeKey. 与 ChannelOption 很相似，AttributeMap ，AttributeKey ，Attribute 相当一个 Map，key 和 value /** * Holds {@link Attribute}s which can be accessed via {@link AttributeKey}. * * Implementations must be Thread-safe. */public interface AttributeMap { /** * Get the {@link Attribute} for the given {@link AttributeKey}. This method will never return null, but may return * an {@link Attribute} which does not have a value set yet. */ &lt;T&gt; Attribute&lt;T&gt; attr(AttributeKey&lt;T&gt; key); /** * Returns {@code} true if and only if the given {@link Attribute} exists in this {@link AttributeMap}. */ &lt;T&gt; boolean hasAttr(AttributeKey&lt;T&gt; key);} 主要维护的是业务数据，可以在程序运行中动态的往里面添加数据和获取数据 ChannelInitializerio.netty.bootstrap.ServerBootstrap#init 回到 init 方法上 @Overridevoid init(Channel channel) throws Exception { ChannelPipeline p = channel.pipeline(); ... p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) throws Exception { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) { pipeline.addLast(handler); } ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); } });} 获取管道添加了一个 ChannelInitializer 实例，先看看这个类 io.netty.channel.ChannelInitializer io.netty.channel@Sharablepublic abstract class ChannelInitializerextends ChannelInboundHandlerAdapter A special ChannelInboundHandler which offers an easy way to initialize a Channel once it was registered to its EventLoop. Implementations are most often used in the context of Bootstrap.handler(ChannelHandler) , ServerBootstrap.handler(ChannelHandler) and ServerBootstrap.childHandler(ChannelHandler) to setup the ChannelPipeline of a Channel. public class MyChannelInitializer extends ChannelInitializer { public void initChannel(Channel channel) { channel.pipeline().addLast(&quot;myHandler&quot;, new MyHandler()); }}ServerBootstrap bootstrap = ...;...bootstrap.childHandler(new MyChannelInitializer());... Be aware that this class is marked as ChannelHandler.Sharable and so the implementation must be safe to be re-used. Type parameters: - A sub-type of Channel addLast() 方法io.netty.channel.DefaultChannelPipeline#addLast @Overridepublic final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) { final AbstractChannelHandlerContext newCtx; synchronized (this) { checkMultiplicity(handler); newCtx = newContext(group, filterName(name, handler), handler); addLast0(newCtx); // If the registered is false it means that the channel was not registered on an eventloop yet. // In this case we add the context to the pipeline and add a task that will call // ChannelHandler.handlerAdded(...) once the channel is registered. if (!registered) { newCtx.setAddPending(); callHandlerCallbackLater(newCtx, true); return this; } EventExecutor executor = newCtx.executor(); if (!executor.inEventLoop()) { newCtx.setAddPending(); executor.execute(new Runnable() { @Override public void run() { callHandlerAdded0(newCtx); } }); return this; } } callHandlerAdded0(newCtx); return this;} AbstractChannelHandlerContext 定义了一个上下文，找到实现的一个接口 ChannelHandlerContext io.netty.channel.ChannelHandlerContext 文档：https://netty.io/5.0/api/io/netty/channel/ChannelHandlerContext.html 接下来我分析一下 ChannelHandlerContext ，PipeLine，Handler 这三者的关系。 加油！！！","link":"/2019/01/15/Netty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"Redis","text":"什么是 Redis ？Redis，全称 Remote Dictionary Server，是一个基于内存的高性能 Key-Value 数据库。 另外，Redis 已经成为互联网公司在缓存组件选择的唯一，更多的关注点是，如何使用好 Redis 。 Redis 有什么优点？1、速度快 因为数据存在内存中，类似于 HashMap ，HashMap 的优势就是查找和操作的时间复杂度都是O (1) 。 Redis 本质上是一个 Key-Value 类型的内存数据库，很像Memcached ，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据 flush 到硬盘上进行保存。 因为是纯内存操作，Redis 的性能非常出色，每秒可以处理超过 10 万次读写操作，是已知性能最快的 Key-Value 数据库。 如果我们查看在阿里云销售的 Redis 规格，最低的也是 8W QPS 。 2、支持丰富数据类型 支持 String ，List，Set，Sorted Set，Hash 。 Redis 的出色之处不仅仅是性能，Redis 最大的魅力是支持保存多种数据结构，此外单个 Value 的最大限制是1GB，不像 Memcached只能保存1MB的数据，因此Redis可以用来实现很多有用的功能。比方说： 用他的 List 来做 FIFO 双向链表，实现一个轻量级的高性能消息队列服务。 用他的 Set 可以做高性能的 tag 系统等等。 3、丰富的特性 订阅发布 Pub / Sub 功能 Key 过期策略 事务 支持多个 DB 计数 … 并且在 Redis 5.0 增加了 Stream 功能，一个新的强大的支持多播的可持久化的消息队列，提供类似 Kafka 的功能。 4、持久化存储 Redis 提供 RDB 和 AOF 两种数据的持久化存储方案，解决内存数据库最担心的万一 Redis 挂掉，数据会消失掉。 Redis 有什么缺点？ 由于 Redis 是内存数据库，所以，单台机器，存储的数据量，跟机器本身的内存大小。虽然 Redis 本身有 Key 过期策略，但是还是需要提前预估和节约内存。如果内存增长过快，需要定期删除数据。 另外，可使用 Redis Cluster、Codis 等方案，对 Redis 进行分区，从单机 Redis 变成集群 Redis 。 如果进行完整重同步，由于需要生成 RDB 文件，并进行传输，会占用主机的 CPU ，并会消耗现网的带宽。不过 Redis2.8 版本，已经有部分重同步的功能，但是还是有可能有完整重同步的。比如，新上线的备机。 修改配置文件，进行重启，将硬盘中的数据加载进内存，时间比较久。在这个过程中，Redis 不能提供服务。 Redis 和 Memcached 的区别有哪些？1、Redis 支持复杂的数据结构 Memcached 仅提供简单的字符串。 Redis 提供复杂的数据结构，丰富的数据操作。 也因为 Redis 支持复杂的数据结构，Redis 即使往于 Memcached 推出，却获得更多开发者的青睐。 Redis 相比 Memcached 来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作，Redis 会是不错的选择。 2、Redis 原生支持集群模式 在 Redis3.x 版本中，官方便能支持 Cluster 模式。 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。 3、性能对比 Redis 只使用单核，而 Memcached 可以使用多核，所以平均每一个核上 Redis在存储小数据时比 Memcached 性能更高。 在 100k 以上的数据中，Memcached 性能要高于 Redis 。虽然 Redis 最近也在存储大数据的性能上进行优化，但是比起 Memcached，还是稍有逊色。 更多关于性能的对比，可以看看 《Memcached 与 Redis 的关键性能指标比较》 。 4、内存使用效率对比 简单的 Key-Value 存储的话，Memcached 的内存利用率更高，可以使用类似内存池。 如果 Redis 采用 hash 结构来做 key-value 存储，由于其组合式的压缩， 其内存利用率会高于 Memcached 。 Redis 和 Memcached 的内存管理方法不同，Redis 采用的是包装的 malloc/free ， 相较于 Memcached 的内存管理方法 tcmalloc / jmalloc 来说，要简单很多 。 5、网络 IO 模型 Memcached 是多线程，非阻塞 IO 复用的网络模型，原型上接近 Nignx 。 Redis 使用单线程的 IO 复用模型，自己封装了一个简单的 AeEvent 事件处理框架，主要实现了 epoll, kqueue 和 select ，更接近 Apache 早期的模式。 TODO 有点看不懂，找亚普表弟确认中。 6、持久化存储 Memcached 不支持持久化存储，重启时，数据被清空。 Redis 支持持久化存储，重启时，可以恢复已持久化的数据。 也推荐阅读下 《脚踏两只船的困惑 - Memcached 与 Redis》 。 请说说 Redis 的线程模型？ 艿艿：这个是我从网络上找的资料，讲的灰常不错。 redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，根据 socket 上的事件来选择对应的事件处理器进行处理。 文件事件处理器的结构包含 4 个部分： 多个 socket IO 多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。 来看客户端与 redis 的一次通信过程： 客户端 socket01 向 redis 的 server socket 请求建立连接，此时 server socket 会产生一个 AE_READABLE 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该事件压入队列中。文件事件分派器从队列中获取该事件，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 AE_READABLE 事件与命令请求处理器关联。 假设此时客户端发送了一个 set key value 请求，此时 redis 中的 socket01 会产生 AE_READABLE 事件，IO 多路复用程序将事件压入队列，此时事件分派器从队列中获取到该事件，由于前面 socket01 的 AE_READABLE 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 key value 并在自己内存中完成 key value 的设置。操作完成后，它会将 socket01 的 AE_WRITABLE 事件与令回复处理器关联。 如果此时客户端准备好接收返回结果了，那么 redis 中的 socket01 会产生一个 AE_WRITABLE 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 ok，之后解除 socket01 的 AE_WRITABLE 事件与命令回复处理器的关联。 这样便完成了一次通信。😈 耐心理解一下，灰常重要。如果还是不能理解，可以在网络上搜一些资料，在理解理解。 为什么 Redis 单线程模型也能效率这么高？ 1、纯内存操作。 Redis 为了达到最快的读写速度，将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以 Redis 具有快速和数据持久化的特征。 如果不将数据放在内存中，磁盘 I/O 速度为严重影响 Redis 的性能。 2、核心是基于非阻塞的 IO 多路复用机制。 3、单线程反而避免了多线程的频繁上下文切换问题。 Redis 利用队列技术，将并发访问变为串行访问，消除了传统数据库串行控制的开销 4、Redis 全程使用 hash 结构，读取速度快，还有一些特殊的数据结构，对数据存储进行了优化，如压缩表，对短数据进行压缩存储，再如，跳表，使用有序的数据结构加快读取的速度。 Redis 有几种持久化方式？持久化方式Redis 提供了两种方式，实现数据的持久化到硬盘。 【全量】RDB 持久化，是指在指定的时间间隔内将内存中的数据集快照写入磁盘。实际操作过程是，fork 一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。 【增量】AOF持久化，以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。 二者的区别RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。 AOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。 二者优缺点RDB存在哪些优势呢？ 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。 性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。 RDB又存在哪些劣势呢？ .如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。 AOF的优势有哪些呢？ 该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。 AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。 AOF的劣势有哪些呢？ 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。 二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent 的意思了。 常用配置RDB持久化配置 Redis会将数据集的快照dump到dump.rdb文件中。此外，我们也可以通过配置文件来修改Redis服务器dump快照的频率，在打开6379.conf文件之后，我们搜索save，可以看到下面的配置信息： save 900 1 # 在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。save 300 10 # 在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。save 60 10000 # 在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。 AOF持久化配置 在Redis的配置文件中存在三种同步方式，它们分别是： appendfsync always # 每次有数据修改发生时都会写入AOF文件。appendfsync everysec # 每秒钟同步一次，该策略为AOF的缺省策略。appendfsync no # 从不同步。高效但是数据不会被持久化。 如何选择 不要仅仅使用 RDB，因为那样会导致你丢失很多数据 也不要仅仅使用 AOF，因为那样有两个问题，第一，你通过 AOF 做冷备，没有 RDB 做冷备，来的恢复速度更快; 第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug 。 Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。 如果同时使用 RDB 和 AOF 两种持久化机制，那么在 Redis 重启的时候，会使用 AOF 来重新构建数据，因为 AOF 中的数据更加完整。 一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用 RDB 持久化。 有很多用户都只使用 AOF 持久化，但并不推荐这种方式：因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用 RDB 还可以避免之前提到的 AOF 程序的 bug。 在 Redis4.0 版本开始，允许你使用 RDB-AOF 混合持久化方式，详细可见 《Redis4.0 之 RDB-AOF 混合持久化》 。也因此，RDB 和 AOF 同时使用，是希望达到安全的持久化的推荐方式。 自动化触发 RDB 持久化的方式 根据 redis.conf 配置中 SAVE m n 定时触发（使用的BGSAVE） 主从复制时，主节点自动触发 执行 Debug Reload 执行 Shutdown 且没有开启 AOF 持久化 BGSAVE 原理： 重要知识： bgsave 做镜像全量持久化，AOF 做增量持久化。因为 bgsave 会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要 AOF 来配合使用。在 Redis 实例重启时，会使用 bgsave 持久化文件重新构建内存，再使用 AOF 重放近期的操作指令来实现完整恢复重启之前的状态。 对方追问那如果突然机器掉电会怎样？取决于 AOF 日志 sync 属性的配置，如果不要求性能，在每条写指令时都 sync 一下磁盘，就不会丢失数据。但是在高性能的要求下每次都 sync 是不现实的，一般都使用定时 sync ，比如 1 秒 1 次，这个时候最多就会丢失 1 秒的数据。 对方追问 bgsave 的原理是什么？你给出两个词汇就可以了，fork 和 cow 。fork 是指 Redis 通过创建子进程来进行 bgsave 操作。cow 指的是 copy on write ，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。 Redis 有几种数据“过期”策略？Redis 的过期策略，就是指当 Redis 中缓存的 key 过期了，Redis 如何处理。 Redis 提供了 3 种数据过期策略： 被动删除：当读/写一个已经过期的 key 时，会触发惰性删除策略，直接删除掉这个过期 key 。 主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以 Redis 会定期主动淘汰一批已过期的 key 。 主动删除：当前已用内存超过 maxmemory 限定时，触发主动清理策略，即 「数据“淘汰”策略」 。 在 Redis 中，同时使用了上述 3 种策略，即它们非互斥的。 想要进一步了解，可以看看 《关于 Redis 数据过期策略》 文章。 Redis 有哪几种数据“淘汰”策略？Redis 内存数据集大小上升到一定大小的时候，就会进行数据淘汰策略。 Redis 提供了 6 种数据淘汰策略： volatile-lru volatile-ttl volatile-random allkeys-lru allkeys-random no-enviction 具体的 每种数据淘汰策略的定义，和 如何选择讨论策略，可见 《Redis实战（二） 内存淘汰机制》 。 Redis LRU 算法 另外，Redis 的 LRU 算法，并不是一个严格的 LRU 实现。这意味着 Redis 不能选择最佳候选键来回收，也就是最久未被访问的那些键。相反，Redis 会尝试执行一个近似的 LRU 算法，通过采样一小部分键，然后在采样键中回收最适合(拥有最久未被访问时间)的那个。 具体的可以看看 《使用 Redis 作为一个 LRU 缓存》 文章。 MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据？ 艿艿：这个是从网络上找到的一个神奇的问题，并且看了答案之后，觉得有点莫名的对不上。 所以，感觉这个问题的目的是，如何保证热点数据不要被淘汰。 在 「Redis 有哪几种数据“淘汰”策略？」 问题中，我们已经看到，“Redis 内存数据集大小上升到一定大小的时候，就会进行数据淘汰策略。” 。 那么，如果我们此时要保证热点数据不被淘汰，那么需要选择 volatile-lru 或 allkeys-lru 这两个基于 LRU 算法的淘汰策略。 相比较来说，最终会选择 allkeys-lru 淘汰策略。原因是，如果我们的应用对缓存的访问符合幂律分布，也就是存在相对热点数据，或者我们不太清楚我们应用的缓存访问分布状况，我们可以选择 allkeys-lru 策略。 Redis 回收进程如何工作的？ 理解回收进程如何工作是非常重要的： 一个客户端运行了新的命令，添加了新的数据 Redis 检查内存使用情况，如果大于 maxmemory 的限制, 则根据设定好的策略进行回收。 Redis 执行新命令…… 所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下（跌宕起伏）。 如果有大量的 key 需要设置同一时间过期，一般需要注意什么？如果大量的 key 过期时间设置的过于集中，到过期的那个时间点，Redis可能会出现短暂的卡顿现象。 一般需要在时间上加一个随机值，使得过期时间分散一些。 Redis 有哪些数据结构？如果你是 Redis 普通玩家，可能你的回答是如下五种数据结构： 字符串 String 字典Hash 列表List 集合Set 有序集合 SortedSet 如果你是 Redis 中级玩家，还需要加上下面几种数据结构： HyperLogLog Geo Pub / Sub 如果你是 Redis 高端玩家，你可能玩过 Redis Module ，可以再加上下面几种数据结构： BloomFilter RedisSearch Redis-ML JSON 另外，在 Redis 5.0 增加了 Stream 功能，一个新的强大的支持多播的可持久化的消息队列，提供类似 Kafka 的功能。😈 默默跟面试官在装一波。 聊聊 Redis 使用场景Redis 可用的场景非常之多： 数据缓存 会话缓存 时效性数据 访问频率 计数器 社交列表 记录用户判定信息 交集、并集和差集 热门列表与排行榜 最新动态 消息队列 分布式锁 详细的介绍，可以看看如下文章： 《聊聊 Redis 使用场景》 《Redis 应用场景及实例》 《Redis 常见的应用场景解析》 《Redis 和 Memcached 各有什么优缺点，主要的应用场景是什么样的？》 请用 Redis 和任意语言实现一段恶意登录保护的代码，限制 1 小时内每用户 Id 最多只能登录 5 次。 用列表实现，列表中每个元素代表登陆时间，只要最后的第 5 次登陆时间和现在时间差不超过 1 小时就禁止登陆。 具体的代码实现，可以看看 《一道 Redis 面试题》 。 Redis 支持的 Java 客户端都有哪些？使用比较广泛的有三个 Java 客户端： Redisson Redisson ，是一个高级的分布式协调 Redis 客服端，能帮助用户在分布式环境中轻松实现一些 Java 的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。 Jedis Jedis 是 Redis 的 Java 实现的客户端，其 API 提供了比较全面的 Redis 命令的支持。 Redisson 实现了分布式和可扩展的 Java 数据结构，和 Jedis 相比，Jedis 功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等 Redis 特性。 Redisson 的宗旨是促进使用者对 Redis 的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。 Lettuce Lettuce 是一个可伸缩线程安全的 Redis 客户端。多个线程可以共享同一个 RedisConnection 。它利用优秀 Netty NIO 框架来高效地管理多个连接。 Redis 官方推荐使用 Redisson 或 Jedis 。 Spring Boot 2.x 内置使用 Lettuce 。 如何使用 Redis 实现分布式锁？ 方案一：set 指令 先拿 setnx 来争抢锁，抢到之后，再用 expire 给锁加一个过期时间防止锁忘记了释放。 这时候对方会告诉你说你回答得不错，然后接着问如果在 setnx 之后执行 expire 之前进程意外 crash 或者要重启维护了，那会怎么样？ 这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。紧接着你需要抓一抓自己得脑袋，故作思考片刻，好像接下来的结果是你主动思考出来的，然后回答：我记得 set 指令有非常复杂的参数，这个应该是可以同时把 setnx 和 expire 合成一条指令来用的！对方这时会显露笑容，心里开始默念：摁，这小子还不错。 所以，我们可以使用 set 指令，实现分布式锁。指令如下： SET key value [EX seconds] [PX milliseconds] [NX|XX] 可以使用 SET key value EX seconds NX 命令，尝试获得锁。 具体的实现，可以参考 《Redis 分布式锁的正确实现方式（Java版）》 文章。 方案二：redlock set 指令的方案，适合用于在单机 Redis 节点的场景下，在多 Redis 节点的场景下，会存在分布式锁丢失的问题。所以，Redis 作者 Antirez 基于分布式环境下提出了一种更高级的分布式锁的实现方式：Redlock 。 具体的方案，胖友可以看看老友飞哥的两篇博客： 《Redlock：Redis分布式锁最牛逼的实现》 《Redisson 实现 Redis 分布式锁的 N 种姿势》 对比 Zookeeper 分布式锁 从可靠性上来说，Zookeeper 分布式锁好于 Redis 分布式锁。 从性能上来说，Redis 分布式锁好于 Zookeeper 分布式锁。 所以，没有绝对的好坏，可以根据自己的业务来具体选择。 如何使用 Redis 实现消息队列？一般使用 list 结构作为队列，rpush 生产消息，lpop 消费消息。当 lpop 没有消息的时候，要适当 sleep 一会再重试。 如果对方追问可不可以不用 sleep 呢？list 还有个指令叫 blpop ，在没有消息的时候，它会阻塞住直到消息到来。 如果对方追问能不能生产一次消费多次呢？使用 pub / sub 主题订阅者模式，可以实现 1:N 的消息队列。 如果对方追问 pub / sub 有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如 rabbitmq 等。 如果对方追问 redis 如何实现延时队列？我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的这么详细。但是你很克制，然后神态自若的回答道：使用 sortedset ，拿时间戳作为 score ，消息内容作为 key 调用 zadd 来生产消息，消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理。 到这里，面试官暗地里已经对你竖起了大拇指。但是他不知道的是此刻你却竖起了中指，在椅子背后。 当然，实际上 Redis 真的真的真的不推荐作为消息队列使用，它最多只是消息队列的存储层，上层的逻辑，还需要做大量的封装和支持。 另外，在 Redis 5.0 增加了 Stream 功能，一个新的强大的支持多播的可持久化的消息队列，提供类似 Kafka 的功能。 什么是 Redis Pipelining ？一次请求/响应服务器能实现处理新的请求即使旧的请求还未被响应。这样就可以将多个命令发送到服务器，而不用等待回复，最后在一个步骤中读取该答复。 这就是管道（pipelining），是一种几十年来广泛使用的技术。例如许多 POP3 协议已经实现支持这个功能，大大加快了从服务器下载新邮件的过程。 Redis 很早就支持管道（pipelining）技术，因此无论你运行的是什么版本，你都可以使用管道（pipelining）操作 Redis。 Redis 如何做大量数据插入？ Redis2.6 开始，Redis-cli 支持一种新的被称之为 pipe mode 的新模式用于执行大量数据插入工作。 具体可见 《Redis 大量数据插入》 文章。 什么是 Redis 事务？和众多其它数据库一样，Redis 作为 NoSQL 数据库也同样提供了事务机制。在Redis中，MULTI / EXEC / DISCARD / WATCH 这四个命令是我们实现事务的基石。相信对有关系型数据库开发经验的开发者而言这一概念并不陌生，即便如此，我们还是会简要的列出 Redis 中事务的实现特征： 1、在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis 不会再为其它客户端的请求提供任何服务，从而保证了事物中的所有命令被原子的执行。 2、和关系型数据库中的事务相比，在 Redis 事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行。 3、我们可以通过 MULTI 命令开启一个事务，有关系型数据库开发经验的人可以将其理解为 &quot;BEGIN TRANSACTION&quot; 语句。在该语句之后执行的命令都，将被视为事务之内的操作，最后我们可以通过执行 EXEC / DISCARD 命令来提交 / 回滚该事务内的所有操作。这两个 Redis 命令，可被视为等同于关系型数据库中的 COMMIT / ROLLBACK 语句。 4、在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在客户端执行 EXEC 命令之后，那么该事务中的所有命令都会被服务器执行。 5、当使用 Append-Only 模式时，Redis 会通过调用系统函数 write 将该事务内的所有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃，如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。 Redis 服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。此时，我们就要充分利用 Redis 工具包中提供的 redis-check-aof 工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。修复之后我们就可以再次重新启动Redis服务器了。 如何实现 Redis CAS 操作？ 在 Redis 的事务中，WATCH 命令可用于提供CAS(check-and-set)功能。 假设我们通过 WATCH 命令在事务执行之前监控了多个 keys ，倘若在 WATCH 之后有任何 Key 的值发生了变化，EXEC 命令执行的事务都将被放弃，同时返回 nil 应答以通知调用者事务执行失败。 具体的示例，可以看看 《Redis 事务锁 CAS 实现以及深入误区》 。 Redis 集群都有哪些方案？Redis 集群方案如下： 1、Redis Sentinel 2、Redis Cluster 3、Twemproxy 4、Codis 5、客户端分片 关于前四种，可以看看 《Redis 实战（四）集群机制》 这篇文章。 关于最后一种，客户端分片，在 Redis Cluster 出现之前使用较多，目前已经使用比较少了。实现方式如下： 在业务代码层实现，起几个毫无关联的 Redis 实例，在代码层，对 Key 进行 hash 计算，然后去对应的 Redis 实例操作数据。 这种方式对 hash 层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。 选择 目前一般在选型上来说： 体量较小时，选择 Redis Sentinel ，单主 Redis 足以支撑业务。 体量较大时，选择 Redis Cluster ，通过分片，使用更多内存。 Redis 集群如何扩容？ 这个问题，艿艿了解的也不是很多，建议在搜索有什么方案。 如果 Redis 被当做缓存使用，使用一致性哈希实现动态扩容缩容。 如果 Redis 被当做一个持久化存储使用，必须使用固定的 keys-to-nodes 映射关系，节点的数量一旦确定不能变化。否则的话(即Redis 节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有 Redis Cluster、Codis 可以做到这样。 什么是 Redis 主从同步？Redis 主从同步 Redis 的主从同步(replication)机制，允许 Slave 从 Master 那里，通过网络传输拷贝到完整的数据备份，从而达到主从机制。 主数据库可以进行读写操作，当发生写操作的时候自动将数据同步到从数据库，而从数据库一般是只读的，并接收主数据库同步过来的数据。 一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库。 第一次同步时，主节点做一次 bgsave 操作，并同时将后续修改操作记录到内存 buffer ，待完成后将 RDB 文件全量同步到复制节点，复制节点接受完成后将 RDB 镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。 好处 通过 Redis 的复制功，能可以很好的实现数据库的读写分离，提高服务器的负载能力。主数据库主要进行写操作，而从数据库负责读操作。 Redis 主从同步，是很多 Redis 集群方案的基础，例如 Redis Sentinel、Redis Cluster 等等。 更多详细，可以看看 《Redis 主从架构》 。 如何使用 Redis Sentinel 实现高可用？可以看看 《Redis 哨兵集群实现高可用》 。 如果使用 Redis Cluster 实现高可用？可以看看 《Redis 集群教程》 完整版 《Redis 集群模式的工作原理能说一下么？》 精简版 说说 Redis 哈希槽的概念？ Redis Cluster 没有使用一致性 hash ，而是引入了哈希槽的概念。 Redis 集群有 16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽，集群的每个节点负责一部分 hash 槽。 因为最大是 16384 个哈希槽，所以考虑 Redis 集群中的每个节点都能分配到一个哈希槽，所以最多支持 16384 个 Redis 节点。 Redis Cluster 的主从复制模型是怎样的？ 为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型，每个节点都会有 N-1 个复制节点。 所以，Redis Cluster 可以说是 Redis Sentinel 带分片的加强版。也可以说： Redis Sentinel 着眼于高可用，在 master 宕机时会自动将 slave 提升为 master ，继续提供服务。 Redis Cluster 着眼于扩展性，在单个 Redis 内存不足时，使用Cluster 进行分片存储。 Redis Cluster 方案什么情况下会导致整个集群不可用？ 有 A，B，C 三个节点的集群，在没有复制模型的情况下，如果节点 B 宕机了，那么整个集群就会以为缺少 5501-11000 这个范围的槽而不可用。 Redis Cluster 会有写操作丢失吗？为什么？ Redis 并不能保证数据的强一致性，而是【异步复制】，这意味这在实际中集群在特定的条件下可能会丢失写操作。 Redis 集群如何选择数据库？ Redis 集群目前无法做数据库选择，默认在 0 数据库。 请说说生产环境中的 Redis 是怎么部署的？ 重点问题，仔细理解。 Redis Cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰 qps 可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求每秒。 机器是什么配置？32G 内存 + 8 核 CPU + 1T 磁盘，但是分配给 Redis 进程的是 10g 内存，一般线上生产环境，Redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。那么，5 台机器对外提供读写，一共有 50g 内存。 因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，Redis 从实例会自动变成主实例继续提供读写服务。 你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb 。100 条数据是 1mb ，10 万条数据是 1g 。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。 其实大型的公司，会有基础架构的 team 负责缓存集群的运维。 什么是 Redis 分区？ 这个问题，和 「Redis 集群都有哪些方案？」 是同类问题。 关于如下四个问题，直接看 《Redis 分区》 文章。 Redis 分区是什么？ 分区的优势？ 分区的不足？ 分区类型？ 可能有胖友会懵逼，又是 Redis 主从复制，又是 Redis 分区，又是 Redis 集群。傻傻分不清啊！ Redis 分区是一种模式，将数据分区到不同的 Redis 节点上，而 Redis 集群的 Redis Cluster、Twemproxy、Codis、客户端分片( 不包括 Redis Sentinel ) 这四种方案，是 Redis 分区的具体实现。 Redis 每个分区，如果想要实现高可用，需要使用到 Redis 主从复制。 你知道有哪些 Redis 分区实现方案？ Redis 分区方案，主要分成两种类型： 客户端分区，就是在客户端就已经决定数据会被存储到哪个 Redis 节点或者从哪个 Redis 节点读取。大多数客户端已经实现了客户端分区。 案例：Redis Cluster 和客户端分区。 代理分区，意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些 Redis 实例，然后根据 Redis 的响应结果返回给客户端。 案例：Twemproxy 和 Codis 。 查询路由(Query routing)的意思，是客户端随机地请求任意一个 Redis 实例，然后由 Redis 将请求转发给正确的 Redis 节点。Redis Cluster 实现了一种混合形式的查询路由，但并不是直接将请求从一个Redis 节点转发到另一个 Redis 节点，而是在客户端的帮助下直接 redirect 到正确的 Redis 节点。 分布式 Redis 是前期做还是后期规模上来了再做好？为什么？？ 如下是网络上的一个大答案： 既然 Redis 是如此的轻量（单实例只使用1M内存），为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让 Redis 以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。 一开始就多设置几个 Redis 实例，例如 32 或者 64 个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。 这样的话，当你的数据不断增长，需要更多的 Redis 服务器时，你需要做的就是仅仅将 Redis 实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的 Redis 实例从第一台机器迁移到第二台机器。 和飞哥沟通了下，这个操作不是很合理。 无论怎么说，建议，需要搭建下 Redis Sentinel 高可用，至于拓展性，根据自己的情况，是否使用 Redis Cluster 集群 Redis 有哪些重要的健康指标？推荐阅读 《Redis 几个重要的健康指标》 存活情况 连接数 阻塞客户端数量 使用内存峰值 内存碎片率 缓存命中率 OPS 持久化 失效KEY 慢日志 如何提高 Redis 命中率？ 推荐阅读 《如何提高缓存命中率（Redis）》 。 怎么优化 Redis 的内存占用推荐阅读 《Redis 的内存优化》 redisObject 对象 缩减键值对象 共享对象池 字符串优化 编码优化 控制 key 的数量 一个 Redis 实例最多能存放多少的 keys？List、Set、Sorted Set 他们最多能存放多少元素？ 一个 Redis 实例，最多能存放多少的 keys ，List、Set、Sorted Set 他们最多能存放多少元素。 理论上，Redis 可以处理多达 2^32 的 keys ，并且在实际中进行了测试，每个实例至少存放了 2 亿 5 千万的 keys。 任何 list、set、和 sorted set 都可以放 2^32 个元素。 假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？ 使用 keys 指令可以扫出指定模式的 key 列表。 对方接着追问：如果这个 Redis 正在给线上的业务提供服务，那使用keys指令会有什么问题？ 这个时候你要回答 Redis 关键的一个特性：Redis 的单线程的。keys 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 scan 指令，scan 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys 指令长。 Redis 常见的性能问题都有哪些？如何解决？1、Master 最好不要做任何持久化工作，如 RDB 内存快照和 AOF 日志文件。 Master 写内存快照，save 命令调度 rdbSave 函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以 Master 最好不要写内存快照。 Master AOF 持久化，如果不重写 AOF 文件，这个持久化方式对性能的影响是最小的，但是 AOF 文件会不断增大，AOF 文件过大会影响 Master 重启的恢复速度。 所以，Master 最好不要做任何持久化工作，包括内存快照和 AOF 日志文件，特别是不要启用内存快照做持久化。如果数据比较关键，某个 Slave 开启AOF备份数据，策略为每秒同步一次 2、Master 调用 BGREWRITEAOF 重写 AOF 文件，AOF 在重写的时候会占大量的 CPU 和内存资源，导致服务 load 过高，出现短暂服务暂停现象。 3、尽量避免在压力很大的主库上增加从库。 4、主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3... 。 这样的结构，也方便解决单点故障问题，实现 Slave 对 Master 的替换。如果 Master挂了，可以立刻启用 Slave1 做 Master ，其他不变。 5、Redis 主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave 和 Master 最好在同一个局域网内。 和飞哥沟通过后，他们主节点开启 AOF ，从节点开启 AOF + RDB 。 和晓峰沟通后，他们主节点开启 AOF ，从节点开启 RDB 居多，也有开启 AOF + RDB 的。 修改配置不重启 Redis 会实时生效吗？针对运行实例，有许多配置选项可以通过 CONFIG SET 命令进行修改，而无需执行任何形式的重启。 从 Redis 2.2 开始，可以从 AOF 切换到 RDB 的快照持久性或其他方式而不需要重启 Redis。检索 CONFIG GET * 命令获取更多信息。 但偶尔重新启动是必须的，如为升级 Redis 程序到新的版本，或者当你需要修改某些目前 CONFIG 命令还不支持的配置参数的时候。 其他问题有些比较凶残的面试官，可能会问我们一些 Redis 数据结构的问题，例如： Skiplist 插入和查询原理？ 压缩列表的原理？ Redis 底层为什么使用跳跃表而不是红黑树？ 跳跃表在范围查找的时候性能比较高。 参考链接 精尽 Redis 面试题","link":"/2019/02/23/Redis/"},{"title":"Java 并发编程","text":"请谈谈你对 volatile 的理解volatile 是 Java 虚拟机提供的轻量级的同步机制 保证可见性 禁止指令排序 不保证原子性 JMM（Java 内存模型） 你谈谈基本概念 JMM 本身是一种抽象的概念并不是真实存在，它描述的是一组规定或则规范，通过这组规范定义了程序中的访问方式。 JMM 同步规定 线程解锁前，必须把共享变量的值刷新回主内存 线程加锁前，必须读取主内存的最新值到自己的工作内存 加锁解锁是同一把锁 由于 JVM 运行程序的实体是线程，而每个线程创建时 JVM 都会为其创建一个工作内存，工作内存是每个线程的私有数据区域，而 Java 内存模型中规定所有变量的储存在主内存，主内存是共享内存区域，所有的线程都可以访问，但线程对变量的操作（读取赋值等）必须都工作内存进行看。 首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，工作内存中存储着主内存中的变量副本拷贝，前面说过，工作内存是每个线程的私有数据区域，因此不同的线程间无法访问对方的工作内存，线程间的通信(传值)必须通过主内存来完成。 内存模型图 三大特性 可见性 /** * @Author: cuzz * @Date: 2019/4/16 21:29 * @Description: 可见性代码实例 */public class VolatileDemo { public static void main(String[] args) { Data data = new Data(); new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; coming...&quot;); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } data.addOne(); System.out.println(Thread.currentThread().getName() + &quot; updated...&quot;); }).start(); while (data.a == 0) { // looping } System.out.println(Thread.currentThread().getName() + &quot; job is done...&quot;); }}class Data { // int a = 0; volatile int a = 0; void addOne() { this.a += 1; }} 如果不加 volatile 关键字，则主线程会进入死循环，加 volatile 则主线程能够退出，说明加了 volatile 关键字变量，当有一个线程修改了值，会马上被另一个线程感知到，当前值作废，从新从主内存中获取值。对其他线程可见，这就叫可见性。 原子性 public class VolatileDemo { public static void main(String[] args) { // test01(); test02(); } // 测试原子性 private static void test02() { Data data = new Data(); for (int i = 0; i &lt; 20; i++) { new Thread(() -&gt; { for (int j = 0; j &lt; 1000; j++) { data.addOne(); } }).start(); } // 默认有 main 线程和 gc 线程 while (Thread.activeCount() &gt; 2) { Thread.yield(); } System.out.println(data.a); }}class Data { volatile int a = 0; void addOne() { this.a += 1; }} 发现并不能输入 20000 有序性 计算机在执行程序时，为了提高性能，编译器个处理器常常会对指令做重排，一般分为以下 3 种 编译器优化的重排 指令并行的重排 内存系统的重排 单线程环境里面确保程序最终执行的结果和代码执行的结果一致 处理器在进行重排序时必须考虑指令之间的数据依赖性 多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证用的变量能否一致性是无法确定的，结果无法预测 代码示例 public class ReSortSeqDemo { int a = 0; boolean flag = false; public void method01() { a = 1; // flag = true; // ----线程切换---- flag = true; // a = 1; } public void method02() { if (flag) { a = a + 3; System.out.println(&quot;a = &quot; + a); } }} 如果两个线程同时执行，method01 和 method02 如果线程 1 执行 method01 重排序了，然后切换的线程 2 执行 method02 就会出现不一样的结果。 禁止指令排序volatile 实现禁止指令重排序的优化，从而避免了多线程环境下程序出现乱序的现象 先了解一个概念，内存屏障（Memory Barrier）又称内存栅栏，是一个 CPU 指令，他的作用有两个： 保证特定操作的执行顺序 保证某些变量的内存可见性（利用该特性实现 volatile 的内存可见性） 由于编译器个处理器都能执行指令重排序优化，如果在指令间插入一条 Memory Barrier 则会告诉编译器和 CPU，不管什么指令都不能个这条 Memory Barrier 指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后执行重排序优化。内存屏障另一个作用是强制刷出各种 CPU 缓存数据，因此任何 CPU 上的线程都能读取到这些数据的最新版本。 下面是保守策略下，volatile写插入内存屏障后生成的指令序列示意图： 下面是在保守策略下，volatile读插入内存屏障后生成的指令序列示意图： 线程安全性保证 工作内存与主内存同步延迟现象导致可见性问题 可以使用 synchronzied 或 volatile 关键字解决，它们可以使用一个线程修改后的变量立即对其他线程可见 对于指令重排导致可见性问题和有序性问题 可以利用 volatile 关键字解决，因为 volatile 的另一个作用就是禁止指令重排序优化 你在哪些地方用到过 volatile单例 多线程环境下可能存在的安全问题 @NotThreadSafepublic class Singleton01 { private static Singleton01 instance = null; private Singleton01() { System.out.println(Thread.currentThread().getName() + &quot; construction...&quot;); } public static Singleton01 getInstance() { if (instance == null) { instance = new Singleton01(); } return instance; } public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { executorService.execute(()-&gt; Singleton01.getInstance()); } executorService.shutdown(); }} 发现构造器里的内容会多次输出 双重锁单例 代码 public class Singleton02 { private static volatile Singleton02 instance = null; private Singleton02() { System.out.println(Thread.currentThread().getName() + &quot; construction...&quot;); } public static Singleton02 getInstance() { if (instance == null) { synchronized (Singleton01.class) { if (instance == null) { instance = new Singleton02(); } } } return instance; } public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { executorService.execute(()-&gt; Singleton02.getInstance()); } executorService.shutdown(); }} 如果没有加 volatile 就不一定是线程安全的，原因是指令重排序的存在，加入 volatile 可以禁止指令重排。 原因是在于某一个线程执行到第一次检测，读取到的 instance 不为 null 时，instance 的引用对象可能还没有完成初始化。 instance = new Singleton() 可以分为以下三步完成 memory = allocate(); // 1.分配对象空间instance(memory); // 2.初始化对象instance = memory; // 3.设置instance指向刚分配的内存地址，此时instance != null 步骤 2 和步骤 3 不存在依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种优化是允许的。 发生重排 memory = allocate(); // 1.分配对象空间instance = memory; // 3.设置instance指向刚分配的内存地址，此时instance != null，但对象还没有初始化完成instance(memory); // 2.初始化对象 所以不加 volatile 返回的实例不为空，但可能是未初始化的实例 CAS 你知道吗？public class CASDemo { public static void main(String[] args) { AtomicInteger atomicInteger = new AtomicInteger(666); // 获取真实值，并替换为相应的值 boolean b = atomicInteger.compareAndSet(666, 2019); System.out.println(b); // true boolean b1 = atomicInteger.compareAndSet(666, 2020); System.out.println(b1); // false atomicInteger.getAndIncrement(); }} CAS 底层原理？谈谈对 UnSafe 的理解？getAndIncrement();/** * Atomically increments by one the current value. * * @return the previous value */public final int getAndIncrement() { return unsafe.getAndAddInt(this, valueOffset, 1);} 引出一个问题：UnSafe 类是什么？ UnSafe 类public class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try { // 获取下面 value 的地址偏移量 valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); } } private volatile int value; // ...} Unsafe 是 CAS 的核心类，由于 Java 方法无法直接访问底层系统，而需要通过本地（native）方法来访问， Unsafe 类相当一个后门，基于该类可以直接操作特定内存的数据。Unsafe 类存在于 sun.misc 包中，其内部方法操作可以像 C 指针一样直接操作内存，因为 Java 中 CAS 操作执行依赖于 Unsafe 类。 变量 vauleOffset，表示该变量值在内存中的偏移量，因为 Unsafe 就是根据内存偏移量来获取数据的。 变量 value 用 volatile 修饰，保证了多线程之间的内存可见性。 CAS 是什么 CAS 的全称 Compare-And-Swap，它是一条 CPU 并发。 它的功能是判断内存某一个位置的值是否为预期，如果是则更改这个值，这个过程就是原子的。 CAS 并发原体现在 JAVA 语言中就是 sun.misc.Unsafe 类中的各个方法。调用 UnSafe 类中的 CAS 方法，JVM 会帮我们实现出 CAS 汇编指令。这是一种完全依赖硬件的功能，通过它实现了原子操作。由于 CAS 是一种系统源语，源语属于操作系统用语范畴，是由若干条指令组成，用于完成某一个功能的过程，并且原语的执行必须是连续的，在执行的过程中不允许被中断，也就是说 CAS 是一条原子指令，不会造成所谓的数据不一致的问题。 分析一下 getAndAddInt 这个方法 // unsafe.getAndAddIntpublic final int getAndAddInt(Object obj, long valueOffset, long expected, int val) { int temp; do { temp = this.getIntVolatile(obj, valueOffset); // 获取快照值 } while (!this.compareAndSwap(obj, valueOffset, temp, temp + val)); // 如果此时 temp 没有被修改，就能退出循环，否则重新获取 return temp;} CAS 的缺点？ 循环时间长开销很大 如果 CAS 失败，会一直尝试，如果 CAS 长时间一直不成功，可能会给 CPU 带来很大的开销（比如线程数很多，每次比较都是失败，就会一直循环），所以希望是线程数比较小的场景。 只能保证一个共享变量的原子操作 对于多个共享变量操作时，循环 CAS 就无法保证操作的原子性。 引出 ABA 问题 原子类 AtomicInteger 的 ABA 问题谈一谈？原子更新引用知道吗？ 原子引用 public class AtomicReferenceDemo { public static void main(String[] args) { User cuzz = new User(&quot;cuzz&quot;, 18); User faker = new User(&quot;faker&quot;, 20); AtomicReference&lt;User&gt; atomicReference = new AtomicReference&lt;&gt;(); atomicReference.set(cuzz); System.out.println(atomicReference.compareAndSet(cuzz, faker)); // true System.out.println(atomicReference.get()); // User(userName=faker, age=20) }} ABA 问题是怎么产生的 /** * @program: learn-demo * @description: ABA * @author: cuzz * @create: 2019-04-21 23:31 **/public class ABADemo { private static AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;&gt;(100); public static void main(String[] args) { new Thread(() -&gt; { atomicReference.compareAndSet(100, 101); atomicReference.compareAndSet(101, 100); }).start(); new Thread(() -&gt; { // 保证上面线程先执行 try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } atomicReference.compareAndSet(100, 2019); System.out.println(atomicReference.get()); // 2019 }).start(); }} 当有一个值从 A 改为 B 又改为 A，这就是 ABA 问题。 时间戳原子引用 package com.cuzz.thread;import java.util.concurrent.atomic.AtomicReference;import java.util.concurrent.atomic.AtomicStampedReference;/** * @program: learn-demo * @description: ABA * @author: cuzz * @create: 2019-04-21 23:31 **/public class ABADemo2 { private static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;&gt;(100, 1); public static void main(String[] args) { new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + &quot; 的版本号为：&quot; + stamp); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1 ); atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1 ); }).start(); new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + &quot; 的版本号为：&quot; + stamp); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } boolean b = atomicStampedReference.compareAndSet(100, 2019, stamp, stamp + 1); System.out.println(b); // false System.out.println(atomicStampedReference.getReference()); // 100 }).start(); }} 我们先保证两个线程的初始版本为一致，后面修改是由于版本不一样就会修改失败。 我们知道 ArrayList 是线程不安全，请编写一个不安全的案例并给出解决方案？ 故障现象 public class ContainerDemo { public static void main(String[] args) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); Random random = new Random(); for (int i = 0; i &lt; 100; i++) { new Thread(() -&gt; { list.add(random.nextInt(10)); System.out.println(list); }).start(); } }} 发现报 java.util.ConcurrentModificationException 导致原因 并发修改导致的异常 解决方案 new Vector(); Collections.synchronizedList(new ArrayList&lt;&gt;()); new CopyOnWriteArrayList&lt;&gt;(); 优化建议 在读多写少的时候推荐使用 CopeOnWriteArrayList 这个类 java 中锁你知道哪些？请手写一个自旋锁？公平和非公平锁 是什么 公平锁：是指多个线程按照申请的顺序来获取值 非公平锁：是值多个线程获取值的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发的情况下，可能会造成优先级翻转或者饥饿现象 两者区别 公平锁：在并发环境中，每一个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个就占有锁，否者就会加入到等待队列中，以后会按照 FIFO 的规则获取锁 非公平锁：一上来就尝试占有锁，如果失败在进行排队 可重入锁和不可重入锁 是什么 可重入锁：指的是同一个线程外层函数获得锁之后，内层仍然能获取到该锁，在同一个线程在外层方法获取锁的时候，在进入内层方法或会自动获取该锁 不可重入锁： 所谓不可重入锁，即若当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到被阻塞 代码实现 可重入锁 public class ReentrantLock { boolean isLocked = false; Thread lockedBy = null; int lockedCount = 0; public synchronized void lock() throws InterruptedException { Thread thread = Thread.currentThread(); while (isLocked &amp;&amp; lockedBy != thread) { wait(); } isLocked = true; lockedCount++; lockedBy = thread; } public synchronized void unlock() { if (Thread.currentThread() == lockedBy) { lockedCount--; if (lockedCount == 0) { isLocked = false; notify(); } } }} 测试 public class Count {// NotReentrantLock lock = new NotReentrantLock(); ReentrantLock lock = new ReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something System.out.println(&quot;ReentrantLock&quot;); lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 发现可以输出 ReentrantLock，我们设计两个线程调用 print() 方法，第一个线程调用 print() 方法获取锁，进入 lock() 方法，由于初始 lockedBy 是 null，所以不会进入 while 而挂起当前线程，而是是增量 lockedCount 并记录 lockBy 为第一个线程。接着第一个线程进入 doAdd() 方法，由于同一进程，所以不会进入 while 而挂起，接着增量 lockedCount，当第二个线程尝试lock，由于 isLocked=true，所以他不会获取该锁，直到第一个线程调用两次 unlock() 将 lockCount 递减为0，才将标记为 isLocked 设置为 false。 不可重入锁 public class NotReentrantLock { private boolean isLocked = false; public synchronized void lock() throws InterruptedException { while (isLocked) { wait(); } isLocked = true; } public synchronized void unlock() { isLocked = false; notify(); }} 测试 public class Count { NotReentrantLock lock = new NotReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 当前线程执行print()方法首先获取lock，接下来执行doAdd()方法就无法执行doAdd()中的逻辑，必须先释放锁。这个例子很好的说明了不可重入锁。 synchronized 和 ReentrantLock 都是可重入锁 synchronzied public class SynchronziedDemo { private synchronized void print() { doAdd(); } private synchronized void doAdd() { System.out.println(&quot;doAdd...&quot;); } public static void main(String[] args) { SynchronziedDemo synchronziedDemo = new SynchronziedDemo(); synchronziedDemo.print(); // doAdd... }} 上面可以说明 synchronized 是可重入锁。 ReentrantLock public class ReentrantLockDemo { private Lock lock = new ReentrantLock(); private void print() { lock.lock(); doAdd(); lock.unlock(); } private void doAdd() { lock.lock(); lock.lock(); System.out.println(&quot;doAdd...&quot;); lock.unlock(); lock.unlock(); } public static void main(String[] args) { ReentrantLockDemo reentrantLockDemo = new ReentrantLockDemo(); reentrantLockDemo.print(); }} 上面例子可以说明 ReentrantLock 是可重入锁，而且在 #doAdd 方法中加两次锁和解两次锁也可以。 自旋锁 是指定尝试获取锁的线程不会立即堵塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上线文切换的消耗，缺点就是循环会消耗 CPU。 手动实现自旋锁 public class SpinLock { private AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;&gt;(); private void lock () { System.out.println(Thread.currentThread() + &quot; coming...&quot;); while (!atomicReference.compareAndSet(null, Thread.currentThread())) { // loop } } private void unlock() { Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread, null); System.out.println(thread + &quot; unlock...&quot;); } public static void main(String[] args) throws InterruptedException { SpinLock spinLock = new SpinLock(); new Thread(() -&gt; { spinLock.lock(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;hahaha&quot;); spinLock.unlock(); }).start(); Thread.sleep(1); new Thread(() -&gt; { spinLock.lock(); System.out.println(&quot;hehehe&quot;); spinLock.unlock(); }).start(); }} 输出： Thread[Thread-0,5,main] coming...Thread[Thread-1,5,main] coming...hahahaThread[Thread-0,5,main] unlock...heheheThread[Thread-1,5,main] unlock... 获取锁的时候，如果原子引用为空就获取锁，不为空表示有人获取了锁，就循环等待。 独占锁（写锁）/共享锁（读锁） 是什么 独占锁：指该锁一次只能被一个线程持有 共享锁：该锁可以被多个线程持有 对于 ReentrantLock 和 synchronized 都是独占锁；对与 ReentrantReadWriteLock 其读锁是共享锁而写锁是独占锁。读锁的共享可保证并发读是非常高效的，读写、写读和写写的过程是互斥的。 读写锁例子 public class MyCache { private volatile Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); private ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); WriteLock writeLock = lock.writeLock(); ReadLock readLock = lock.readLock(); public void put(String key, Object value) { try { writeLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在写入...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } map.put(key, value); System.out.println(Thread.currentThread().getName() + &quot; 写入完成，写入结果是 &quot; + value); } finally { writeLock.unlock(); } } public void get(String key) { try { readLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在读...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } Object res = map.get(key); System.out.println(Thread.currentThread().getName() + &quot; 读取完成，读取结果是 &quot; + res); } finally { readLock.unlock(); } }} 测试 public class ReadWriteLockDemo { public static void main(String[] args) { MyCache cache = new MyCache(); for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.put(temp + &quot;&quot;, temp + &quot;&quot;); }).start(); } for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.get(temp + &quot;&quot;); }).start(); } }} 输出结果 Thread-0 正在写入...Thread-0 写入完成，写入结果是 0Thread-1 正在写入...Thread-1 写入完成，写入结果是 1Thread-2 正在写入...Thread-2 写入完成，写入结果是 2Thread-3 正在写入...Thread-3 写入完成，写入结果是 3Thread-4 正在写入...Thread-4 写入完成，写入结果是 4Thread-5 正在读...Thread-7 正在读...Thread-8 正在读...Thread-6 正在读...Thread-9 正在读...Thread-5 读取完成，读取结果是 0Thread-7 读取完成，读取结果是 2Thread-8 读取完成，读取结果是 3Thread-6 读取完成，读取结果是 1Thread-9 读取完成，读取结果是 4 能保证读写、写读和写写的过程是互斥的时候是独享的，读读的时候是共享的。 CountDownLatch/CyclicBarrier/Semaphore 使用过吗？CountDownLatch让一些线程堵塞直到另一个线程完成一系列操作后才被唤醒。CountDownLatch 主要有两个方法，当一个或多个线程调用 await 方法时，调用线程会被堵塞，其他线程调用 countDown 方法会将计数减一（调用 countDown 方法的线程不会堵塞），当计数其值变为零时，因调用 await 方法被堵塞的线程会被唤醒，继续执行。 假设我们有这么一个场景，教室里有班长和其他6个人在教室上自习，怎么保证班长等其他6个人都走出教室在把教室门给关掉。 public class CountDownLanchDemo { public static void main(String[] args) { for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; 离开了教室...&quot;); }, String.valueOf(i)).start(); } System.out.println(&quot;班长把门给关了，离开了教室...&quot;); }} 此时输出 0 离开了教室...1 离开了教室...2 离开了教室...3 离开了教室...班长把门给关了，离开了教室...5 离开了教室...4 离开了教室... 发现班长都没有等其他人理他教室就把门给关了，此时我们就可以使用 CountDownLatch 来控制 public class CountDownLanchDemo { public static void main(String[] args) throws InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(6); for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { countDownLatch.countDown(); System.out.println(Thread.currentThread().getName() + &quot; 离开了教室...&quot;); }, String.valueOf(i)).start(); } countDownLatch.await(); System.out.println(&quot;班长把门给关了，离开了教室...&quot;); }} 此时输出 0 离开了教室...1 离开了教室...2 离开了教室...3 离开了教室...4 离开了教室...5 离开了教室...班长把门给关了，离开了教室... CyclicBarrier我们假设有这么一个场景，每辆车只能坐个人，当车满了，就发车。 public class CyclicBarrierDemo { public static void main(String[] args) { CyclicBarrier cyclicBarrier = new CyclicBarrier(4, () -&gt; { System.out.println(&quot;车满了，开始出发...&quot;); }); for (int i = 0; i &lt; 8; i++) { new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; 开始上车...&quot;); try { cyclicBarrier.await(); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }).start(); } }} 输出结果 Thread-0 开始上车...Thread-1 开始上车...Thread-3 开始上车...Thread-4 开始上车...车满了，开始出发...Thread-5 开始上车...Thread-7 开始上车...Thread-2 开始上车...Thread-6 开始上车...车满了，开始出发... Semaphore假设我们有 3 个停车位，6 辆车去抢 public class SemaphoreDemo { public static void main(String[] args) { Semaphore semaphore = new Semaphore(3); for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { try { semaphore.acquire(); // 获取一个许可 System.out.println(Thread.currentThread().getName() + &quot; 抢到车位...&quot;); Thread.sleep(3000); System.out.println(Thread.currentThread().getName() + &quot; 离开车位&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { semaphore.release(); // 释放一个许可 } }).start(); } }} 输出 Thread-1 抢到车位...Thread-2 抢到车位...Thread-0 抢到车位...Thread-2 离开车位Thread-0 离开车位Thread-3 抢到车位...Thread-1 离开车位Thread-4 抢到车位...Thread-5 抢到车位...Thread-3 离开车位Thread-5 离开车位Thread-4 离开车位 堵塞队列你知道吗？阻塞队列有哪些 ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）对元素进行排序。 LinkedBlokcingQueue：是一个基于链表结构的阻塞队列，此队列按 FIFO（先进先出）对元素进行排序，吞吐量通常要高于 ArrayBlockingQueue。 SynchronousQueue：是一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于 LinkedBlokcingQueue。 什么是阻塞队列 阻塞队列，顾名思义，首先它是一个队列，而一个阻塞队列在数据结构中所起的作用大致如图所示： 当阻塞队列是空时，从队列中获取元素的操作将会被阻塞。 当阻塞队列是满时，往队列里添加元素的操作将会被阻塞。 核心方法 方法\\行为 抛异常 特定的值 阻塞 超时 插入方法 add(o) offer(o) put(o) offer(o, timeout, timeunit) 移除方法 poll()、remove(o) take() poll(timeout, timeunit) 检查方法 element() peek() 行为解释： 抛异常：如果操作不能马上进行，则抛出异常 特定的值：如果操作不能马上进行，将会返回一个特殊的值，一般是 true 或者 false 阻塞：如果操作不能马上进行，操作会被阻塞 超时：如果操作不能马上进行，操作会被阻塞指定的时间，如果指定时间没执行，则返回一个特殊值，一般是 true 或者 false 插入方法： add(E e)：添加成功返回true，失败抛 IllegalStateException 异常 offer(E e)：成功返回 true，如果此队列已满，则返回 false put(E e)：将元素插入此队列的尾部，如果该队列已满，则一直阻塞 删除方法： remove(Object o) ：移除指定元素,成功返回true，失败返回false poll()：获取并移除此队列的头元素，若队列为空，则返回 null take()：获取并移除此队列头元素，若没有元素则一直阻塞 检查方法： element() ：获取但不移除此队列的头元素，没有元素则抛异常 peek() :获取但不移除此队列的头；若队列为空，则返回 null SynchronousQueueSynchronousQueue，实际上它不是一个真正的队列，因为它不会为队列中元素维护存储空间。与其他队列不同的是，它维护一组线程，这些线程在等待着把元素加入或移出队列。 public class SynchronousQueueDemo { public static void main(String[] args) { SynchronousQueue&lt;Integer&gt; synchronousQueue = new SynchronousQueue&lt;&gt;(); new Thread(() -&gt; { try { synchronousQueue.put(1); Thread.sleep(3000); synchronousQueue.put(2); Thread.sleep(3000); synchronousQueue.put(3); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); new Thread(() -&gt; { try { Integer val = synchronousQueue.take(); System.out.println(val); Integer val2 = synchronousQueue.take(); System.out.println(val2); Integer val3 = synchronousQueue.take(); System.out.println(val3); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); }} 使用场景 生产者消费者模式 线程池 消息中间件 synchronized 和 Lock 有什么区别？ 原始结构 synchronized 是关键字属于 JVM 层面，反应在字节码上是 monitorenter 和 monitorexit，其底层是通过 monitor 对象来完成，其实 wait/notify 等方法也是依赖 monitor 对象只有在同步快或方法中才能调用 wait/notify 等方法。 Lock 是具体类（java.util.concurrent.locks.Lock）是 api 层面的锁。 使用方法 synchronized 不需要用户手动去释放锁，当 synchronized 代码执行完后系统会自动让线程释放对锁的占用。 ReentrantLock 则需要用户手动的释放锁，若没有主动释放锁，可能导致出现死锁的现象，lock() 和 unlock() 方法需要配合 try/finally 语句来完成。 等待是否可中断 synchronized 不可中断，除非抛出异常或者正常运行完成。 ReentrantLock 可中断，设置超时方法 tryLock(long timeout, TimeUnit unit)，lockInterruptibly() 放代码块中，调用 interrupt() 方法可中断。 加锁是否公平 synchronized 非公平锁 ReentrantLock 默认非公平锁，构造方法中可以传入 boolean 值，true 为公平锁，false 为非公平锁。 锁可以绑定多个 Condition synchronized 没有 Condition。 ReentrantLock 用来实现分组唤醒需要唤醒的线程们，可以精确唤醒，而不是像 synchronized 要么随机唤醒一个线程要么唤醒全部线程。 线程池使用过吗？谈谈对 ThreadPoolExector 的理解？为什使用线程池，线程池的优势？线程池用于多线程处理中，它可以根据系统的情况，可以有效控制线程执行的数量，优化运行效果。线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量，那么超出数量的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。 主要特点为： 线程复用 控制最大并发数量 管理线程 主要优点 降低资源消耗，通过重复利用已创建的线程来降低线程创建和销毁造成的消耗。 提高相应速度，当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性，线程是稀缺资源，如果无限制的创建，不仅仅会消耗系统资源，还会降低体统的稳定性，使用线程可以进行统一分配，调优和监控。 创建线程的几种方式 继承 Thread 实现 Runnable 接口 实现 Callable public class CallableDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { // 在 FutureTask 中传入 Callable 的实现类 FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { return 666; } }); // 把 futureTask 放入线程中 new Thread(futureTask).start(); // 获取结果 Integer res = futureTask.get(); System.out.println(res); }} 线程池如果使用？架构说明 编码实现 Executors.newSingleThreadExecutor()：只有一个线程的线程池，因此所有提交的任务是顺序执行 Executors.newCachedThreadPool()：线程池里有很多线程需要同时执行，老的可用线程将被新的任务触发重新执行，如果线程超过60秒内没执行，那么将被终止并从池中删除 Executors.newFixedThreadPool()：拥有固定线程数的线程池，如果没有任务执行，那么线程会一直等待 Executors.newScheduledThreadPool()：用来调度即将执行的任务的线程池 Executors.newWorkStealingPool()： newWorkStealingPool适合使用在很耗时的操作，但是newWorkStealingPool不是ThreadPoolExecutor的扩展，它是新的线程池类ForkJoinPool的扩展，但是都是在统一的一个Executors类中实现，由于能够合理的使用CPU进行对任务操作（并行操作），所以适合使用在很耗时的任务中 ThreadPoolExecutorThreadPoolExecutor作为java.util.concurrent包对外提供基础实现，以内部线程池的形式对外提供管理任务执行，线程调度，线程池管理等等服务。 线程池的几个重要参数介绍？ 参数 作用 corePoolSize 核心线程池大小 maximumPoolSize 最大线程池大小 keepAliveTime 线程池中超过 corePoolSize 数目的空闲线程最大存活时间；可以allowCoreThreadTimeOut(true) 使得核心线程有效时间 TimeUnit keepAliveTime 时间单位 workQueue 阻塞任务队列 threadFactory 新建线程工厂 RejectedExecutionHandler 当提交任务数超过 maxmumPoolSize+workQueue 之和时，任务会交给RejectedExecutionHandler 来处理 说说线程池的底层工作原理？ 重点讲解： 其中比较容易让人误解的是：corePoolSize，maximumPoolSize，workQueue之间关系。 当线程池小于corePoolSize时，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。 当线程池达到corePoolSize时，新提交任务将被放入 workQueue 中，等待线程池中任务调度执行。 当workQueue已满，且 maximumPoolSize 大于 corePoolSize 时，新提交任务会创建新线程执行任务。 当提交任务数超过 maximumPoolSize 时，新提交任务由 RejectedExecutionHandler 处理。 当线程池中超过corePoolSize 线程，空闲时间达到 keepAliveTime 时，关闭空闲线程 。 当设置allowCoreThreadTimeOut(true) 时，线程池中 corePoolSize 线程空闲时间达到 keepAliveTime 也将关闭。 线程池用过吗？生产上你如何设置合理参数？线程池的拒绝策略你谈谈？ 是什么 等待队列已经满了，再也塞不下新的任务，同时线程池中的线程数达到了最大线程数，无法继续为新任务服务。 拒绝策略 AbortPolicy：处理程序遭到拒绝将抛出运行时 RejectedExecutionException CallerRunsPolicy：线程调用运行该任务的 execute 本身。此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。 DiscardPolicy：不能执行的任务将被删除 DiscardOldestPolicy：如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程） 你在工作中单一的、固定数的和可变的三种创建线程池的方法，你用哪个多，超级大坑？如果读者对Java中的阻塞队列有所了解的话，看到这里或许就能够明白原因了。 Java中的BlockingQueue主要有两种实现，分别是ArrayBlockingQueue 和 LinkedBlockingQueue。 ArrayBlockingQueue是一个用数组实现的有界阻塞队列，必须设置容量。 LinkedBlockingQueue是一个用链表实现的有界阻塞队列，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE。 这里的问题就出在：不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE。也就是说，如果我们不设置LinkedBlockingQueue的容量的话，其默认容量将会是Integer.MAX_VALUE。 而newFixedThreadPool中创建LinkedBlockingQueue时，并未指定容量。此时，LinkedBlockingQueue就是一个无边界队列，对于一个无边界队列来说，是可以不断的向队列中加入任务的，这种情况下就有可能因为任务过多而导致内存溢出问题。 上面提到的问题主要体现在newFixedThreadPool和newSingleThreadExecutor两个工厂方法上，并不是说newCachedThreadPool和newScheduledThreadPool这两个方法就安全了，这两种方式创建的最大线程数可能是Integer.MAX_VALUE，而创建这么多线程，必然就有可能导致OOM。 你在工作中是如何使用线程池的，是否自定义过线程池使用？自定义线程池 public class ThreadPoolExecutorDemo { public static void main(String[] args) { Executor executor = new ThreadPoolExecutor(2, 3, 1L, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(5), Executors.defaultThreadFactory(), new ThreadPoolExecutor.DiscardPolicy()); }} 合理配置线程池你是如果考虑的？ CPU 密集型 CPU 密集的意思是该任务需要大量的运算，而没有阻塞，CPU 一直全速运行。 CPU 密集型任务尽可能的少的线程数量，一般为 CPU 核数 + 1 个线程的线程池。 IO 密集型 由于 IO 密集型任务线程并不是一直在执行任务，可以多分配一点线程数，如 CPU * 2 。 也可以使用公式：CPU 核数 / (1 - 阻塞系数)；其中阻塞系数在 0.8 ～ 0.9 之间。 死锁编码以及定位分析 产生死锁的原因 死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种相互等待的现象，如果无外力的干涉那它们都将无法推进下去，如果系统的资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则就会因争夺有限的资源而陷入死锁。 代码 public class DeadLockDemo { public static void main(String[] args) { String lockA = &quot;lockA&quot;; String lockB = &quot;lockB&quot;; DeadLockDemo deadLockDemo = new DeadLockDemo(); Executor executor = Executors.newFixedThreadPool(2); executor.execute(() -&gt; deadLockDemo.method(lockA, lockB)); executor.execute(() -&gt; deadLockDemo.method(lockB, lockA)); } public void method(String lock1, String lock2) { synchronized (lock1) { System.out.println(Thread.currentThread().getName() + &quot;--获取到：&quot; + lock1 + &quot;; 尝试获取：&quot; + lock2); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (lock2) { System.out.println(&quot;获取到两把锁!&quot;); } } }} 解决 jps -l 命令查定位进程号 28519 org.jetbrains.jps.cmdline.Launcher32376 com.intellij.idea.Main28521 com.cuzz.thread.DeadLockDemo27836 org.jetbrains.kotlin.daemon.KotlinCompileDaemon28591 sun.tools.jps.Jps jstack 28521 找到死锁查看 2019-05-07 00:04:15Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.191-b12 mixed mode):&quot;Attach Listener&quot; #13 daemon prio=9 os_prio=0 tid=0x00007f7acc001000 nid=0x702a waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE// ...Found one Java-level deadlock:=============================&quot;pool-1-thread-2&quot;: waiting to lock monitor 0x00007f7ad4006478 (object 0x00000000d71f60b0, a java.lang.String), which is held by &quot;pool-1-thread-1&quot;&quot;pool-1-thread-1&quot;: waiting to lock monitor 0x00007f7ad4003be8 (object 0x00000000d71f60e8, a java.lang.String), which is held by &quot;pool-1-thread-2&quot;Java stack information for the threads listed above:===================================================&quot;pool-1-thread-2&quot;: at com.cuzz.thread.DeadLockDemo.method(DeadLockDemo.java:34) - waiting to lock &lt;0x00000000d71f60b0&gt; (a java.lang.String) - locked &lt;0x00000000d71f60e8&gt; (a java.lang.String) at com.cuzz.thread.DeadLockDemo.lambda$main$1(DeadLockDemo.java:21) at com.cuzz.thread.DeadLockDemo$$Lambda$2/2074407503.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)&quot;pool-1-thread-1&quot;: at com.cuzz.thread.DeadLockDemo.method(DeadLockDemo.java:34) - waiting to lock &lt;0x00000000d71f60e8&gt; (a java.lang.String) - locked &lt;0x00000000d71f60b0&gt; (a java.lang.String) at com.cuzz.thread.DeadLockDemo.lambda$main$0(DeadLockDemo.java:20) at com.cuzz.thread.DeadLockDemo$$Lambda$1/558638686.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Found 1 deadlock. 最后发现一个死锁。 后续JVM 面试 参考链接 Java内存模型-volatile","link":"/2019/04/16/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"title":"深入理解Java虚拟机（二）","text":"ClassLoader文档：https://docs.oracle.com/javase/7/docs/api/java/lang/ClassLoader.html public abstract class ClassLoader extends Object A class loader is an object that is responsible for loading classes. The class ClassLoader is an abstract class. Given the binary name of a class, a class loader should attempt to locate or generate data that constitutes a definition for the class. A typical strategy is to transform the name into a file name and then read a “class file” of that name from a file system. Every Class object contains a reference to the ClassLoader that defined it. Class objects for array classes are not created by class loaders, but are created automatically as required by the Java runtime. The class loader for an array class, as returned by Class.getClassLoader() is the same as the class loader for its element type; if the element type is a primitive type, then the array class has no class loader. Applications implement subclasses of ClassLoader in order to extend the manner in which the Java virtual machine dynamically loads classes. Class loaders may typically be used by security managers to indicate security domains. The ClassLoader class uses a delegation model to search for classes and resources. Each instance of ClassLoader has an associated parent class loader. When requested to find a class or resource, a ClassLoader instance will delegate the search for the class or resource to its parent class loader before attempting to find the class or resource itself. The virtual machine’s built-in class loader, called the “bootstrap class loader”, does not itself have a parent but may serve as the parent of a ClassLoader instance. Class loaders that support concurrent loading of classes are known as parallel capable class loaders and are required to register themselves at their class initialization time by invoking the ClassLoader.registerAsParallelCapable method. Note that the ClassLoader class is registered as parallel capable by default. However, its subclasses still need to register themselves if they are parallel capable. In environments in which the delegation model is not strictly hierarchical, class loaders need to be parallel capable, otherwise class loading can lead to deadlocks because the loader lock is held for the duration of the class loading process (see loadClass methods). Normally, the Java virtual machine loads classes from the local file system in a platform-dependent manner. For example, on UNIX systems, the virtual machine loads classes from the directory defined by the CLASSPATH environment variable. However, some classes may not originate from a file; they may originate from other sources, such as the network, or they could be constructed by an application. The method defineClass converts an array of bytes into an instance of class Class. Instances of this newly defined class can be created using Class.newInstance. The methods and constructors of objects created by a class loader may reference other classes. To determine the class(es) referred to, the Java virtual machine invokes the loadClass method of the class loader that originally created the class. For example, an application could create a network class loader to download class files from a server. Sample code might look like: ClassLoader loader = new NetworkClassLoader(host, port);Object main = loader.loadClass(&quot;Main&quot;, true).newInstance(); . . . The network class loader subclass must define the methods findClass and loadClassData to load a class from the network. Once it has downloaded the bytes that make up the class, it should use the method defineClass to create a class instance. A sample implementation is: class NetworkClassLoader extends ClassLoader { String host; int port; public Class findClass(String name) { byte[] b = loadClassData(name); return defineClass(name, b, 0, b.length); } private byte[] loadClassData(String name) { // load the class data from the connection . . . }} Binary names Any class name provided as a String parameter to methods in ClassLoader must be a binary name as defined by The Java™ Language Specification. Examples of valid class names include: &quot;java.lang.String&quot; // 一个类&quot;javax.swing.JSpinner$DefaultEditor&quot; // 一个内部类&quot;java.security.KeyStore$Builder$FileBuilder$1&quot; // 内部类的匿名类&quot;java.net.URLClassLoader$3$1&quot; // 匿名类的匿名类 我们知道类的加载是双亲委派机制，我们先来看一个例子 public class MyTest15 { public static void main(String[] args) { ClassLoader loader = MyTest15.class.getClassLoader(); System.out.println(loader); ClassLoader loader1 = loader.getParent(); System.out.println(loader1); ClassLoader loader2 = loader1.getParent(); System.out.println(loader2); }} 输出 sun.misc.Launcher$AppClassLoader@dad5dcsun.misc.Launcher$ExtClassLoader@16d3586null 当为根加载器时，返回null 看了文档，写一个自定义 ClassLoader /** * @Author: cuzz * @Date: 2019/1/28 12:39 * @Description: */public class MyClassLoader extends ClassLoader{ private String classLoaderName; private final String fileExtension = &quot;.class&quot;; public MyClassLoader(String classLoaderName) { super(); // 将系统类加载当做该类加载器的父加载器 this.classLoaderName = classLoaderName; } public MyClassLoader(ClassLoader parent, String classLoaderName) { super(parent); // 显示指定该类加载的父加载器 this.classLoaderName = classLoaderName; } @Override protected Class&lt;?&gt; findClass(String className) throws ClassNotFoundException { byte[] data = loadClassData(className); return defineClass(className, data,0, data.length); } private byte[] loadClassData(String name) { InputStream is = null; byte[] data = null; ByteArrayOutputStream baos = null; try { this.classLoaderName = this.classLoaderName.replace(&quot;.&quot;, &quot;/&quot;); is = new FileInputStream(new File(name, this.fileExtension)); baos = new ByteArrayOutputStream(); int ch; while (-1 != (ch = is.read())) { baos.write(ch); } data = baos.toByteArray(); } catch (Exception e) { e.printStackTrace(); } finally { try { is.close(); baos.close(); } catch (Exception e) { e.printStackTrace(); } } return data; } public static void main(String[] args) throws Exception{ MyClassLoader myClassLoader = new MyClassLoader(&quot;myLoader&quot;); Class&lt;?&gt; clazz = myClassLoader.loadClass(&quot;com.cuzz.jvm.classloader.MyTest01&quot;); Object o = clazz.newInstance(); // 获取实例对象 System.out.println(&quot;类加载器：&quot; + clazz.getClassLoader()); System.out.println(o); }} 输出 类加载器：sun.misc.Launcher$AppClassLoader@dad5dccom.cuzz.jvm.classloader.MyTest01@16d3586 我们编写的类加载器不起作用，因为双亲委派机制，当我们尝试使用自己编写的类加载器去加载时，它会委派自己的双亲去加载，刚好系统类加载器（应用类加载器）就能加载，所以不会使用我们自己编写的类加载器，而使用系统类加载器 如果我们把路径换一下，把项目路径下 classes 中的 MyTest01.class 文件移动在别的地方，让系统类加载器找不到，然后它就会调用我们自己编写的类加载器加载 public class MyClassLoader extends ClassLoader{ private String classLoaderName; private final String fileExtension = &quot;.class&quot;; private String path; public MyClassLoader(String classLoaderName) { super(); // 将系统类加载当做该类加载器的父加载器 this.classLoaderName = classLoaderName; } public MyClassLoader(ClassLoader parent, String classLoaderName) { super(parent); // 显示指定该类加载的父加载器 this.classLoaderName = classLoaderName; } public void setPath(String path) { this.path = path; } @Override protected Class&lt;?&gt; findClass(String className) throws ClassNotFoundException { byte[] data = loadClassData(className); return defineClass(className, data,0, data.length); } private byte[] loadClassData(String name) { InputStream is = null; byte[] data = null; ByteArrayOutputStream baos = null; name = name.replace(&quot;.&quot;, &quot;\\\\&quot;); try { is = new FileInputStream(new File(this.path + name + this.fileExtension)); baos = new ByteArrayOutputStream(); int ch; while (-1 != (ch = is.read())) { baos.write(ch); } data = baos.toByteArray(); } catch (Exception e) { e.printStackTrace(); } finally { try { is.close(); baos.close(); } catch (Exception e) { e.printStackTrace(); } } return data; } public static void main(String[] args) throws Exception{ MyClassLoader myClassLoader = new MyClassLoader(&quot;myLoader&quot;); // Class&lt;?&gt; clazz = myClassLoader.loadClass(&quot;com.cuzz.jvm.classloader.MyTest01&quot;); String path = &quot;C:/Users/my/Desktop/&quot;; myClassLoader.setPath(path); Class&lt;?&gt; clazz = myClassLoader.loadClass(&quot;com.cuzz.jvm.classloader.MyTest01&quot;); Object o = clazz.newInstance(); // 获取实例对象 System.out.println(&quot;类加载器：&quot; + clazz.getClassLoader()); System.out.println(&quot;父类加载器：&quot; + myClassLoader.getParent()); System.out.println(o); }} 输出 类加载器：com.cuzz.jvm.classloader.MyClassLoader@16d3586父类加载器：sun.misc.Launcher$AppClassLoader@dad5dccom.cuzz.jvm.classloader.MyTest01@a14482 defineClasjava.lang.ClassLoader#defineClass(java.lang.String, byte[], int, int) protected final Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len) throws ClassFormatError { return defineClass(name, b, off, len, null);} 通过一个字节数组返回一个 Class 的实例 loadClassjava.lang.ClassLoader#loadClass(java.lang.String, boolean) 文档： java.lang.ClassLoaderprotected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundExceptionLoads the class with the specified binary name. The default implementation of this method searches for classes in the following order: Invoke findLoadedClass(String) to check if the class has already been loaded. Invoke the loadClass method on the parent class loader. If the parent is null the class loader built-in to the virtual machine is used, instead. Invoke the findClass(String) method to find the class. If the class was found using the above steps, and the resolve flag is true, this method will then invoke the resolveClass(Class) method on the resulting Class object.Subclasses of ClassLoader are encouraged to override findClass(String), rather than this method.Unless overridden, this method synchronizes on the result of getClassLoadingLock method during the entire class loading process.Parameters: name - The binary name of the class resolve - If true then resolve the class protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException{ synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) { c = parent.loadClass(name, false); } else { c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // 我们只需要重写这个方法就可以 // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; }} 命名空间每一个类加载器斗鱼自己的命名空间，命名空间由该加载器及所有父类加载器所加载的类组成，在同一个命名空间中，不会出现类的完整名字（包括类的包名）相同的两个类，在不同的命名空间中，有可能会出现类的完整名字（包括类的包名）相同的两个类 public static void main(String[] args) throws Exception{ MyClassLoader myClassLoader = new MyClassLoader(&quot;myLoader&quot;); MyClassLoader myClassLoader1 = new MyClassLoader(&quot;myLoader1&quot;); String path = &quot;C:/Users/my/Desktop/&quot;; myClassLoader.setPath(path); myClassLoader1.setPath(path); Class&lt;?&gt; clazz = myClassLoader.loadClass(&quot;com.cuzz.jvm.classloader.MyTest01&quot;); Class&lt;?&gt; clazz1 = myClassLoader1.loadClass(&quot;com.cuzz.jvm.classloader.MyTest01&quot;); System.out.println(&quot;clazz: &quot; + clazz.hashCode()); System.out.println(&quot;clazz1: &quot; + clazz1.hashCode());} 输出 clazz: 24324022clazz1: 21685669 说明类被加载了两次，这就是由不同的命名空间导致的 如果我们给 myClassLoader1 添加一个父加载器 public static void main(String[] args) throws Exception{ MyClassLoader myClassLoader = new MyClassLoader(&quot;myLoader&quot;); // 把 myClassLoader 当做父加载器 MyClassLoader myClassLoader1 = new MyClassLoader(myClassLoader,&quot;myLoader1&quot;); String path = &quot;C:/Users/my/Desktop/&quot;; myClassLoader.setPath(path); myClassLoader1.setPath(path); Class&lt;?&gt; clazz = myClassLoader.loadClass(&quot;com.cuzz.jvm.classloader.MyTest01&quot;); Class&lt;?&gt; clazz1 = myClassLoader1.loadClass(&quot;com.cuzz.jvm.classloader.MyTest01&quot;); System.out.println(&quot;clazz: &quot; + clazz.hashCode()); System.out.println(&quot;clazz1: &quot; + clazz1.hashCode());} 输出 clazz: 10568834clazz1: 10568834 由于父加载器已经加载过了，所以就不会加载了 类的卸载由 Java 虚拟机自带的类加载器所加载的类，在虚拟机的生命周期中，始终不会被卸载。前面已经介绍过，Java 虚拟机自带的类加载器包括根类加载器、扩展类加载器和系统类加载器。Java 虚拟机本身会始终引用这些类加载器，而这些类加载器则会始终引用它们所加载类的 Class 对象，因此这些 Class 对象始终是可触及的 而由用户自定义的类加载器所加载的类是可以被卸载的 类加载器命名空间深度解析通过一个例子来分析 MyCat public class MyCat { public MyCat() { System.out.println(&quot;MyCat is loaded by: &quot; + this.getClass().getClassLoader()); }} MySample public class MySample { public MySample () { System.out.println(&quot;MySample is loaded by:&quot; + this.getClass().getClassLoader()); new MyCat (); }} MyClassLoader public class MyClassLoader extends ClassLoader{ private String classLoaderName; private final String fileExtension = &quot;.class&quot;; private String path; public MyClassLoader(String classLoaderName) { super(); // 将系统类加载当做该类加载器的父加载器 this.classLoaderName = classLoaderName; } public MyClassLoader(ClassLoader parent, String classLoaderName) { super(parent); // 显示指定该类加载的父加载器 this.classLoaderName = classLoaderName; } public void setPath(String path) { this.path = path; } @Override protected Class&lt;?&gt; findClass(String className) throws ClassNotFoundException { byte[] data = loadClassData(className); return defineClass(className, data,0, data.length); } private byte[] loadClassData(String name) { InputStream is = null; byte[] data = null; ByteArrayOutputStream baos = null; name = name.replace(&quot;.&quot;, &quot;\\\\&quot;); try { is = new FileInputStream(new File(this.path + name + this.fileExtension)); baos = new ByteArrayOutputStream(); int ch; while (-1 != (ch = is.read())) { baos.write(ch); } data = baos.toByteArray(); } catch (Exception e) { e.printStackTrace(); } finally { try { is.close(); baos.close(); } catch (Exception e) { e.printStackTrace(); } } return data; } public static void main(String[] args) throws Exception{ MyClassLoader myClassLoader = new MyClassLoader(&quot;myLoader&quot;); String path = &quot;C:/Users/my/Desktop/&quot;; myClassLoader.setPath(path); Class&lt;?&gt; clazz = myClassLoader.loadClass(&quot;com.cuzz.jvm.classloader.MySample&quot;); Object object = clazz.newInstance(); }} 输出 MySample is loaded by: sun.misc.Launcher$AppClassLoader@dad5dcMyCat is loaded by: sun.misc.Launcher$AppClassLoader@dad5dc 我们知道我们自己写的 ClassLoader 与委托父类加载器去加载，所以是系统加载器加载的 现在我们把项目下 classes 路径中的 MySample.class 和 MyCat.class 删除，并复制一份到桌面 则输出 MySample is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586MyCat is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586 由于委托父类加载器加载不到就用自己加载器加载 如果我们只把当前类路径下 MySample.class 这给文件删掉，保留 MyCat.class 文件，则输出 MySample is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586MyCat is loaded by: sun.misc.Launcher$AppClassLoader@dad5dc 我们知道 MySample 是我们自定义类加载加载出来的，MyCat 是有系统类加载加载的 public class MySample { public MySample () { System.out.println(&quot;MySample is loaded by: &quot; + this.getClass().getClassLoader()); new MyCat (); System.out.println(MyCat.class); }} 输出 MySample is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586MyCat is loaded by: sun.misc.Launcher$AppClassLoader@dad5dcclass com.cuzz.jvm.classloader.MyCat 说明自定义类加载加载的类，可以访问系统类加载加载的类 如果我们在系统类加载的类中访问自定义类加载器加载的类 public class MyCat { public MyCat() { System.out.println(&quot;MyCat is loaded by: &quot; + this.getClass().getClassLoader()); System.out.println(MySample.class); }} 输出 MySample is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586MyCat is loaded by: sun.misc.Launcher$AppClassLoader@dad5dcException in thread &quot;main&quot; java.lang.NoClassDefFoundError: com/cuzz/jvm/classloader/MySample at com.cuzz.jvm.classloader.MyCat.&lt;init&gt;(MyCat.java:6) at com.cuzz.jvm.classloader.MySample.&lt;init&gt;(MySample.java:6) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:422) at java.lang.Class.newInstance(Class.java:442) at com.cuzz.jvm.classloader.MyClassLoader.main(MyClassLoader.java:68)Caused by: java.lang.ClassNotFoundException: com.cuzz.jvm.classloader.MySample at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 8 more 报错，说明系统加载器加载的类不能访问自定义加载器加载的类 说明当我现在加载 MySample 这个类时，使用的是我们自己定义的类加载器，然后初始实例化这个类时，需要初始化 MyCat 这个类，所以会先委托父加载器（系统加载器）去加载 但是如果我们把当前路径下的 MyCat.class 文件删掉，保留 MySample.class 文件，则报错 Exception in thread &quot;main&quot; MySample is loaded by: sun.misc.Launcher$AppClassLoader@dad5dcjava.lang.NoClassDefFoundError: com/cuzz/jvm/classloader/MyCat at com.cuzz.jvm.classloader.MySample.&lt;init&gt;(MySample.java:6) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:422) at java.lang.Class.newInstance(Class.java:442) at com.cuzz.jvm.classloader.MyClassLoader.main(MyClassLoader.java:68)Caused by: java.lang.ClassNotFoundException: com.cuzz.jvm.classloader.MyCat at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 7 more 我要加载 MySample 先委托系统类加载加载，发现能加载到，然后再想加载 MyCat 这个类，此时它会调用系统加载器的父类去加载，发现加载不到，自己也不能加载，就报错了。 通过上面的例子，我们可以得出以下结论： 子类加载器所加载的类能够访问到父加载器所加载的类 父类加载器所加载的类无法访问到子加载器所加载的类 类加载器的双亲委托模型的好处可以确保 Java 核心库的类型安全：所有的 Java 应用都至少会引用 java.lang.Object 类，也就是说在运行期，java.lang.Object 这个类会被加载到 Java 虚拟机中；如果这个加载过程是由 Java 应用自己的类加载所完成的，那么很可能就会在 JVM 中存在多个版本的 java.lang.Object 了，而这些类之间还是不兼容的，相互不可见（正是命名空间发挥着作用）。可以确保 Java 核心类库所提供的类不会被自定义的类所取代。不同的类加载器可以为相同的名称（binary name）的类创建额外的命名空间。相同的名称的类可以并存在 Java 虚拟机中，只要用不同的类加载器来加载它们即可（可是是不同的类加载器，也可以是相同类加载器的不同实例）。不同的类加载器所加载的类之间是不兼容的，就相同于在 Java 虚拟机内部创建了一个又一个相互隔离的 Java 类空间，这类技术在很多框架中都得到了实际的应用。 内建于 JVM 中的启动类加载器会加载 java.lang.ClassLoader 以及其他的 Java 平台类，当 JVM 启动时，一块特殊的机器码会运行，它会加载扩展类加载器和系统类加载器，这块特殊的机器码叫做启动类加载器（Bootstrap），启动类加载器并不是 Java 类，而其它加载器则都是 Java 类，启动类加载器是特定于平台的机器指令，它负责开启整个加载过程。启动类加载器还会负责加载 JRE 正常运行所需要的基本组件，这包括 java.util 与 java.lang 包中的类等等。 Launcher 类源码分析前面我们分析类 ClassLoader，里面有一个静态方法 getSystemClassLoader，发现 ClassLoader 是 Launcher 中一个成员变量 @CallerSensitive public static ClassLoader getSystemClassLoader() { initSystemClassLoader(); // 初始化 if (scl == null) { return null; } SecurityManager sm = System.getSecurityManager(); if (sm != null) { checkClassLoaderPermission(scl, Reflection.getCallerClass()); } return scl; } private static synchronized void initSystemClassLoader() { if (!sclSet) { if (scl != null) throw new IllegalStateException(&quot;recursive invocation&quot;); // 获取一个 Launcher 类 sun.misc.Launcher l = sun.misc.Launcher.getLauncher(); if (l != null) { Throwable oops = null; // scl 表示 SystemClassLoader scl = l.getClassLoader(); try { scl = AccessController.doPrivileged( new SystemClassLoaderAction(scl)); } catch (PrivilegedActionException pae) { oops = pae.getCause(); if (oops instanceof InvocationTargetException) { oops = oops.getCause(); } } ... } } }} 我们在idea里边看到的 sun.misc.Launcher.getLauncher() 的实现是反编译工具给出的，oracle并没有给出源码，可以到网上查找相关代码 private static Launcher launcher = new Launcher();private static String bootClassPath = System.getProperty(&quot;sun.boot.class.path&quot;); public static Launcher getLauncher() { return launcher; } private ClassLoader loader; public Launcher() { // Create the extension class loader ClassLoader extcl; try { extcl = ExtClassLoader.getExtClassLoader(); } catch (IOException e) { throw new InternalError( &quot;Could not create extension class loader&quot;); } // Now create the class loader to use to launch the application try { loader = AppClassLoader.getAppClassLoader(extcl); } catch (IOException e) { throw new InternalError( &quot;Could not create application class loader&quot;); } // Also set the context class loader for the primordial thread. Thread.currentThread().setContextClassLoader(loader); // Finally, install a security manager if requested String s = System.getProperty(&quot;java.security.manager&quot;); ...... } /* * Returns the class loader used to launch the main application. */ public ClassLoader getClassLoader() { return loader; } 可以看到 Launcher 类初始化时，先初始化了个 ExtClassLoader，然后又初始化了个 AppClassLoader，然后把ExtClassLoader 作为 AppClassLoader的父 loader，ExtClassLoader 没有指定父类，即表明，父类是BootstrapClassLoader。把初始化 的AppClassLoader 作为全局变量保存起来，并设置到当前线程contextClassLoader，每个线程实例可以设置一个 contextClassLoader 。 先回到 initSystemClassLoader 方法中，有这一段代码 try { scl = AccessController.doPrivileged( new SystemClassLoaderAction(scl));} catch (PrivilegedActionException pae) { oops = pae.getCause(); if (oops instanceof InvocationTargetException) { oops = oops.getCause(); }} 我们把系统加载传入到 doPrivileged 中的 SystemClassLoaderAction 中又返回了系统加载器，我们看看 SystemClassLoaderAction 这个类 class SystemClassLoaderAction implements PrivilegedExceptionAction&lt;ClassLoader&gt; { private ClassLoader parent; SystemClassLoaderAction(ClassLoader parent) { this.parent = parent; } public ClassLoader run() throws Exception { String cls = System.getProperty(&quot;java.system.class.loader&quot;); if (cls == null) { return parent; } Constructor&lt;?&gt; ctor = Class.forName(cls, true, parent) .getDeclaredConstructor(new Class&lt;?&gt;[] { ClassLoader.class }); ClassLoader sys = (ClassLoader) ctor.newInstance( new Object[] { parent }); Thread.currentThread().setContextClassLoader(sys); return sys; }} 这块逻辑的作用是看看是否设置了系统属性 java.system.class.loader，即自定义的系统类加载器，如果设置了那么实例化自定义的系统类加载器返回，替代之前获取的系统类加载器，如果没有设置直接返回默认的系统类加载器。 Class.forName()java.lang.Class#forName(java.lang.String, boolean, java.lang.ClassLoader) 文档： java.lang.Classpublic static Class&lt;?&gt; forName(@NonNls String name, boolean initialize, ClassLoader loader) throws ClassNotFoundExceptionReturns the Class object associated with the class or interface with the given string name, using the given class loader. Given the fully qualified name for a class or interface (in the same format returned by getName) this method attempts to locate, load, and link the class or interface. The specified class loader is used to load the class or interface. If the parameter loader is null, the class is loaded through the bootstrap class loader. The class is initialized only if the initialize parameter is true and if it has not been initialized earlier.If name denotes a primitive type or void, an attempt will be made to locate a user-defined class in the unnamed package whose name is name. Therefore, this method cannot be used to obtain any of the Class objects representing primitive types or void.If name denotes an array class, the component type of the array class is loaded but not initialized.For example, in an instance method the expression:Class.forName(“Foo”)is equivalent to:Class.forName(“Foo”, true, this.getClass().getClassLoader())Note that this method throws errors related to loading, linking or initializing as specified in Sections 12.2, 12.3 and 12.4 of The Java Language Specification. Note that this method does not check whether the requested class is accessible to its caller.If the loader is null, and a security manager is present, and the caller’s class loader is not null, then this method calls the security manager’s checkPermission method with a RuntimePermission(“getClassLoader”) permission to ensure it’s ok to access the bootstrap class loader.Parameters: name - fully qualified name of the desired class initialize - if true the class will be initialized. See Section 12.4 of The Java Language Specification. loader - class loader from which the class must be loaded 代码： public static Class&lt;?&gt; forName(String name, boolean initialize, ClassLoader loader) throws ClassNotFoundException{ Class&lt;?&gt; caller = null; SecurityManager sm = System.getSecurityManager(); if (sm != null) { // Reflective call to get caller class is only needed if a security manager // is present. Avoid the overhead of making this call otherwise. // 获取调用 forName 方法的的那个类 caller = Reflection.getCallerClass(); if (sun.misc.VM.isSystemDomainLoader(loader)) { ClassLoader ccl = ClassLoader.getClassLoader(caller); if (!sun.misc.VM.isSystemDomainLoader(ccl)) { sm.checkPermission( SecurityConstants.GET_CLASSLOADER_PERMISSION); } } } return forName0(name, initialize, loader, caller);} 线程上下文类加载器分析与实现接下来我们来分析一下线程上下文类加载的作用 前言看一个程序来一下感性的认识： public class MyTest24 { public static void main(String[] args) System.out.println(Thread.currentThread().getContextClassLoader()); System.out.println(Thread.class.getClassLoader()); }} 这个程序的输出是： sun.misc.Launcher$AppClassLoader@18b4aac2null 解析：第一行当前的线程是运行MyTest24 的线程，而MyTest24 是由系统类加载器加载，所以打印的是系统类加载器第二行Thread类是java核心库的类，是由启动类加载器加载，所以不打印 null **当前类加载器(Current ClassLoader) ** 每个类都会使用自己的类加载器(即加载自身的类加载器) 来去加载其他类(指的是所依赖的类) ，如果ClassA引用了ClassY，那么ClassX的类加载器就会加载ClassY（前提是ClassY尚未被加载） 线程上下文加载器（Context ClassLoader）线程上下文类加载器是从jdk1.2开始引入的，类Thread中的 getContextCLassLoader() 与setContextClassLoader(ClassLoader classloader) 分别用来获取和设置上下文类加载器，如果没有通过与setContextClassLoader(ClassLoader classloader)进行设置的话，线程将继承其父线程的上下文类加载器。 Java应用运行时的初始线程的上下文加载器是系统类加载器，在线程中运行的代码可以通过该类加载器来加载类与资源。 我们在使用jdbc的时候，不同的数据库的驱动都是由每个厂商自己去实现，开发者在使用的时候，只需要把驱动jar包 ，放到当前path下边就可以了，这些驱动是由系统类加载器加载，而 java.sql 下边的一些Class在使用的时候不可避免的 ，要去使用厂商自定义的实现的逻辑，但是这些 java.sql 下的类的加载器是由启动类加载器完成的加载，由于父加载器(启动类加载器)加载的类无法访问子加载器（系统类加载器或者应用类加载器）加载的类，所以就无法在有些 java.sql 的类去访问具体的厂商实现，这个是双亲委托模型尴尬的一个局面。 线程上下文加载器的重要性： SPI (Service Provider Interface) 父 ClassLoader 可以使用当前线程 Thread.currentThread().getContextClassLoader() 所指定的 classloader 加载的类。 这就改变了父 ClassLoader 不能使用子 ClassLoader 或是其他没有直接父子关系的 CLassLoader 加载的类的情况，即改变了双亲委托模型。 线程上下文加载器就是当前线程的 Current ClassLoader 在双亲委托模型下，类加载器由下至上的，即下层的类加载器会委托上层进行加载。但是对于 SPI 来说，有些接口是 java 核心库所提供的，而java核心库是由启动类加器来加载的，而这些接口的实现来自于不同的jar包（厂商提供），java 的启动类加载器是不会加载其他来源的jar包，这样传统的双亲委托模型就无法满足SPI的要求，而通过给当前线程设置上下文加载器，就可以设置上下文类加载器来实现对于接口实现类的加载。 线程上下文的一般使用模式线程上下文的一般使用模式分为3步，获取、使用和还原，下面是伪代码 // 获取ClassLoader classLoader = Thread.currentThread().getContextClassLoader();try { // 使用 Thread.currentThread().setContextClassLoader(targetClassLoader); method();} finally { // 还原 Thread.currentThread().setContextClassLoader(classLoader);} method 里面调用了 Thread.currentThread().getContextClassLoader()，获取当前线程上下文类加载器做某些事情。如果一个类由类加载器 A 加载，那么这个类的依赖也是有相同的类加载器加载的（如果该依赖类之前没有加载过的话），ContextClassLoader 的作用就是为了破坏 Java 的类加载委托机制。 当高层提供了统一的接口让底层去实现，同时又要在高层加载（或实例化）底层类时，就必须要通过线程上下文类加载器来帮助高层的 ClassLoader 找到并加载该类。 ServiceLoader我们先引入驱动依赖 group 'com.cuzz.jvm'version '1.0'apply plugin: 'java'sourceCompatibility = 1.8repositories { mavenCentral()}dependencies { compile ( &quot;mysql:mysql-connector-java:5.1.34&quot; )} 我们先来看一个例子 /** * @Author: cuzz * @Date: 2019/2/1 14:46 * @Description: */public class MyTest26 { public static void main(String[] args) { ServiceLoader&lt;Driver&gt; serviceLoader = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; iterator = serviceLoader.iterator(); while(iterator.hasNext()){ Driver driver = iterator.next(); System.out.println(&quot;driver: &quot;+driver.getClass() + &quot;loader: &quot;+ driver.getClass().getClassLoader() ); } System.out.println(&quot;当前线程上下文类加载器: &quot; + Thread.currentThread().getContextClassLoader()); System.out.println(&quot;ServiceLoader的类加载器: &quot;+ServiceLoader.class.getClassLoader()); }} 输出 driver: class com.mysql.jdbc.Driverloader: sun.misc.Launcher$AppClassLoader@dad5dcdriver: class com.mysql.fabric.jdbc.FabricMySQLDriverloader: sun.misc.Launcher$AppClassLoader@dad5dc当前线程上下文类加载器: sun.misc.Launcher$AppClassLoader@dad5dcServiceLoader的类加载器: null 我们可以看到 ServiceLoader 找到了 mysql 的两个驱动，这两个驱动都是由系统类加载器加载的，当前线程的上下文加载器默认也是系统类加载器，ServiceLoader是由启动类加载器加载，但是程序是怎样找到 mysql 的两个驱动的呢？我们没有在程序里边设置任何的属性或者路径之类的东西让程序能找到 mysql 的驱动，那么我们只能研究一下 ServiceLoader 的源码和文档看一下他们的原理： public final class ServiceLoader&lt;S&gt;extends Objectimplements Iterable&lt;S&gt; A simple service-provider loading facility.A service is a well-known set of interfaces and (usually abstract) classes. A service provider is a specific implementation of a service. The classes in a provider typically implement the interfaces and subclass the classes defined in the service itself. Service providers can be installed in an implementation of the Java platform in the form of extensions, that is, jar files placed into any of the usual extension directories. Providers can also be made available by adding them to the application’s class path or by some other platform-specific means.For the purpose of loading, a service is represented by a single type, that is, a single interface or abstract class. (A concrete class can be used, but this is not recommended.) A provider of a given service contains one or more concrete classes that extend this service type with data and code specific to the provider. The provider class is typically not the entire provider itself but rather a proxy which contains enough information to decide whether the provider is able to satisfy a particular request together with code that can create the actual provider on demand. The details of provider classes tend to be highly service-specific; no single class or interface could possibly unify them, so no such type is defined here. The only requirement enforced by this facility is that provider classes must have a zero-argument constructor so that they can be instantiated during loading.A service provider is identified by placing a provider-configuration file in the resource directory META-INF/services. The file’s name is the fully-qualified binary name of the service’s type. The file contains a list of fully-qualified binary names of concrete provider classes, one per line. Space and tab characters surrounding each name, as well as blank lines, are ignored. The comment character is ‘#’ (‘\\u0023’, NUMBER SIGN); on each line all characters following the first comment character are ignored. The file must be encoded in UTF-8.If a particular concrete provider class is named in more than one configuration file, or is named in the same configuration file more than once, then the duplicates are ignored. The configuration file naming a particular provider need not be in the same jar file or other distribution unit as the provider itself. The provider must be accessible from the same class loader that was initially queried to locate the configuration file; note that this is not necessarily the class loader from which the file was actually loaded.Providers are located and instantiated lazily, that is, on demand. A service loader maintains a cache of the providers that have been loaded so far. Each invocation of the iterator method returns an iterator that first yields all of the elements of the cache, in instantiation order, and then lazily locates and instantiates any remaining providers, adding each one to the cache in turn. The cache can be cleared via the reload method.Service loaders always execute in the security context of the caller. Trusted system code should typically invoke the methods in this class, and the methods of the iterators which they return, from within a privileged security context.Instances of this class are not safe for use by multiple concurrent threads.Unless otherwise specified, passing a null argument to any method in this class will cause a NullPointerException to be thrown.Example Suppose we have a service type com.example.CodecSet which is intended to represent sets of encoder/decoder pairs for some protocol. In this case it is an abstract class with two abstract methods: public abstract Encoder getEncoder(String encodingName); public abstract Decoder getDecoder(String encodingName);Each method returns an appropriate object or null if the provider does not support the given encoding. Typical providers support more than one encoding.If com.example.impl.StandardCodecs is an implementation of the CodecSet service then its jar file also contains a file named META-INF/services/com.example.CodecSetThis file contains the single line: com.example.impl.StandardCodecs # Standard codecsThe CodecSet class creates and saves a single service instance at initialization:` private static ServiceLoader&lt;CodecSet&gt; codecSetLoader = ServiceLoader.load(CodecSet.class); To locate an encoder for a given encoding name it defines a static factory method which iterates through the known and available providers, returning only when it has located a suitable encoder or has run out of providers. public static Encoder getEncoder(String encodingName) { for (CodecSet cp : codecSetLoader) Encoder enc = cp.getEncoder(encodingName); if (enc != null) return enc; } return null; } A getDecoder method is defined similarly.Usage Note If the class path of a class loader that is used for provider loading includes remote network URLs then those URLs will be dereferenced in the process of searching for provider-configuration files.This activity is normal, although it may cause puzzling entries to be created in web-server logs. If a web server is not configured correctly, however, then this activity may cause the provider-loading algorithm to fail spuriously.A web server should return an HTTP 404 (Not Found) response when a requested resource does not exist. Sometimes, however, web servers are erroneously configured to return an HTTP 200 (OK) response along with a helpful HTML error page in such cases. This will cause a ServiceConfigurationError to be thrown when this class attempts to parse the HTML page as a provider-configuration file. The best solution to this problem is to fix the misconfigured web server to return the correct response code (HTTP 404) along with the HTML error page. 我们先看源码 public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt; { // 前缀 private static final String PREFIX = &quot;META-INF/services/&quot;; // The class or interface representing the service being loaded private final Class&lt;S&gt; service; // The class loader used to locate, load, and instantiate providers private final ClassLoader loader; // The access control context taken when the ServiceLoader is created private final AccessControlContext acc; // Cached providers, in instantiation order private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;(); // The current lazy-lookup iterator private LazyIterator lookupIterator; ...} 该类中有个常量 PREFIX ，根据文档我们可以知道这是一个目录，我们看看 mysql-connnector-java 中也有 其下的文件名字就是服务的名字，比如数据库驱动的服务是java.sql.Drive，我们在mysql的jar包下可以看到这个文件，文件里边的内容是具体的实现类的全限定名： com.mysql.jdbc.Drivercom.mysql.fabric.jdbc.FabricMySQLDriver 与前面打印出来的驱动是一样的 ServiceLoader 是由启动类加载器加载的，为什么 mysql 的驱动是由系统类加载器加载呢？ 前面代码中 ServiceLoader serviceLoader = ServiceLoader.load(Driver.class); 这段代码是怎么起作用的呢，跟进源码 public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) { // 获取当前上下文类加载，并使用上下文类加载器去加载 ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl);}public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader) { // 调用一个构造方法 return new ServiceLoader&lt;&gt;(service, loader);} 既然 ServiceLoader 是由启动类加载器加载，那么 ServiceLoader 里边的类都会用启动类加载器去加载，但是呢我们的 mysql 驱动不在启动类加载器加载的目录下边，我们的 mysql 驱动位于 classpath 下边，无法用启动类加载器加载，这个时候，我们可以看到 load 方法使用了线程上下文加载器，线程上下文加载器默认是系统类加载器 我们来看看这个构造方法 private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) { service = Objects.requireNonNull(svc, &quot;Service interface cannot be null&quot;); loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; reload(); }// 调用reload() 方法 public void reload() { // 清空缓存 providers = new LinkedHashMap&lt;&gt;(); providers.clear(); // 懒加载 lookupIterator = new LazyIterator(service, loader); } LazyIterator 类 java.util.ServiceLoader.LazyIterator private class LazyIterator implements Iterator&lt;S&gt; { Class&lt;S&gt; service; ClassLoader loader; Enumeration&lt;URL&gt; configs = null; Iterator&lt;String&gt; pending = null; String nextName = null; private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) { this.service = service; this.loader = loader; } private boolean hasNextService() { if (nextName != null) { return true; } if (configs == null) { try { String fullName = PREFIX + service.getName(); if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); } catch (IOException x) { fail(service, &quot;Error locating configuration files&quot;, x); } } while ((pending == null) || !pending.hasNext()) { if (!configs.hasMoreElements()) { return false; } pending = parse(service, configs.nextElement()); } nextName = pending.next(); return true; } private S nextService() { if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try { c = Class.forName(cn, false, loader); } catch (ClassNotFoundException x) { fail(service, &quot;Provider &quot; + cn + &quot; not found&quot;); } if (!service.isAssignableFrom(c)) { fail(service, &quot;Provider &quot; + cn + &quot; not a subtype&quot;); } try { S p = service.cast(c.newInstance()); providers.put(cn, p); return p; } catch (Throwable x) { fail(service, &quot;Provider &quot; + cn + &quot; could not be instantiated&quot;, x); } throw new Error(); // This cannot happen } public boolean hasNext() { if (acc == null) { return hasNextService(); } else { PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() { public Boolean run() { return hasNextService(); } }; return AccessController.doPrivileged(action, acc); } } public S next() { if (acc == null) { return nextService(); } else { PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() { public S run() { return nextService(); } }; return AccessController.doPrivileged(action, acc); } } public void remove() { throw new UnsupportedOperationException(); }} 这样就把驱动加载出来了，则前面代码输出 driver: class com.mysql.jdbc.Driverloader: sun.misc.Launcher$AppClassLoader@dad5dcdriver: class com.mysql.fabric.jdbc.FabricMySQLDriverloader: sun.misc.Launcher$AppClassLoader@dad5dc当前线程上下文类加载器: sun.misc.Launcher$AppClassLoader@dad5dcServiceLoader的类加载器: null 如果我们把前面代码改一下，设置当前线程的上下文类加载器为扩展类加载器 public class MyTest26 { public static void main(String[] args) { // 把当前线程设置为扩展类加载器 Thread.currentThread().setContextClassLoader(MyTest26.class.getClassLoader().getParent()); ServiceLoader&lt;Driver&gt; serviceLoader = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; iterator = serviceLoader.iterator(); while(iterator.hasNext()){ Driver driver = iterator.next(); System.out.println(&quot;driver: &quot;+driver.getClass() + &quot;loader: &quot;+ driver.getClass().getClassLoader() ); } System.out.println(&quot;当前线程上下文类加载器: &quot; + Thread.currentThread().getContextClassLoader()); System.out.println(&quot;ServiceLoader的类加载器: &quot;+ServiceLoader.class.getClassLoader()); }} 则输出 当前线程上下文类加载器: sun.misc.Launcher$ExtClassLoader@a14482ServiceLoader的类加载器: null 可以看到循环没有去执行，上下文类加载器是扩展类加载器没啥问题，因为系统类加载器的上级是扩展类加载器，但是为什么循环是空的呢？原因就是扩展类加载器无法加载 classpath下边的类，mysql 的 jar 包是放在 classpath下边的。","link":"/2019/01/29/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"Python零基础入门笔记","text":"学习python有一年多了，希望通过学习笔记来复习了，也能让后来者少走一点弯路。在课程笔记的同时加入了一部分自己的经验补充。 [√] 廖雪峰老师在慕课网的课程: Python入门 Python的初次体验python语言介绍全世界有几百种编程语言，但是流行的只有十几种，python就是其中一种。荷兰人龟叔于1989年圣诞节创立。 特点：优雅，明确，简单。 适合的领域： web网站和各种网络服务； 系统工具和脚本； 作为胶水语言把其他语言开发的模块包装起来方便使用。 Python是一门高级语言，所以不适合贴近硬件的代码: 比如驱动程序（首选C） 移动开发，有各自的语言，（objectC，swift/java） 游戏开发（首选C/C++）。 Python实际应用： YouTube，豆瓣，搜狐邮箱；Openstack开源云计算平台。Google，Yahoo，NASA。 语言之间的对比： C编译为机器码；JAVA编译为字节码；python为解释执行。 缺点： 运行慢，Python源码不能加密。 Python版本的选择博主建议选择安装环境篇的进阶版：2.7版本与3.x版本共存。 3.x版本建议选择Python 3.5.1 |Anaconda 4.1.0 (64-bit)以后如果要使用python进行TensorFlow windows版的配置可以省下时间。 windows下安装python参考：搭建Python开发环境 第一个python程序cmd下输入python。进入交互式环境。 命令行模式启动python:python 命令行模式执行python文件python 目录/xxx.py 命令行模式关闭python：exit() 注意：不要使用word，或者windows下自带的记事本来进行代码编写。 推荐使用： 轻量级：sublime Text 或 editplus 重量级(较大工程) : pycharm Professional 2.7版本专属： print 'hello,world!' 3.x版本(2.7版本也可以正常运行)： print (&quot;hello,world!&quot;) Python变量和数据类型 讲解Python基本的数据类型.包括整数、浮点数、字符串和布尔类型，以及变量的概念和基本的数据运算。 数据类型整数在Python程序中，整数的表示方法和数学上的写法一模一样. 例如：1，100，-8080，0，等等。十六进制用0x前缀和0-9，a-f表示. 例如：0xff00，0xa5b4c3d2，等等。 浮点数浮点数也就是小数，之所以称为浮点数: 因为按照科学记数法表示时，一个浮点数的小数点位置是可变的 比如，1.23x10^9和12.3x10^8是相等的。 浮点数可以用数学写法: 如1.23，3.14，-9.01，等等。但是对于很大或很小的浮点数，就必须用科学计数法表示，把10用e替代，1.23x10^9就是1.23e9，或者12.3e8，0.000012可以写成1.2e-5，等等。 整数和浮点数在计算机内部存储的方式是不同的，整数运算永远是精确的（除法难道也是精确的？是的！），而浮点数运算则可能会有四舍五入的误差。 知识点：python2与3不同整除 python2.7下：/ 和 // 都是整数除法。 例: 1/2结果为0.后面小数部分会直接去除掉。 python3.x下： / 为浮点数除法(如：1/2=0.5) //为整数除法(如: 1//2 = 0） a = 1 b = 2print a+b#python2.7下想要浮点数除法就得使用类型转换。print float(a)/b 字符串字符串是以’’或””括起来的任意文本，比如’abc’，”xyz”等等。请注意，’’或””本身只是一种表示方式，不是字符串的一部分. 因此，字符串’abc’只有a，b，c这3个字符。 布尔值布尔值和布尔代数的表示完全一致，一个布尔值只有True、False两种值，要么是True，要么是False，在Python中，可以直接用True、False表示布尔值（请注意大小写），也可以通过布尔运算计算出来。 布尔值可以用and、or和not运算。 and运算是与运算，只有所有都为 True，and运算结果才是 True。 or运算是或运算，只要其中有一个为 True，or 运算结果就是 True。 not运算是非运算，它是一个单目运算符，把 True 变成 False，False 变成 True。 空值空值是Python里一个特殊的值，用None表示。 None不能理解为0，因为0是有意义的，而None是一个特殊的空值。 编程小任务： 计算十进制整数 45678 和十六进制整数 0x12fd2 之和。 请用字符串表示出Learn Python in imooc。 请计算以下表达式的布尔值（注意==表示判断是否相等）：100 &lt; 990xff == 255 题目答案： print 45678+0x12fd2print &quot;Learn Python in imooc&quot; print 100&lt;99 print 0xff == 255 运行结果： 123456Learn Python in imoocFalseTrue print语句print语句可以向屏幕上输出指定的文字。比如输出’hello, world’，用代码实现如下： print 'hello, world' 注意： 当我们在Python交互式环境下编写代码时，&gt;&gt;&gt;是Python解释器的提示符，不是代码的一部分。 当我们在文本编辑器中编写代码时，千万不要自己添加 &gt;&gt;&gt;。 print语句也可以跟上多个字符串，用逗号,隔开，就可以连成一串输出： print 'The quick brown fox', 'jumps over', 'the lazy dog' 运行结果： The quick brown fox jumps over the lazy dog print会依次打印每个字符串，知识点：遇到逗号,会输出一个空格. print也可以打印整数，或者计算结果： &gt;&gt;&gt; print 300300 #运行结果&gt;&gt;&gt; print 100 + 200300 #运行结果 漂亮做法： &gt;&gt;&gt; print '100 + 200 =', 100 + 200100 + 200 = 300 #运行结果 注意: 对于100 + 200，Python解释器自动计算出结果300.但是，’100 + 200 =’是字符串而非数学公式，Python把它视为字符串. 编程任务：请用两种方式打印出 hello, python.实现代码： #input codeprint 'hello, python.'print 'hello,','python.' 运行结果： hello, python.hello, python. 注释Python的注释以#开头，后面的文字直到行尾都算注释 # 这一行全部都是注释...print 'hello' # 这也是注释# 暂时不想运行下面一行代码:# print 'hello, python.' 注释还有一个巧妙的用途，就是一些代码我们不想运行，但又不想删除，就可以用注释暂时屏蔽掉： 编程任务:将代码编辑器中的 “print ‘hello’” 语句修改成注释语句 实现代码： # print 'hello' 注释：多行注释'''下面是一行被注释代码下面是两行被注释代码''' 什么是变量在Python中，变量的概念基本上和初中代数的方程变量是一致的。 例如，对于方程式y=x*x ，x就是变量。 当x=2时，计算结果是4。当x=5时，计算结果是25。 只是在计算机程序中，变量不仅可以是数字，还可以是任意数据类型。 在Python程序中，变量是用一个变量名表示。 知识点：变量名必须是大小写英文、数字和下划线 _ 的组合，且不能用数字开头。比如： a = 1t_007 = 'T007' 变量a是一个整数。变量t_007是一个字符串。 在Python中，等号=是赋值语句，可以把任意数据类型赋值给变量，同一个变量可以反复赋值，而且可以是不同类型的变量，例如： a = 123 # a是整数print aa = 'imooc' # a变为字符串print a 知识点: 这种变量本身类型不固定的语言称之为动态语言，与之对应的是静态语言。 静态语言在定义变量时必须指定变量类型，如果赋值的时候类型不匹配，就会报错。例如Java是静态语言，赋值语句如下（// 表示注释）： //这些是java代码int a = 123; // a是整数类型变量a = &quot;mooc&quot;; // 错误：不能把字符串赋给整型变量 和静态语言相比，动态语言更灵活，就是这个原因。请不要把赋值语句的等号等同于数学的等号。比如下面的代码： x = 10x = x + 2 如果从数学上理解x = x + 2那无论如何是不成立的. 在程序中，赋值语句先计算右侧的表达式x + 2，得到结果12，再赋给变量x。由于x之前的值是10，重新赋值后，x的值变成12。 最后，知识点: 理解变量在计算机内存中的表示也非常重要。当我们写：a = ‘ABC’时，Python解释器干了两件事情： 在内存中创建了一个’ABC’的字符串； 在内存中创建了一个名为a的变量，并把它指向’ABC’。 也可以把一个变量a赋值给另一个变量b，这个操作实际上是把变量b指向变量a所指向的数据，例如下面的代码： a = 'ABC'b = aa = 'XYZ'print b 最后一行打印出变量b的内容到底是’ABC’呢还是’XYZ’？如果从数学意义上理解，就会错误地得出b和a相同，也应该是’XYZ’，但实际上b的值是’ABC’，让我们一行一行地执行代码，就可以看到到底发生了什么事： 执行a = 'ABC'，解释器创建了字符串 'ABC'和变量 a，并把a指向 'ABC'： 执行b = a，解释器创建了变量 b，并把b指向 a 指向的字符串'ABC'： 执行a = 'XYZ'，解释器创建了字符串'XYZ'，并把a的指向改为’XYZ’，但b并没有更改： 所以，最后打印变量b的结果自然是’ABC’了。 编程任务： 等差数列可以定义为每一项与它的前一项的差等于一个常数，可以用变量 x1 表示等差数列的第一项，用 d 表示公差，请计算数列 1 4 7 10 13 16 19 … 前 100 项的和。 实现代码: x1 = 1d = 3n = 100x100 = x1+(100-1)*ds2 = (x1+x100)*100/2s = n*x1+n*(n-1)*d/2print s,s2 等差数列公式： （首项+尾项）*项数/2 项数*首项+项数*(项数-1)*公差/2 运行结果： 14950 14950 定义字符串字符串可以用''或者&quot;&quot;括起来表示。 如果字符串本身包含'怎么办？比如我们要表示字符串 I'm OK ，这时，可以用&quot; &quot;括起来表示： &quot;I'm OK&quot;'Learn &quot;Python&quot; in imooc' 类似的，知识点: 如果字符串包含&quot;，我们就可以用' '括起来表示： 如果字符串既包含'又包含&quot;怎么办？ 知识点：转义 这个时候，就需要对字符串的某些特殊字符进行**转义**，Python字符串用\\进行转义。 要表示字符串 Bob said &quot;I'm OK&quot;.由于 ' 和&quot;会引起歧义，因此，我们在它前面插入一个\\表示这是一个普通字符，不代表字符串的起始，因此，这个字符串又可以表示为 'Bob said \\&quot;I\\'m OK\\&quot;.'# 在要保留原状的字符串前面加上右斜杠 注意：转义字符 \\不计入字符串的内容中。 常用的转义字符还有： \\n表示换行 \\t 表示一个制表符 \\\\ 表示 \\ 字符本身 编程任务： 请将下面两行内容用Python的字符串表示并打印出来： Python was started in 1989 by &quot;Guido&quot;. Python is free and easy to learn. s = 'Python was started in 1989 by&quot;Guido&quot;.\\nPython is free and easy to learn.'print s raw字符串与多行字符串如果一个字符串包含很多需要转义的字符，对每一个字符都进行转义会很麻烦。为了避免这种情况，我们可以在字符串前面加个前缀 r ，表示这是一个 raw 字符串，里面的字符就不需要转义了。例如： r'\\(~_~)/ \\(~_~)/' 解释： 这个例子举得不是很好。可以看出raw加上之后。可能产生误会的\\被修改为\\\\(\\\\ 表示 \\ 字符本身) 不加上r 只有\\和(并没有合成转义字符。 加上r。\\需要被转义，经过转义后显示出来还是自己。 知识点: 个人小题(r的强大作用) 上图效果可以看出r的强大作用。 但是r'我是一段字符'表示法不能表示多行字符串(r'''一段字符''')，也不能表示包含'和 &quot;的字符串（为什么？） 因为如果r'mtian'yan' r遇到左边第一个',会继续往后找闭合的标志'然后找到mtian的地方。它任务结束了。代码继续往下执行。当扫到yan这里他就会报错。 ???(更深层待续) 或者r&quot;mtian&quot;yan&quot; 或导致r提前结束掉。后面的就无法继续匹配到对应的。 知识点: 多行字符串，可以用'''...'''表示： '''Line 1Line 2Line 3'''#上面这个字符串的表示方法和下面的是完全一样的：'Line 1\\nLine 2\\nLine 3' 还可以在多行字符串前面添加 r ，把这个多行字符串也变成一个raw字符串： r'''Python is created by &quot;Guido&quot;.It is free and easy to learn.Let's start learn Python in imooc!''' 编程任务：请把下面的字符串用r'''...'''的形式改写，并用print打印出来： '\\&quot;To be, or not to be\\&quot;: that is the question.\\nWhether it\\'s nobler in the mind to suffer.' print r'''&quot;To be,or not to be&quot;:that is the question.Whether it's nobler in the mind to suffer.''' 知识点: Unicode字符串字符串还有一个编码问题。 因为计算机只能处理数字，如果要处理文本，就必须先把文本转换为数字才能处理。最早的计算机在设计时采用8个比特（bit）作为一个字节（byte），所以，一个字节能表示的最大的整数就是255（二进制11111111=十进制255），0 - 255被用来表示大小写英文字母、数字和一些符号，这个编码表被称为ASCII编码，比如大写字母 A 的编码是65，小写字母 z 的编码是122。 如果要表示中文，显然一个字节是不够的，至少需要两个字节，而且还不能和ASCII编码冲突，所以，中国制定了GB2312编码，用来把中文编进去。 类似的，日文和韩文等其他语言也有这个问题。为了统一所有文字的编码，Unicode应运而生。Unicode把所有语言都统一到一套编码里，这样就不会再有乱码问题了。 Unicode通常用两个字节表示一个字符，原有的英文编码从单字节变成双字节，只需要把高字节全部填为0就可以。 因为Python的诞生比Unicode标准发布的时间还要早，所以最早的Python只支持ASCII编码，普通的字符串’ABC’在Python内部都是ASCII编码的。 Python在后来添加了对Unicode的支持，以Unicode表示的字符串用u’…’表示，比如： print u'中文'中文注意: 不加 u ，中文就不能正常显示。(这个应该是很早版本才会。笔者现在已经无法复现) 转载: http://blog.csdn.net/lxdcyh/article/details/4018054 字符串在Python内部的表示是unicode编码，因此，在做编码转换时，通常需要以unicode作为中间编码，即先将其他编码的字符串解码decode成unicode，再从unicode编码encode成另一种编码。 decode的作用是将其他编码的字符串转换成unicode编码，如str1.decode('gb2312')，表示将gb2312编码的字符串str1转换成unicode编码。 encode的作用是将unicode编码转换成其他编码的字符串，如str2.encode(‘gb2312’)，表示将unicode编码的字符串str2转换成gb2312编码 代码中字符串的默认编码与代码文件本身的编码一致。 如：s=’中文’ 如果是在utf8的文件中，该字符串就是utf8编码，如果是在gb2312的文件中，则其编码为gb2312。这种情况下，要进行编码转换，都需要先用decode方法将其转换成unicode编码，再使用encode方法将其转换成其他编码。通常，在没有指定特定的编码方式时，都是使用的系统默认编码创建的代码文件 如果字符串是这样定义：s=u’中文’ 则该字符串的编码就被指定为unicode了，即python的内部编码，而与代码文件本身的编码无关。因此，对于这种情况做编码转换，只需要直接使用encode方法将其转换成指定编码即可。 如果一个字符串已经是unicode了，再进行解码则将出错，因此通常要对其编码方式是否为unicode进行判断： isinstance(s, unicode) #用来判断是否为unicode 用非unicode编码形式的str来encode会报错 如何获得系统的默认编码？ #!/usr/bin/env python#coding=utf-8import sysprint sys.getdefaultencoding() 该段程序在Win10(1079)上输出为：ascii 在某些IDE中，字符串的输出总是出现乱码，甚至错误，其实是由于IDE的结果输出控制台自身不能显示字符串的编码，而不是程序本身的问题。 如在UliPad(注:UliPad是wxPython的动力，导向和灵活的编程器)中运行如下代码： s=u&quot;中文&quot;print s 会提示：UnicodeEncodeError: ‘ascii’ codec can’t encode characters in position 0-1: ordinal not in range(128)。这是因为UliPad在控制台信息输出窗口是按照ascii编码输出的（系统的默认编码是ascii），而上面代码中的字符串是Unicode编码的，所以输出时产生了错误。 将最后一句改为：print s.encode('gb2312') 则能正确输出“中文”两个字。 若最后一句改为：print s.encode('utf8') 则输出：/xe4/xb8/xad/xe6/x96/x87，这是控制台信息输出窗口按照ascii编码输出utf8编码的字符串的结果。 unicode(str,'gb2312')与str.decode('gb2312')是一样的，都是将gb2312编码的str转为unicode编码 使用str.__class__可以查看str的编码形式为str类型。 window默认编码gbk；linux默认编码utf8 原理说了半天，最后来个包治百病的吧：(天涯)：下面代码 #!/usr/bin/env python #coding=utf-8def getCoding(strInput): ''' 获取编码格式 ''' if isinstance(strInput, unicode): return &quot;unicode&quot; try: strInput.decode(&quot;utf8&quot;) return 'utf8' except: pass try: strInput.decode(&quot;gbk&quot;) return 'gbk' except: pass def tran2UTF8(strInput): ''' 转化为utf8格式 ''' strCodingFmt = getCoding(strInput) if strCodingFmt == &quot;utf8&quot;: return strInput elif strCodingFmt == &quot;unicode&quot;: return strInput.encode(&quot;utf8&quot;) elif strCodingFmt == &quot;gbk&quot;: return strInput.decode(&quot;gbk&quot;).encode(&quot;utf8&quot;)def tran2GBK(strInput): ''' 转化为gbk格式 ''' strCodingFmt = getCoding(strInput) if strCodingFmt == &quot;gbk&quot;: return strInput elif strCodingFmt == &quot;unicode&quot;: return strInput.encode(&quot;gbk&quot;) elif strCodingFmt == &quot;utf8&quot;: return strInput.decode(&quot;utf8&quot;).encode(&quot;gbk&quot;)s = &quot;中文&quot;if isinstance(s, unicode): #s=u&quot;中文&quot; print s.encode('gb2312') print &quot;我是Unicode编码的&quot;elif getCoding(s) == &quot;utf8&quot;: #s=&quot;中文&quot; print s.decode('utf-8').encode('gb2312') print &quot;我是utf-8编码的&quot;else: print s.decode('gbk').encode('gbk') print &quot;我是gbk编码的&quot; 上图结果一：以utf-8格式保存的py文件。图二：以ascii格式保存的py文件。 编码检测包 chardet 知识点：因此，转码的时候一定要先搞明白，字符串str是什么编码，然后decode成unicode，然后再encode成其他编码 插入数据库报错的解决方案:UnicodeDecodeError: ‘ascii’ codec can’t decode byte import sysreload(sys)sys.setdefaultencoding('utf8') Unicode字符串除了多了一个 u 之外，与普通字符串没啥区别，转义字符和多行表示法仍然有效： 转义： u'中文\\n日文\\n韩文'#多行：u'''第一行第二行'''#raw+多行：ur'''Python的Unicode字符串支持&quot;中文&quot;,&quot;日文&quot;,&quot;韩文&quot;等多种语言''' 如果中文字符串在Python环境下遇到 UnicodeDecodeError，这是因为.py文件保存的格式有问题。可以在第一行添加注释 # -*- coding: utf-8 -*-#简洁版#coding=utf-8 目的是告诉Python解释器，用UTF-8编码读取源代码。然后用Notepad++ 另存为… 并选择UTF-8格式保存。 编程任务：用多行Unicode字符串表示下面的唐诗并打印： 静夜思 床前明月光，疑是地上霜。举头望明月，低头思故乡。 知识点: https://www.python.org/dev/peps/pep-0263/ python定义文件编码到底用哪种？ # coding=&lt;encoding name&gt; #!/usr/bin/python# -*- coding: &lt;encoding name&gt; -*-#!/usr/bin/python# vim: set fileencoding=&lt;encoding name&gt; : 这些都可以只要第一二行能满足如下正则表达式 ^[ \\t\\v]*#.*?coding[:=][ \\t]*([-_.a-zA-Z0-9]+) # -*- coding: utf-8 -*-# This Python file uses the following encoding: utf-8# 花式标明print '''静夜思床前明月光，疑是地上霜。举头望明月，低头思故乡。''' 如果不标明文件编码或找不到。python会默认你是ASCII 整数和浮点数Python支持对整数和浮点数直接进行四则混合运算，运算规则和数学上的四则运算规则完全一致。 基本的运算： 1 + 2 + 3 # ==&gt; 64 * 5 - 6 # ==&gt; 147.5 / 8 + 2.1 # ==&gt; 3.0375 使用括号可以提升优先级，这和数学运算完全一致，注意只能使用小括号，但是括号可以嵌套很多层： (1 + 2) * 3 # ==&gt; 9(2.2 + 3.3) / (1.5 * (9 - 0.3)) # ==&gt; 0.42145593869731807 和数学运算不同的地方是，Python的整数运算结果仍然是整数，浮点数运算结果仍然是浮点数： 1 + 2 # ==&gt; 整数 31.0 + 2.0 # ==&gt; 浮点数 3.0 但是整数和浮点数混合运算的结果就变成浮点数了： 1 + 2.0 # ==&gt; 浮点数 3.0 为什么要区分整数运算和浮点数运算呢？ 这是因为整数运算的结果永远是精确的，而浮点数运算的结果不一定精确，因为计算机内存再大，也无法精确表示出无限循环小数，比如 0.1 换成二进制表示就是无限循环小数。 那整数的除法运算遇到除不尽的时候，结果难道不是浮点数吗？我们来试一下： 11 / 4 # ==&gt; 2 令很多初学者惊讶的是，Python的整数除法，即使除不尽，结果仍然是整数，余数直接被扔掉。不过，Python提供了一个求余的运算 % 可以计算余数： 11 % 4 # ==&gt; 3 如果我们要计算 11 / 4 的精确结果，按照“整数和浮点数混合运算的结果是浮点数”的法则，把两个数中的一个变成浮点数再运算就没问题了： 11.0 / 4 # ==&gt; 2.75 编程任务：请计算 2.5 + 10 / 4 ,并解释计算结果为什么不是期望的 5.0 ? 请修复上述运算，使得计算结果是 5.0 print 2.5 + 10.0 / 4 运行结果： 5.0 布尔类型我们已经了解了Python支持布尔类型的数据，布尔类型只有True和False两种值，但是布尔类型有以下几种运算： 与运算：只有两个布尔值都为 True 时，计算结果才为 True。 True and True # ==&gt; TrueTrue and False # ==&gt; FalseFalse and True # ==&gt; FalseFalse and False # ==&gt; False 或运算：只要有一个布尔值为 True，计算结果就是 True。 True or True # ==&gt; TrueTrue or False # ==&gt; TrueFalse or True # ==&gt; TrueFalse or False # ==&gt; False 非运算：把True变为False，或者把False变为True： not True # ==&gt; Falsenot False # ==&gt; True 布尔运算在计算机中用来做条件判断，根据计算结果为True或者False，计算机可以自动执行不同的后续代码。 在Python中，布尔类型还可以与其他数据类型做 and、or和not运算，请看下面的代码： 知识点：Python把0、空字符串’’和None看成 False，其他数值和非空字符串都看成 True。短路运算 a = Trueprint a and 'a=T' or 'a=F' 计算结果不是布尔类型，而是字符串 'a=T'，这是为什么呢？ 因为Python把0、空字符串’’和None看成 False，其他数值和非空字符串都看成 True，所以： True and ‘a=T’ 计算结果是 ‘a=T’继续计算 ‘a=T’ or ‘a=F’ 计算结果还是 ‘a=T’要解释上述结果，又涉及到 and 和 or 运算的一条重要法则：短路计算。 在计算 a and b 时，如果 a 是 False，则根据与运算法则，整个结果必定为 False，因此返回 a；如果 a 是 True，则整个计算结果必定取决与 b，因此返回 b。 在计算 a or b 时，如果 a 是 True，则根据或运算法则，整个计算结果必定为 True，因此返回 a；如果 a 是 False，则整个计算结果必定取决于 b，因此返回 b。 所以Python解释器在做布尔运算时，只要能提前确定计算结果，它就不会往后算了，直接返回结果。 编码任务：请运行如下代码，并解释打印的结果： a = 'python'print 'hello,', a or 'world'b = ''print 'hello,', b or 'world' # -*- coding: utf-8 -*-a = 'python'print 'hello,', a or 'world'#a为非空，则输出ab = ''#b为空，输出worldprint 'hello,', b or 'world' 运行结果： hello, pythonhello, world Python集合类型:list和tuple创建listPython内置的一种数据类型是列表：list。list是一种有序的集合，可以随时添加和删除其中的元素。 比如，列出班里所有同学的名字，就可以用一个list表示： &gt;&gt;&gt; ['Michael', 'Bob', 'Tracy']['Michael', 'Bob', 'Tracy'] list是数学意义上的有序集合，也就是说，list中的元素是按照顺序排列的。 构造list非常简单，按照上面的代码，直接用 [ ] 把list的所有元素都括起来，就是一个list对象。通常，我们会把list赋值给一个变量，这样，就可以通过变量来引用list： &gt;&gt;&gt; classmates = ['Michael', 'Bob', 'Tracy']&gt;&gt;&gt; classmates # 打印classmates变量的内容['Michael', 'Bob', 'Tracy'] 由于Python是动态语言，所以list中包含的元素并不要求都必须是同一种数据类型，我们完全可以在list中包含各种数据： &gt;&gt;&gt; L = ['Michael', 100, True] 一个元素也没有的list，就是空list： &gt;&gt;&gt; empty_list = [] 编程任务 假设班里有3名同学：Adam，Lisa和Bart，他们的成绩分别是 95.5，85 和 59，请按照 名字, 分数, 名字, 分数… 的顺序按照分数从高到低用一个list表示，然后打印出来。 L = ['Adam', 95.5,'Lisa', 85, 'Bart', 59]print L 运行结果: ['Adam', 95.5, 'Lisa', 85, 'Bart', 59] 注：list本身就是有序的。所以直接打印即可。 Python按照索引访问list由于list是一个有序集合，所以，我们可以用一个list按分数从高到低表示出班里的3个同学： &gt;&gt;&gt; L = ['Adam', 'Lisa', 'Bart'] 那我们如何从list中获取指定第 N 名的同学呢？方法是通过索引来获取list中的指定元素。 需要特别注意的是，索引从 0 开始，也就是说，第一个元素的索引是0，第二个元素的索引是1，以此类推。 因此，要打印第一名同学的名字，用 L[0]: &gt;&gt;&gt; print L[0]Adam#要打印第二名同学的名字，用 L[1]:&gt;&gt;&gt; print L[1]Lisa#要打印第三名同学的名字，用 L[2]:&gt;&gt;&gt; print L[2]Bart 要打印第四名同学的名字，用 L[3]: &gt;&gt;&gt; print L[3]Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;IndexError: list index out of range 报错了！IndexError意思就是索引超出了范围，因为上面的list只有3个元素，有效的索引是 0，1，2。 所以，使用索引时，千万注意不要越界。 编程任务 三名同学的成绩可以用一个list表示：L = [95.5, 85, 59] 请按照索引分别打印出第一名、第二名、第三名，同时测试 print L[3]。 实现代码： L = [95.5,85,59]print L[0]print L[1]print L[2]print L[3] 运行结果： Traceback (most recent call last): File &quot;index.py&quot;, line 5, in print L[3]IndexError: list index out of range95.58559 知识点：正序从0开始，逆序从-1开始是最好一个list内容。 当索引数字为负数时，表示逆序读出List中的内容，记住List的最后一个空间的编号为-1开始 倒序访问list我们还是用一个list按分数从高到低表示出班里的3个同学： &gt;&gt;&gt; L = ['Adam', 'Lisa', 'Bart'] 这时，老师说，请分数最低的同学站出来。 要写代码完成这个任务，我们可以先数一数这个 list，发现它包含3个元素，因此，最后一个元素的索引是2： &gt;&gt;&gt; print L[2]Bart Bart同学是最后一名，俗称倒数第一，所以，我们可以用 -1 这个索引来表示最后一个元素： &gt;&gt;&gt; print L[-1]Bart Bart同学表示躺枪。 类似的，倒数第二用 -2 表示，倒数第三用 -3 表示，倒数第四用 -4 表示： &gt;&gt;&gt; print L[-2]Lisa&gt;&gt;&gt; print L[-3]Adam&gt;&gt;&gt; print L[-4]Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;IndexError: list index out of rangeL[-4] 报错了，因为倒数第四不存在，一共只有3个元素。 使用倒序索引时，也要注意不要越界。 编程任务 三名同学的成绩可以用一个list表示：L = [95.5, 85, 59] 请按照倒序索引分别打印出倒数第一、倒数第二、倒数第三。 实现代码： L = [95.5, 85, 59]print L[-1]print L[-2]print L[-3]print L[-4] 运行结果： Traceback (most recent call last): File &quot;index.py&quot;, line 5, in print L[-4]IndexError: list index out of range598595.5 list添加新元素(append insert)现在，班里有3名同学： &gt;&gt;&gt; L = ['Adam', 'Lisa', 'Bart'] 今天，班里转来一名新同学 Paul，如何把新同学添加到现有的 list 中呢？ 第一个办法是用 list 的 append() 方法，把新同学追加到 list 的末尾： &gt;&gt;&gt; L = ['Adam', 'Lisa', 'Bart']&gt;&gt;&gt; L.append('Paul')&gt;&gt;&gt; print L['Adam', 'Lisa', 'Bart', 'Paul'] append()总是把新的元素添加到 list 的尾部。 如果 Paul 同学表示自己总是考满分，要求添加到第一的位置，怎么办？ 方法是用list的 insert()方法，它接受两个参数，第一个参数是索引号，第二个参数是待添加的新元素： &gt;&gt;&gt; L = ['Adam', 'Lisa', 'Bart']&gt;&gt;&gt; L.insert(0, 'Paul')&gt;&gt;&gt; print L['Paul', 'Adam', 'Lisa', 'Bart'] L.insert(0, 'Paul') 的意思是，’Paul’将被添加到索引为 0 的位置上（也就是第一个），而原来索引为 0 的Adam同学，以及后面的所有同学，都自动向后移动一位。 编程任务 假设新来一名学生Paul，Paul 同学的成绩比Bart好，但是比Lisa差，他应该排到第三名的位置，请用代码实现。 代码实现: L = ['Adam', 'Lisa', 'Bart']L.insert(2,'paul')print L 运行结果: ['Adam', 'Lisa', 'paul', 'Bart'] 正向第三名索引号为2.倒数第三名索引号为-3 list删除元素(pop)Paul同学刚来几天又要转走了，那么我们怎么把Paul 从现有的list中删除呢？ 如果Paul同学排在最后一个，我们可以用list的pop()方法删除： &gt;&gt;&gt; L = ['Adam', 'Lisa', 'Bart', 'Paul']&gt;&gt;&gt; L.pop()'Paul'&gt;&gt;&gt; print L['Adam', 'Lisa', 'Bart'] pop()方法总是删掉list的最后一个元素，并且它还返回这个元素，所以我们执行 L.pop() 后，会打印出 ‘Paul’。 如果Paul同学不是排在最后一个怎么办？比如Paul同学排在第三： &gt;&gt;&gt; L = ['Adam', 'Lisa', 'Paul', 'Bart'] 要把Paul踢出list，我们就必须先定位Paul的位置。由于Paul的索引是2，因此，用 pop(2)把Paul删掉： &gt;&gt;&gt; L.pop(2)'Paul'&gt;&gt;&gt; print L['Adam', 'Lisa', 'Bart'] 两种方式：直接pop()默认删除第一个，括号内指定参数：索引，删除索引位置上。 编码任务L = ['Adam', 'Lisa', 'Paul', 'Bart'] Paul的索引是2，Bart的索引是3，如果我们要把Paul和Bart都删掉，请解释下面的代码为什么不能正确运行： L.pop(2)L.pop(3) 怎样调整代码可以把Paul和Bart都正确删除掉？ 解释：因为语句是按顺序执行的删除了Paul之后。索引号3已经越界。我们要删除的Bart已经变成2了。 知识点：这教育我们删除list时要秉着从前到后顺序。 List替换元素假设现在班里仍然是3名同学： &gt;&gt;&gt; L = ['Adam', 'Lisa', 'Bart'] 现在，Bart同学要转学走了，碰巧来了一个Paul同学，要更新班级成员名单，我们可以先把Bart删掉，再把Paul添加进来。 另一个办法是直接用Paul把Bart给替换掉： &gt;&gt;&gt; L[2] = 'Paul'&gt;&gt;&gt; print LL = ['Adam', 'Lisa', 'Paul'] 对list中的某一个索引赋值，就可以直接用新的元素替换掉原来的元素，list包含的元素个数保持不变。 由于Bart还可以用 -1 做索引，因此，下面的代码也可以完成同样的替换工作： &gt;&gt;&gt; L[-1] = 'Paul' 编程任务 班里的同学按照分数排名是这样的：L = [‘Adam’, ‘Lisa’, ‘Bart’]但是，在一次考试后，Bart同学意外取得第一，而Adam同学考了倒数第一。 请通过对list的索引赋值，生成新的排名。 实现代码： L = ['Adam', 'Lisa', 'Bart']L[0]='Bart'L[-1]='Adam'print L 运行结果： ['Bart', 'Lisa', 'Adam'] 创建tupletuple是另一种有序的列表，中文翻译为“ 元组 ”。tuple 和 list 非常类似，但是，知识点：tuple一旦创建完毕，就不能修改了。 同样是表示班里同学的名称，用tuple表示如下： &gt;&gt;&gt; t = ('Adam', 'Lisa', 'Bart') 创建tuple和创建list唯一不同之处是用( )替代了[ ]。 现在，这个 t 就不能改变了，tuple没有 append()方法，也没有insert()和pop()方法。所以，新同学没法直接往 tuple 中添加，老同学想退出 tuple 也不行。 获取 tuple 元素的方式和 list 是一模一样的，我们可以正常使用 t[0]，t[-1]等索引方式访问元素，但是不能赋值成别的元素，不信可以试试： &gt;&gt;&gt; t[0] = 'Paul'Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: 'tuple' object does not support item assignment 编程任务 创建一个tuple，顺序包含0 - 9这10个数。 实现代码： t = (0,1,2,3,4,5,6,7,8,9)print t 运行结果： (0, 1, 2, 3, 4, 5, 6, 7, 8, 9) 创建单元素tupletuple和list一样，可以包含 0 个、1个和任意多个元素。 包含多个元素的 tuple，前面我们已经创建过了。 包含 0 个元素的 tuple，也就是空tuple，直接用 ()表示： &gt;&gt;&gt; t = ()&gt;&gt;&gt; print t() 创建包含1个元素的 tuple 呢？来试试： &gt;&gt;&gt; t = (1)&gt;&gt;&gt; print t1 好像哪里不对！t 不是 tuple ，而是整数1。为什么呢？ 知识点：单元素tuple的()被当做优先级。(1)变成整数1.单元素括号结尾加, 因为()既可以表示tuple，又可以作为括号表示运算时的优先级，结果 (1) 被Python解释器计算出结果 1，导致我们得到的不是tuple，而是整数 1。 正是因为用()定义单元素的tuple有歧义，所以 Python 规定，单元素 tuple 要多加一个逗号,，这样就避免了歧义： &gt;&gt;&gt; t = (1,)&gt;&gt;&gt; print t(1,) Python在打印单元素tuple时，也自动添加了一个,，为了更明确地告诉你这是一个tuple。 多元素 tuple 加不加这个额外的,效果是一样的： &gt;&gt;&gt; t = (1, 2, 3,)&gt;&gt;&gt; print t(1, 2, 3) 编程任务下面代码为什么没有创建出包含一个学生的 tuple： t = ('Adam')print t 请修改代码，确保 t 是一个tuple。 因为单元素tuple的括号被当做是优先级标志。要加上额外,标识这是一个元组。 实现代码： t = ('Adam',)print t 运行结果: ('Adam',) “可变”的tuple(指向不变。指向的东西可以变)前面我们看到了tuple一旦创建就不能修改。现在，我们来看一个可变的tuple： &gt;&gt;&gt; t = ('a', 'b', ['A', 'B']) 注意到 t 有 3 个元素：'a'，'b'和一个list：['A', 'B']。list作为一个整体是tuple的第3个元素。list对象可以通过 t[2] 拿到： &gt;&gt;&gt; L = t[2]# 然后，我们把list的两个元素改一改：&gt;&gt;&gt; L[0] = 'X'&gt;&gt;&gt; L[1] = 'Y' 再看看tuple的内容： &gt;&gt;&gt; print t('a', 'b', ['X', 'Y']) 不是说tuple一旦定义后就不可变了吗？怎么现在又变了？ 别急，我们先看看定义的时候tuple包含的3个元素： 当我们把list的元素’A’和’B’修改为’X’和’Y’后，tuple变为： 表面上看，tuple的元素确实变了，但其实变的不是 tuple 的元素，而是list的元素。 tuple一开始指向的list并没有改成别的list，所以，tuple所谓的“不变”是说，tuple的每个元素，指向永远不变。即指向’a’，就不能改成指向’b’，指向一个list，就不能改成指向其他对象，但指向的这个list本身是可变的！ 理解了指向不变后，要创建一个内容也不变的tuple怎么做？那就必须保证tuple的每一个元素本身也不能变。 编程任务： 定义了tuple：t = (‘a’, ‘b’, [‘A’, ‘B’]) 由于 t 包含一个list元素，导致tuple的内容是可变的。能否修改上述代码，让tuple内容不可变？ 解答：将里面的list替换成一个不可变的元素。比如tuple。 实现代码: t = ('a', 'b', ('A', 'B'))print t 运行结果： ('a', 'b', ('A', 'B')) Python的条件判断和循环语句if语句计算机之所以能做很多自动化的任务，因为它可以自己做条件判断。 比如，输入用户年龄，根据年龄打印不同的内容，在Python程序中，可以用if语句实现： age = 20if age &gt;= 18: print 'your age is', age print 'adult'print 'END' 注意: Python代码的缩进规则。具有相同缩进的代码被视为代码块，上面的3，4行 print 语句就构成一个代码块（但不包括第5行的print）。如果 if 语句判断为 True，就会执行这个代码块。 知识点: 缩进请严格按照Python的习惯写法：4个空格，不要使用Tab，更不要混合Tab和空格，否则很容易造成因为缩进引起的语法错误。 注意: if 语句后接表达式，然后用:表示代码块开始。 如果你在Python交互环境下敲代码，还要特别留意缩进，并且退出缩进需要多敲一行回车： &gt;&gt;&gt; age = 20&gt;&gt;&gt; if age &gt;= 18:... print 'your age is', age... print 'adult'... your age is 20adult 编程任务 如果成绩达到60分或以上，视为passed。 假设Bart同学的分数是75，请用if语句判断是否能打印出 passed: 实现代码: score = 75if score&gt;=60: print 'passed' 运行结果: passed if-else当 if 语句判断表达式的结果为 True 时，就会执行 if 包含的代码块： if age &gt;= 18: print 'adult' 如果我们想判断年龄在18岁以下时，打印出 ‘teenager’，怎么办？ 方法是再写一个 if: if age &lt; 18: print 'teenager' 或者用 not 运算： if not age &gt;= 18: print 'teenager' 细心的同学可以发现，这两种条件判断是“非此即彼”的，要么符合条件1，要么符合条件2，因此，完全可以用一个 if ... else ... 语句把它们统一起来： if age &gt;= 18: print 'adult'else: print 'teenager' 利用 if ... else ...语句，我们可以根据条件表达式的值为 True 或者 False ，分别执行 if 代码块或者 else 代码块。 注意: else 后面有个:。 编程任务 如果成绩达到60分或以上，视为passed，否则视为failed。 假设Bart同学的分数是55，请用if语句打印出 passed 或者 failed: 实现代码： score = 55if score&gt;=60: print 'passed'else: print 'failed' 运行结果: failed if-elif-else有的时候，一个 if … else … 还不够用。比如，根据年龄的划分： 条件1：18岁或以上：adult 条件2：6岁或以上：teenager 条件3：6岁以下：kid 我们可以用一个 if age &gt;= 18 判断是否符合条件1，如果不符合，再通过一个 if 判断 age &gt;= 6 来判断是否符合条件2，否则，执行条件3： if age &gt;= 18: print 'adult'else: if age &gt;= 6: print 'teenager' else: print 'kid' 这样写出来，我们就得到了一个两层嵌套的 if … else … 语句。这个逻辑没有问题，但是，如果继续增加条件，比如3岁以下是 baby： if age &gt;= 18: print 'adult'else: if age &gt;= 6: print 'teenager' else: if age &gt;= 3: print 'kid' else: print 'baby' 这种缩进只会越来越多，代码也会越来越难看。 要避免嵌套结构的 if … else …，我们可以用 if … 多个elif … else … 的结构，一次写完所有的规则： if age &gt;= 18: print 'adult'elif age &gt;= 6: print 'teenager'elif age &gt;= 3: print 'kid'else: print 'baby' elif 意思就是 else if。这样一来，我们就写出了结构非常清晰的一系列条件判断。 特别注意: 这一系列条件判断会从上到下依次判断，如果某个判断为 True，执行完对应的代码块，后面的条件判断就直接忽略，不再执行了。 请思考下面的代码： age = 8if age &gt;= 6: print 'teenager'elif age &gt;= 18: print 'adult'else: print 'kid' 当 age = 8 时，结果正确，但 age = 20 时，为什么没有打印出 adult？ 如果要修复，应该如何修复？ 知识点解答: 因为当age=20.第一个条件&gt;=6满足就短路了。因此我们在设置条件应该从严格到松泛. age = 20if age &gt;= 18: print 'teenager'elif age &gt;= 6: print 'adult'else: print 'kid' 编程任务 如果按照分数划定结果： 90分或以上：excellent 80分或以上：good 60分或以上：passed 60分以下：failed 请编写程序根据分数打印结果。 实现代码: score = 85if score&gt;=90: print 'excellent'elif score&gt;=80: print 'good'elif score&gt;=60: print 'passed'else: print 'failed' 运行结果: good for循环list或tuple可以表示一个有序集合。如果我们想依次访问一个list中的每一个元素呢？比如 list： L = ['Adam', 'Lisa', 'Bart']print L[0]print L[1]print L[2] 如果list只包含几个元素，这样写还行，如果list包含1万个元素，我们就不可能写1万行print。 这时，循环就派上用场了。 Python的 for 循环就可以依次把list或tuple的每个元素迭代出来： L = ['Adam', 'Lisa', 'Bart']for name in L: print name 注意: name 这个变量是在 for 循环中定义的(这是一个临时变量名字可自定义)，意思是，依次取出list中的每一个元素，并把元素赋值给 name，然后执行for循环体（就是缩进的代码块）。 这样一来，遍历一个list或tuple就非常容易了。 编程任务 班里考试后，老师要统计平均成绩，已知4位同学的成绩用list表示如下：L = [75, 92, 59, 68] 请利用for循环计算出平均成绩。 实现代码: L = [75, 92, 59, 68]sum = 0.0for x in L: sum =sum+xprint sum / 4 运行结果： 73.5 while循环和 for 循环不同的另一种循环是 while 循环，while 循环不会迭代 list 或 tuple 的元素，而是根据表达式判断循环是否结束。 比如要从 0 开始打印不大于 N 的整数： N = 10x = 0while x &lt; N: print x x = x + 1 while循环每次先判断 x &lt; N，如果为True，则执行循环体的代码块,否则，退出循环。 在循环体内，x = x + 1 会让 x 不断增加，最终因为 x &lt; N 不成立而退出循环。 如果没有这一个语句，while循环在判断 x &lt; N 时总是为True，就会无限循环下去，变成死循环，所以要特别留意while循环的退出条件。 编程任务 利用while循环计算100以内奇数的和。 实现代码: sum = 0x = 1while x&lt;=100: sum=sum+x x=x+2print sum 知识点: 奇数只需要从1开始不断加2都是奇数。 运行结果： 2500 break退出循环用for 循环或者 while 循环时，如果要在循环体内直接退出循环，可以使用 break 语句。 比如计算1至100的整数和，我们用while来实现： sum = 0x = 1while True: sum = sum + x x = x + 1 if x &gt; 100: breakprint sum 咋一看， while True 就是一个死循环，但是在循环体内，我们还判断了 x &gt; 100 条件成立时，用break语句退出循环，这样也可以实现循环的结束。 编程任务 利用 while True 无限循环配合 break 语句，计算 1 + 2 + 4 + 8 + 16 + … 的前20项的和。 实现代码: sum = 0x = 1n = 1while True: sum =sum+x x =2*x n =n+1 if n &gt;20: breakprint sum 运行结果: 1048575 continue继续循环在循环过程中，可以用break退出当前循环，还可以用continue跳过后续循环代码，继续下一次循环。 假设我们已经写好了利用for循环计算平均分的代码： L = [75, 98, 59, 81, 66, 43, 69, 85]sum = 0.0n = 0for x in L: sum = sum + x n = n + 1print sum / n 现在老师只想统计及格分数的平均分，就要把 x &lt; 60 的分数剔除掉，这时，利用continue，可以做到当 x &lt; 60的时候，不继续执行循环体的后续代码，直接进入下一次循环： for x in L: if x &lt; 60: continue sum = sum + x n = n + 1 coutinue: 跳过下面的代码。开始下一次循环。 编程任务 对已有的计算 0 - 100 的while循环进行改造，通过增加 continue 语句，使得只计算奇数的和： sum = 0x = 1while True: sum = sum + x x = x + 1 if x &gt; 100: breakprint sum 思路: if判断到是偶数，continue跳过。 实现代码: sum = 0x = 0while True: x = x + 1 if x &gt; 100: break if x%2==0: continue sum = sum+x print sum 运行结果: 2500 多重循环(嵌套循环)在循环内部，还可以嵌套循环，我们来看一个例子： for x in ['A', 'B', 'C']: for y in ['1', '2', '3']: print x + y x 每循环一次，y就会循环 3 次，这样，我们可以打印出一个全排列： A1A2A3B1B2B3C1C2C3 编程任务 对100以内的两位数，请使用一个两重循环打印出所有十位数数字比个位数数字小的数，例如，23（2 &lt; 3）。 代码实现。 tens_place = [1,2,3,4,5,6,7,8,9]ones_place = [0,1,2,3,4,5,6,7,8,9]for x in tens_place: for y in ones_place: if x&lt;y: print x*10 + y 运行结果： 121314151617181923略 重要的数据类型Dict和Set什么是dict我们已经知道，list 和 tuple 可以用来表示顺序集合，例如，班里同学的名字： ['Adam', 'Lisa', 'Bart'] 或者考试的成绩列表： [95, 85, 59] 但是，要根据名字找到对应的成绩，用两个 list 表示就不方便。 如果把名字和分数关联起来，组成类似的查找表： 'Adam' ==&gt; 95'Lisa' ==&gt; 85'Bart' ==&gt; 59 给定一个名字，就可以直接查到分数。 Python的 dict 就是专门干这件事的。用 dict 表示名字-成绩的查找表如下： d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59} 我们把名字称为key，对应的成绩称为value，dict就是通过 key 来查找 value。 花括号 {} 表示这是一个dict，然后按照 key: value, 写出来即可。最后一个 key: value 的逗号可以省略。 知识点： 区别小课堂 单元素的tuple必须在后面多加一个逗号。 dict最后的逗号可以省略 由于dict也是集合，len() 函数可以计算任意集合的大小： &gt;&gt;&gt; len(d)3 知识点：注意: 一个 key-value 算一个，因此，dict大小为3。 编程任务 新来的Paul同学成绩是 75 分，请编写一个dict，把Paul同学的成绩也加进去。 d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59} 实现代码: d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59, 'Paul': 75 } 访问dict我们已经能创建一个dict，用于表示名字和成绩的对应关系： d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59} 那么，如何根据名字来查找对应的成绩呢？ 可以简单地使用 d[key] 的形式来查找对应的 value，这和 list 很像，不同之处是，list 必须使用索引返回对应的元素，而dict使用key： &gt;&gt;&gt; print d['Adam']95&gt;&gt;&gt; print d['Paul']Traceback (most recent call last): File &quot;index.py&quot;, line 11, in &lt;module&gt; print d['Paul']KeyError: 'Paul' 注意: 通过 key 访问 dict 的value，只要 key 存在，dict就返回对应的value。如果key不存在，会直接报错：KeyError。 知识点：避免 KeyError 发生，有两个办法： 是先判断一下 key 是否存在，用 in 操作符： if 'Paul' in d: print d['Paul'] 如果 ‘Paul’ 不存在，if语句判断为False，自然不会执行 print d[‘Paul’] ，从而避免了错误。 是使用dict本身提供的一个get方法，在Key不存在的时候，返回None： &gt;&gt;&gt; print d.get('Bart')59&gt;&gt;&gt; print d.get('Paul')None 编程任务根据如下dict： d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59} 请打印出：Adam: 95Lisa: 85Bart: 59 实现代码: d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59}print 'Adam:',d['Adam']print 'Lisa:',d.get('Lisa')print 'Bart:',d['Bart'] 运行结果： Adam: 95Lisa: 85Bart: 59 dict的特点知识点：dict查找速度快。list查找速度随着元素增加而逐渐下降。缺点：内存占用大。list慢但内存占用小。 dict的第一个特点是查找速度快，无论dict有10个元素还是10万个元素，查找速度都一样。而list的查找速度随着元素增加而逐渐下降。 不过dict的查找速度快不是没有代价的，dict的缺点是占用内存大，还会浪费很多内容，list正好相反，占用内存小，但是查找速度慢。 由于dict是按 key 查找，所以，在一个dict中，key不能重复。 dict的第二个特点就是存储的key-value序对是没有顺序的！这和list不一样： d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59} 当我们试图打印这个dict时： &gt;&gt;&gt; print d{'Lisa': 85, 'Adam': 95, 'Bart': 59} 打印的顺序不一定是我们创建时的顺序，而且，不同的机器打印的顺序都可能不同，这说明 知识点:dict内部是无序的，不能用dict存储有序的集合。 知识点：dict的第三个特点是作为 key 的元素必须不可变，Python的基本类型如字符串、整数、浮点数都是不可变的，都可以作为 key。 但是list是可变的，就不能作为 key。 可以试试用list作为key时会报什么样的错误。 不可变这个限制仅作用于key，value是否可变无所谓： { '123': [1, 2, 3], # key 是 str，value是list 123: '123', # key 是 int，value 是 str ('a', 'b'): True # key 是 tuple，并且tuple的每个元素都是不可变对象，value是 boolean} 最常用的key还是字符串，因为用起来最方便。 编程任务 请设计一个dict，可以根据分数来查找名字，已知成绩如下： Adam: 95,Lisa: 85,Bart: 59. 实现代码: d = { 95:'Adam', 85:'Lisa', 59:'Bart'} 运行结果：无 更新dictdict是可变的，也就是说，我们可以随时往dict中添加新的 key-value。比如已有dict： d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59} 要把新同学’Paul’的成绩 72 加进去，用赋值语句： &gt;&gt;&gt; d['Paul'] = 72 再看看dict的内容： &gt;&gt;&gt; print d{'Lisa': 85, 'Paul': 72, 'Adam': 95, 'Bart': 59} 如果 key 已经存在，则赋值会用新的 value 替换掉原来的 value： &gt;&gt;&gt; d['Bart'] = 60&gt;&gt;&gt; print d{'Lisa': 85, 'Paul': 72, 'Adam': 95, 'Bart': 60} 编程任务 请根据Paul的成绩 72 更新下面的dict： d = { 95: 'Adam', 85: 'Lisa', 59: 'Bart'} 实现代码: d = { 95: 'Adam', 85: 'Lisa', 59: 'Bart'}d[72] = 'Paul'print d 运行结果： {72: 'Paul', 59: 'Bart', 85: 'Lisa', 95: 'Adam'} 遍历dict由于dict也是一个集合，所以，遍历dict和遍历list类似，都可以通过 for 循环实现。 直接使用for循环可以遍历 dict 的 key： &gt;&gt;&gt; d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59 }&gt;&gt;&gt; for key in d:... print key... LisaAdamBart 由于通过 key 可以获取对应的 value，因此，在循环体内，可以获取到value的值。 注：这里的key只是一个约定俗称的变量，可以改为其他名字。但是推荐用key。 编程任务 请用 for 循环遍历如下的dict，打印出 name: score 来。 d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59} 实现代码： d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59}for key in d: print key+&quot;:&quot;,d[key] 运行结果: Lisa: 85Adam: 95Bart: 59 什么是setdict的作用是建立一组 key 和一组 value 的映射关系，dict的key是不能重复的。 有的时候，我们只想要 dict 的 key，不关心 key 对应的 value，目的就是保证这个集合的元素不会重复，这时，set就派上用场了。 set 持有一系列元素，这一点和 list 很像，但是set的元素没有重复，而且是无序的，这点和 dict 的 key很像。 知识点: 创建 set 的方式是调用 set() 并传入一个 list，list的元素将作为set的元素： &gt;&gt;&gt; s = set(['A', 'B', 'C'])可以查看 set 的内容：&gt;&gt;&gt; print sset(['A', 'C', 'B']) 请注意，上述打印的形式类似 list， 但它不是 list，仔细看还可以发现，打印的顺序和原始 list 的顺序有可能是不同的，因为set内部存储的元素是无序的。 因为set不能包含重复的元素，所以，当我们传入包含重复元素的 list 会怎么样呢？ &gt;&gt;&gt; s = set(['A', 'B', 'C', 'C'])&gt;&gt;&gt; print sset(['A', 'C', 'B'])&gt;&gt;&gt; len(s)3 结果显示，set会自动去掉重复的元素，原来的list有4个元素，但set只有3个元素。 编程任务 请用set表示班里的4位同学：Adam, Lisa, Bart, Paul 实现代码: s = set(['Adam', 'Lisa', 'Bart', 'Paul'])print s 运行结果: set(['Lisa', 'Paul', 'Adam', 'Bart']) 访问set由于set存储的是无序集合，所以我们没法通过索引来访问。 访问 set中的某个元素实际上就是判断一个元素是否在set中。 例如，存储了班里同学名字的set： &gt;&gt;&gt; s = set(['Adam', 'Lisa', 'Bart', 'Paul']) 我们可以用 in 操作符判断： Bart是该班的同学吗？ &gt;&gt;&gt; 'Bart' in sTrueBill是该班的同学吗？&gt;&gt;&gt; 'Bill' in sFalsebart是该班的同学吗？&gt;&gt;&gt; 'bart' in sFalse 知识点：大小写很重要，’Bart’ 和 ‘bart’被认为是两个不同的元素。 编程任务 由于上述set不能识别小写的名字，请改进set，使得 ‘adam’ 和 ‘bart’都能返回True。 既然大小写是不同的。那我们的set中就把大小写都包含。 实现代码: s = set(['Adam', 'Lisa', 'Bart', 'Paul','adam', 'lisa', 'bart', 'paul'])print 'adam' in sprint 'bart' in s 运行结果. TrueTrue set的特点set的内部结构和dict很像，唯一区别是不存储value，因此，判断一个元素是否在set中速度很快。 set存储的元素和dict的key类似，必须是不变对象，因此，任何可变对象是不能放入set中的。 最后，set存储的元素也是没有顺序的。 set的这些特点，可以应用在哪些地方呢？ 星期一到星期日可以用字符串'MON', 'TUE', ... 'SUN'表示。 假设我们让用户输入星期一至星期日的某天，如何判断用户的输入是否是一个有效的星期呢？ 可以用 if 语句判断，但这样做非常繁琐： x = '???' # 用户输入的字符串if x!= 'MON' and x!= 'TUE' and x!= 'WED' ... and x!= 'SUN': print 'input error'else: print 'input ok' 注意：if 语句中的…表示没有列出的其它星期名称，测试时，请输入完整。 如果事先创建好一个set，包含'MON' ~ 'SUN'： weekdays = set(['MON', 'TUE', 'WED', 'THU', 'FRI', 'SAT', 'SUN']) 再判断输入是否有效，只需要判断该字符串是否在set中： x = '???' # 用户输入的字符串if x in weekdays: print 'input ok'else: print 'input error'这样一来，代码就简单多了。 编程任务 月份也可以用set表示，请设计一个set并判断用户输入的月份是否有效。月份可以用字符串'Jan', 'Feb', ...表示。 实现代码: months = set(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul','Aug','Sep','Oct','Nov','Dec'])x1 = 'Feb'x2 = 'Sun'if x1 in months: print 'x1: ok'else: print 'x1: error'if x2 in months: print 'x2: ok'else: print 'x2: error' 运行结果: x1: okx2: error 遍历set由于 set 也是一个集合，所以，遍历 set 和遍历 list 类似，都可以通过 for 循环实现。 直接使用 for 循环可以遍历 set 的元素： &gt;&gt;&gt; s = set(['Adam', 'Lisa', 'Bart'])&gt;&gt;&gt; for name in s:... print name... LisaAdamBart 注意: 观察 for 循环在遍历set时，元素的顺序和list的顺序很可能是不同的，而且不同的机器上运行的结果也可能不同。 编程任务 请用 for 循环遍历如下的set，打印出 name: score 来。 s = set([('Adam', 95), ('Lisa', 85), ('Bart', 59)]) 上面这个set中的每一个元素又是一个字典。 set([ ])是壳子。 ('Adam', 95), ('Lisa', 85), ('Bart', 59)才是真正的内容 实现代码： s = set([('Adam', 95), ('Lisa', 85), ('Bart', 59)])for name,score in s: print name,':',score 运行结果: Lisa : 85Adam : 95Bart : 59 更新set(add remove)由于set存储的是一组不重复的无序元素，因此，更新set主要做两件事： 是把新的元素添加到set中 是把已有元素从set中删除。(前提是如果有) 添加元素时，用set的add()方法： &gt;&gt;&gt; s = set([1, 2, 3])&gt;&gt;&gt; s.add(4)&gt;&gt;&gt; print sset([1, 2, 3, 4]) 如果添加的元素已经存在于set中，add()不会报错，但是不会加进去了： &gt;&gt;&gt; s = set([1, 2, 3])&gt;&gt;&gt; s.add(3)&gt;&gt;&gt; print sset([1, 2, 3]) 删除set中的元素时，用set的remove()方法： &gt;&gt;&gt; s = set([1, 2, 3, 4])&gt;&gt;&gt; s.remove(4)&gt;&gt;&gt; print sset([1, 2, 3]) 如果删除的元素不存在set中，remove()会报错： &gt;&gt;&gt; s = set([1, 2, 3])&gt;&gt;&gt; s.remove(4)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;KeyError: 4 所以用add()可以直接添加，而remove()前需要判断。 编程任务 针对下面的set，给定一个list，对list中的每一个元素，如果在set中，就将其删除，如果不在set中，就添加进去。 s = set(['Adam', 'Lisa', 'Paul'])L = ['Adam', 'Lisa', 'Bart', 'Paul'] 实现代码： s = set(['Adam', 'Lisa', 'Paul'])L = ['Adam', 'Lisa', 'Bart', 'Paul']for name in L: if name in s: s.remove(name) else: s.add(name)print s 函数定义与调用什么是函数我们知道圆的面积计算公式为： S = πr² 当我们知道半径r的值时，就可以根据公式计算出面积。假设我们需要计算3个不同大小的圆的面积： r1 = 12.34r2 = 9.08r3 = 73.1s1 = 3.14 * r1 * r1s2 = 3.14 * r2 * r2s3 = 3.14 * r3 * r3 当代码出现有规律的重复的时候，你就需要当心了，每次写3.14 * x * x不仅很麻烦，而且，如果要把3.14改成3.14159265359的时候，得全部替换。 有了函数，我们就不再每次写s = 3.14 * x * x，而是写成更有意义的函数调用 s = area_of_circle(x)，而函数 area_of_circle本身只需要写一次，就可以多次调用。 抽象是数学中非常常见的概念。举个例子： 计算数列的和，比如：1 + 2 + 3 + … + 100，写起来十分不方便，于是数学家发明了求和符号∑，可以把1 + 2 + 3 + … + 100记作： 100∑nn=1 这种抽象记法非常强大，因为我们看到∑就可以理解成求和，而不是还原成低级的加法运算。 而且，这种抽象记法是可扩展的，比如： 100∑(n²+1)n=1 还原成加法运算就变成了： (1 x 1 + 1) + (2 x 2 + 1) + (3 x 3 + 1) + ... + (100 x 100 + 1)可见，借助抽象，我们才能不关心底层的具体计算过程，而直接在更高的层次上思考问题。 写计算机程序也是一样，函数就是最基本的一种代码抽象的方式。 Python不但能非常灵活地定义函数，而且本身内置了很多有用的函数，可以直接调用。 编程任务 写一个函数 实现代码： s = area_of_circle(x)area_of_circle(x) 运行结果： 调用函数,内置函数Python内置了很多有用的函数，我们可以直接调用。 要调用一个函数，需要知道函数的名称和参数，比如求绝对值的函数 abs，它接收一个参数。 可以直接从Python的官方网站查看文档：http://docs.python.org/2/library/functions.html#abs 也可以在交互式命令行通过 help(abs) 查看abs函数的帮助信息。 调用 abs 函数： &gt;&gt;&gt; abs(100)100&gt;&gt;&gt; abs(-20)20&gt;&gt;&gt; abs(12.34)12.34 调用函数的时候，如果传入的参数数量不对，会报TypeError的错误，并且Python会明确地告诉你：abs()有且仅有1个参数，但给出了两个： &gt;&gt;&gt; abs(1, 2)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: abs() takes exactly one argument (2 given) 如果传入的参数数量是对的，但参数类型不能被函数所接受，也会报TypeError的错误，并且给出错误信息：str是错误的参数类型： &gt;&gt;&gt; abs('a')Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: bad operand type for abs(): 'str' 而比较函数 cmp(x, y) 就需要两个参数，如果 x&lt;y，返回 -1，如果 x==y，返回0，如果 x&gt;y，返回 1： &gt;&gt;&gt; cmp(1, 2)-1&gt;&gt;&gt; cmp(2, 1)1&gt;&gt;&gt; cmp(3, 3)0 Python内置的常用函数还包括数据类型转换函数，比如 int()函数可以把其他数据类型转换为整数： &gt;&gt;&gt; int('123')123&gt;&gt;&gt; int(12.34)12 str()函数把其他类型转换成 str： &gt;&gt;&gt; str(123)'123'&gt;&gt;&gt; str(1.23)'1.23' 编程任务 sum()函数接受一个list作为参数，并返回list所有元素之和。请计算 1*1 + 2*2 + 3*3 + ... + 100*100。 实现代码： L = []L = []x = 1while x &lt;= 100: L.append(x * x) x = x + 1print sum(L) 运行结果: 338350 编写函数在Python中，定义一个函数要使用 def 语句，依次写出函数名、括号、括号中的参数和冒号:，然后，在缩进块中编写函数体，函数的返回值用 return语句返回。 我们以自定义一个求绝对值的 my_abs 函数为例： def my_abs(x): if x &gt;= 0: return x else: return -x 请注意，函数体内部的语句在执行时，一旦执行到return时，函数就执行完毕，并将结果返回。因此，函数内部通过条件判断和循环可以实现非常复杂的逻辑。 知识点； 如果没有return语句，函数执行完毕后也会返回结果，只是结果为 None。return None可以简写为return。 编程任务 请定义一个 square_of_sum 函数，它接受一个list，返回list中每个元素平方的和。 实现代码: def square_of_sum(L): sum = 0 for x in L: sum = x*x+sum return sumprint square_of_sum([1, 2, 3, 4, 5])print square_of_sum([-5, 0, 5, 15, 25]) 运行结果: 55900 函数之返回”多值”函数可以返回多个值吗？答案是肯定的。 比如在游戏中经常需要从一个点移动到另一个点，给出坐标、位移和角度，就可以计算出新的坐标： math包提供了sin()和 cos()函数，我们先用import引用它： import mathdef move(x, y, step, angle): nx = x + step * math.cos(angle) ny = y - step * math.sin(angle) return nx, ny 这样我们就可以同时获得返回值： &gt;&gt;&gt; x, y = move(100, 100, 60, math.pi / 6)&gt;&gt;&gt; print x, y151.961524227 70.0 但其实这只是一种假象，Python函数返回的仍然是单一值： &gt;&gt;&gt; r = move(100, 100, 60, math.pi / 6)&gt;&gt;&gt; print r(151.96152422706632, 70.0) 知识点：用print打印返回结果，原来返回值是一个tuple！ 但是，在语法上，返回一个tuple可以省略括号，而多个变量可以同时接收一个tuple，按位置赋给对应的值，所以，知识点：Python的函数返回多值其实就是返回一个tuple，但写起来更方便。 编程任务 一元二次方程的定义是：ax² + bx + c = 0 请编写一个函数，返回一元二次方程的两个解。 注意：Python的math包提供了sqrt()函数用于计算平方根。 实现代码: import mathdef quadratic_equation(a, b, c): t = math.sqrt(b*b - 4*a*c) return (-b + t) / (2 * a),( -b - t )/ (2 * a)print quadratic_equation(2, 3, 0)print quadratic_equation(1, -6, 5) 运行结果: (0.0, -1.5)(5.0, 1.0) 递归函数在函数内部，可以调用其他函数。知识点: 如果一个函数在内部调用自身本身，这个函数就是递归函数。 举个例子，我们来计算阶乘 n! = 1 * 2 * 3 * ... * n，用函数 fact(n)表示，可以看出： fact(n) = n! = 1 * 2 * 3 * ... * (n-1) * n = (n-1)! * n = fact(n-1) * n所以，fact(n)可以表示为 n * fact(n-1)，只有n=1时需要特殊处理。 于是，fact(n)用递归的方式写出来就是： def fact(n): if n==1: return 1 return n * fact(n - 1) 上面就是一个递归函数。可以试试： &gt;&gt;&gt; fact(1)1&gt;&gt;&gt; fact(5)120&gt;&gt;&gt; fact(100)93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000 如果我们计算fact(5)，可以根据函数定义看到计算过程如下： ===&gt; fact(5)===&gt; 5 * fact(4)===&gt; 5 * (4 * fact(3))===&gt; 5 * (4 * (3 * fact(2)))===&gt; 5 * (4 * (3 * (2 * fact(1))))===&gt; 5 * (4 * (3 * (2 * 1)))===&gt; 5 * (4 * (3 * 2))===&gt; 5 * (4 * 6)===&gt; 5 * 24===&gt; 120 递归函数的优点是定义简单，逻辑清晰。知识点: 理论上，所有的递归函数都可以写成循环的方式，但循环的逻辑不如递归清晰。 知识点: 使用递归函数需要注意防止栈溢出。在计算机中，函数调用是通过栈（stack）这种数据结构实现的，每当进入一个函数调用，栈就会加一层栈帧，每当函数返回，栈就会减一层栈帧。由于栈的大小不是无限的，所以，递归调用的次数过多，会导致栈溢出。可以试试计算 fact(10000)。 编程任务(天涯) 汉诺塔 (http://baike.baidu.com/view/191666.htm) 的移动也可以看做是递归函数。 我们对柱子编号为a, b, c，将所有圆盘从a移到c可以描述为： 如果a只有一个圆盘，可以直接移动到c； 如果a有N个圆盘，可以看成a有1个圆盘（底盘） + (N-1)个圆盘，首先需要把 (N-1) 个圆盘移动到 b，然后，将 a的最后一个圆盘移动到c，再将b的(N-1)个圆盘移动到c。 请编写一个函数，给定输入 n, a, b, c，打印出移动的步骤： move(n, a, b, c) 例如，输入 move(2, ‘A’, ‘B’, ‘C’)，打印出： A --&gt; BA --&gt; CB --&gt; C 实现代码： def move(n, a, b, c): if n ==1: print a, '--&gt;', c return move(n-1, a, c, b) print a, '--&gt;', c move(n-1, b, a, c)move(4, 'A', 'B', 'C') 运行结果: A --&gt; BA --&gt; CB --&gt; CA --&gt; BC --&gt; AC --&gt; BA --&gt; BA --&gt; CB --&gt; CB --&gt; AC --&gt; AB --&gt; CA --&gt; BA --&gt; CB --&gt; C 定义默认参数定义函数的时候，还可以有默认参数。 例如Python自带的 int() 函数，其实就有两个参数，我们既可以传一个参数，又可以传两个参数： &gt;&gt;&gt; int('123')123&gt;&gt;&gt; int('123', 8)83 知识点: int()函数的第二个参数是转换进制，如果不传，默认是十进制 (base=10)，如果传了，就用传入的参数。 可见，函数的默认参数的作用是简化调用，你只需要把必须的参数传进去。但是在需要的时候，又可以传入额外的参数来覆盖默认参数值。 我们来定义一个计算 x 的N次方的函数: def power(x, n): s = 1 while n &gt; 0: n = n - 1 s = s * x return s 假设计算平方的次数最多，我们就可以把 n 的默认值设定为 2： def power(x, n=2): s = 1 while n &gt; 0: n = n - 1 s = s * x return s 这样一来，计算平方就不需要传入两个参数了： &gt;&gt;&gt; power(5)25 知识点: 由于函数的参数按从左到右的顺序匹配，所以默认参数只能定义在必需参数的后面： # OK:def fn1(a, b=1, c=2): pass# Error:def fn2(a=1, b): pass 个人: 这里我们可以把自己想象成计算机。在自己感到为难不知道哪个是哪个的时候。那么恭喜你，计算机也不知道。 编程任务 请定义一个 greet() 函数，它包含一个默认参数，如果没有传入，打印 'Hello, world.'，如果传入，打印 'Hello, xxx.' 实现代码: def greet(x = 'World'): print 'Hello,'+x+'.'greet()greet('mtianyan') 运行结果: Hello,World.Hello,mtianyan. 知识点: 定义可变参数如果想让一个函数能接受任意个参数，我们就可以定义一个可变参数： def fn(*args): print args 可变参数的名字前面有个 * 号，我们可以传入0个、1个或多个参数给可变参数： &gt;&gt;&gt; fn()()&gt;&gt;&gt; fn('a')('a',)&gt;&gt;&gt; fn('a', 'b')('a', 'b')&gt;&gt;&gt; fn('a', 'b', 'c')('a', 'b', 'c') 可变参数也不是很神秘，Python解释器会把传入的一组参数组装成一个tuple传递给可变参数，因此，在函数内部，直接把变量 args 看成一个 tuple 就好了。 定义可变参数的目的也是为了简化调用。假设我们要计算任意个数的平均值，就可以定义一个可变参数： def average(*args): ... 这样，在调用的时候，可以这样写： &gt;&gt;&gt; average()0&gt;&gt;&gt; average(1, 2)1.5&gt;&gt;&gt; average(1, 2, 2, 3, 4)2.4 编程任务 请编写接受可变参数的 average() 函数。 def average(*args): sum = 0.0 if len(args) == 0: return sum for x in args: sum = sum + x return sum / len(args)print average()print average(1, 2)print average(1, 2, 2, 3, 4) 运行结果: 0.01.52.4 切片操作对list进行切片取一个list的部分元素是非常常见的操作。比如，一个list如下： &gt;&gt;&gt; L = ['Adam', 'Lisa', 'Bart', 'Paul'] 取前3个元素，应该怎么做？ 笨办法： &gt;&gt;&gt; [L[0], L[1], L[2]]['Adam', 'Lisa', 'Bart'] 之所以是笨办法是因为扩展一下，取前N个元素就没辙了。 取前N个元素，也就是索引为0-(N-1)的元素，可以用循环： &gt;&gt;&gt; r = []&gt;&gt;&gt; n = 3&gt;&gt;&gt; for i in range(n):... r.append(L[i])... &gt;&gt;&gt; r['Adam', 'Lisa', 'Bart'] 对这种经常取指定索引范围的操作，用循环十分繁琐，因此，Python提供了切片（Slice）操作符，能大大简化这种操作。 对应上面的问题，取前3个元素，用一行代码就可以完成切片： &gt;&gt;&gt; L[0:3]['Adam', 'Lisa', 'Bart']L[0:3]表示，从索引0开始取，直到索引3为止，但不包括索引3。即索引0，1，2，正好是3个元素。 知识点： [0:3]表示，从索引0开始取，直到索引3为止，但不包括索引3。即索引0，1，2，正好是3个元素。 如果第一个索引是0，还可以省略： &gt;&gt;&gt; L[:3]['Adam', 'Lisa', 'Bart'] 也可以从索引1开始，取出2个元素出来： &gt;&gt;&gt; L[1:3]['Lisa', 'Bart'] 只用一个 : ，表示从头到尾： &gt;&gt;&gt; L[:]['Adam', 'Lisa', 'Bart', 'Paul'] 因此，L[:]实际上复制出了一个新list。 知识点: 切片操作还可以指定第三个参数： &gt;&gt;&gt; L[::2]['Adam', 'Bart'] 第三个参数表示每N个取一个，上面的 L[::2] 会每两个元素取出一个来，也就是隔一个取一个。 把list换成tuple，切片操作完全相同，只是切片的结果也变成了tuple。 编程任务 range()函数可以创建一个数列： &gt;&gt;&gt; range(1, 101)[1, 2, 3, ..., 100] 请利用切片，取出： 前10个数； 3的倍数； 不大于50的5的倍数。 实现代码: L = range(1, 101)print L[:10]print L[2::3]print L[4:50:5] 运行结果: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10][3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99][5, 10, 15, 20, 25, 30, 35, 40, 45, 50] 倒序切片对于list，既然Python支持L[-1]取倒数第一个元素，那么它同样支持倒数切片，试试： &gt;&gt;&gt; L = ['Adam', 'Lisa', 'Bart', 'Paul']&gt;&gt;&gt; L[-2:]['Bart', 'Paul']&gt;&gt;&gt; L[:-2]['Adam', 'Lisa']&gt;&gt;&gt; L[-3:-1]['Lisa', 'Bart']&gt;&gt;&gt; L[-4:-1:2]['Adam', 'Bart'] 记住倒数第一个元素的索引是-1。知识点：倒序切片包含起始索引，不包含结束索引。 编程任务 利用倒序切片对 1 - 100 的数列取出： 最后10个数； 最后10个5的倍数。 实现代码： L = range(1, 101)print L[-10:]print L[-46::5] 对字符串切片字符串 'xxx'和 Unicode字符串 u'xxx'也可以看成是一种list，每个元素就是一个字符。因此，字符串也可以用切片操作，只是操作结果仍是字符串： &gt;&gt;&gt; 'ABCDEFG'[:3]'ABC'&gt;&gt;&gt; 'ABCDEFG'[-3:]'EFG'&gt;&gt;&gt; 'ABCDEFG'[::2]'ACEG' 在很多编程语言中，针对字符串提供了很多各种截取函数，其实目的就是对字符串切片。知识点：Python没有针对字符串的截取函数，只需要切片一个操作就可以完成，非常简单。 编程任务 字符串有个方法 upper() 可以把字符变成大写字母： &gt;&gt;&gt; 'abc'.upper()'ABC' 但它会把所有字母都变成大写。请设计一个函数，它接受一个字符串，然后返回一个仅首字母变成大写的字符串。 提示：利用切片操作简化字符串操作。 实现代码: def firstCharUpper(s): return s[0].upper() + s[1:]print firstCharUpper('hello')print firstCharUpper('sunday')print firstCharUpper('september') 运行结果： HelloSundaySeptember 各种迭代方式什么是迭代在Python中，如果给定一个list或tuple，我们可以通过for循环来遍历这个list或tuple，这种遍历我们称为迭代（Iteration）。 在Python中，迭代是通过 for ... in 来完成的，而很多语言比如C或者Java，迭代list是通过下标完成的，比如Java代码： for (i=0; i&lt;list.length; i++) { n = list[i];} 可以看出，Python的for循环抽象程度要高于Java的for循环。 因为 Python 的 for循环不仅可以用在list或tuple上，还可以作用在其他任何可迭代对象上。 因此，迭代操作就是对于一个集合，无论该集合是有序还是无序，我们用 for 循环总是可以依次取出集合的每一个元素。 注意: 集合是指包含一组元素的数据结构，我们已经介绍的包括： 有序集合：list，tuple，知识点: str和unicode； 无序集合：set 无序集合并且具有 key-value 对：dict 而迭代是一个动词，它指的是一种操作，在Python中，就是 for 循环。 迭代与按下标访问数组最大的不同是，后者是一种具体的迭代实现方式，而前者只关心迭代结果，根本不关心迭代内部是如何实现的。 编程任务 请用for循环迭代数列 1-100 并打印出7的倍数。 实现代码: for i in range(1, 101): if i % 7 == 0: print i 运行结果: 714212835424956637077849198 索引迭代知识点：Python中，迭代永远是取出元素本身，而非元素的索引。 对于有序集合，元素确实是有索引的。有的时候，我们确实想在 for 循环中拿到索引，怎么办？ 方法是使用 enumerate() 函数： &gt;&gt;&gt; L = ['Adam', 'Lisa', 'Bart', 'Paul']&gt;&gt;&gt; for index, name in enumerate(L):... print index, '-', name... 0 - Adam1 - Lisa2 - Bart3 - Paul 使用 enumerate() 函数，我们可以在for循环中同时绑定索引index和元素name。但是，这不是 enumerate() 的特殊语法。实际上，enumerate() 函数把： ['Adam', 'Lisa', 'Bart', 'Paul'] 变成了类似： [(0, 'Adam'), (1, 'Lisa'), (2, 'Bart'), (3, 'Paul')] 因此，迭代的每一个元素实际上是一个tuple： for t in enumerate(L): index = t[0] name = t[1] print index, '-', name 如果我们知道每个tuple元素都包含两个元素，for循环又可以进一步简写为： for index, name in enumerate(L): print index, '-', name 这样不但代码更简单，而且还少了两条赋值语句。 可见，知识点: 索引迭代也不是真的按索引访问，而是由 enumerate() 函数自动把每个元素变成 (index, element) 这样的tuple，再迭代，就同时获得了索引和元素本身。 编程任务(天涯) zip()函数可以把两个 list 变成一个 list： &gt;&gt;&gt; zip([10, 20, 30], ['A', 'B', 'C'])[(10, 'A'), (20, 'B'), (30, 'C')] 在迭代 ['Adam', 'Lisa', 'Bart', 'Paul'] 时，如果我们想打印出名次 - 名字（名次从1开始)，请考虑如何在迭代中打印出来。 提示：考虑使用zip()函数和range()函数 实现代码: L = ['Adam', 'Lisa', 'Bart', 'Paul']for index, name in zip(range(1, len(L)+1), L): print index, '-', name 运行结果: 1 - Adam2 - Lisa3 - Bart4 - Paul 迭代dict的value迭代dict的value我们已经了解了dict对象本身就是可迭代对象，用 for 循环直接迭代 dict，可以每次拿到dict的一个key。 如果我们希望迭代 dict 对象的value，应该怎么做？ 知识点：values()把dict转换成一个包含所有value的listdict 对象有一个 values() 方法，这个方法把dict转换成一个包含所有value的list，这样，我们迭代的就是 dict的每一个 value： d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59 }print d.values()# [85, 95, 59]for v in d.values(): print v# 85# 95# 59 如果仔细阅读Python的文档，还可以发现，dict除了values()方法外，还有一个 itervalues() 方法，用 itervalues() 方法替代 values() 方法，迭代效果完全一样： d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59 }print d.itervalues()# &lt;dictionary-valueiterator object at 0x106adbb50&gt;for v in d.itervalues(): print v# 85# 95# 59 那这两个方法有何不同之处呢？ values() 方法实际上把一个 dict 转换成了包含 value 的list。 但是 itervalues() 方法不会转换，它会在迭代过程中依次从 dict 中取出 value，所以 itervalues() 方法比 values() 方法节省了生成 list 所需的内存。 打印 itervalues() 发现它返回一个 对象，这说明在Python中，for 循环可作用的迭代对象远不止 list，tuple，str，unicode，dict等，知识点: 任何可迭代对象都可以作用于for循环，而内部如何迭代我们通常并不用关心。 如果一个对象说自己可迭代，那我们就直接用 for 循环去迭代它，知识点: 可见，迭代是一种抽象的数据操作，它不对迭代对象内部的数据有任何要求。 编程任务 给定一个dict：d = { ‘Adam’: 95, ‘Lisa’: 85, ‘Bart’: 59, ‘Paul’: 74 } 请计算所有同学的平均分。 实现代码: d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59, 'Paul': 74 }sum = 0.0for v in d.itervalues(): sum = sum + vprint sum / len(d) 运行结果: 78.25 迭代dict的key和value我们了解了如何迭代 dict 的key和value，那么，在一个 for 循环中，能否同时迭代 key和value？答案是肯定的。 首先，我们看看 dict 对象的 items() 方法返回的值： &gt;&gt;&gt; d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59 }&gt;&gt;&gt; print d.items()[('Lisa', 85), ('Adam', 95), ('Bart', 59)] 可以看到，items() 方法把dict对象转换成了包含tuple的list，我们对这个list进行迭代，可以同时获得key和value： &gt;&gt;&gt; for key, value in d.items():... print key, ':', value... Lisa : 85Adam : 95Bart : 59 和 values() 有一个 itervalues() 类似，items() 也有一个对应的 iteritems()，知识点： iteritems() 不把dict转换成list，而是在迭代过程中不断给出 tuple，所以， iteritems() 不占用额外的内存。 编程任务 请根据dict：d = { ‘Adam’: 95, ‘Lisa’: 85, ‘Bart’: 59, ‘Paul’: 74 } 打印出 name : score，最后再打印出平均分 average : score。 实现代码： d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59, 'Paul': 74 }sum = 0.0for k, v in d.iteritems(): sum = sum + v print k, ':', vprint 'average', ':', sum / len(d) 运行结果： Lisa : 85Paul : 74Adam : 95Bart : 59average : 78.25 列表生成式:快速生成列表生成列表要生成list [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]，我们可以用range(1, 11)： &gt;&gt;&gt; range(1, 11)[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 但如果要生成[1x1, 2x2, 3x3, ..., 10x10]怎么做？ 方法一是循环： &gt;&gt;&gt; L = []&gt;&gt;&gt; for x in range(1, 11):... L.append(x * x)... &gt;&gt;&gt; L[1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 但是循环太繁琐，而列表生成式则可以用一行语句代替循环生成上面的list： &gt;&gt;&gt; [x * x for x in range(1, 11)][1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 这种写法就是Python特有的列表生成式。利用列表生成式，可以以非常简洁的代码生成 list。 知识点: 写列表生成式时，把要生成的元素 x * x 放到前面，后面跟 for 循环，就可以把list创建出来，十分有用，多写几次，很快就可以熟悉这种语法。 编程任务 请利用列表生成式生成列表 [1x2, 3x4, 5x6, 7x8, ..., 99x100] 提示：range(1, 100, 2) 可以生成list [1, 3, 5, 7, 9,...] 实现代码： print [x * (x + 1) for x in range(1, 100, 2)] 运行结果： [2, 12, 30, 56, 90, 132, 182, 240, 306, 380, 462, 552, 650, 756, 870, 992, 1122, 1260, 1406, 1560, 1722, 1892, 2070, 2256, 2450, 2652, 2862, 3080, 3306, 3540, 3782, 4032, 4290, 4556, 4830, 5112, 5402, 5700, 6006, 6320, 6642, 6972, 7310, 7656, 8010, 8372, 8742, 9120, 9506, 9900] 复杂表达式使用for循环的迭代不仅可以迭代普通的list，还可以迭代dict。 假设有如下的dict： d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59 } 完全可以通过一个复杂的列表生成式把它变成一个 HTML 表格： tds = ['&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%s&lt;/td&gt;&lt;/tr&gt;' % (name, score) for name, score in d.iteritems()]print '&lt;table&gt;'print '&lt;tr&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Score&lt;/th&gt;&lt;tr&gt;'print '\\n'.join(tds)print '&lt;/table&gt;' 个人：&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%s&lt;/td&gt;&lt;/tr&gt; 中： 第一个%s是name的填充位置。 第二个%s为score的填充位置。 有多少个name和score，会通过循环生成多少个。&lt;tr&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Score&lt;/th&gt;&lt;tr&gt;设置表格头print ‘\\n’.join(tds)。列表里的项通过\\n连接成字符串。 注：字符串可以通过%进行格式化，用指定的参数替代 %s。字符串的join()方法可以把一个 list拼接成一个字符串。 把打印出来的结果保存为一个html文件，就可以在浏览器中看到效果了： &lt;table border=&quot;1&quot;&gt;&lt;tr&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Score&lt;/th&gt;&lt;tr&gt;&lt;tr&gt;&lt;td&gt;Lisa&lt;/td&gt;&lt;td&gt;85&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Adam&lt;/td&gt;&lt;td&gt;95&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Bart&lt;/td&gt;&lt;td&gt;59&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 编程任务(天涯) 在生成的表格中，对于没有及格的同学，请把分数标记为红色。 提示：红色可以用 &lt;td style=&quot;color:red&quot;&gt; 实现。 实现代码: d = { 'Adam': 95, 'Lisa': 85, 'Bart': 59 }def generate_tr(name, score): if score &lt; 60: return '&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td style=&quot;color:red&quot;&gt;%s&lt;/td&gt;&lt;/tr&gt;' % (name, score) return '&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%s&lt;/td&gt;&lt;/tr&gt;' % (name, score)tds = [generate_tr(name, score) for name, score in d.iteritems()]print '&lt;table border=&quot;1&quot;&gt;'print '&lt;tr&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Score&lt;/th&gt;&lt;tr&gt;'print '\\n'.join(tds)print '&lt;/table&gt;' 运行结果: 条件过滤列表生成式的 for 循环后面还可以加上 if 判断。例如： &gt;&gt;&gt; [x * x for x in range(1, 11)][1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 如果我们只想要偶数的平方，不改动 range()的情况下，可以加上 if 来筛选： &gt;&gt;&gt; [x * x for x in range(1, 11) if x % 2 == 0][4, 16, 36, 64, 100] 有了 if 条件，只有 if 判断为 True 的时候，才把循环的当前元素添加到列表中。 编程任务 请编写一个函数，它接受一个 list，然后把list中的所有字符串变成大写后返回，非字符串元素将被忽略。 提示： isinstance(x, str) 可以判断变量 x 是否是字符串； 字符串的 upper() 方法可以返回大写的字母。 实现代码: def toUppers(L): return [x.upper() for x in L if isinstance(x, str)]print toUppers(['Hello', 'world', 101]) 运行结果: ['HELLO', 'WORLD'] 多层表达式(知识点)for循环可以嵌套，知识点：因此，在列表生成式中，也可以用多层 for 循环来生成列表。 对于字符串 'ABC' 和 '123'，可以使用两层循环，生成全排列： &gt;&gt;&gt; [m + n for m in 'ABC' for n in '123']['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'C1', 'C2', 'C3'] 翻译成循环代码就像下面这样： L = []for m in 'ABC': for n in '123': L.append(m + n) 编程任务(天涯) 利用 3 层for循环的列表生成式，找出对称的 3 位数。例如，121 就是对称数，因为从右到左倒过来还是 121。 实现代码: print [100 * n1 + 10 * n2 + n3 for n1 in range(1, 10) for n2 in range(10) for n3 in range(10) if n1==n3] 运行结果： 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 202, 212, 222, 232, 242, 252, 262, 272, 282, 292, 303, 313, 323, 333, 343, 353, 363, 373, 383, 393, 404, 414, 424, 434, 444, 454, 464, 474, 484, 494, 505, 515, 525, 535, 545, 555, 565, 575, 585, 595, 606, 616, 626, 636, 646, 656, 666, 676, 686, 696, 707, 717, 727, 737, 747, 757, 767, 777, 787, 797, 808, 818, 828, 838, 848, 858, 868, 878, 888, 898, 909, 919, 929, 939, 949, 959, 969, 979, 989, 999]","link":"/2018/01/02/Python%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"面试","slug":"面试","link":"/tags/%E9%9D%A2%E8%AF%95/"},{"name":"多线程","slug":"多线程","link":"/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"线程通信","slug":"线程通信","link":"/tags/%E7%BA%BF%E7%A8%8B%E9%80%9A%E4%BF%A1/"},{"name":"转载","slug":"转载","link":"/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"锁","slug":"锁","link":"/tags/%E9%94%81/"},{"name":"反射","slug":"反射","link":"/tags/%E5%8F%8D%E5%B0%84/"},{"name":"博客","slug":"博客","link":"/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"LRUCache","slug":"LRUCache","link":"/tags/LRUCache/"},{"name":"Full-Text Search","slug":"Full-Text-Search","link":"/tags/Full-Text-Search/"},{"name":"英文","slug":"英文","link":"/tags/%E8%8B%B1%E6%96%87/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"注解","slug":"注解","link":"/tags/%E6%B3%A8%E8%A7%A3/"},{"name":"源码","slug":"源码","link":"/tags/%E6%BA%90%E7%A0%81/"},{"name":"jQuery","slug":"jQuery","link":"/tags/jQuery/"},{"name":"堆排序","slug":"堆排序","link":"/tags/%E5%A0%86%E6%8E%92%E5%BA%8F/"},{"name":"lintcode","slug":"lintcode","link":"/tags/lintcode/"},{"name":"Seata","slug":"Seata","link":"/tags/Seata/"},{"name":"实习","slug":"实习","link":"/tags/%E5%AE%9E%E4%B9%A0/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"ProducerConsumer","slug":"ProducerConsumer","link":"/tags/ProducerConsumer/"},{"name":"join","slug":"join","link":"/tags/join/"},{"name":"volatile","slug":"volatile","link":"/tags/volatile/"},{"name":"synchronized","slug":"synchronized","link":"/tags/synchronized/"},{"name":"分布式锁","slug":"分布式锁","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"name":"Go","slug":"Go","link":"/tags/Go/"},{"name":"Java8","slug":"Java8","link":"/tags/Java8/"},{"name":"lambda","slug":"lambda","link":"/tags/lambda/"},{"name":"Future","slug":"Future","link":"/tags/Future/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"网络","slug":"网络","link":"/tags/%E7%BD%91%E7%BB%9C/"},{"name":"TCP&#x2F;IP","slug":"TCP-IP","link":"/tags/TCP-IP/"},{"name":"NIO","slug":"NIO","link":"/tags/NIO/"},{"name":"Reactor","slug":"Reactor","link":"/tags/Reactor/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"并发编程","slug":"并发编程","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"零基础入门","slug":"零基础入门","link":"/tags/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"name":"学习笔记","slug":"学习笔记","link":"/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"categories":[{"name":"monthly","slug":"monthly","link":"/categories/monthly/"},{"name":"日记","slug":"日记","link":"/categories/%E6%97%A5%E8%AE%B0/"},{"name":"Java 基础","slug":"Java-基础","link":"/categories/Java-%E5%9F%BA%E7%A1%80/"},{"name":"知识图谱","slug":"知识图谱","link":"/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"Go","slug":"Go","link":"/categories/Go/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"前端","slug":"前端","link":"/categories/%E5%89%8D%E7%AB%AF/"},{"name":"分布式","slug":"分布式","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"深入理解Java虚拟机","slug":"深入理解Java虚拟机","link":"/categories/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"面试","slug":"面试","link":"/categories/%E9%9D%A2%E8%AF%95/"},{"name":"HTTP","slug":"HTTP","link":"/categories/HTTP/"},{"name":"Netty","slug":"Netty","link":"/categories/Netty/"},{"name":"python从入门到精通","slug":"python从入门到精通","link":"/categories/python%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/"}]}