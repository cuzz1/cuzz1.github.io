<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Let&#039;s build a Full-Text Search engine - Hexo</title><meta description="博客记录"><meta property="og:type" content="blog"><meta property="og:title" content="Let&#039;s build a Full-Text Search engine"><meta property="og:url" content="http://blog.cuzz.site/2020/08/17/Let&#039;s%20build%20a%20Full-Text%20Search%20engine/"><meta property="og:site_name" content="cuzz&#039;s blog"><meta property="og:description" content="博客记录"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://raw.githubusercontent.com/cuzz1/img/master/2020/08/book-index.png"><meta property="og:image" content="https://raw.githubusercontent.com/cuzz1/img/master/2020/08/text-analysis.png"><meta property="og:image" content="https://raw.githubusercontent.com/cuzz1/img/master/2020/08/venn.png"><meta property="og:image" content="https://raw.githubusercontent.com/cuzz1/img/master/2020/08/asian-golden-cat-s.jpg"><meta property="article:published_time" content="2020-08-17T13:54:59.000Z"><meta property="article:modified_time" content="2020-08-21T12:42:19.214Z"><meta property="article:author" content="cuzz"><meta property="article:tag" content="转载"><meta property="article:tag" content="Full-Text Search"><meta property="article:tag" content="英文"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://raw.githubusercontent.com/cuzz1/img/master/2020/08/book-index.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://blog.cuzz.site/2020/08/17/Let's%20build%20a%20Full-Text%20Search%20engine/"},"headline":"Hexo","image":["https://raw.githubusercontent.com/cuzz1/img/master/2020/08/book-index.png","https://raw.githubusercontent.com/cuzz1/img/master/2020/08/text-analysis.png","https://raw.githubusercontent.com/cuzz1/img/master/2020/08/venn.png","https://raw.githubusercontent.com/cuzz1/img/master/2020/08/asian-golden-cat-s.jpg"],"datePublished":"2020-08-17T13:54:59.000Z","dateModified":"2020-08-21T12:42:19.214Z","author":{"@type":"Person","name":"John Doe"},"description":"这是一篇转载文章原文地址，原文讲述如何构建一个全文搜索引擎，用的 Go 实现的，本来想翻译一下，顺便用 Java 实现一下，由于翻译出来比较生硬，还是把原文放出来，顺便把我用 Java 实现的版本放在链接中Java实现版本。  Full-Text Search is one of those tools people use every day without realizing it. If"}</script><link rel="canonical" href="http://blog.cuzz.site/2020/08/17/Let&#039;s%20build%20a%20Full-Text%20Search%20engine/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.0.2"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Hexo" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-08-17T13:54:59.000Z" title="2020-08-17T13:54:59.000Z">2020-08-17</time><span class="level-item"><a class="link-muted" href="/categories/Go/">Go</a></span><span class="level-item">16 minutes read (About 2327 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Let&#039;s build a Full-Text Search engine</h1><div class="content"><blockquote>
<p>这是一篇转载文章<a target="_blank" rel="noopener" href="https://artem.krylysov.com/blog/2020/07/28/lets-build-a-full-text-search-engine/">原文地址</a>，原文讲述如何构建一个全文搜索引擎，用的 Go 实现的，本来想翻译一下，顺便用 Java 实现一下，由于翻译出来比较生硬，还是把原文放出来，顺便把我用 Java 实现的版本放在链接中<a target="_blank" rel="noopener" href="https://github.com/cuzz1/simplefts">Java实现版本</a>。</p>
</blockquote>
<p>Full-Text Search is one of those tools people use every day without realizing it. If you ever googled “golang coverage report” or tried to find “indoor wireless camera” on an e-commerce website, you used some kind of full-text search.</p>
<p>Full-Text Search (FTS) is a technique for searching text in a collection of documents. A document can refer to a web page, a newspaper article, an email message, or any structured text.</p>
<p>Today we are going to build our own FTS engine. By the end of this post, we’ll be able to search across millions of documents in less than a millisecond. We’ll start with simple search queries like “give me all documents that contain the word <em>cat</em>“ and we’ll extend the engine to support more sophisticated boolean queries.</p>
<p>Note</p>
<blockquote>
<p>Most well-known FTS engine is <a target="_blank" rel="noopener" href="https://lucene.apache.org/">Lucene</a> (as well as <a target="_blank" rel="noopener" href="https://github.com/elastic/elasticsearch">Elasticsearch</a> and Solr built on top of it).</p>
</blockquote>
<h2 id="Why-FTS"><a href="#Why-FTS" class="headerlink" title="Why FTS"></a>Why FTS</h2><p>Before we start writing code, you may ask “can’t we just use <em>grep</em> or have a loop that checks if every document contains the word I’m looking for?“. Yes, we can. However, it’s not always the best idea.</p>
<h2 id="Corpus"><a href="#Corpus" class="headerlink" title="Corpus"></a>Corpus</h2><p>We are going to search a part of the abstract of English Wikipedia. The latest dump is available at <a target="_blank" rel="noopener" href="https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-abstract1.xml.gz">dumps.wikimedia.org</a>. As of today, the file size after decompression is 913 MB. The XML file contains over 600K documents.</p>
<p>Document example:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>Wikipedia: Kit-Cat Klock<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">url</span>&gt;</span>https://en.wikipedia.org/wiki/Kit-Cat_Klock<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">abstract</span>&gt;</span>The Kit-Cat Klock is an art deco novelty wall clock shaped like a grinning cat with cartoon eyes that swivel in time with its pendulum tail.<span class="tag">&lt;/<span class="name">abstract</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="Loading-documents"><a href="#Loading-documents" class="headerlink" title="Loading documents"></a>Loading documents</h2><p>First, we need to load all the documents from the dump. The built-in encoding/xml package comes very handy:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;encoding/xml&quot;</span></span><br><span class="line">    <span class="string">&quot;os&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> document <span class="keyword">struct</span> &#123;</span><br><span class="line">    Title <span class="keyword">string</span> <span class="string">`xml:&quot;title&quot;`</span></span><br><span class="line">    URL   <span class="keyword">string</span> <span class="string">`xml:&quot;url&quot;`</span></span><br><span class="line">    Text  <span class="keyword">string</span> <span class="string">`xml:&quot;abstract&quot;`</span></span><br><span class="line">    ID    <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">loadDocuments</span><span class="params">(path <span class="keyword">string</span>)</span> <span class="params">([]document, error)</span></span> &#123;</span><br><span class="line">    f, err := os.Open(path)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">defer</span> f.Close()</span><br><span class="line"></span><br><span class="line">    dec := xml.NewDecoder(f)</span><br><span class="line">    dump := <span class="keyword">struct</span> &#123;</span><br><span class="line">        Documents []document <span class="string">`xml:&quot;doc&quot;`</span></span><br><span class="line">    &#125;&#123;&#125;</span><br><span class="line">    <span class="keyword">if</span> err := dec.Decode(&amp;dump); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    docs := dump.Documents</span><br><span class="line">    <span class="keyword">for</span> i := <span class="keyword">range</span> docs &#123;</span><br><span class="line">        docs[i].ID = i</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> docs, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Every loaded document gets assigned a unique identifier. To keep things simple, the first loaded document gets assigned ID=0, the second ID=1 and so on.</p>
<h2 id="First-attempt"><a href="#First-attempt" class="headerlink" title="First attempt"></a>First attempt</h2><h3 id="Searching-the-content"><a href="#Searching-the-content" class="headerlink" title="Searching the content"></a>Searching the content</h3><p>Now that we have all documents loaded into memory, we can try to find the ones about cats. At first, let’s loop through all documents and check if they contain the substring <em>cat</em>:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">search</span><span class="params">(docs []document, term <span class="keyword">string</span>)</span> []<span class="title">document</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> r []document</span><br><span class="line">    <span class="keyword">for</span> _, doc := <span class="keyword">range</span> docs &#123;</span><br><span class="line">        <span class="keyword">if</span> strings.Contains(doc.Text, term) &#123;</span><br><span class="line">            r = <span class="built_in">append</span>(r, doc)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> r</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>On my laptop, the search phase takes 103ms - not too bad. If you spot check a few documents from the output, you may notice that the function matches <em>caterpillar</em> and <em>category</em>, but doesn’t match <em>Cat</em> with the capital <em>C</em>. That’s not quite what I was looking for.</p>
<p>We need to fix two things before moving forward:</p>
<ul>
<li><p>Make the search case-insensitive (so <em>Cat</em> matches as well).</p>
</li>
<li><p>Match on a word boundary rather than on a substring (so <em>caterpillar</em> and <em>communication</em> don’t match).</p>
</li>
</ul>
<h3 id="Searching-with-regular-expressions"><a href="#Searching-with-regular-expressions" class="headerlink" title="Searching with regular expressions"></a>Searching with regular expressions</h3><p>One solution that quickly comes to mind and allows implementing both requirements is <em>regular expressions</em>.</p>
<p>Here it is - (?i)\bcat\b:</p>
<ul>
<li>(?i) makes the regex case-insensitive</li>
<li>\b matches a word boundary (position where one side is a word character and another side is not a word character)</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">search</span><span class="params">(docs []document, term <span class="keyword">string</span>)</span> []<span class="title">document</span></span> &#123;</span><br><span class="line">    re := regexp.MustCompile(<span class="string">`(?i)\b`</span> + term + <span class="string">`\b`</span>) <span class="comment">// Don&#x27;t do this in production, it&#x27;s a security risk. term needs to be sanitized.</span></span><br><span class="line">    <span class="keyword">var</span> r []document</span><br><span class="line">    <span class="keyword">for</span> _, doc := <span class="keyword">range</span> docs &#123;</span><br><span class="line">        <span class="keyword">if</span> re.MatchString(doc.Text) &#123;</span><br><span class="line">            r = <span class="built_in">append</span>(r, doc)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> r</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Ugh, the search took more than 2 seconds. As you can see, things started getting slow even with 600K documents. While the approach is easy to implement, it doesn’t scale well. As the dataset grows larger, we need to scan more and more documents. The time complexity of this algorithm is linear - the number of documents required to scan is equal to the total number of documents. If we had 6M documents instead of 600K, the search would take 20 seconds. We need to do better than that.</p>
<h2 id="Inverted-Index"><a href="#Inverted-Index" class="headerlink" title="Inverted Index"></a>Inverted Index</h2><p>To make search queries faster, we’ll preprocess the text and build an index in advance.</p>
<p>The core of FTS is a data structure called <em>Inverted Index</em>. The Inverted Index associates every word in documents with documents that contain the word.</p>
<p>Example:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">documents = &#123;</span><br><span class="line">    <span class="number">1</span>: <span class="string">&quot;a donut on a glass plate&quot;</span>,</span><br><span class="line">    <span class="number">2</span>: <span class="string">&quot;only the donut&quot;</span>,</span><br><span class="line">    <span class="number">3</span>: <span class="string">&quot;listen to the drum machine&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">index = &#123;</span><br><span class="line">    <span class="string">&quot;a&quot;</span>: [<span class="number">1</span>],</span><br><span class="line">    <span class="string">&quot;donut&quot;</span>: [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">    <span class="string">&quot;on&quot;</span>: [<span class="number">1</span>],</span><br><span class="line">    <span class="string">&quot;glass&quot;</span>: [<span class="number">1</span>],</span><br><span class="line">    <span class="string">&quot;plate&quot;</span>: [<span class="number">1</span>],</span><br><span class="line">    <span class="string">&quot;only&quot;</span>: [<span class="number">2</span>],</span><br><span class="line">    <span class="string">&quot;the&quot;</span>: [<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">    <span class="string">&quot;listen&quot;</span>: [<span class="number">3</span>],</span><br><span class="line">    <span class="string">&quot;to&quot;</span>: [<span class="number">3</span>],</span><br><span class="line">    <span class="string">&quot;drum&quot;</span>: [<span class="number">3</span>],</span><br><span class="line">    <span class="string">&quot;machine&quot;</span>: [<span class="number">3</span>],</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Below is a real-world example of the Inverted Index. An index in a book where a term references a page number:</p>
<p><img src="https://raw.githubusercontent.com/cuzz1/img/master/2020/08/book-index.png"></p>
<h2 id="Text-analysis"><a href="#Text-analysis" class="headerlink" title="Text analysis"></a>Text analysis</h2><p>Before we start building the index, we need to break the raw text down into a list of words (tokens) suitable for indexing and searching.</p>
<p>The text analyzer consists of a tokenizer and multiple filters.</p>
<p><img src="https://raw.githubusercontent.com/cuzz1/img/master/2020/08/text-analysis.png"></p>
<h2 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h2><p>The tokenizer is the first step of text analysis. Its job is to convert text into a list of tokens. Our implementation splits the text on a word boundary and removes punctuation marks:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">tokenize</span><span class="params">(text <span class="keyword">string</span>)</span> []<span class="title">string</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> strings.FieldsFunc(text, <span class="function"><span class="keyword">func</span><span class="params">(r <span class="keyword">rune</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">        <span class="comment">// Split on any character that is not a letter or a number.</span></span><br><span class="line">        <span class="keyword">return</span> !unicode.IsLetter(r) &amp;&amp; !unicode.IsNumber(r)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; tokenize(&quot;A donut on a glass plate. Only the donuts.&quot;)</span><br><span class="line"></span><br><span class="line">[&quot;A&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;Only&quot;, &quot;the&quot;, &quot;donuts&quot;]</span><br></pre></td></tr></table></figure>

<h2 id="Filters"><a href="#Filters" class="headerlink" title="Filters"></a>Filters</h2><p>In most cases, just converting text into a list of tokens is not enough. To make the text easier to index and search, we’ll need to do additional normalization.</p>
<h3 id="Lowercase"><a href="#Lowercase" class="headerlink" title="Lowercase"></a>Lowercase</h3><p>In order to make the search case-insensitive, the lowercase filter converts tokens to lower case. <em>cAt</em>, <em>Cat</em> and <em>caT</em> are normalized to <em>cat</em>. Later, when we query the index, we’ll lower case the search terms as well. This will make the search term <em>cAt</em> match the text <em>Cat</em>.</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">lowercaseFilter</span><span class="params">(tokens []<span class="keyword">string</span>)</span> []<span class="title">string</span></span> &#123;</span><br><span class="line">    r := <span class="built_in">make</span>([]<span class="keyword">string</span>, <span class="built_in">len</span>(tokens))</span><br><span class="line">    <span class="keyword">for</span> i, token := <span class="keyword">range</span> tokens &#123;</span><br><span class="line">        r[i] = strings.ToLower(token)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> r</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; lowercaseFilter([]string&#123;&quot;A&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;Only&quot;, &quot;the&quot;, &quot;donuts&quot;&#125;)</span><br><span class="line"></span><br><span class="line">[&quot;a&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;the&quot;, &quot;donuts&quot;]</span><br></pre></td></tr></table></figure>

<h3 id="Dropping-common-words"><a href="#Dropping-common-words" class="headerlink" title="Dropping common words"></a>Dropping common words</h3><p>Almost any English text contains commonly used words like <em>a</em>, <em>I</em>, <em>the</em> or <em>be</em>. Such words are called <em>stop words</em>. We are going to remove them since almost any document would match the stop words.</p>
<p>There is no “official” list of stop words. Let’s exclude the top 10 by the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Most_common_words_in_English">OEC rank</a>. Feel free to add more:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> stopwords = <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">struct</span>&#123;&#125;&#123; <span class="comment">// I wish Go had built-in sets.</span></span><br><span class="line">    <span class="string">&quot;a&quot;</span>: &#123;&#125;, <span class="string">&quot;and&quot;</span>: &#123;&#125;, <span class="string">&quot;be&quot;</span>: &#123;&#125;, <span class="string">&quot;have&quot;</span>: &#123;&#125;, <span class="string">&quot;i&quot;</span>: &#123;&#125;,</span><br><span class="line">    <span class="string">&quot;in&quot;</span>: &#123;&#125;, <span class="string">&quot;of&quot;</span>: &#123;&#125;, <span class="string">&quot;that&quot;</span>: &#123;&#125;, <span class="string">&quot;the&quot;</span>: &#123;&#125;, <span class="string">&quot;to&quot;</span>: &#123;&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stopwordFilter</span><span class="params">(tokens []<span class="keyword">string</span>)</span> []<span class="title">string</span></span> &#123;</span><br><span class="line">    r := <span class="built_in">make</span>([]<span class="keyword">string</span>, <span class="number">0</span>, <span class="built_in">len</span>(tokens))</span><br><span class="line">    <span class="keyword">for</span> _, token := <span class="keyword">range</span> tokens &#123;</span><br><span class="line">        <span class="keyword">if</span> _, ok := stopwords[token]; !ok &#123;</span><br><span class="line">            r = <span class="built_in">append</span>(r, token)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> r</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; stopwordFilter([]string&#123;&quot;a&quot;, &quot;donut&quot;, &quot;on&quot;, &quot;a&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;the&quot;, &quot;donuts&quot;&#125;)</span><br><span class="line"></span><br><span class="line">[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donuts&quot;]</span><br></pre></td></tr></table></figure>

<h3 id="Stemming"><a href="#Stemming" class="headerlink" title="Stemming"></a>Stemming</h3><p>Because of the grammar rules, documents may include different forms of the same word. Stemming reduces words into their base form. For example, <em>fishing</em>, <em>fished</em> and <em>fisher</em> may be reduced to the base form (stem) <em>fish</em>.</p>
<p>Implementing a stemmer is a non-trivial task, it’s not covered in this post. We’ll take one of the <a target="_blank" rel="noopener" href="https://github.com/kljensen/snowball">existing</a> modules:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> snowballeng <span class="string">&quot;github.com/kljensen/snowball/english&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">stemmerFilter</span><span class="params">(tokens []<span class="keyword">string</span>)</span> []<span class="title">string</span></span> &#123;</span><br><span class="line">    r := <span class="built_in">make</span>([]<span class="keyword">string</span>, <span class="built_in">len</span>(tokens))</span><br><span class="line">    <span class="keyword">for</span> i, token := <span class="keyword">range</span> tokens &#123;</span><br><span class="line">        r[i] = snowballeng.Stem(token, <span class="literal">false</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> r</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; stemmerFilter([]string&#123;&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donuts&quot;&#125;)</span><br><span class="line"></span><br><span class="line">[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donut&quot;]</span><br></pre></td></tr></table></figure>

<p>Note</p>
<blockquote>
<p>A stem is not always a valid word. For example, some stemmers may reduce <em>airline</em> to <em>airlin</em>.</p>
</blockquote>
<h2 id="Putting-the-analyzer-together"><a href="#Putting-the-analyzer-together" class="headerlink" title="Putting the analyzer together"></a>Putting the analyzer together</h2><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">analyze</span><span class="params">(text <span class="keyword">string</span>)</span> []<span class="title">string</span></span> &#123;</span><br><span class="line">    tokens := tokenize(text)</span><br><span class="line">    tokens = lowercaseFilter(tokens)</span><br><span class="line">    tokens = stopwordFilter(tokens)</span><br><span class="line">    tokens = stemmerFilter(tokens)</span><br><span class="line">    <span class="keyword">return</span> tokens</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>The tokenizer and filters convert sentences into a list of tokens:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; analyze(&quot;A donut on a glass plate. Only the donuts.&quot;)</span><br><span class="line"></span><br><span class="line">[&quot;donut&quot;, &quot;on&quot;, &quot;glass&quot;, &quot;plate&quot;, &quot;only&quot;, &quot;donut&quot;]</span><br></pre></td></tr></table></figure>

<p>The tokens are ready for indexing.</p>
<h2 id="Building-the-index"><a href="#Building-the-index" class="headerlink" title="Building the index"></a>Building the index</h2><p>Back to the inverted index. It maps every word in documents to document IDs. The built-in map is a good candidate for storing the mapping. The key in the map is a token (string) and the value is a list of document IDs:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> index <span class="keyword">map</span>[<span class="keyword">string</span>][]<span class="keyword">int</span></span><br></pre></td></tr></table></figure>

<p>Building the index consists of analyzing the documents and adding their IDs to the map:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(idx index)</span> <span class="title">add</span><span class="params">(docs []document)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> _, doc := <span class="keyword">range</span> docs &#123;</span><br><span class="line">        <span class="keyword">for</span> _, token := <span class="keyword">range</span> analyze(doc.Text) &#123;</span><br><span class="line">            ids := idx[token]</span><br><span class="line">            <span class="keyword">if</span> ids != <span class="literal">nil</span> &amp;&amp; ids[<span class="built_in">len</span>(ids)<span class="number">-1</span>] == doc.ID &#123;</span><br><span class="line">                <span class="comment">// Don&#x27;t add same ID twice.</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            &#125;</span><br><span class="line">            idx[token] = <span class="built_in">append</span>(ids, doc.ID)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    idx := <span class="built_in">make</span>(index)</span><br><span class="line">    idx.add([]document&#123;&#123;ID: <span class="number">1</span>, Text: <span class="string">&quot;A donut on a glass plate. Only the donuts.&quot;</span>&#125;&#125;)</span><br><span class="line">    idx.add([]document&#123;&#123;ID: <span class="number">2</span>, Text: <span class="string">&quot;donut is a donut&quot;</span>&#125;&#125;)</span><br><span class="line">    fmt.Println(idx)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>It works! Each token in the map refers to IDs of the documents that contain the token:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">map[donut:[1 2] glass:[1] is:[2] on:[1] only:[1] plate:[1]]</span><br></pre></td></tr></table></figure>

<h2 id="Querying"><a href="#Querying" class="headerlink" title="Querying"></a>Querying</h2><p>To query the index, we are going to apply the same tokenizer and filters we used for indexing:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(idx index)</span> <span class="title">search</span><span class="params">(text <span class="keyword">string</span>)</span> [][]<span class="title">int</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> r [][]<span class="keyword">int</span></span><br><span class="line">    <span class="keyword">for</span> _, token := <span class="keyword">range</span> analyze(text) &#123;</span><br><span class="line">        <span class="keyword">if</span> ids, ok := idx[token]; ok &#123;</span><br><span class="line">            r = <span class="built_in">append</span>(r, ids)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> r</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; idx.search(&quot;Small wild cat&quot;)</span><br><span class="line"></span><br><span class="line">[[24, 173, 303, ...], [98, 173, 765, ...], [[24, 51, 173, ...]]</span><br></pre></td></tr></table></figure>

<p>And finally, we can find all documents that mention cats. Searching 600K documents took less than a millisecond (18µs)!</p>
<p>With the inverted index, the time complexity of the search query is linear to the number of search tokens. In the example query above, other than analyzing the input text, search had to perform only three map lookups.</p>
<h2 id="Boolean-queries"><a href="#Boolean-queries" class="headerlink" title="Boolean queries"></a>Boolean queries</h2><p>The query from the previous section returned a disjoined list of documents for each token. What we normally expect to find when we type <em>small wild cat</em> in a search box is a list of results that contain <em>small</em>, <em>wild</em> and <em>cat</em> at the same time. The next step is to compute the set intersection between the lists. This way we’ll get a list of documents matching all tokens.</p>
<p><img src="https://raw.githubusercontent.com/cuzz1/img/master/2020/08/venn.png" alt="xx"></p>
<p>Luckily, IDs in our inverted index are inserted in ascending order. Since the IDs are sorted, it’s possible to compute the intersection between two lists in linear time. The intersection function iterates two lists simultaneously and collect IDs that exist in both:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">intersection</span><span class="params">(a []<span class="keyword">int</span>, b []<span class="keyword">int</span>)</span> []<span class="title">int</span></span> &#123;</span><br><span class="line">    maxLen := <span class="built_in">len</span>(a)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(b) &gt; maxLen &#123;</span><br><span class="line">        maxLen = <span class="built_in">len</span>(b)</span><br><span class="line">    &#125;</span><br><span class="line">    r := <span class="built_in">make</span>([]<span class="keyword">int</span>, <span class="number">0</span>, maxLen)</span><br><span class="line">    <span class="keyword">var</span> i, j <span class="keyword">int</span></span><br><span class="line">    <span class="keyword">for</span> i &lt; <span class="built_in">len</span>(a) &amp;&amp; j &lt; <span class="built_in">len</span>(b) &#123;</span><br><span class="line">        <span class="keyword">if</span> a[i] &lt; b[j] &#123;</span><br><span class="line">            i++</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> a[i] &gt; b[j] &#123;</span><br><span class="line">            j++</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            r = <span class="built_in">append</span>(r, a[i])</span><br><span class="line">            i++</span><br><span class="line">            j++</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> r</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Updated search analyzes the given query text, lookups tokens and computes the set intersection between lists of IDs:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(idx index)</span> <span class="title">search</span><span class="params">(text <span class="keyword">string</span>)</span> []<span class="title">int</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> r []<span class="keyword">int</span></span><br><span class="line">    <span class="keyword">for</span> _, token := <span class="keyword">range</span> analyze(text) &#123;</span><br><span class="line">        <span class="keyword">if</span> ids, ok := idx[token]; ok &#123;</span><br><span class="line">            <span class="keyword">if</span> r == <span class="literal">nil</span> &#123;</span><br><span class="line">                r = ids</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                r = intersection(r, ids)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// Token doesn&#x27;t exist.</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> r</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>The Wikipedia dump contains only two documents that match <em>small</em>, <em>wild</em> and <em>cat</em> at the same time:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; idx.search(&quot;Small wild cat&quot;)</span><br><span class="line"></span><br><span class="line">130764  The wildcat is a species complex comprising two small wild cat species, the European wildcat (Felis silvestris) and the African wildcat (F. lybica).</span><br><span class="line">131692  Catopuma is a genus containing two Asian small wild cat species, the Asian golden cat (C. temminckii) and the bay cat.</span><br></pre></td></tr></table></figure>

<p>The search is working as expected!</p>
<p>By the way, this is the first time I hear about <em>catopuma</em>, here is one of them:</p>
<p><img src="https://raw.githubusercontent.com/cuzz1/img/master/2020/08/asian-golden-cat-s.jpg" alt="cat"></p>
<h2 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h2><p>We just built a Full-Text Search engine. Despite its simplicity, it can be a solid foundation for more advanced projects.</p>
<p>I didn’t touch on a lot of things that can significantly improve the performance and make the engine more user friendly. Here are some ideas for further improvements:</p>
<ul>
<li>Extend boolean queries to support <em>OR</em> and <em>NOT</em>.</li>
<li>Store the index on disk:<ul>
<li>Rebuilding the index on every application restart may take a while.</li>
<li>Large indexes may not fit in memory.</li>
</ul>
</li>
<li>Experiment with memory and CPU-efficient data formats for storing sets of document IDs. Take a look at <a target="_blank" rel="noopener" href="https://roaringbitmap.org/">Roaring Bitmaps</a>.</li>
<li>Support indexing multiple document fields.</li>
<li>Sort results by relevance.</li>
</ul>
<p>The full source code is available on <a target="_blank" rel="noopener" href="https://github.com/akrylysov/simplefts">GitHub</a>.</p>
<p>I’m not a native English speaker and I’m trying to improve my language skills. Feel free to correct me if you spot any spelling or grammatical error!</p>
</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E8%BD%AC%E8%BD%BD/">转载</a><a class="link-muted mr-2" rel="tag" href="/tags/Full-Text-Search/">Full-Text Search</a><a class="link-muted mr-2" rel="tag" href="/tags/%E8%8B%B1%E6%96%87/">英文</a></div><div class="notification is-danger">You need to set <code>install_url</code> to use ShareThis. Please set it in <code>_config.yml</code>.</div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/" alt="Alipay"></span></a><a class="button donate" href="/" style="background-color:rgba(255,128,62,.87);border-color:transparent;color:white;" target="_blank" rel="noopener"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a><a class="button is-danger donate" href="/" target="_blank" rel="noopener"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><div class="notification is-danger">You forgot to set the <code>business</code> or <code>currency_code</code> for Paypal. Please set it in <code>_config.yml</code>.</div><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/10/11/Go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"><span class="level-item">Go语言入门笔记</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="notification is-danger">You forgot to set the <code>shortname</code> for Disqus. Please set it in <code>_config.yml</code>.</div></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1 is-sticky"><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="is-flex" href="#Why-FTS"><span class="mr-2">1</span><span>Why FTS</span></a></li><li><a class="is-flex" href="#Corpus"><span class="mr-2">2</span><span>Corpus</span></a></li><li><a class="is-flex" href="#Loading-documents"><span class="mr-2">3</span><span>Loading documents</span></a></li><li><a class="is-flex" href="#First-attempt"><span class="mr-2">4</span><span>First attempt</span></a><ul class="menu-list"><li><a class="is-flex" href="#Searching-the-content"><span class="mr-2">4.1</span><span>Searching the content</span></a></li><li><a class="is-flex" href="#Searching-with-regular-expressions"><span class="mr-2">4.2</span><span>Searching with regular expressions</span></a></li></ul></li><li><a class="is-flex" href="#Inverted-Index"><span class="mr-2">5</span><span>Inverted Index</span></a></li><li><a class="is-flex" href="#Text-analysis"><span class="mr-2">6</span><span>Text analysis</span></a></li><li><a class="is-flex" href="#Tokenizer"><span class="mr-2">7</span><span>Tokenizer</span></a></li><li><a class="is-flex" href="#Filters"><span class="mr-2">8</span><span>Filters</span></a><ul class="menu-list"><li><a class="is-flex" href="#Lowercase"><span class="mr-2">8.1</span><span>Lowercase</span></a></li><li><a class="is-flex" href="#Dropping-common-words"><span class="mr-2">8.2</span><span>Dropping common words</span></a></li><li><a class="is-flex" href="#Stemming"><span class="mr-2">8.3</span><span>Stemming</span></a></li></ul></li><li><a class="is-flex" href="#Putting-the-analyzer-together"><span class="mr-2">9</span><span>Putting the analyzer together</span></a></li><li><a class="is-flex" href="#Building-the-index"><span class="mr-2">10</span><span>Building the index</span></a></li><li><a class="is-flex" href="#Querying"><span class="mr-2">11</span><span>Querying</span></a></li><li><a class="is-flex" href="#Boolean-queries"><span class="mr-2">12</span><span>Boolean queries</span></a></li><li><a class="is-flex" href="#Conclusions"><span class="mr-2">13</span><span>Conclusions</span></a></li></ul></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Hexo" height="28"></a><p class="size-small"><span>&copy; 2020 John Doe</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://blog.cuzz.site',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: false,
                    fold: ''
                }
            }
        };</script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>